@inproceedings{10.1109/ASE.2019.00064,
  abstract = {The decompiler is one of the most common tools for examining binaries without corresponding source code. It transforms binaries into high-level code, reversing the compilation process. Decompilers can reconstruct much of the information that is lost during the compilation process (e.g., structure and type information). Unfortunately, they do not reconstruct semantically meaningful variable names, which are known to increase code understandability. We propose the Decompiled Identifier Renaming Engine (DIRE), a novel probabilistic technique for variable name recovery that uses both lexical and structural information recovered by the decompiler. We also present a technique for generating corpora suitable for training and evaluating models of decompiled code renaming, which we use to create a corpus of 164,632 unique x86-64 binaries generated from C projects mined from GitHub.1 Our results show that on this corpus DIRE can predict variable names identical to the names in the original source code up to 74.3% of the time.},
  author = {Lacomis, Jeremy and Yin, Pengcheng and Schwartz, Edward J. and Allamanis, Miltiadis and Le Goues, Claire and Neubig, Graham and Vasilescu, Bogdan},
  booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
  doi = {10.1109/ASE.2019.00064},
  isbn = {9781728125084},
  location = {San Diego, California},
  numpages = {12},
  pages = {628–639},
  publisher = {IEEE Press},
  series = {ASE '19},
  title = {DIRE: a neural approach to decompiled identifier naming},
  url = {https://doi.org/10.1109/ASE.2019.00064},
  year = {2020}
}

@inproceedings{10.1109/ASE56229.2023.00099,
  abstract = {Decompilation is a widely used process for reverse engineers to significantly enhance code readability by lifting assembly code to a higher-level C-like language, pseudo-code. Nevertheless, the process of compilation and stripping irreversibly discards high-level semantic information that is crucial to code comprehension, such as comments, identifier names, and types. Existing approaches typically recover only one type of information, making them suboptimal for semantic inference. In this paper, we treat pseudo-code as a special programming language, then present a unified pre-trained model, HexT5, that is trained on vast amounts of natural language comments, source identifiers, and pseudo-code using novel pseudo-code-based pretraining objectives. We fine-tune HexT5 on various downstream tasks, including code summarization, variable name recovery, function name recovery, and similarity detection. Comprehensive experiments show that HexT5 achieves state-of-the-art performance on four downstream tasks, and it demonstrates the robust effectiveness and generalizability of HexT5 for binary-related tasks.},
  author = {Xiong, Jiaqi and Chen, Guoqiang and Chen, Kejiang and Gao, Han and Cheng, Shaoyin and Zhang, Weiming},
  booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
  doi = {10.1109/ASE56229.2023.00099},
  isbn = {9798350329964},
  keywords = {reverse engineering, deep learning, binary diffing, information inference, programming language model},
  location = {Echternach, Luxembourg},
  numpages = {13},
  pages = {774–786},
  publisher = {IEEE Press},
  series = {ASE '23},
  title = {HexT5: Unified Pre-Training for Stripped Binary Code Information Inference},
  url = {https://doi.org/10.1109/ASE56229.2023.00099},
  year = {2024}
}

@inproceedings{10.1109/CGO57630.2024.10444788,
  abstract = {Decompilation is a well-studied area with numerous high-quality tools available. These are frequently used for security tasks and to port legacy code. However, they regularly generate difficult-to-read programs and require a large amount of engineering effort to support new programming languages and ISAs. Recent interest in neural approaches has produced portable tools that generate readable code. Nevertheless, to-date such techniques are usually restricted to synthetic programs without optimization, and no models have evaluated their portability. Furthermore, while the code generated may be more readable, it is usually incorrect.This paper presents SLaDe, a Small Language model Decompiler based on a sequence-to-sequence Transformer trained over real-world code and augmented with a type inference engine. We utilize a novel tokenizer, dropout-free regularization, and type inference to generate programs that are more readable and accurate than standard analytic and recent neural approaches. Unlike standard approaches, SLaDe can infer out-of-context types and unlike neural approaches, it generates correct code.We evaluate SLaDe on over 4,000 ExeBench functions on two ISAs and at two optimization levels. SLaDe is up to 6\texttimes{} more accurate than Ghidra, a state-of-the-art, industrial-strength decompiler and up to 4\texttimes{} more accurate than the large language model ChatGPT and generates significantly more readable code than both.},
  author = {Armengol-Estap\'{e}, Jordi and Woodruff, Jackson and Cummins, Chris and O'Boyle, Michael F. P.},
  booktitle = {Proceedings of the 2024 IEEE/ACM International Symposium on Code Generation and Optimization},
  doi = {10.1109/CGO57630.2024.10444788},
  isbn = {9798350395099},
  keywords = {decompilation, neural decompilation, transformer, language models, type inference},
  location = {Edinburgh, United Kingdom},
  numpages = {14},
  pages = {67–80},
  publisher = {IEEE Press},
  series = {CGO '24},
  title = {SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly},
  url = {https://doi.org/10.1109/CGO57630.2024.10444788},
  year = {2024}
}

@inproceedings{10.1145/3106237.3121274,
  abstract = {Decompiled code lacks meaningful variable names. We used statistical machine translation to suggest variable names that are natural given the context. This technique has previously been successfully applied to obfuscated JavaScript code, but decompiled C code poses unique challenges in constructing an aligned corpus and selecting the best translation from among several candidates.},
  address = {New York, NY, USA},
  author = {Jaffe, Alan},
  booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
  doi = {10.1145/3106237.3121274},
  isbn = {9781450351058},
  keywords = {Statistical machine translation, Reverse engineering, Decompilation},
  location = {Paderborn, Germany},
  numpages = {3},
  pages = {1050–1052},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2017},
  title = {Suggesting meaningful variable names for decompiled code: a machine translation approach},
  url = {https://doi.org/10.1145/3106237.3121274},
  year = {2017}
}

@inproceedings{10.1145/3196321.3196330,
  abstract = {When code is compiled, information is lost, including some of the structure of the original source code as well as local identifier names. Existing decompilers can reconstruct much of the original source code, but typically use meaningless placeholder variables for identifier names. Using variable names which are more natural in the given context can make the code much easier to interpret, despite the fact that variable names have no effect on the execution of the program. In theory, it is impossible to recover the original identifier names since that information has been lost. However, most code is natural: it is highly repetitive and predictable based on the context. In this paper we propose a technique that assigns variables meaningful names by taking advantage of this naturalness property. We consider decompiler output to be a noisy distortion of the original source code, where the original source code is transformed into the decompiler output. Using this noisy channel model, we apply standard statistical machine translation approaches to choose natural identifiers, combining a translation model trained on a parallel corpus with a language model trained on unmodified C code. We generate a large parallel corpus from 1.2 TB of C source code obtained from GitHub. Under the most conservative assumptions, our technique is still able to recover the original variable names up to 16.2% of the time, which represents a lower bound for performance.},
  address = {New York, NY, USA},
  author = {Jaffe, Alan and Lacomis, Jeremy and Schwartz, Edward J. and Le Goues, Claire and Vasilescu, Bogdan},
  booktitle = {Proceedings of the 26th Conference on Program Comprehension},
  doi = {10.1145/3196321.3196330},
  isbn = {9781450357142},
  location = {Gothenburg, Sweden},
  numpages = {11},
  pages = {20–30},
  publisher = {Association for Computing Machinery},
  series = {ICPC '18},
  title = {Meaningful variable names for decompiled code: a machine translation approach},
  url = {https://doi.org/10.1145/3196321.3196330},
  year = {2018}
}

@inproceedings{10.1145/3468264.3468607,
  abstract = {Binary type inference is a critical reverse engineering task supporting many security applications, including vulnerability analysis, binary hardening, forensics, and decompilation. It is a difficult task because source-level type information is often stripped during compilation, leaving only binaries with untyped memory and register accesses. Existing approaches rely on hand-coded type inference rules defined by domain experts, which are brittle and require nontrivial effort to maintain and update. Even though machine learning approaches have shown promise at automatically learning the inference rules, their accuracy is still low, especially for optimized binaries.  We present StateFormer, a new neural architecture that is adept at accurate and robust type inference. StateFormer follows a two-step transfer learning paradigm. In the pretraining step, the model is trained with Generative State Modeling (GSM), a novel task that we design to teach the model to statically approximate execution effects of assembly instructions in both forward and backward directions. In the finetuning step, the pretrained model learns to use its knowledge of operational semantics to infer types.  We evaluate StateFormer's performance on a corpus of 33 popular open-source software projects containing over 1.67 billion variables of different types. The programs are compiled with GCC and LLVM over 4 optimization levels O0-O3, and 3 obfuscation passes based on LLVM. Our model significantly outperforms state-of-the-art ML-based tools by 14.6% in recovering types for both function arguments and variables. Our ablation studies show that GSM improves type inference accuracy by 33%.},
  address = {New York, NY, USA},
  author = {Pei, Kexin and Guan, Jonas and Broughton, Matthew and Chen, Zhongtian and Yao, Songchen and Williams-King, David and Ummadisetty, Vikas and Yang, Junfeng and Ray, Baishakhi and Jana, Suman},
  booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  doi = {10.1145/3468264.3468607},
  isbn = {9781450385626},
  keywords = {Type Inference, Transfer Learning, Reverse Engineering, Machine Learning for Program Analysis},
  location = {Athens, Greece},
  numpages = {13},
  pages = {690–702},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2021},
  title = {StateFormer: fine-grained type recovery from binaries using generative state modeling},
  url = {https://doi.org/10.1145/3468264.3468607},
  year = {2021}
}

@inproceedings{10.1145/3519939.3523449,
  abstract = {The increasing popularity of WebAssembly creates a demand for understanding and reverse engineering WebAssembly binaries. Recovering high-level function types is an important part of this process. One method to recover types is data-flow analysis, but it is complex to implement and may require manual heuristics when logical constraints fall short. In contrast, this paper presents SnowWhite, a learning-based approach for recovering precise, high-level parameter and return types for WebAssembly functions. It improves over prior work on learning-based type recovery by representing the types-to-predict in an expressive type language, which can describe a large number of complex types, instead of the fixed, and usually small type vocabulary used previously. Thus, recovery of a single type is no longer a classification task but sequence prediction, for which we build on the success of neural sequence-to-sequence models. We evaluate SnowWhite on a new, large-scale dataset of 6.3 million type samples extracted from 300,905 WebAssembly object files. The results show the type language is expressive, precisely describing 1,225 types instead the 7 to 35 types considered in previous learning-based approaches. Despite this expressiveness, our type recovery has high accuracy, exactly matching 44.5% (75.2%) of all parameter types and 57.7% (80.5%) of all return types within the top-1 (top-5) predictions.},
  address = {New York, NY, USA},
  author = {Lehmann, Daniel and Pradel, Michael},
  booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3519939.3523449},
  isbn = {9781450392655},
  keywords = {type recovery, type prediction, reverse engineering, neural networks, machine learning, debugging information, dataset, corpus, WebAssembly, DWARF},
  location = {San Diego, CA, USA},
  numpages = {16},
  pages = {410–425},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2022},
  title = {Finding the Dwarf: Recovering Precise Types from WebAssembly Binaries},
  url = {https://doi.org/10.1145/3519939.3523449},
  year = {2022}
}

@inproceedings{10.1145/3611643.3616343,
  abstract = {Smart contracts play an increasingly important role in Ethereum platform. It provides various functions implementing numerous services, whose bytecode runs on Ethereum Virtual Machine. To use services by invoking corresponding functions, the callers need to know the function signatures. Moreover, such signatures provide crucial information for many downstream applications, e.g., identifying smart contracts, fuzzing, detecting vulnerabilities, etc. However, it is challenging to infer function signatures from the bytecode due to a lack of type information. Existing work solving this problem depended heavily on limited databases or hard-coded heuristic patterns. However, these approaches are hard to be adapted to semantic differences in distinct languages and various compiler versions when developing smart contracts. In this paper, we propose a novel framework DeepInfer that first leverages deep learning techniques to automatically infer function signatures and returns. The novelties of DeepInfer are: 1) DeepInfer lifts the bytecode into the Intermediate Representation (IR) to preserve code semantics; 2) DeepInfer extracts the type-related knowledge (e.g., critical data flows, constant values, and control flow graphs) from the IR to recover function signatures and returns. We conduct experiments on Solidity and Vyper smart contracts and the results show that DeepInfer performs faster and more accurate than existing tools, while being immune to changes in different languages and various compiler versions.},
  address = {New York, NY, USA},
  author = {Zhao, Kunsong and Li, Zihao and Li, Jianfeng and Ye, He and Luo, Xiapu and Chen, Ting},
  booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  doi = {10.1145/3611643.3616343},
  isbn = {9798400703270},
  keywords = {Deep Learning, Smart Contract, Type Inference},
  location = {San Francisco, CA, USA},
  numpages = {13},
  pages = {745–757},
  publisher = {Association for Computing Machinery},
  series = {ESEC/FSE 2023},
  title = {DeepInfer: Deep Type Inference from Smart Contract Bytecode},
  url = {https://doi.org/10.1145/3611643.3616343},
  year = {2023}
}

@inproceedings{10.1145/3650215.3650347,
  abstract = {Binary function naming is a code analysis task that generates functional descriptions of functions, and its results can be applied in the fields of malicious code analysis, vulnerability causation analysis, and algorithm governance. Aiming at the shortcomings of the pseudocode abstract syntax tree being difficult to extract and the binary function naming scheme having low accuracy rate, a binary function naming prediction model A2N based on variable alignment and sequence translation model is proposed. First, A2N extracts the function variable features of binary files from debugging information and performs variable alignment with the pseudocode obtained from decompiling; then, it obtains the hierarchical structure of the binary functions and designs the node extraction rules to generate an abstract syntax tree AST for each function; then, extract the paths between the leaf nodes of the AST and serialize the tree structure to represent it; finally, with the help of the neural network translation model, establish a mapping between the AST and the binary function names to realize the prediction function. The experimental results show that compared with Dire, Nero and XFL models, the F1 value of A2N is improved by 84%, 44% and 14% on file-level isolation experiments respectively, and the F1 value reaches 80.94% on function-level isolation experiments.},
  address = {New York, NY, USA},
  author = {Xia, Bing and Yin, Jiabin and Ge, Yunxiang and Yang, Ruinan},
  booktitle = {Proceedings of the 2023 4th International Conference on Machine Learning and Computer Application},
  doi = {10.1145/3650215.3650347},
  isbn = {9798400709449},
  location = {Hangzhou, China},
  numpages = {5},
  pages = {757–761},
  publisher = {Association for Computing Machinery},
  series = {ICMLCA '23},
  title = {A Binary Function Name Prediction Method Based on Variable Alignment and Translation Model},
  url = {https://doi.org/10.1145/3650215.3650347},
  year = {2024}
}

@inproceedings{10.1145/3658644.3670340,
  abstract = {Decompilation aims to recover a binary executable to the source code form and hence has a wide range of applications in cyber security, such as malware analysis and legacy code hardening. A prominent challenge is to recover variable symbols, including both primitive and complex types such as user-defined data structures, along with their symbol information such as names and types. Existing efforts focus on solving parts of the problem, e.g., recovering only types (without names) or only local variables (without user-defined structures). In this paper, we propose ReSym, a novel hybrid technique that combines Large Language Models (LLMs) and program analysis to recover both names and types for local variables and user-defined data structures. Our method encompasses fine-tuning two LLMs to handle local variables and structures, respectively. To overcome the token limitations inherent in current LLMs, we devise a novel Prolog-based algorithm to aggregate and cross-check results from multiple LLM queries, suppressing uncertainty and hallucinations. Our experiments show that ReSym is effective in recovering variable information and user-defined data structures, substantially outperforming the state-of-the-art methods.},
  address = {New York, NY, USA},
  author = {Xie, Danning and Zhang, Zhuo and Jiang, Nan and Xu, Xiangzhe and Tan, Lin and Zhang, Xiangyu},
  booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  doi = {10.1145/3658644.3670340},
  isbn = {9798400706363},
  keywords = {large language models, program analysis, reverse engineering},
  location = {Salt Lake City, UT, USA},
  numpages = {15},
  pages = {4554–4568},
  publisher = {Association for Computing Machinery},
  series = {CCS '24},
  title = {ReSym: Harnessing LLMs to Recover Variable and Data Structure Symbols from Stripped Binaries},
  url = {https://doi.org/10.1145/3658644.3670340},
  year = {2024}
}

@inproceedings{10.1145/3691620.3695020,
  abstract = {WebAssembly (abbreviated Wasm) has emerged as a cornerstone of web development, offering a compact binary format that allows high-performance applications to run at near-native speeds in web browsers. Despite its advantages, Wasm's binary nature presents significant challenges for developers and researchers, particularly regarding readability when debugging or analyzing web applications. Therefore, effective decompilation becomes crucial. Unfortunately, traditional decompilers often struggle with producing readable outputs. While some large language model (LLM)-based decompilers have shown good compatibility with general binary files, they still face specific challenges when dealing with Wasm.In this paper, we introduce a novel approach, WaDec, which is the first use of a fine-tuned LLM to interpret and decompile Wasm binary code into a higher-level, more comprehensible source code representation. The LLM was meticulously fine-tuned using a specialized dataset of wat-c code snippets, employing self-supervised learning techniques. This enables WaDec to effectively decompile not only complete wat functions but also finer-grained wat code snippets. Our experiments demonstrate that WaDec markedly outperforms current state-of-the-art tools, offering substantial improvements across several metrics. It achieves a code inflation rate of only 3.34%, a dramatic 97% reduction compared to the state-of-the-art's 116.94%. Unlike the output of baselines that cannot be directly compiled or executed, WaDec maintains a recompilability rate of 52.11%, a re-execution rate of 43.55%, and an output consistency of 27.15%. Additionally, it significantly exceeds state-of-the-art performance in AST edit distance similarity by 185%, cyclomatic complexity by 8%, and cosine similarity by 41%, achieving an average code similarity above 50%. In summary, WaDec enhances understanding of the code's structure and execution flow, facilitating automated code analysis, optimization, and security auditing.},
  address = {New York, NY, USA},
  author = {She, Xinyu and Zhao, Yanjie and Wang, Haoyu},
  booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
  doi = {10.1145/3691620.3695020},
  isbn = {9798400712487},
  location = {Sacramento, CA, USA},
  numpages = {12},
  pages = {481–492},
  publisher = {Association for Computing Machinery},
  series = {ASE '24},
  title = {WaDec: Decompiling WebAssembly Using Large Language Model},
  url = {https://doi.org/10.1145/3691620.3695020},
  year = {2024}
}

@inproceedings{10.1145/3691620.3695502,
  abstract = {Type recovery in stripped binaries is a critical and challenging task in reverse engineering, as it is the basis for many security applications (e.g., vulnerability detection). Traditional analysis methods are limited by software complexity and emerging types in real-world projects. To address these limitations, machine learning methods have been explored. However, the existing supervised learning approaches struggle with analyzing complicated and uncommon types due to the limited availability of samples. Additionally, none of the existing works can capture fine-grained and inter-procedural features in the binaries. In this paper, we present TypeFSL, a framework that addresses the challenge of imbalanced type distributions by incorporating few-shot learning and captures inter-procedural semantics through program slicing. Moreover, based on a dataset with 3,003,117 functions, TypeFSL achieves an average of 77.9% and 84.6% accuracy across all architecture and optimizations in 20-way 5-shot and 10-shot classification tasks. Our prototype outperforms existing techniques in prediction accuracy and obfuscation resistance. Finally, the case studies demonstrate how TypeFSL predicts uncommon and complicated types in practical analysis.},
  address = {New York, NY, USA},
  author = {Song, Zirui and Zhou, YuTong and Dong, Shuaike and Zhang, Ke and Zhang, Kehuan},
  booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
  doi = {10.1145/3691620.3695502},
  isbn = {9798400712487},
  keywords = {reverse engineering, type recovery, few-shot learning},
  location = {Sacramento, CA, USA},
  numpages = {13},
  pages = {1269–1281},
  publisher = {Association for Computing Machinery},
  series = {ASE '24},
  title = {TypeFSL: Type Prediction from Binaries via Inter-procedural Data-flow Analysis and Few-shot Learning},
  url = {https://doi.org/10.1145/3691620.3695502},
  year = {2024}
}

@inproceedings{10.1145/3696410.3714790,
  abstract = {The vision of Web3 is to improve user control over data and assets, but one challenge that complicates this vision is the prevalence of non-transparent, scam-prone applications and vulnerable smart contracts that put Web3 users at risk. While code audits are one solution to this problem, the lack of smart contracts source code on many blockchain platforms, such as Sui, hinders the ease of auditing. A promising approach to this issue is the use of a decompiler to reverse-engineer smart contract bytecode. However, existing decompilers for Sui produce code that is difficult to understand and cannot be directly recompiled. To address this, we developed the SuiGPT Move AI Decompiler (MAD), a Large Language Model (LLM)-powered web application that decompiles smart contract bytecodes on Sui into logically correct, human-readable, and re-compilable source code with prompt engineering. Our evaluation shows that MAD's output successfully passes original unit tests and achieves a 73.33% recompilation success rate on real-world smart contracts. Additionally, newer models tend to deliver improved performance, suggesting that MAD's approach will become increasingly effective as LLMs continue to advance. In a user study involving 12 developers, we found that MAD significantly reduced the auditing workload compared to using traditional decompilers. Participants found MAD's outputs comparable to the original source code, improving accessibility for understanding and auditing non-open-source smart contracts. Through qualitative interviews with these developers and Web3 projects, we further discussed the strengths and concerns of MAD. MAD has practical implications for blockchain smart contract transparency, auditing, and education. It empowers users to easily and independently review and audit non-open-source smart contracts, fostering accountability and decentralization. Moreover, MAD's methodology could potentially extend to other smart contract languages, like Solidity, further enhancing Web3 transparency.},
  address = {New York, NY, USA},
  author = {Chen, Eason and Tang, Xinyi and Xiao, Zimo and Li, Chuangji and Li, Shizhuo and Wu, Tingguan and Wang, Siyun and Chalkias, Kostas Kryptos},
  booktitle = {Proceedings of the ACM on Web Conference 2025},
  doi = {10.1145/3696410.3714790},
  isbn = {9798400712746},
  keywords = {auditing tools, large language models, move, prompt engineering, smart contract, sui, transparency, web applications, web3},
  location = {Sydney NSW, Australia},
  numpages = {10},
  pages = {1567–1576},
  publisher = {Association for Computing Machinery},
  series = {WWW '25},
  title = {SuiGPT MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract},
  url = {https://doi.org/10.1145/3696410.3714790},
  year = {2025}
}

@inproceedings{10.1145/3722041.3723097,
  abstract = {Vulnerability prediction is valuable in identifying security issues efficiently, even though it requires the source code of the target software system, which is a restrictive hypothesis. This paper presents an experimental study to predict vulnerabilities in binary code without source code or complex representations of the binary, leveraging the pivotal idea of decompiling the binary file through neural decompilation and predicting vulnerabilities through deep learning on the decompiled source code. The results outperform the state-of-the-art in both neural decompilation and vulnerability prediction, showing that it is possible to identify vulnerable programs with this approach concerning bi-class (vulnerable/non-vulnerable) and multi-class (type of vulnerability) analysis.},
  address = {New York, NY, USA},
  author = {Cotroneo, Domenico and Grasso, Francesco C. and Natella, Roberto and Orbinato, Vittorio},
  booktitle = {Proceedings of the 18th European Workshop on Systems Security},
  doi = {10.1145/3722041.3723097},
  isbn = {9798400715631},
  keywords = {Binary Analysis, Deep Learning, Neural Decompilation, Security, Vulnerability Prediction},
  location = {Rotterdam, Netherlands},
  numpages = {7},
  pages = {26–32},
  publisher = {Association for Computing Machinery},
  series = {EuroSec'25},
  title = {Can Neural Decompilation Assist Vulnerability Prediction on Binary Code?},
  url = {https://doi.org/10.1145/3722041.3723097},
  year = {2025}
}

@article{10.1145/3728958,
  abstract = {Decompilers are widely used in reverse engineering (RE) to convert compiled executables into human-readable pseudocode and support various security analysis tasks. Existing decompilers, such as IDA Pro and Ghidra, focus on enhancing the readability of decompiled code rather than its recompilability, which limits further programmatic use, such as for CodeQL-based vulnerability analysis that requires compilable versions of the decompiled code. Recent LLM-based approaches for enhancing decompilation results, while useful for human RE analysts, unfortunately also follow the same path.    In this paper, we explore, for the first time, how off-the-shelf large language models (LLMs) can be used to enable recompilable decompilation—automatically correcting decompiler outputs into compilable versions. We first show that this is non-trivial through a pilot study examining existing rule-based and LLM-based approaches. Based on the lessons learned, we design DecLLM, an iterative LLM-based repair loop that utilizes both static recompilation and dynamic runtime feedback as oracles to iteratively fix decompiler outputs. We test DecLLM on popular C benchmarks and real-world binaries using two mainstream LLMs, GPT-3.5 and GPT-4, and show that off-the-shelf LLMs can achieve an upper bound of around 70% recompilation success rate, i.e., 70 out of 100 originally non-recompilable decompiler outputs are now recompilable. We also demonstrate the practical applicability of the recompilable code for CodeQL-based vulnerability analysis, which is impossible to perform directly on binaries. For the remaining 30% of hard cases, we further delve into their errors to gain insights for future improvements in decompilation-oriented LLM design.},
  address = {New York, NY, USA},
  articleno = {ISSTA081},
  author = {Wong, Wai Kin and Wu, Daoyuan and Wang, Huaijin and Li, Zongjie and Liu, Zhibo and Wang, Shuai and Tang, Qiyi and Nie, Sen and Wu, Shi},
  doi = {10.1145/3728958},
  issue_date = {July 2025},
  journal = {Proc. ACM Softw. Eng.},
  keywords = {Large Language Model, Recompilable Decompilation, Reverse Engineering},
  month = {June},
  number = {ISSTA},
  numpages = {24},
  publisher = {Association for Computing Machinery},
  title = {DecLLM: LLM-Augmented Recompilable Decompilation for Enabling Programmatic Use of Decompiled Code},
  url = {https://doi.org/10.1145/3728958},
  volume = {2},
  year = {2025}
}

@article{10.1145/3729373,
  abstract = {Understanding the Ethereum smart contract bytecode is essential for ensuring cryptoeconomics security. However, existing decompilers primarily convert bytecode into pseudocode, which is not easily comprehensible for general users, potentially leading to misunderstanding of contract behavior and increased vulnerability to scams or exploits. In this paper, we propose DiSCo, the first LLMs-based EVM decompilation pipeline, which aims to enable LLMs to understand the opaque bytecode and lift it into smart contract code. DiSCo introduces three core technologies. First, a logic-invariant intermediate representation is proposed to reproject the low-level bytecode into high-level abstracted units. The second technique involves semantic enhancement based on a novel type-aware graph model to infer stripped variables during compilation, enhancing the lifting effect. The third technology is a flexible method incorporating code specifications to construct LLM-comprehensible prompts for source code generation. Extensive experiments illustrate that our generated code guarantees a high compilability rate at 75%, with differential fuzzing pass rate averaging at 50%. Manual validation results further indicate that the generated solidity contracts significantly outperforms baseline methods in tasks such as code comprehension and attack reproduction.},
  address = {New York, NY, USA},
  articleno = {FSE103},
  author = {Su, Xing and Liang, Hanzhong and Wu, Hao and Niu, Ben and Xu, Fengyuan and Zhong, Sheng},
  doi = {10.1145/3729373},
  issue_date = {July 2025},
  journal = {Proc. ACM Softw. Eng.},
  keywords = {Decompilation, EVM bytecode, Large Language Models, Smart Contract, Source Code Generation},
  month = {June},
  number = {FSE},
  numpages = {24},
  publisher = {Association for Computing Machinery},
  title = {DiSCo: Towards Decompiling EVM Bytecode to Source Code using Large Language Models},
  url = {https://doi.org/10.1145/3729373},
  volume = {2},
  year = {2025}
}

@inproceedings{10.1145/3733822.3764668,
  abstract = {We introduce the ideco framework for improving the decompilation of non-C programming languages. ideco provides users with the ability to create rules which rewrite parts of the decompilation.We show that by using a small set of rules, the number of lines of decompiled code for binaries written in C++, Swift, Go, and Rust can be decreased by 5% to 10%. In addition, by using GPT-4o and GPT-4.1-mini as test subjects, we show that a reverse engineering task is easier to solve when its decompilation is processed by ideco.},
  address = {New York, NY, USA},
  author = {Lerner, Sam},
  booktitle = {Proceedings of the 2025 Workshop on Software Understanding and Reverse Engineering},
  doi = {10.1145/3733822.3764668},
  isbn = {9798400719103},
  keywords = {Decompilation, Software Understanding, Reverse Engineering},
  location = {},
  numpages = {24},
  pages = {17–40},
  publisher = {Association for Computing Machinery},
  series = {SURE '25},
  title = {ideco: A Framework for Improving Non-C Decompilation},
  url = {https://doi.org/10.1145/3733822.3764668},
  year = {2025}
}

@inproceedings{10.1145/3733822.3764673,
  abstract = {Recovering semantic information from binary code is a fundamental challenge in reverse engineering, especially when source-level information is unavailable. We aim to analyze the types and roles of structural elements from the binary observed in the compiled program, focusing on their contextual usage patterns and associations to other members.We refer to such semantic aspects as structural semantics , meaning that cooccurring patterns of jointly updated structure members reveal the functional roles that can be inferred from their coupling, throughout this paper. Recent approaches have applied graph neural networks (GNNs) to data-flow graphs (DFGs) for variable type inference, but most rely on a single model architecture, such as the relational graph convolutional network (R-GCN). While effective, such models may overlook alternative patterns of structure member behavior. In this paper, we investigate the effectiveness of three alternative GNN architectures gated graph neural networks (GGNN), graph attention networks (GAT), and standard graph convolutional networks (GCN) in capturing structural semantics from binary-level data-flow graphs. We evaluate these models on real-world binaries compiled at multiple optimization levels, measuring their ability to infer semantic properties of structure members. Our results show that these architectures capture complementary aspects of structural semantics. GGNN is effective at modeling long-range dependencies, GAT suppresses irrelevant connections, and GCN offers computational simplicity. Different model architectures emphasize distinct aspects of structural semantics, capturing complementary patterns of how structure members are accessed together in memory. This demonstrates that architectural diversity provides richer perspectives for semantic inference in binary analysis.},
  address = {New York, NY, USA},
  author = {Sakamoto, Noriki and Takeuchi, Kazuhiro},
  booktitle = {Proceedings of the 2025 Workshop on Software Understanding and Reverse Engineering},
  doi = {10.1145/3733822.3764673},
  isbn = {9798400719103},
  keywords = {Decompiler, Reverse Engineering},
  location = {},
  numpages = {12},
  pages = {102–113},
  publisher = {Association for Computing Machinery},
  series = {SURE '25},
  title = {Toward Inferring Structural Semantics from Binary Code Using Graph Neural Networks},
  url = {https://doi.org/10.1145/3733822.3764673},
  year = {2025}
}

@article{10.1145/3749988,
  abstract = {Analysis of binary executables implementing mathematical equations can benefit from the reverse engineering of semantic information about the implementation. Traditional algorithmic reverse engineering tools either do not recover semantic information or rely on dynamic analysis and symbolic execution with high reverse engineering time. Algorithmic tools also require significant re-engineering effort to target new platforms and languages. Recently, neural methods for decompilation have been developed to recover human-like source code, but they do not extract semantic information explicitly. We develop REMEND, a neural decompilation framework to reverse engineer math equations from binaries to explicitly recover program semantics like data flow and order of operations. REMEND combines a transformer encoder-decoder model for neural decompilation with algorithmic processing for enhanced symbolic reasoning necessary for math equations. REMEND is the first work to demonstrate that transformers for neural decompilation go beyond source code and reason about program semantics in the form of math equations. We train on a synthetically generated dataset containing multiple implementations and compilations of math equations to produce a robust neural decompilation model and demonstrate retargettability. REMEND obtains an accuracy of 89.8% to 92.4% across three Instruction Set Architectures (ISAs), three optimization levels, and two programming languages with a single trained model, extending the capability of state-of-the-art neural decompilers. We achieve high accuracy with a small model of upto 12 million parameters and an average execution time of 0.132 seconds per function. On a real-world dataset collected from open-source programs, REMEND generalizes better than state-of-the-art neural decompilers despite being trained with synthetic data, achieving 8% higher accuracy. The synthetic and real-world datasets are provided at .},
  address = {New York, NY, USA},
  author = {Udeshi, Meet and Krishnamurthy, Prashanth and Karri, Ramesh and Khorrami, Farshad},
  doi = {10.1145/3749988},
  issn = {2157-6904},
  journal = {ACM Trans. Intell. Syst. Technol.},
  keywords = {reverse engineering, neural decompilation, math equations},
  month = {July},
  note = {Just Accepted},
  publisher = {Association for Computing Machinery},
  title = {REMEND: Neural Decompilation for Reverse Engineering Math Equations from Binary Executables},
  url = {https://doi.org/10.1145/3749988},
  year = {2025}
}

@inproceedings{10.1145/3759425.3763387,
  abstract = {Firmware reverse engineering is crucial for exposing internal mechanisms and identifying security vulnerabilities in embedded systems. While reconstructing the structural components of code is   generally feasible, the absence of function names greatly complicates efforts to analyze and comprehend firmware logic. Motivated by the demonstrated code generation capabilities of large   language models (LLMs), this paper investigates their potential to automate function renaming. We introduce FirmNamer, a prototype system designed to streamline the labor-intensive process of ana-   lyzing decompiled code and assigning meaningful function names. FirmNamer accomplishes this by dynamically constructing LLM prompts based on extracted function code and contextual informa-   tion. Extensive evaluation shows that FirmNamer achieves superior performance in function renaming, obtaining a functional precision of 86.6% and a semantic precision of 49%, thereby surpassing   existing state-of-the-art approaches such as DeGPT, DEBIN, NFRE, NERO, and SYMLM.},
  address = {New York, NY, USA},
  author = {Liu, Puzhuo and Di, Peng and Jiang, Yu},
  booktitle = {Proceedings of the 1st ACM SIGPLAN International Workshop on Language Models and Programming Languages},
  doi = {10.1145/3759425.3763387},
  isbn = {9798400721489},
  keywords = {Firmware, Function Summary, Large Language Model},
  location = {Singapore, Singapore},
  numpages = {9},
  pages = {57–65},
  publisher = {Association for Computing Machinery},
  series = {LMPL '25},
  title = {Function Renaming in Reverse Engineering of Embedded Device Firmware with ChatGPT},
  url = {https://doi.org/10.1145/3759425.3763387},
  year = {2025}
}

@inproceedings{10174218,
  abstract = {Compiled binary executables are often the only available artifact in reverse engineering, malware analysis, and software systems maintenance. Unfortunately, the lack of semantic information like variable types makes comprehending binaries difficult. In efforts to improve the comprehensibility of binaries, researchers have recently used machine learning techniques to predict semantic information contained in the original source code. Chen et al. implemented DIRTY, a Transformer-based Encoder-Decoder architecture capable of augmenting decompiled code with variable names and types by leveraging decompiler output tokens and variable size information. Chen et al. were able to demonstrate a substantial increase in name and type extraction accuracy on Hex-Rays decompiler outputs compared to existing static analysis and AI-based techniques. We extend the original DIRTY results by re-training the DIRTY model on a dataset produced by the open-source Ghidra decompiler. Although Chen et al. concluded that Ghidra was not a suitable decompiler candidate due to its difficulty in parsing and incorporating DWARF symbols during analysis, we demonstrate that straightforward parsing of variable data generated by Ghidra results in similar retyping performance. We hope this work inspires further interest and adoption of the Ghidra decompiler for use in research projects.},
  author = {Cao, Kevin and Leach, Kevin},
  booktitle = {2023 IEEE/ACM 31st International Conference on Program Comprehension (ICPC)},
  doi = {10.1109/ICPC58990.2023.00042},
  issn = {2643-7171},
  keywords = {Training;Source coding;Semantics;Reverse engineering;Symbols;Computer architecture;Static analysis;Ghidra;Hex-Rays;Machine Learning;Transformers},
  month = {May},
  number = {},
  pages = {275-279},
  title = {Revisiting Deep Learning for Variable Type Recovery},
  volume = {},
  year = {2023}
}

@inproceedings{10195624,
  abstract = {Conducting binary function naming helps reverse engineers understand the internal workings of the code and perform malicious code analysis without accessing the source code. However, the loss of debugging information poses the challenge of insufficient high-level semantic information description for stripping binary code function naming. Meanwhile, the existing binary function naming scheme has one function label for only one sample. The long-tail effect of function labels for a single sample makes the machine learning-based prediction models face the challenge. To obtain a function correlation label and improve the propensity score of uncommon tail labels, we propose a multi-label learning-based binary function naming model BContext2Name. This model automatically generates relevant labels for binary function naming by function context information with the help of PfastreXML model. The experimental results show that BContext2Name can enrich function labels and alleviate the long-tail effect that exists for a single sample class. To obtain high-level semantics of binary functions, we align pseudocode and basic blocks based on disassembly and decompilation, identify concrete or abstract values of API parameters by variable tracking, and construct API-enhanced control flow graphs. Finally, a seq2seq neural network translation model with attention mechanism is constructed between function multi-label learning and enhanced control flow graphs. Experiments on the dataset reveal that the F1 values of the BContext2Name model improve by 3.55% and 15.23% over the state-of-the-art XFL and Nero, respectively. This indicates that function multi-label learning can provide accurate labels for binary functions and can help reverse analysts understand the inner working mechanism of binary code. Code and data for this evaluation are available at https://github.com/CSecurityZhongYuan/BContext2Name.},
  author = {Xia, Bing and Ge, Yunxiang and Yang, Ruinan and Yin, Jiabin and Pang, Jianmin and Tang, Chongjun},
  booktitle = {2023 IEEE 10th International Conference on Cyber Security and Cloud Computing (CSCloud)/2023 IEEE 9th International Conference on Edge Computing and Scalable Cloud (EdgeCom)},
  doi = {10.1109/CSCloud-EdgeCom58631.2023.00037},
  issn = {2693-8928},
  keywords = {Cloud computing;Source coding;Semantics;Neural networks;Binary codes;Tail;Malware;Program analysis;Software reverse engineering;Binary code;Neural network translation;Multi-Label learning},
  month = {July},
  number = {},
  pages = {167-172},
  title = {BContext2Name: Naming Functions in Stripped Binaries with Multi-Label Learning and Neural Networks},
  volume = {},
  year = {2023}
}

@inproceedings{10320193,
  abstract = {Building a model to reassign descriptive names for binary functions is considerable assistance for reverse engineering. Existing methods proposed for this issue are based on the low-level representation of binary code (e.g., assembly code), and especially the recent approaches employed neural-based models on instruction sequences. However, their performance is still unsatisfactory. Meanwhile, modern decompilers provide lifted representations of binary code, and their effectiveness has not been adequately studied. This paper further explores the issue of function name reassignment from the perspective of binary code representation. Specifically, we present a general and flexible NEural-based function name Reassignment framework NER, which leverages a decompiler to obtain a specific representation and applies the corresponding serialization strategy on it. NER then uses an alternative neural network to make predictions. Three levels of representation are investigated, including assembly code, Intermediate Representation (IR), and pseudo-code. We observe the binary code representations are significant for the final performance. It demonstrates that the pseudo-code is the most effective one. Based on these findings, we leverage the framework to implement a reassignment model NER-pc, which has 25% and 10% F1 score improvements against the state-of-the-art methods. Besides, more experiments are conducted to verify the design of NER and the effectiveness of NER-pc.},
  author = {Chen, Guoqiang and Gao, Han and Zhang, Jie and He, Yanru and Cheng, Shaoyin and Zhang, Weiming},
  booktitle = {2023 20th Annual International Conference on Privacy, Security and Trust (PST)},
  doi = {10.1109/PST58708.2023.10320193},
  issn = {2643-4202},
  keywords = {Privacy;Reverse engineering;Neural networks;Buildings;Binary codes;Predictive models;Security;Binary analysis;Reverse engineering;Function name prediction;Binary code representation;Neural networks},
  month = {Aug},
  number = {},
  pages = {1-11},
  title = {Investigating Neural-based Function Name Reassignment from the Perspective of Binary Code Representation},
  volume = {},
  year = {2023}
}

@inproceedings{10515515,
  abstract = {The article is devoted to the problem of security of cyber-physical systems as part of production according to the Industry 4.0 concept. For this purpose, the author's approach of “Genetic Reverse Engineering of Machine Code” (GREMC) is proposed. The essence of this approach lies in the use of artificial intelligence in the field of genetic algorithms to restore the source code of software executed in the form of machine code on cyber-physical devices for Industry 4.0. The resulting code can then be analysed for vulnerabilities by an expert. One issue that arises during genetic reverse engineering is predicting the size of the source code based on its machine representation (i.e., in an object or executable file). The article is devoted to solving this problem for functions in the C programming language. To do this, a method for obtaining a relationship between the sizes of the source and machine code of individual functions is described, which consists of steps such as loading a dataset with C-functions, isolating the function code in it, preprocessing them, compiling them into machine code, calculating the required sizes, building dependencies between each source code size and the corresponding machine code sizes, generating the final table and determining the dependency formula. An experiment is carried out using a software prototype that implements the method; ExeBench with 83 thousand C-functions is taken as a dataset. Justifications are given regarding the appearance of abnormal machine code sizes and their impact on the dependence formula.},
  author = {Izrailov, Konstantin},
  booktitle = {2024 International Russian Smart Industry Conference (SmartIndustryCon)},
  doi = {10.1109/SmartIndustryCon61328.2024.10515515},
  issn = {},
  keywords = {Codes;Source coding;Reverse engineering;Prototypes;Production;Genetics;Software;machine code;source code;reverse-engineering;decompilation;size dependence},
  month = {March},
  number = {},
  pages = {622-628},
  title = {GREMC: Genetic Reverse-Engineering of Machine Code to Search Vulnerabilities in Software for Industry 4.0. Predicting the Size of the Decompiling Source Code},
  volume = {},
  year = {2024}
}

@inproceedings{10646727,
  abstract = {Binary reverse engineering is an arduous and tedious task performed by skilled and expensive human analysts. Information about the source code is irrevocably lost in the compilation process. While modern decompilers attempt to generate C-style source code from a binary, they cannot recover lost variable names. Prior works have explored machine learning techniques for predicting variable names in decompiled code. However, the state-of-the-art systems, DIRE and DIRTY, generalize poorly to functions in the testing set that are not included in the training set—31.8% for DIRE on DIRTY’s data set and 36.9% for DIRTY on DIRTY’s data set.In this paper, we present VarBERT, a Bidirectional Encoder Representations from Transformers (BERT) to predict meaningful variable names in decompilation output. An advantage of VarBERT is that we can pre-train on human source code and then fine-tune the model to the task of predicting variable names. We also create a new data set VarCorpus, which significantly expands the size and variety of the data set. Our evaluation of VarBERT on VarCorpus, demonstrates a significant improvement in predicting the developer’s original variable names for O2 optimized binaries achieving accuracies of 54.43% for IDA and 54.49% for Ghidra. VarBERT is strictly better than state-of-the-art techniques: On a subset of VarCorpus, VarBERT could predict the developer’s original variable names 50.70% of the time, while DIRE and DIRTY predicted original variable names 35.94% and 38.00% of the time, respectively.},
  author = {Pal, Kuntal Kumar and Bajaj, Ati Priya and Banerjee, Pratyay and Dutcher, Audrey and Nakamura, Mutsumi and Basque, Zion Leonahenahe and Gupta, Himanshu and Sawant, Saurabh Arjun and Anantheswaran, Ujjwala and Shoshitaishvili, Yan and Doupé, Adam and Baral, Chitta and Wang, Ruoyu},
  booktitle = {2024 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP54263.2024.00152},
  issn = {2375-1207},
  keywords = {Training;Privacy;Codes;Source coding;Transfer learning;Reverse engineering;Transformers;Program and binary analysis;Machine learning and computer security;Decompilation},
  month = {May},
  number = {},
  pages = {4069-4087},
  title = {"Len or index or count, anything but v1": Predicting Variable Names in Decompilation Output with Transfer Learning},
  volume = {},
  year = {2024}
}

@article{10967090,
  abstract = {Decompilation is the main process of software development, which is very important when a program tries to retrieve lost source codes. Although decompiling Java bytecode is easier than bytecode, many Java decompilers cannot recover originally lost sources, especially the selection statement, i.e., if statement. This deficiency affects directly decompilation performance. In this paper, we propose the methodology for guiding Java decompiler to deal with the aforementioned problem. In the framework, Java bytecode is transformed into two kinds of features called frame feature and latent semantic feature. The former is extracted directly from the bytecode. The latter is achieved by two-step transforming the Java bytecode to bigram and then term frequency-inverse document frequency (TFIDF). After that, both of them are fed to the genetic algorithm to reduce their dimensions. The proposed feature is achieved by converting the selected TFIDF to a latent semantic feature and concatenating it with the selected frame feature. Finally, KNN is used to classify the proposed feature. The experimental results show that the decompilation accuracy is 93.68 percent, which is obviously better than Java Decompiler.},
  author = {Sateanpattanakul, Siwadol and Jetpipattanapong, Duangpen and Mathulaprangsan, Seksan},
  doi = {10.13052/jmm1550-4646.1822},
  issn = {1550-4654},
  journal = {Journal of Mobile Multimedia},
  keywords = {Java;Accuracy;Source coding;Semantics;Nearest neighbor methods;Feature extraction;Genetic algorithms;Software development management;Indexing;Decompilation;feature selection;latent semantic indexing;genetic algorithm},
  month = {March},
  number = {2},
  pages = {179-202},
  title = {Java Bytecode Control Flow Classification: Framework for Guiding Java Decompilation},
  volume = {18},
  year = {2022}
}

@inproceedings{11023256,
  abstract = {Python is one of the most popular programming languages among both industry developers and malware authors. Despite demand for Python decompilers, community efforts to maintain automatic Python decompilation tools have been hindered by Python's aggressive language improvements and unstable bytecode specification. Every year, language features are added, code generation undergoes significant changes, and opcodes are added, deleted, and modified. Our research aims to integrate Natural Language Processing (NLP) techniques with classical Programming Language (PL) theory to create a Python decompiler that accomodates evolving language features and changes to the bytecode specification with minimal human maintenance effort. PyLINGUAL plugs in data-driven NLP components to a version-agnostic core to automatically absorb superficial bytecode and compiler changes, while leveraging programmatic components for abstract control flow reconstruction. To establish trust in the decompilation results, we introduce a stringent correctness measure based on “perfect decompilation”, a statically verifiable refinement of semantic equivalence. We demonstrate the efficacy of our approach with extensive real-world datasets of benign and malicious Python source code and their corresponding compiled PYC binaries. Our research makes three major contributions: (1) we present PyLINGUAL, a scalable, data-driven decompilation framework with state-of-the-art support for Python versions 3.6 through 3.12, improving the perfect decompilation rate by an average of 45% over the best results of existing decompiler across four datasets; (2) we provide a Python decompiler evaluation framework that verifies decompilation results with perfect decompilation; and (3) we launch PyLINGUAL as a public online service.},
  author = {Wiedemeier, Josh and Tarbet, Elliot and Zheng, Max and Ko, Sangsoo and Ouyang, Jessica and Cha, Sang Kil and Jee, Kangkook},
  booktitle = {2025 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP61157.2025.00052},
  issn = {2375-1207},
  keywords = {Codes;Translation;Program processors;Source coding;Semantics;Reverse engineering;Syntactics;Natural language processing;Security;Python;python;decompiler;nlp;reverse engineering},
  month = {May},
  number = {},
  pages = {2976-2994},
  title = {PyLingual: Toward Perfect Decompilation of Evolving High-Level Languages},
  volume = {},
  year = {2025}
}

@inproceedings{11023499,
  abstract = {Static binary analysis is a widely used approach for ensuring the security of closed-source software. However, the absence of type information in stripped binaries, particularly for composite data types, poses significant challenges for both static analyzers and reverse engineering experts in achieving efficient and accurate analysis. Existing methods often struggle with inaccuracies and scalability limitations when dealing with such data types. To address these problems, we present Typeforge, a novel approach inspired by the workflow of reverse engineering experts, which uses a two-stage synthesis-selection strategy to automate the recovery of composite data types from stripped binaries. We design a new graph structure, the Type Flow Graph (TFG) to represent type information within stripped binaries. In the first stage, TFG-based Type Synthesis focuses on efficiently and accurately building constraints and synthesizing possible composite type declarations from the stripped binaries. In the second stage, we propose an LLM-assisted double-elimination framework to select the best-fit type declaration from the candidates by assessing the readability of the decompiled code. Our comparison with state-of-the-art approaches demonstrates that TYPEFORGE achieves F1 scores of 81.7% and 88.2% in Composite Data Type Identification and Layout Recovery, respectively, substantially outperforming existing methods. Additionally, TYPEFORGE achieves an F1 score of 72.1% in Relationship Recovery, a particularly challenging task for previous approaches. Furthermore, TYPEFORGE has significantly lower time overhead, requiring only about 3.8% of the time taken by OSPREY, the best-performing existing approach, making it a promising solution for various real-world reverse engineering tasks.},
  author = {Wang, Yanzhong and Liang, Ruigang and Li, Yilin and Hu, Peiwei and Chen, Kai and Zhang, Bolun},
  booktitle = {2025 IEEE Symposium on Security and Privacy (SP)},
  doi = {10.1109/SP61157.2025.00193},
  issn = {2375-1207},
  keywords = {Privacy;Codes;Accuracy;Scalability;Reverse engineering;Layout;Buildings;Software;Security;Flow graphs},
  month = {May},
  number = {},
  pages = {1-18},
  title = {TypeForge: Synthesizing and Selecting Best-Fit Composite Data Types for Stripped Binaries},
  volume = {},
  year = {2025}
}

@inproceedings{11028410,
  abstract = {Modern industry is built, among other things, on software, the presence of vulnerabilities in which is a significant problem. It is more rational to search for vulnerabilities in those representations of the program (source code, algorithms, architecture, etc.) on the basis of which they were developed. However, as a rule, there is difficult-to-analyze machine code available. Obtaining higher-level representations is possible by reverse engineering, carried out in various ways, such as expert, algorithmic, intelligent, enumeration and logging. The qualitative comparison of these representations is given. The current study is devoted to a new method of reverse engineering based on the use of genetic algorithms. The course of the research and the following main scientific results are briefly described: the methodology of reverse engineering of a software system, the model of the life cycle of a program with multi-level vulnerabilities, the concept of genetic de-evolution of program representations, scientific, methodological and algorithmic instrumentation for genetic decompilation, an architectural block for conducting genetic de-evolution of representations with functionality for searching for multi-level vulnerabilities. All results are novel, as well as theoretically and practically significant.},
  author = {Izrailov, Konstantin and Kotenko, Igor and Buinevich, Mikhail},
  booktitle = {2025 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)},
  doi = {10.1109/ICIEAM65163.2025.11028410},
  issn = {2993-4060},
  keywords = {Industries;Source coding;Instruments;Reverse engineering;Software algorithms;Information security;Genetics;Software systems;Manufacturing;Genetic algorithms;software;vulnerability;information security;reverse engineering;genetic algorithms},
  month = {May},
  number = {},
  pages = {918-923},
  title = {Reengineering Modern Industrial Software to Find Vulnerabilities Based on Genetic Algorithms},
  volume = {},
  year = {2025}
}

@inproceedings{11068876,
  abstract = {Reverse engineering is a crucial technique in software security, enabling professionals to analyze malware, identify vulnerabilities, and patch legacy software without access to source code. Although decompilers attempt to reconstruct high-level code from binaries, essential information, such as variable names and types, is often dissimilar from the original version, hindering readability and comprehension.Recent advancements have employed AI to enhance decompiler output by recovering original variable names and types. Traditional evaluation of recovery techniques relies on measuring similarity between original and recovered names, assuming that higher similarity enhances readability. However, studies suggest that these "intrinsic" metrics may not accurately predict "extrinsic" outcomes like user comprehension or task performance, revealing a gap in understanding readability and cognitive load in reverse engineering.This paper presents an extrinsic evaluation of machine-generated variable and type names, focusing on their impact on reverse engineers’ comprehension of decompiled code. We conducted a user study with 40 participants—including students and professionals—to assess code comprehension both with and without AI-generated variable and type name assistance. Our findings indicate a lack of correlation between traditional machine learning metrics and actual comprehension gains, highlighting limitations in current evaluation techniques. Despite this, participants showed a preference for AI-augmented decompiler outputs. These insights contribute to understanding the effectiveness of automatic recovery techniques in enhancing reverse engineering tasks and underscore the need for comprehensive, user-centered evaluation frameworks.},
  author = {Yang, Yuwei and Grandel, Skyler and Lacomis, Jeremy and Schwartz, Edward and Vasilescu, Bogdan and Le Goues, Claire and Leach, Kevin},
  booktitle = {2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)},
  doi = {10.1109/DSN64029.2025.00026},
  issn = {2158-3927},
  keywords = {Measurement;Codes;Correlation;Source coding;Reverse engineering;Focusing;Machine learning;Cognitive load;Malware;Security;Decompilation;Binary Reverse Engineering;Human Study},
  month = {June},
  number = {},
  pages = {129-142},
  title = {A Human Study of Automatically Generated Decompiler Annotations},
  volume = {},
  year = {2025}
}

@inproceedings{11334294,
  abstract = {The growing demand for high-performance tensor programs on GPUs, especially for large language models (LLMs), necessitates advanced compilation and optimization techniques. However, the critical task of analyzing optimized, low-level PTX code for performance tuning or understanding poses significant challenges. While LLMs hold promise for PTX-to-CUDA de-compilation to improve code intelligibility, their effectiveness is severely limited by the scarcity of aligned training data and the inherent complexity of highly optimized, unrolled PTX code.In this work, we explore methodologies to significantly enhance LLM capabilities for accurate and readable PTX-to-CUDA decompilation and present PtxDec, a decompilation prototype implementing our approach. To overcome the critical barrier of data scarcity, we develop a compiler-based data augmentation framework coupled with rigorous post-processing, enabling the creation of a large-scale, high-quality dataset of 400K aligned CUDA-PTX kernel pairs for effective LLM training. Furthermore, to empower LLMs to handle the complexity of optimized PTX, we introduce Rolled-PTX—an intermediate representation generated through heuristic loop rerolling during preprocessing. Rolled-PTX condenses unrolled patterns, drastically simplifying the input structure presented to the LLM and aligning it better with higher-level loop constructs.Comprehensive evaluation demonstrates that PtxDec achieves substantial performance gains: our approach yields a 2.3×–3.1× improvement in functional accuracy over baseline methods, alongside significant enhancements in generated code readability and scheduling consistency with the original optimized kernels. Ablation studies further validate the contribution of each proposed component to the overall performance.To the best of our knowledge, this is the first work tackling PTX-to-CUDA decompilation, specifically focusing on and demonstrating effective strategies for augmenting LLMs to overcome the key challenges in this domain.},
  author = {Sun, Xinyu and Tang, Fugen and Zhang, Yu and Shen, Han and Song, Chengru and Zhang, Di},
  booktitle = {2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  doi = {10.1109/ASE63991.2025.00185},
  issn = {2643-1572},
  keywords = {Codes;Tensors;Accuracy;Graphics processing units;Training data;Data augmentation;Complexity theory;Kernel;Optimization;Tuning;LLM;Decompilation;Deep learning compiler;GPU Programming},
  month = {Nov},
  number = {},
  pages = {2235-2247},
  title = {Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs},
  volume = {},
  year = {2025}
}

@inproceedings{11334626,
  abstract = {Decompilation can convert binary programs into clear C-style pseudocode, which is of great value in a wide range of security applications. Existing research primarily focuses on recovering symbolic information in pseudocode, such as function names, variable names, and data types, but neglecting structural information. We observe that even when symbolic information is fully preserved, severe and complex structure distortions remain in the pseudocode, greatly impairing code readability and comprehension. In this work, we first systematically investigate structure distortions in decompiled pseudocode, revealing their variation patterns through quantitative analysis. Using open coding, we derive a taxonomy comprising six top-level categories of structure distortions. Building upon this taxonomy, we propose PseudoFix, a novel framework that combines large language models (LLMs) with retrieval-based in-context learning. PseudoFix employs semantic retrieval to select the most relevant few-shot examples that provide structure distortion knowledge, and combines this with the well-structured coding patterns learned by LLMs from vast source code repositories, to efficiently refactor distorted pseudocode. Comprehensive evaluations demonstrate that PseudoFix significantly improves pseudocode readability, achieving up to a 34% reduction in Halstead Complexity Effort and a 105% increase in BLEU-4 score. Notably, it significantly outperforms state-of-the-art approaches in both temporary variable elimination and goto statement removal tasks. Additionally, human evaluations yield consistently positive feedback from users across readability, consistency, and reasonability.},
  author = {Li, Gangyang and Shang, Xiuwei and Cheng, Shaoyin and Zhang, Junqi and Hu, Li and Zhu, Xu and Zhang, Weiming and Yu, Nenghai},
  booktitle = {2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  doi = {10.1109/ASE63991.2025.00075},
  issn = {2643-1572},
  keywords = {Systematics;Statistical analysis;Large language models;Source coding;Taxonomy;Semantics;Software algorithms;Distortion;Security;Software engineering;Decompilation;Refactor Structure Distortion;Taxonomy;In-context Learning;Large Language Models},
  month = {Nov},
  number = {},
  pages = {841-853},
  title = {PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode},
  volume = {},
  year = {2025}
}

@article{11367734,
  abstract = {Decompilation plays a critical role in firmware analysis and reverse engineering by enabling the recovery of high-level source code from binary executables. However, existing neural decompilation models often face challenges due to the semantic gap between assembly code and high-level languages, and they typically require large-scale models that impose significant computational demands. In this paper, we propose DECodeT5, a lightweight and efficient neural decompilation method for the C language. DECodeT5 builds upon the CodeT5 code generation model by integrating a pre-trained assembly encoder in place of its original embedding layer. This modification allows for more effective semantic learning from assembly code, improving the model’s ability to capture the intricacies of assembly-to-source code mapping. The architecture of DECodeT5 not only accelerates convergence during end-to-end decompilation tasks but also supports rapid adaptation across different compilers and instruction set architectures (ISAs) by swapping out the encoder module as needed. Our experimental evaluation on the HumanEval and Exebench benchmarks reveals that DECodeT5 significantly improves semantic recovery accuracy, outperforming Ghidra by over 83% and LLM4Decompile by more than 43% in terms of execution recovery. Furthermore, DECodeT5 maintains a compact model size of only 360M parameters, providing inference speeds that are twice as fast as LLM4Decompile. These results underscore DECodeT5’s suitability for deployment in resource-constrained environments and its flexibility in adapting to real-world reverse engineering scenarios, offering a practical solution for modern firmware analysis and security tasks.},
  author = {Liu, Li and Sun, Fanghui and Wang, Shen and Jiang, Xunzhi},
  doi = {10.1109/JIOT.2026.3659328},
  issn = {2327-4662},
  journal = {IEEE Internet of Things Journal},
  keywords = {Codes;Semantics;Assembly;Source coding;Optimization;Instruction sets;Computer architecture;Adaptation models;Microprogramming;Internet of Things;Decompile;reverse engineering;firmware security;deep neural network},
  month = {},
  number = {},
  pages = {1-1},
  title = {DECodeT5: A Lightweight and Efficient Neural Decompiler with Assembly Semantic Assistance},
  volume = {},
  year = {2026}
}

@inproceedings{8330222,
  abstract = {Decompilation, recovering source code from binary, is useful in many situations where it is necessary to analyze or understand software for which source code is not available. Source code is much easier for humans to read than binary code, and there are many tools available to analyze source code. Existing decompilation techniques often generate source code that is difficult for humans to understand because the generated code often does not use the coding idioms that programmers use. Differences from human-written code also reduce the effectiveness of analysis tools on the decompiled source code. To address the problem of differences between decompiled code and human-written code, we present a novel technique for decompiling binary code snippets using a model based on Recurrent Neural Networks. The model learns properties and patterns that occur in source code and uses them to produce decompilation output. We train and evaluate our technique on snippets of binary machine code compiled from C source code. The general approach we outline in this paper is not language-specific and requires little or no domain knowledge of a language and its properties or how a compiler operates, making the approach easily extensible to new languages and constructs. Furthermore, the technique can be extended and applied in situations to which traditional decompilers are not targeted, such as for decompilation of isolated binary snippets; fast, on-demand decompilation; domain-specific learned decompilation; optimizing for readability of decompilation; and recovering control flow constructs, comments, and variable or function names. We show that the translations produced by this technique are often accurate or close and can provide a useful picture of the snippet's behavior.},
  author = {Katz, Deborah S. and Ruchti, Jason and Schulte, Eric},
  booktitle = {2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  doi = {10.1109/SANER.2018.8330222},
  issn = {},
  keywords = {Recurrent neural networks;Tools;Training;Binary codes;Natural languages;Decoding;Data models;decompilation;recurrent neural networks;translation;deep learning},
  month = {March},
  number = {},
  pages = {346-356},
  title = {Using recurrent neural networks for decompilation},
  volume = {},
  year = {2018}
}

@article{Achamyeleh2026,
  abstract = {Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \textsc\{HELIOS\}, a framework that reframes LLM-based decompilation as a structured reasoning task. \textsc\{HELIOS\} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build. On HumanEval-Decompile for \texttt\{x86\_64\}, \textsc\{HELIOS\} raises average object file compilability from 45.0\% to 85.2\% for Gemini~2.0 and from 71.4\% to 89.6\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \textsc\{HELIOS\} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \textsc\{HELIOS\} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets. },
  author = {Achamyeleh, Gizachew, Yonatan AND Thomare, Harsh AND Faruque, Al, Abdullah, Mohammad},
  doi = {https://doi.org/10.48550/arXiv.2601.14598},
  howpublished = {\url{https://arxiv.org/pdf/2601.14598}},
  month = {jan},
  note = {},
  title = {HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation},
  year = {2026}
}

@article{arXiv:2405.19581,
  abstract = {Human-Oriented Binary Reverse Engineering (HOBRE) lies at the intersection of binary and source code, aiming to lift binary code to human-readable content relevant to source code, thereby bridging the binary-source semantic gap. Recent advancements in uni-modal code model pre-training, particularly in generative Source Code Foundation Models (SCFMs) and binary understanding models, have laid the groundwork for transfer learning applicable to HOBRE. However, existing approaches for HOBRE rely heavily on uni-modal models like SCFMs for supervised fine-tuning or general LLMs for prompting, resulting in sub-optimal performance. Inspired by recent progress in large multi-modal models, we propose that it is possible to harness the strengths of uni-modal code models from both sides to bridge the semantic gap effectively. In this paper, we introduce a novel probe-and-recover framework that incorporates a binary-source encoder-decoder model and black-box LLMs for binary analysis. Our approach leverages the pre-trained knowledge within SCFMs to synthesize relevant, symbol-rich code fragments as context. This additional context enables black-box LLMs to enhance recovery accuracy. We demonstrate significant improvements in zero-shot binary summarization and binary function name recovery, with a 10.3\% relative gain in CHRF and a 16.7\% relative gain in a GPT4-based metric for summarization, as well as a 6.7\% and 7.4\% absolute increase in token-level precision and recall for name recovery, respectively. These results highlight the effectiveness of our approach in automating and improving binary code analysis.},
  archiveprefix = {arXiv},
  author = {Zian Su and Xiangzhe Xu and Ziyang Huang and Kaiyuan Zhang and Xiangyu Zhang},
  categories = {cs.SE cs.AI cs.CL},
  eprint = {2405.19581},
  journal = {arXiv preprint arXiv:2405.19581},
  month = {05},
  pdf = {https://arxiv.org/pdf/2405.19581v2},
  primaryclass = {cs.SE},
  published = {2024-05-30T00:17:44Z},
  title = {Source Code Foundation Models are Transferable Binary Analysis Knowledge Bases},
  updated = {2024-10-30T16:12:36Z},
  url = {https://arxiv.org/abs/2405.19581v2},
  year = {2024}
}

@article{arXiv:2509.14646,
  abstract = {Decompilation is widely used in reverse engineering to recover high-level language code from binary executables. While recent approaches leveraging Large Language Models (LLMs) have shown promising progress, they typically treat assembly code as a linear sequence of instructions, overlooking arbitrary jump patterns and isolated data segments inherent to binary files. This limitation significantly hinders their ability to correctly infer source code semantics from assembly code. To address this limitation, we propose \\saltm, a novel binary decompilation method that abstracts stable logical features shared between binary and source code. The core idea of \\saltm is to abstract selected binary-level operations, such as specific jumps, into a high-level logic framework that better guides LLMs in semantic recovery. Given a binary function, \\saltm constructs a Source-level Abstract Logic Tree (\\salt) from assembly code to approximate the logic structure of high-level language. It then fine-tunes an LLM using the reconstructed \\salt to generate decompiled code. Finally, the output is refined through error correction and symbol recovery to improve readability and correctness. We compare \\saltm to three categories of baselines (general-purpose LLMs, commercial decompilers, and decompilation methods) using three well-known datasets (Decompile-Eval, MBPP, Exebench). Our experimental results demonstrate that \\saltm is highly effective in recovering the logic of the source code, significantly outperforming state-of-the-art methods (e.g., 70.4\\\% TCP rate on Decompile-Eval with a 10.6\\\% improvement). The results further validate its robustness against four commonly used obfuscation techniques. Additionally, analyses of real-world software and a user study confirm that our decompiled output offers superior assistance to human analysts in comprehending binary functions.},
  archiveprefix = {arXiv},
  author = {Yongpan Wang and Xin Xu and Xiaojie Zhu and Xiaodong Gu and Beijun Shen},
  categories = {cs.SE cs.PL},
  comment = {13 pages, 7 figures},
  eprint = {2509.14646},
  journal = {arXiv preprint arXiv:2509.14646},
  month = {09},
  pdf = {https://arxiv.org/pdf/2509.14646v1},
  primaryclass = {cs.SE},
  published = {2025-09-18T05:57:15Z},
  title = {SALT4Decompile: Inferring Source-level Abstract Logic Tree for LLM-Based Binary Decompilation},
  updated = {2025-09-18T05:57:15Z},
  url = {https://arxiv.org/abs/2509.14646v1},
  year = {2025}
}

@article{Banerjee2021,
  abstract = {Decompilation is the procedure of transforming binary programs into a high-level representation, such as source code, for human analysts to examine. While modern decompilers can reconstruct and recover much information that is discarded during compilation, inferring variable names is still extremely difficult. Inspired by recent advances in natural language processing, we propose a novel solution to infer variable names in decompiled code based on Masked Language Modeling, Byte-Pair Encoding, and neural architectures such as Transformers and BERT. Our solution takes \textit\{raw\} decompiler output, the less semantically meaningful code, as input, and enriches it using our proposed \textit\{finetuning\} technique, Constrained Masked Language Modeling. Using Constrained Masked Language Modeling introduces the challenge of predicting the number of masked tokens for the original variable name. We address this \textit\{count of token prediction\} challenge with our post-processing algorithm. Compared to the state-of-the-art approaches, our trained VarBERT model is simpler and of much better performance. We evaluated our model on an existing large-scale data set with 164,632 binaries and showed that it can predict variable names identical to the ones present in the original source code up to 84.15\% of the time. },
  author = {Banerjee, Pratyay AND Pal, Kumar, Kuntal AND Wang, Fish AND Baral, Chitta},
  doi = {https://doi.org/10.48550/arXiv.2103.12801},
  howpublished = {\url{https://arxiv.org/pdf/2103.12801}},
  month = {mar},
  note = {Work In Progress},
  title = {Variable Name Recovery in Decompiled Binary Code using Constrained Masked Language Modeling},
  year = {2021}
}

@article{Cao2023,
  abstract = {Decompilation aims to transform a low-level program language (LPL) (eg., binary file) into its functionally-equivalent high-level program language (HPL) (e.g., C/C++). It is a core technology in software security, especially in vulnerability discovery and malware analysis. In recent years, with the successful application of neural machine translation (NMT) models in natural language processing (NLP), researchers have tried to build neural decompilers by borrowing the idea of NMT. They formulate the decompilation process as a translation problem between LPL and HPL, aiming to reduce the human cost required to develop decompilation tools and improve their generalizability. However, state-of-the-art learning-based decompilers do not cope well with compiler-optimized binaries. Since real-world binaries are mostly compiler-optimized, decompilers that do not consider optimized binaries have limited practical significance. In this paper, we propose a novel learning-based approach named NeurDP, that targets compiler-optimized binaries. NeurDP uses a graph neural network (GNN) model to convert LPL to an intermediate representation (IR), which bridges the gap between source code and optimized binary. We also design an Optimized Translation Unit (OTU) to split functions into smaller code fragments for better translation performance. Evaluation results on datasets containing various types of statements show that NeurDP can decompile optimized binaries with 45.21% higher accuracy than state-of-the-art neural decompilation frameworks. },
  author = {Cao, Ying AND Liang, Ruigang AND Chen, Kai AND Hu, Peiwei},
  doi = {https://doi.org/10.48550/arXiv.2301.00969},
  howpublished = {\url{https://arxiv.org/pdf/2301.00969}},
  month = {jan},
  note = {},
  title = {Boosting Neural Networks to Decompile Optimized Binaries},
  year = {2023}
}

@article{Chen2021,
  abstract = {A common tool used by security professionals for reverse-engineering binaries found in the wild is the decompiler. A decompiler attempts to reverse compilation, transforming a binary to a higher-level language such as C. High-level languages ease reasoning about programs by providing useful abstractions such as loops, typed variables, and comments, but these abstractions are lost during compilation. Decompilers are able to deterministically reconstruct structural properties of code, but comments, variable names, and custom variable types are technically impossible to recover. In this paper we present DIRTY (DecompIled variable ReTYper), a novel technique for improving the quality of decompiler output that automatically generates meaningful variable names and types. Empirical evaluation on a novel dataset of C code mined from GitHub shows that DIRTY outperforms prior work approaches by a sizable margin, recovering the original names written by developers 66.4% of the time and the original types 75.8% of the time. },
  author = {Chen, Qibin AND Lacomis, Jeremy AND Schwartz, J., Edward AND Goues, Le, Claire AND Neubig, Graham AND Vasilescu, Bogdan},
  doi = {https://doi.org/10.48550/arXiv.2108.06363},
  howpublished = {\url{https://arxiv.org/pdf/2108.06363}},
  month = {aug},
  note = {17 pages to be published in USENIX Security '22},
  title = {Augmenting Decompiler Output with Learned Variable Names and Types},
  year = {2021}
}

@article{Chukkol2024,
  abstract = {Binary program vulnerability detection is critical for software security, yet existing deep learning approaches often rely on source code analysis, limiting their ability to detect unknown vulnerabilities. To address this, we propose VulCatch, a binary-level vulnerability detection framework. VulCatch introduces a Synergy Decompilation Module (SDM) and Kolmogorov-Arnold Networks (KAN) to transform raw binary code into pseudocode using CodeT5, preserving high-level semantics for deep analysis with tools like Ghidra and IDA. KAN further enhances feature transformation, enabling the detection of complex vulnerabilities. VulCatch employs word2vec, Inception Blocks, BiLSTM Attention, and Residual connections to achieve high detection accuracy (98.88%) and precision (97.92%), while minimizing false positives (1.56%) and false negatives (2.71%) across seven CVE datasets. },
  author = {Chukkol, Adama, Hamman, Abdulrahman AND Luo, Senlin AND Sharif, Kashif AND Haruna, Yunusa AND Abdullahi, Muhammad, Muhammad},
  doi = {https://doi.org/10.48550/arXiv.2408.07181},
  howpublished = {\url{https://arxiv.org/pdf/2408.07181}},
  month = {aug},
  note = {},
  title = {VulCatch: Enhancing Binary Vulnerability Detection through CodeT5 Decompilation and KAN Advanced Feature Extraction},
  year = {2024}
}

@article{David2025,
  abstract = {The widespread lack of broad source code verification on blockchain explorers such as Etherscan, where despite 78,047,845 smart contracts deployed on Ethereum (as of May 26, 2025), a mere 767,520 (< 1%) are open source, presents a severe impediment to blockchain security. This opacity necessitates the automated semantic analysis of on-chain smart contract bytecode, a fundamental research challenge with direct implications for identifying vulnerabilities and understanding malicious behavior. Prevailing decompilers struggle to reverse bytecode in a readable manner, often yielding convoluted code that critically hampers vulnerability analysis and thwarts efforts to dissect contract functionalities for security auditing. This paper addresses this challenge by introducing a pioneering decompilation pipeline that, for the first time, successfully leverages Large Language Models (LLMs) to transform Ethereum Virtual Machine (EVM) bytecode into human-readable and semantically faithful Solidity code. Our novel methodology first employs rigorous static program analysis to convert bytecode into a structured three-address code (TAC) representation. This intermediate representation then guides a Llama-3.2-3B model, specifically fine-tuned on a comprehensive dataset of 238,446 TAC-to-Solidity function pairs, to generate high-quality Solidity. This approach uniquely recovers meaningful variable names, intricate control flow, and precise function signatures. Our extensive empirical evaluation demonstrates a significant leap beyond traditional decompilers, achieving an average semantic similarity of 0.82 with original source and markedly superior readability. The practical viability and effectiveness of our research are demonstrated through its implementation in a publicly accessible system, available at https://evmdecompiler.com. },
  author = {David, Isaac AND Zhou, Liyi AND Song, Dawn AND Gervais, Arthur AND Qin, Kaihua},
  doi = {https://doi.org/10.48550/arXiv.2506.19624},
  howpublished = {\url{https://arxiv.org/pdf/2506.19624}},
  month = {jun},
  note = {},
  title = {Decompiling Smart Contracts with a Large Language Model},
  year = {2025}
}

@article{Escalada2021,
  abstract = {In software reverse engineering, decompilation is the process of recovering source code from binary files. Decompilers are used when it is necessary to understand or analyze software for which the source code is not available. Although existing decompilers commonly obtain source code with the same behavior as the binaries, that source code is usually hard to interpret and certainly differs from the original code written by the programmer. Massive codebases could be used to build supervised machine learning models aimed at improving existing decompilers. In this article, we build different classification models capable of inferring the high-level type returned by functions, with significantly higher accuracy than existing decompilers. We automatically instrument C source code to allow the association of binary patterns with their corresponding high-level constructs. A dataset is created with a collection of real open-source applications plus a huge number of synthetic programs. Our system is able to predict function return types with a 79.1% F1-measure, whereas the best decompiler obtains a 30% F1-measure. Moreover, we document the binary patterns used by our classifier to allow their addition in the implementation of existing decompilers. },
  author = {Escalada, Javier AND Scully, Ted AND Ortin, Francisco},
  doi = {https://doi.org/10.48550/arXiv.2101.08116},
  howpublished = {\url{https://arxiv.org/pdf/2101.08116}},
  month = {feb},
  note = {},
  title = {Improving type information inferred by decompilers with supervised machine learning},
  year = {2021}
}

@article{Fang2024,
  abstract = {WebAssembly enables near-native execution in web applications and is increasingly adopted for tasks that demand high performance and robust security. However, its assembly-like syntax, implicit stack machine, and low-level data types make it extremely difficult for human developers to understand, spurring the need for effective WebAssembly reverse engineering techniques. In this paper, we propose StackSight, a novel neurosymbolic approach that combines Large Language Models (LLMs) with advanced program analysis to decompile complex WebAssembly code into readable C++ snippets. StackSight visualizes and tracks virtual stack alterations via a static analysis algorithm and then applies chain-of-thought prompting to harness LLM's complex reasoning capabilities. Evaluation results show that StackSight significantly improves WebAssembly decompilation. Our user study also demonstrates that code snippets generated by StackSight have significantly higher win rates and enable a better grasp of code semantics. },
  author = {Fang, Weike AND Zhou, Zhejian AND He, Junzhou AND Wang, Weihang},
  doi = {https://doi.org/10.48550/arXiv.2406.04568},
  howpublished = {\url{https://arxiv.org/pdf/2406.04568}},
  month = {jun},
  note = {9 pages. In the Proceedings of the 41st International Conference on Machine Learning (ICML' 24)},
  title = {StackSight: Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation},
  year = {2024}
}

@article{Feng2024,
  abstract = {Decompilation transforms compiled code back into a high-level programming language for analysis when source code is unavailable. Previous work has primarily focused on enhancing decompilation performance by increasing the scale of model parameters or training data for pre-training. Based on the characteristics of the decompilation task, we propose two methods: (1) Without fine-tuning, the Self-Constructed Context Decompilation (sc$^2$dec) method recompiles the LLM's decompilation results to construct pairs for in-context learning, helping the model improve decompilation performance. (2) Fine-grained Alignment Enhancement (FAE), which meticulously aligns assembly code with source code at the statement level by leveraging debugging information, is employed during the fine-tuning phase to achieve further improvements in decompilation. By integrating these two methods, we achieved a Re-Executability performance improvement of approximately 3.90% on the Decompile-Eval benchmark, establishing a new state-of-the-art performance of 52.41%. The code, data, and models are available at https://github.com/AlongWY/sccdec. },
  author = {Feng, Yunlong AND Teng, Dechuan AND Xu, Yang AND Mu, Honglin AND Xu, Xiao AND Qin, Libo AND Zhu, Qingfu AND Che, Wanxiang},
  doi = {https://doi.org/10.48550/arXiv.2406.17233},
  howpublished = {\url{https://arxiv.org/pdf/2406.17233}},
  month = {oct},
  note = {EMNLP 2024 Findings},
  title = {Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement},
  year = {2024}
}

@article{Feng2025,
  abstract = {The goal of decompilation is to convert compiled low-level code (e.g., assembly code) back into high-level programming languages, enabling analysis in scenarios where source code is unavailable. This task supports various reverse engineering applications, such as vulnerability identification, malware analysis, and legacy software migration. The end-to-end decompile method based on large langauge models (LLMs) reduces reliance on additional tools and minimizes manual intervention due to its inherent properties. However, previous end-to-end methods often lose critical information necessary for reconstructing control flow structures and variables when processing binary files, making it challenging to accurately recover the program's logic. To address these issues, we propose the \textbf\{ReF Decompile\} method, which incorporates the following innovations: (1) The Relabelling strategy replaces jump target addresses with labels, preserving control flow clarity. (2) The Function Call strategy infers variable types and retrieves missing variable information from binary files. Experimental results on the Humaneval-Decompile Benchmark demonstrate that ReF Decompile surpasses comparable baselines and achieves state-of-the-art (SOTA) performance of $61.43\%$. },
  author = {Feng, Yunlong AND Li, Bohan AND Shi, Xiaoming AND Zhu, Qingfu AND Che, Wanxiang},
  doi = {https://doi.org/10.48550/arXiv.2502.12221},
  howpublished = {\url{https://arxiv.org/pdf/2502.12221}},
  month = {feb},
  note = {},
  title = {ReF Decompile: Relabeling and Function Call Enhanced Decompile},
  year = {2025}
}

@article{Fu2019,
  abstract = {Reverse engineering of binary executables is a critical problem in the computer security domain. On the one hand, malicious parties may recover interpretable source codes from the software products to gain commercial advantages. On the other hand, binary decompilation can be leveraged for code vulnerability analysis and malware detection. However, efficient binary decompilation is challenging. Conventional decompilers have the following major limitations: (i) they are only applicable to specific source-target language pair, hence incurs undesired development cost for new language tasks; (ii) their output high-level code cannot effectively preserve the correct functionality of the input binary; (iii) their output program does not capture the semantics of the input and the reversed program is hard to interpret. To address the above problems, we propose Coda, the first end-to-end neural-based framework for code decompilation. Coda decomposes the decompilation task into two key phases: First, Coda employs an instruction type-aware encoder and a tree decoder for generating an abstract syntax tree (AST) with attention feeding during the code sketch generation stage. Second, Coda then updates the code sketch using an iterative error correction machine guided by an ensembled neural error predictor. By finding a good approximate candidate and then fixing it towards perfect, Coda achieves superior performance compared to baseline approaches. We assess Coda's performance with extensive experiments on various benchmarks. Evaluation results show that Coda achieves an average of 82\% program recovery accuracy on unseen binary samples, where the state-of-the-art decompilers yield 0\% accuracy. Furthermore, Coda outperforms the sequence-to-sequence model with attention by a margin of 70\% program accuracy. },
  author = {Fu, Cheng AND Chen, Huili AND Liu, Haolan AND Chen, Xinyun AND Tian, Yuandong AND Koushanfar, Farinaz AND Zhao, Jishen},
  doi = {https://doi.org/10.48550/arXiv.1906.12029},
  howpublished = {\url{https://arxiv.org/pdf/1906.12029}},
  month = {jun},
  note = {},
  title = {A Neural-based Program Decompiler},
  year = {2019}
}

@article{Green2024,
  abstract = {Decompilers are widely used by security researchers and developers to reverse engineer executable code. While modern decompilers are adept at recovering instructions, control flow, and function boundaries, some useful information from the original source code, such as variable types and names, is lost during the compilation process. Our work aims to predict these variable types and names from the remaining information. We propose STRIDE, a lightweight technique that predicts variable names and types by matching sequences of decompiler tokens to those found in training data. We evaluate it on three benchmark datasets and find that STRIDE achieves comparable performance to state-of-the-art machine learning models for both variable retyping and renaming while being much simpler and faster. We perform a detailed comparison with two recent SOTA transformer-based models in order to understand the specific factors that make our technique effective. We implemented STRIDE in fewer than 1000 lines of Python and have open-sourced it under a permissive license at https://github.com/hgarrereyn/STRIDE. },
  author = {Green, Harrison AND Schwartz, J., Edward AND Goues, Le, Claire AND Vasilescu, Bogdan},
  doi = {https://doi.org/10.48550/arXiv.2407.02733},
  howpublished = {\url{https://arxiv.org/pdf/2407.02733}},
  month = {jul},
  note = {},
  title = {STRIDE: Simple Type Recognition In Decompiled Executables},
  year = {2024}
}

@article{Hosseini2022,
  abstract = {The problem of reversing the compilation process, decompilation, is an important tool in reverse engineering of computer software. Recently, researchers have proposed using techniques from neural machine translation to automate the process in decompilation. Although such techniques hold the promise of targeting a wider range of source and assembly languages, to date they have primarily targeted C code. In this paper we argue that existing neural decompilers have achieved higher accuracy at the cost of requiring language-specific domain knowledge such as tokenizers and parsers to build an abstract syntax tree (AST) for the source language, which increases the overhead of supporting new languages. We explore a different tradeoff that, to the extent possible, treats the assembly and source languages as plain text, and show that this allows us to build a decompiler that is easily retargetable to new languages. We evaluate our prototype decompiler, Beyond The C (BTC), on Go, Fortran, OCaml, and C, and examine the impact of parameters such as tokenization and training data selection on the quality of decompilation, finding that it achieves comparable decompilation results to prior work in neural decompilation with significantly less domain knowledge. We will release our training data, trained decompilation models, and code to help encourage future research into language-agnostic decompilation. },
  author = {Hosseini, Iman AND Dolan-Gavitt, Brendan},
  doi = {https://doi.org/10.48550/arXiv.2212.08950},
  howpublished = {\url{https://arxiv.org/pdf/2212.08950}},
  month = {dec},
  note = {},
  title = {Beyond the C: Retargetable Decompilation using Neural Machine Translation},
  year = {2022}
}

@article{Jiang2025,
  abstract = {Binary code analysis is the foundation of crucial tasks in the security domain; thus building effective binary analysis techniques is more important than ever. Large language models (LLMs) although have brought impressive improvement to source code tasks, do not directly generalize to assembly code due to the unique challenges of assembly: (1) the low information density of assembly and (2) the diverse optimizations in assembly code. To overcome these challenges, this work proposes a hierarchical attention mechanism that builds attention summaries to capture the semantics more effectively and designs contrastive learning objectives to train LLMs to learn assembly optimization. Equipped with these techniques, this work develops Nova, a generative LLM for assembly code. Nova outperforms existing techniques on binary code decompilation by up to 14.84 -- 21.58% (absolute percentage point improvement) higher Pass@1 and Pass@10, and outperforms the latest binary code similarity detection techniques by up to 6.17% Recall@1, showing promising abilities on both assembly generation and understanding tasks. },
  author = {Jiang, Nan AND Wang, Chengxiao AND Liu, Kevin AND Xu, Xiangzhe AND Tan, Lin AND Zhang, Xiangyu AND Babkin, Petr},
  doi = {https://doi.org/10.48550/arXiv.2311.13721},
  howpublished = {\url{https://arxiv.org/pdf/2311.13721}},
  month = {nov},
  note = {Published as a conference paper at ICLR 2025},
  title = {Nova: Generative Language Models for Assembly Code with Hierarchical Attention and Contrastive Learning},
  year = {2025}
}

@article{Katz2019,
  abstract = {We address the problem of automatic decompilation, converting a program in low-level representation back to a higher-level human-readable programming language. The problem of decompilation is extremely important for security researchers. Finding vulnerabilities and understanding how malware operates is much easier when done over source code. The importance of decompilation has motivated the construction of hand-crafted rule-based decompilers. Such decompilers have been designed by experts to detect specific control-flow structures and idioms in low-level code and lift them to source level. The cost of supporting additional languages or new language features in these models is very high. We present a novel approach to decompilation based on neural machine translation. The main idea is to automatically learn a decompiler from a given compiler. Given a compiler from a source language S to a target language T , our approach automatically trains a decompiler that can translate (decompile) T back to S . We used our framework to decompile both LLVM IR and x86 assembly to C code with high success rates. Using our LLVM and x86 instantiations, we were able to successfully decompile over 97% and 88% of our benchmarks respectively. },
  author = {Katz, Omer AND Olshaker, Yuval AND Goldberg, Yoav AND Yahav, Eran},
  doi = {https://doi.org/10.48550/arXiv.1905.08325},
  howpublished = {\url{https://arxiv.org/pdf/1905.08325}},
  month = {may},
  note = {},
  title = {Towards Neural Decompilation},
  year = {2019}
}

@article{Li2019,
  abstract = {Reverse Engineering(RE) has been a fundamental task in software engineering. However, most of the traditional Java reverse engineering tools are strictly rule defined, thus are not fault-tolerant, which pose serious problem when noise and interference were introduced into the system. In this paper, we view reverse engineering as a statistical machine translation task instead of rule-based task, and propose a fault-tolerant Java decompiler based on machine translation models. Our model is based on attention-based Neural Machine Translation (NMT) and Transformer architectures. First, we measure the translation quality on both the redundant and purified datasets. Next, we evaluate the fault-tolerance(anti-noise ability) of our framework on test sets with different unit error probability (UEP). In addition, we compare the suitability of different word segmentation algorithms for decompilation task. Experimental results demonstrate that our model is more robust and fault-tolerant compared to traditional Abstract Syntax Tree (AST) based decompilers. Specifically, in terms of BLEU-4 and Word Error Rate (WER), our performance has reached 94.50% and 2.65% on the redundant test set; 92.30% and 3.48% on the purified test set. },
  author = {Li, Zhiming AND Wu, Qing AND Qian, Kun},
  doi = {https://doi.org/10.48550/arXiv.1908.06748},
  howpublished = {\url{https://arxiv.org/pdf/1908.06748}},
  month = {oct},
  note = {8 pages},
  title = {Adabot: Fault-Tolerant Java Decompiler},
  year = {2019}
}

@article{Li2025,
  abstract = {Security patch detection (SPD) is crucial for maintaining software security, as unpatched vulnerabilities can lead to severe security risks. In recent years, numerous learning-based SPD approaches have demonstrated promising results on source code. However, these approaches typically cannot be applied to closed-source applications and proprietary systems that constitute a significant portion of real-world software, as they release patches only with binary files, and the source code is inaccessible. Given the impressive performance of code large language models (LLMs) in code intelligence and binary analysis tasks such as decompilation and compilation optimization, their potential for detecting binary security patches remains unexplored, exposing a significant research gap between their demonstrated low-level code understanding capabilities and this critical security task. To address this gap, we construct a large-scale binary patch dataset containing \textbf\{19,448\} samples, with two levels of representation: assembly code and pseudo-code, and systematically evaluate \textbf\{19\} code LLMs of varying scales to investigate their capability in binary SPD tasks. Our initial exploration demonstrates that directly prompting vanilla code LLMs struggles to accurately identify security patches from binary patches, and even state-of-the-art prompting techniques fail to mitigate the lack of domain knowledge in binary SPD within vanilla models. Drawing on the initial findings, we further investigate the fine-tuning strategy for injecting binary SPD domain knowledge into code LLMs through two levels of representation. Experimental results demonstrate that fine-tuned LLMs achieve outstanding performance, with the best results obtained on the pseudo-code representation. },
  author = {Li, Qingyuan AND Li, Binchang AND Gao, Cuiyun AND Gao, Shuzheng AND Li, Zongjie},
  doi = {https://doi.org/10.48550/arXiv.2509.06052},
  howpublished = {\url{https://arxiv.org/pdf/2509.06052}},
  month = {sep},
  note = {},
  title = {Empirical Study of Code Large Language Models for Binary Security Patch Detection},
  year = {2025}
}

@article{Liang2021,
  abstract = {Decompilation transforms low-level program languages (PL) (e.g., binary code) into high-level PLs (e.g., C/C++). It has been widely used when analysts perform security analysis on software (systems) whose source code is unavailable, such as vulnerability search and malware analysis. However, current decompilation tools usually need lots of experts' efforts, even for years, to generate the rules for decompilation, which also requires long-term maintenance as the syntax of high-level PL or low-level PL changes. Also, an ideal decompiler should concisely generate high-level PL with similar functionality to the source low-level PL and semantic information (e.g., meaningful variable names), just like human-written code. Unfortunately, existing manually-defined rule-based decompilation techniques only functionally restore the low-level PL to a similar high-level PL and are still powerless to recover semantic information. In this paper, we propose a novel neural decompilation approach to translate low-level PL into accurate and user-friendly high-level PL, effectively improving its readability and understandability. Furthermore, we implement the proposed approaches called SEAM. Evaluations on four real-world applications show that SEAM has an average accuracy of 94.41%, which is much better than prior neural machine translation (NMT) models. Finally, we evaluate the effectiveness of semantic information recovery through a questionnaire survey, and the average accuracy is 92.64%, which is comparable or superior to the state-of-the-art compilers. },
  author = {Liang, Ruigang AND Cao, Ying AND Hu, Peiwei AND He, Jinwen AND Chen, Kai},
  doi = {https://doi.org/10.48550/arXiv.2112.15491},
  howpublished = {\url{https://arxiv.org/pdf/2112.15491}},
  month = {dec},
  note = {},
  title = {Semantics-Recovering Decompilation through Neural Machine Translation},
  year = {2021}
}

@article{Liu2022,
  abstract = {Due to their widespread use on heterogeneous hardware devices, deep learning (DL) models are compiled into executables by DL compilers to fully leverage low-level hardware primitives. This approach allows DL computations to be undertaken at low cost across a variety of computing platforms, including CPUs, GPUs, and various hardware accelerators. We present BTD (Bin to DNN), a decompiler for deep neural network (DNN) executables. BTD takes DNN executables and outputs full model specifications, including types of DNN operators, network topology, dimensions, and parameters that are (nearly) identical to those of the input models. BTD delivers a practical framework to process DNN executables compiled by different DL compilers and with full optimizations enabled on x86 platforms. It employs learning-based techniques to infer DNN operators, dynamic analysis to reveal network architectures, and symbolic execution to facilitate inferring dimensions and parameters of DNN operators. Our evaluation reveals that BTD enables accurate recovery of full specifications of complex DNNs with millions of parameters (e.g., ResNet). The recovered DNN specifications can be re-compiled into a new DNN executable exhibiting identical behavior to the input executable. We show that BTD can boost two representative attacks, adversarial example generation and knowledge stealing, against DNN executables. We also demonstrate cross-architecture legacy code reuse using BTD, and envision BTD being used for other critical downstream tasks like DNN security hardening and patching. },
  author = {Liu, Zhibo AND Yuan, Yuanyuan AND Wang, Shuai AND Xie, Xiaofei AND Ma, Lei},
  doi = {https://doi.org/10.48550/arXiv.2210.01075},
  howpublished = {\url{https://arxiv.org/pdf/2210.01075}},
  month = {oct},
  note = {The extended version of a paper to appear in the Proceedings of the 32nd USENIX Security Symposium, 2023, (USENIX Security '23), 25 pages},
  title = {Decompiling x86 Deep Neural Network Executables},
  year = {2022}
}

@article{Liu2025,
  abstract = {Binary decompilation plays a vital role in various cybersecurity and software engineering tasks. Recently, end-to-end decompilation methods powered by large language models (LLMs) have garnered significant attention due to their ability to generate highly readable source code with minimal human intervention. However, existing LLM-based approaches face several critical challenges, including limited capability in reconstructing code structure and logic, low accuracy in data recovery, concerns over data security and privacy, and high computational resource requirements. To address these issues, we develop the CodeInverter Suite, making three contributions: (1) the CodeInverter Workflow (CIW) is a novel prompt engineering workflow that incorporates control flow graphs (CFG) and explicit data mappings to improve LLM-based decompilation. (2) Using CIW on well-known source code datasets, we curate the CodeInverter Dataset (CID), a domain-specific dataset containing 8.69 million samples that contains CFGs and data mapping tables. (3) We train the CoderInverter Models (CIMs) on CID, generating two lightweight LLMs (with 1.3B and 6.7B parameters) intended for efficient inference in privacy-sensitive or resource-constrained environments. Extensive experiments on two benchmarks demonstrate that the CIW substantially enhances the performance of various LLMs across multiple metrics. Our CIM-6.7B can achieve state-of-the-art decompilation performance, outperforming existing LLMs even with over 100x more parameters in decompilation tasks, an average improvement of 11.03% in re-executability, 6.27% in edit similarity. },
  author = {Liu, Peipei AND Sun, Jian AND Sun, Rongkang AND Chen, Li AND Yan, Zhaoteng AND Zhang, Peizheng AND Sun, Dapeng AND Wang, Dawei AND Zhang, Xiaoling AND Li, Dan},
  doi = {https://doi.org/10.48550/arXiv.2503.07215},
  howpublished = {\url{https://arxiv.org/pdf/2503.07215}},
  month = {may},
  note = {},
  title = {The CodeInverter Suite: Control-Flow and Data-Mapping Augmented Binary Decompilation with LLMs},
  year = {2025}
}

@article{Manuel2024,
  abstract = {Security experts reverse engineer (decompile) binary code to identify critical security vulnerabilities. The limited access to source code in vital systems - such as firmware, drivers, and proprietary software used in Critical Infrastructures (CI) - makes this analysis even more crucial on the binary level. Even with available source code, a semantic gap persists after compilation between the source and the binary code executed by the processor. This gap may hinder the detection of vulnerabilities in source code. That being said, current research on Large Language Models (LLMs) overlooks the significance of decompiled binaries in this area by focusing solely on source code. In this work, we are the first to empirically uncover the substantial semantic limitations of state-of-the-art LLMs when it comes to analyzing vulnerabilities in decompiled binaries, largely due to the absence of relevant datasets. To bridge the gap, we introduce DeBinVul, a novel decompiled binary code vulnerability dataset. Our dataset is multi-architecture and multi-optimization, focusing on C/C++ due to their wide usage in CI and association with numerous vulnerabilities. Specifically, we curate 150,872 samples of vulnerable and non-vulnerable decompiled binary code for the task of (i) identifying; (ii) classifying; (iii) describing vulnerabilities; and (iv) recovering function names in the domain of decompiled binaries. Subsequently, we fine-tune state-of-the-art LLMs using DeBinVul and report on a performance increase of 19%, 24%, and 21% in the capabilities of CodeLlama, Llama3, and CodeGen2 respectively, in detecting binary code vulnerabilities. Additionally, using DeBinVul, we report a high performance of 80-90% on the vulnerability classification task. Furthermore, we report improved performance in function name recovery and vulnerability description tasks. },
  author = {Manuel, Dylan AND Islam, Tanveer, Nafis AND Khoury, Joseph AND Nunez, Ana AND Bou-Harb, Elias AND Najafirad, Peyman},
  doi = {https://doi.org/10.48550/arXiv.2411.04981},
  howpublished = {\url{https://arxiv.org/pdf/2411.04981}},
  month = {nov},
  note = {},
  title = {Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries},
  year = {2024}
}

@article{Su2026,
  abstract = {Blockchain systems are increasingly targeted by on-chain attacks that exploit contract vulnerabilities to extract value rapidly and stealthily, making systematic analysis and reproduction highly challenging. In practice, reproducing such attacks requires manually crafting proofs-of-concept (PoCs), a labor-intensive process that demands substantial expertise and scales poorly. In this work, we present the first automated framework for synthesizing verifiable PoCs directly from on-chain attack executions. Our key insight is that attacker logic can be recovered from low-level transaction traces via trace-driven reverse engineering, and then translated into executable exploits by leveraging the code-generation capabilities of large language models (LLMs). To this end, we propose TracExp, which localizes attack-relevant execution contexts from noisy, multi-contract traces and introduces a novel dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode. Guided by this representation, TracExp synthesizes PoCs and refines them to preserve exploitability-relevant semantics. We evaluate TracExp on 321 real-world attacks over the past 20 months. TracExp successfully synthesizes PoCs for 93% of incidents, with 58.78% being directly verifiable, at an average cost of only \$0.07 per case. Moreover, TracExp enabled the release of a large number of previously unavailable PoCs to the community, earning a $900 bounty and demonstrating strong practical impact. },
  author = {Su, Xing AND Wu, Hao AND Liang, Hanzhong AND Jiang, Yunlin AND Cheng, Yuxi AND Liu, Yating AND Xu, Fengyuan},
  doi = {https://doi.org/10.48550/arXiv.2601.16681},
  howpublished = {\url{https://arxiv.org/pdf/2601.16681}},
  month = {jan},
  note = {14 pages, 10 figures},
  title = {From Transactions to Exploits: Automated PoC Synthesis for Real-World DeFi Attacks},
  year = {2026}
}

@article{Szafraniec2023,
  abstract = {In this paper, we leverage low-level compiler intermediate representations (IR) to improve code translation. Traditional transpilers rely on syntactic information and handcrafted rules, which limits their applicability and produces unnatural-looking code. Applying neural machine translation (NMT) approaches to code has successfully broadened the set of programs on which one can get a natural-looking translation. However, they treat the code as sequences of text tokens, and still do not differentiate well enough between similar pieces of code which have different semantics in different languages. The consequence is low quality translation, reducing the practicality of NMT, and stressing the need for an approach significantly increasing its accuracy. Here we propose to augment code translation with IRs, specifically LLVM IR, with results on the C++, Java, Rust, and Go languages. Our method improves upon the state of the art for unsupervised code translation, increasing the number of correct translations by 11% on average, and up to 79% for the Java -> Rust pair with greedy decoding. We extend previous test sets for code translation, by adding hundreds of Go and Rust functions. Additionally, we train models with high performance on the problem of IR decompilation, generating programming source code from IR, and study using IRs as intermediary pivot for translation. },
  author = {Szafraniec, Marc AND Roziere, Baptiste AND Leather, Hugh AND Charton, Francois AND Labatut, Patrick AND Synnaeve, Gabriel},
  doi = {https://doi.org/10.48550/arXiv.2207.03578},
  howpublished = {\url{https://arxiv.org/pdf/2207.03578}},
  month = {apr},
  note = {9 pages},
  title = {Code Translation with Compiler Representations},
  year = {2023}
}

@article{Tan2024,
  abstract = {Decompilation aims to convert binary code to high-level source code, but traditional tools like Ghidra often produce results that are difficult to read and execute. Motivated by the advancements in Large Language Models (LLMs), we propose LLM4Decompile, the first and largest open-source LLM series (1.3B to 33B) trained to decompile binary code. We optimize the LLM training process and introduce the LLM4Decompile-End models to decompile binary directly. The resulting models significantly outperform GPT-4o and Ghidra on the HumanEval and ExeBench benchmarks by over 100% in terms of re-executability rate. Additionally, we improve the standard refinement approach to fine-tune the LLM4Decompile-Ref models, enabling them to effectively refine the decompiled code from Ghidra and achieve a further 16.2% improvement over the LLM4Decompile-End. LLM4Decompile demonstrates the potential of LLMs to revolutionize binary code decompilation, delivering remarkable improvements in readability and executability while complementing conventional tools for optimal results. Our code, dataset, and models are released at https://github.com/albertan017/LLM4Decompile },
  author = {Tan, Hanzhuo AND Luo, Qi AND Li, Jing AND Zhang, Yuqun},
  doi = {https://doi.org/10.48550/arXiv.2403.05286},
  howpublished = {\url{https://arxiv.org/pdf/2403.05286}},
  month = {oct},
  note = {},
  title = {LLM4Decompile: Decompiling Binary Code with Large Language Models},
  year = {2024}
}

@article{Tan2025,
  abstract = {Recent advances in LLM-based decompilers have been shown effective to convert low-level binaries into human-readable source code. However, there still lacks a comprehensive benchmark that provides large-scale binary-source function pairs, which is critical for advancing the LLM decompilation technology. Creating accurate binary-source mappings incurs severe issues caused by complex compilation settings and widespread function inlining that obscure the correspondence between binaries and their original source code. Previous efforts have either relied on used contest-style benchmarks, synthetic binary-source mappings that diverge significantly from the mappings in real world, or partially matched binaries with only code lines or variable names, compromising the effectiveness of analyzing the binary functionality. To alleviate these issues, we introduce Decompile-Bench, the first open-source dataset comprising two million binary-source function pairs condensed from 100 million collected function pairs, i.e., 450GB of binaries compiled from permissively licensed GitHub projects. For the evaluation purposes, we also developed a benchmark Decompile-Bench-Eval including manually crafted binaries from the well-established HumanEval and MBPP, alongside the compiled GitHub repositories released after 2025 to mitigate data leakage issues. We further explore commonly-used evaluation metrics to provide a thorough assessment of the studied LLM decompilers and find that fine-tuning with Decompile-Bench causes a 20% improvement over previous benchmarks in terms of the re-executability rate. Our code and data has been released in HuggingFace and Github. https://github.com/albertan017/LLM4Decompile },
  author = {Tan, Hanzhuo AND Tian, Xiaolong AND Qi, Hanrui AND Liu, Jiaming AND Gao, Zuchen AND Wang, Siyi AND Luo, Qi AND Li, Jing AND Zhang, Yuqun},
  doi = {https://doi.org/10.48550/arXiv.2505.12668},
  howpublished = {\url{https://arxiv.org/pdf/2505.12668}},
  month = {oct},
  note = {},
  title = {Decompile-Bench: Million-Scale Binary-Source Function Pairs for Real-World Binary Decompilation},
  year = {2025}
}

@article{Thurnherr2024,
  abstract = {Recently, the transformer architecture has enabled substantial progress in many areas of pattern recognition and machine learning. However, as with other neural network models, there is currently no general method available to explain their inner workings. The present paper represents a first step towards this direction. We utilize \textit\{Transformer Compiler for RASP\} (Tracr) to generate a large dataset of pairs of transformer weights and corresponding RASP programs. Based on this dataset, we then build and train a model, with the aim of recovering the RASP code from the compiled model. We demonstrate that the simple form of Tracr compiled transformer weights is interpretable for such a decompiler model. In an empirical evaluation, our model achieves exact reproductions on more than 30\% of the test objects, while the remaining 70\% can generally be reproduced with only few errors. Additionally, more than 70\% of the programs, produced by our model, are functionally equivalent to the ground truth, and therefore a valid decompilation of the Tracr compiled transformer weights. },
  author = {Thurnherr, Hannes AND Riesen, Kaspar},
  doi = {https://doi.org/10.48550/arXiv.2410.00061},
  howpublished = {\url{https://arxiv.org/pdf/2410.00061}},
  month = {sep},
  note = {},
  title = {Neural Decompiling of Tracr Transformers},
  year = {2024}
}

@article{Wong2023,
  abstract = {A C decompiler converts an executable into source code. The recovered C source code, once re-compiled, is expected to produce an executable with the same functionality as the original executable. With over twenty years of development, C decompilers have been widely used in production to support reverse engineering applications. Despite the prosperous development of C decompilers, it is widely acknowledged that decompiler outputs are mainly used for human consumption, and are not suitable for automatic recompilation. Often, a substantial amount of manual effort is required to fix the decompiler outputs before they can be recompiled and executed properly. This paper is motived by the recent success of large language models (LLMs) in comprehending dense corpus of natural language. To alleviate the tedious, costly and often error-prone manual effort in fixing decompiler outputs, we investigate the feasibility of using LLMs to augment decompiler outputs, thus delivering recompilable decompilation. Note that different from previous efforts that focus on augmenting decompiler outputs with higher readability (e.g., recovering type/variable names), we focus on augmenting decompiler outputs with recompilability, meaning to generate code that can be recompiled into an executable with the same functionality as the original executable. We conduct a pilot study to characterize the obstacles in recompiling the outputs of the de facto commercial C decompiler -- IDA-Pro. We then propose a two-step, hybrid approach to augmenting decompiler outputs with LLMs. We evaluate our approach on a set of popular C test cases, and show that our approach can deliver a high recompilation success rate to over 75% with moderate effort, whereas none of the IDA-Pro's original outputs can be recompiled. We conclude with a discussion on the limitations of our approach and promising future research directions. },
  author = {Wong, Kin, Wai AND Wang, Huaijin AND Li, Zongjie AND Liu, Zhibo AND Wang, Shuai AND Tang, Qiyi AND Nie, Sen AND Wu, Shi},
  doi = {https://doi.org/10.48550/arXiv.2310.06530},
  howpublished = {\url{https://arxiv.org/pdf/2310.06530}},
  month = {nov},
  note = {},
  title = {Refining Decompiled C Code with Large Language Models},
  year = {2023}
}

@article{WOS:000415662500002,
  abstract = {Existing decompilers use rule-based algorithms to transform unstructured
Control flow graph (CFG) into equivalent high-level programming language
constructs with ``goto{''} statements. One problem of such approaches is
that they generate a large number of ``goto{''}s in the output code,
which reduce the readability and hinder the understanding of input
binaries. A global search algorithm is proposed based on structural
analysis. This algorithm restructures a CFG and generates fewer number
of ``goto{''} statements than the rule-based algorithm does. We also
present a Genetic algorithm (GA) for the global search approach to
locate near optimal solutions for large CFGs. Evaluation results on a
set of real CFGs show that the genetic algorithm-based heuristic for
global search is capable of finding high-quality solutions.},
  address = {26-28 AU PUI WAN ST, STE 1102, FO TAN INDUSTRIAL CENTRE, FO TAN, SHATIN,
00000, PEOPLES R CHINA},
  affiliation = {Ji, WX (Corresponding Author), Beijing Inst Technol, Beijing 100081, Peoples R China.
Ji Weixing; Huo Yuanhong; Wang Yizhuo; Gao Yujin; Shi Feng, Beijing Inst Technol, Beijing 100081, Peoples R China.},
  affiliations = {Beijing Institute of Technology},
  author = {Ji Weixing and Huo Yuanhong and Wang Yizhuo and Gao Yujin and Shi Feng},
  author-email = {jwx@bit.edu.cn
hyh@bit.edu.cn
frankwyz@bit.edu.cn
paulgyj@bit.edu.cn
bitsf@bit.edu.cn},
  cited-references = {AMMARGUELLAT Z, 1992, IEEE T SOFTWARE ENG, V18, P237, DOI 10.1109/32.126773.
ARM Ltd. and ARM Germany GmbH, 2015, KEIL C51 C COMP.
Ashcroft E., 1979, CLASSICS SOFTWARE EN.
BAKER AL, 1980, IEEE T SOFTWARE ENG, V6, P506, DOI 10.1109/TSE.1980.230799.
BAKER BS, 1977, J ACM, V24, P98, DOI 10.1145/321992.321999.
Bao T, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P845.
{[}陈芳园 Chen Fangyuan], 2012, {[}电子学报, Acta Electronica Sinica], V40, P1372.
Chen GBA, 2013, SOFTWARE PRACT EXPER, V43, P1337, DOI 10.1002/spe.2138.
Chen Ping, 2010, Acta Electronica Sinica, V38, P1741.
Cifuentes C., 1992, P 19 C LAT INF, P257.
Cifuentes Cristina, 1993, P 19 C LAT INF AT, P267.
EROSA AM, 1994, PROCEEDINGS OF THE 1994 INTERNATIONAL CONFERENCE ON COMPUTER LANGUAGES, P229, DOI 10.1109/ICCL.1994.288377.
Flatassembler, 2015, FLAT ASS.
Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739.
Holland J., 1975, Adaptive in Natural and artificial Systems.
Knuth D. E., 1971, Information Processing Letters, V1, P23, DOI 10.1016/0020-0190(71)90018-4.
LICHTBLAU U, 1985, PROC INT JOINT C, V185, P284.
Muchnick S.S., 1997, Advanced Compiler Design and Implementation.
Naeem NA, 2006, INT C PROGRAM COMPRE, P327, DOI 10.1109/ICPC.2006.40.
OULSNAM G, 1982, COMPUT J, V25, P379, DOI 10.1093/comjnl/25.3.379.
Pfeffer T.F., 2014, P 7 INT C SEC INF NE, P345.
RAMSHAW L, 1988, J ACM, V35, P893, DOI 10.1145/48014.48021.
{[}任武 Ren Wu], 2013, {[}电子学报, Acta Electronica Sinica], V41, P1412.
Troshina K., 2009, P INT WORKSHOP PROGR, P18.
Williams M.H., 1997, COMPUT J, V20, P45.
WILLIAMS MH, 1985, COMPUT J, V28, P134, DOI 10.1093/comjnl/28.2.134.},
  da = {2026-02-04},
  doc-delivery-number = {FN0IW},
  doi = {10.1049/cje.2017.09.003},
  eissn = {2075-5597},
  funding-acknowledgement = {National Natural Science Foundation of China {[}61300010]},
  funding-text = {This work is supported by the National Natural Science Foundation of
China (No.61300010).},
  issn = {1022-4653},
  journal = {CHINESE JOURNAL OF ELECTRONICS},
  journal-iso = {Chin. J. Electron.},
  keywords = {Decompiling; Control flow graph restructuring; Structural analysis;
Genetic algorithm (GA)},
  keywords-plus = {PROGRAMS},
  language = {English},
  month = {NOV},
  number = {6},
  number-of-cited-references = {26},
  oa = {Bronze},
  pages = {1118-1124},
  publisher = {TECHNOLOGY EXCHANGE LIMITED HONG KONG},
  research-areas = {Engineering},
  researcherid-numbers = {wang, yizhuo/LXW-7659-2024},
  times-cited = {0},
  title = {Control Structure Analysis and Recovery of Embedded Binaries},
  type = {Article},
  unique-id = {WOS:000415662500002},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {11},
  volume = {26},
  web-of-science-categories = {Engineering, Electrical \& Electronic},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
  year = {2017}
}

@article{WOS:000672841700001,
  abstract = {Decompilation aims to analyze and transform low-level program language
(PL) codes such as binary code or assembly code to obtain an equivalent
high-level PL. Decompilation plays a vital role in the cyberspace
security fields such as software vulnerability discovery and analysis,
malicious code detection and analysis, and software engineering fields
such as source code analysis, optimization, and cross-language
cross-operating system migration. Unfortunately, the existing
decompilers mainly rely on experts to write rules, which leads to
bottlenecks such as low scalability, development difficulties, and long
cycles. The generated high-level PL codes often violate the code writing
specifications. Further, their readability is still relatively low. The
problems mentioned above hinder the efficiency of advanced applications
(e.g., vulnerability discovery) based on decompiled high-level PL
codes.In this paper, we propose a decompilation approach based on the
attention-based neural machine translation (NMT) mechanism, which
converts low-level PL into high-level PL while acquiring legibility and
keeping functionally similar. To compensate for the information
asymmetry between the low-level and high-level PL, a translation method
based on basic operations of low-level PL is designed. This method
improves the generalization of the NMT model and captures the
translation rules between PLs more accurately and efficiently. Besides,
we implement a neural decompilation framework called Neutron. The
evaluation of two practical applications shows that Neutron's average
program accuracy is 96.96\%, which is better than the traditional NMT
model.},
  address = {CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND},
  affiliation = {Liang, RG; Chen, K (Corresponding Author), Chinese Acad Sci, Inst Informat Engn, SKLOIS, Beijing 100093, Peoples R China.
Liang, RG; Chen, K (Corresponding Author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100049, Peoples R China.
Liang, Ruigang; Cao, Ying; Hu, Peiwei; Chen, Kai, Chinese Acad Sci, Inst Informat Engn, SKLOIS, Beijing 100093, Peoples R China.
Liang, Ruigang; Cao, Ying; Hu, Peiwei; Chen, Kai, Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100049, Peoples R China.},
  affiliations = {Chinese Academy of Sciences; Institute of Information Engineering, CAS;
Chinese Academy of Sciences; University of Chinese Academy of Sciences,
CAS},
  article-number = {5},
  author = {Liang, Ruigang and Cao, Ying and Hu, Peiwei and Chen, Kai},
  author-email = {liangruigang@iie.ac.cn
chenkai@iie.ac.cn},
  cited-references = {Allamanis M, 2015, PR MACH LEARN RES, V37, P2123.
{[}Anonymous], 2020, MATH C LIB.
Durfina L, 2013, WORK CONF REVERSE EN, P449, DOI 10.1109/WCRE.2013.6671321.
Fu C, 2019, ADV NEUR IN, V32.
Heo K, 2017, PROC INT CONF SOFTW, P519, DOI 10.1109/ICSE.2017.54.
Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI {[}10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1].
Katz DS, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2018), P346, DOI 10.1109/SANER.2018.8330222.
Katz Omer, 2019, CoRR.
Koustek J., 2017, Retdec: An open-source machine-code decompiler.
Levy D, 2017, PR MACH LEARN RES, V70.
Liu ZB, 2020, PROCEEDINGS OF THE 29TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2020, P475, DOI 10.1145/3395363.3397370.
Loyola P, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P287, DOI 10.18653/v1/P17-2045.
Luong T., 2015, P 2015 C EMPIRICAL M, P1412, DOI DOI 10.18653/V1/D15-1166.
Medress M. F., 1977, Artificial Intelligence, V9, P307, DOI 10.1016/0004-3702(77)90026-1.
PEARLMUTTER BA, 1995, IEEE T NEURAL NETWOR, V6, P1212, DOI 10.1109/72.410363.
Peng C., 2018, 25 ANN NETWORK DISTR, DOI DOI 10.14722/NDSS.2018.23158.
Peng F, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P829.
Schkufza E, 2013, ACM SIGPLAN NOTICES, V48, P305, DOI 10.1145/2499368.2451150.
Schwartz Edward J., 2013, Proceedings of the 22nd USENIX Security Symposium. Security `13, P353.
Shi T, 2018, ACM T DATA SCI, V2.
Shoshitaishvili Y, 2016, P IEEE S SECUR PRIV, P138, DOI 10.1109/SP.2016.17.
Sutskever I, 2014, ADV NEUR IN, V27.
tensor, 2020, TENSOR 2TENSOR.
urfina L, 2011, P 2 INT C CIRC SYST, P199.
Wang Y, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P1914, DOI 10.1145/3243734.3243847.
Warren H.S., 2012, HACKERS DELIGHT, V2nd.
Wu Y, 2016, ARXIV160908144, DOI {[}10.1145/3234150, DOI 10.1145/3234150].
Yadegari B, 2015, P IEEE S SECUR PRIV, P674, DOI 10.1109/SP.2015.47.
Yakdan K, 2015, MORE GOTOS DECOMPILA.
Yakdan K, 2016, P IEEE S SECUR PRIV, P158, DOI 10.1109/SP.2016.18.
Yang XJ, 2011, PLDI 11: PROCEEDINGS OF THE 2011 ACM CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P283.
Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10.
You W, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2139, DOI 10.1145/3133956.3134085.
Zong PY, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2255.},
  da = {2026-02-04},
  doc-delivery-number = {TI5KP},
  doi = {10.1186/s42400-021-00070-0},
  funding-acknowledgement = {NSFC {[}U1836211]},
  funding-text = {Our research was supported by NSFC U1836211. And the recipient is
Professor Kai Chen.},
  issn = {2523-3246},
  journal = {CYBERSECURITY},
  journal-iso = {Cybersecurity},
  keywords = {Decompilation; LSTM; Attention; Translation},
  language = {English},
  month = {MAR 5},
  number = {1},
  number-of-cited-references = {34},
  oa = {Green Submitted, gold},
  publisher = {SPRINGERNATURE},
  research-areas = {Computer Science},
  researcherid-numbers = {Liang, Ruigang/HQZ-6397-2023},
  times-cited = {12},
  title = {Neutron: an attention-based neural decompiler},
  type = {Article},
  unique-id = {WOS:000672841700001},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {7},
  volume = {4},
  web-of-science-categories = {Computer Science, Information Systems; Computer Science,
Interdisciplinary Applications; Computer Science, Software Engineering},
  web-of-science-index = {Emerging Sources Citation Index (ESCI)},
  year = {2021}
}

@article{WOS:000870301800008,
  abstract = {Much software, whether beneficent or malevolent, is distributed only as
binaries, sans source code. Absent source code, understanding binaries'
behavior can be quite challenging, especially when compiled under higher
levels of compiler optimization. These optimizations can transform
comprehensible, ``natural{''} source constructions into something
entirely unrecognizable. Reverse engineering binaries, especially those
suspected of being malevolent or guilty of intellectual property theft,
are important and time-consuming tasks. There is a great deal of
interest in tools to ``decompile{''} binaries back into more natural
source code to aid reverse engineering. Decompilation involves several
desirable steps, including recreating source-language constructions,
variable names, and perhaps even comments. One central step in creating
binaries is optimizing function calls, using steps such as inlining.
Recovering these (possibly inlined) function calls from optimized
binaries is an essential task that most state-of-the-art decompiler
tools try to do but do not perform very well. In this paper, we evaluate
a supervised learning approach to the problem of recovering optimized
function calls. We leverage open-source software and develop an
automated labeling scheme to generate a reasonably large dataset of
binaries labeled with actual function usages. We augment this large but
limited labeled dataset with a pre-training step, which learns the
decompiled code statistics from a much larger unlabeled dataset. Thus
augmented, our learned labeling model can be combined with an existing
decompilation tool, Ghidra, to achieve substantially improved
performance in function call recovery, especially at higher levels of
optimization.},
  address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
  affiliation = {Ahmed, T (Corresponding Author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
Ahmed, Toufique; Devanbu, Premkumar; Sawant, Anand Ashok, Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.},
  affiliations = {University of California System; University of California Davis},
  author = {Ahmed, Toufique and Devanbu, Premkumar and Sawant, Anand Ashok},
  author-email = {tfahmed@ucdavis.edu
ptdevanbu@ucdavis.edu
asawant@ucdavis.edu},
  cited-references = {{[}Anonymous], 2008, UTDCS0508.
{[}Anonymous], 2020, TRAVIS BUILD UTILITY.
{[}Anonymous], 2020, DOCKER CONTAINERS CR.
{[}Anonymous], 2020, HUGGINGFACE TRANSFOR.
{[}Anonymous], 2020, BUGSWARMGITHUBORY RE.
{[}Anonymous], 2020, TRAVIS DOCKERHUB REP.
Bao T, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P845.
Bayer U., 2006, THESIS TU VIENNA VIE.
BE H. B., 2020, HEXRAYS IDA PRO.
BE H. B., 2020, HEXRAYS IDA PROINLIN.
BE H. B., FLIRT SIGNATURES.
Blinded, 2020, REPLICATION PACKAGE, DOI {[}10.5281/zenodo.4007527, DOI 10.5281/ZENODO.4007527].
Casalnuovo C, 2019, EMPIR SOFTW ENG, V24, P1823, DOI 10.1007/s10664-018-9669-7.
CHIKOFSKY EJ, 1990, IEEE SOFTWARE, V7, P13, DOI 10.1109/52.43044.
Collard ML, 2011, IEEE INT WORK C SO, P173, DOI 10.1109/SCAM.2011.19.
David Y, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428293.
Devlin J, 2019, Arxiv, DOI {[}arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805, 10.48550/arXiv.1810.04805].
Docker, 2020, DOCK JOB MATR CONF.
Eisenbarth T, 2001, PROC IEEE INT CONF S, P602, DOI 10.1109/ICSM.2001.972777.
Feng ZY, 2020, Arxiv, DOI arXiv:2002.08155.
He JX, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P1667, DOI 10.1145/3243734.3243866.
Hunt G, 1999, PROCEEDINGS OF THE 3RD USENIX WINDOWS NT SYMPOSIUM, P135.
Islam R, 2013, J NETW COMPUT APPL, V36, P646, DOI 10.1016/j.jnca.2012.10.004.
Kanade A, 2020, PR MACH LEARN RES, V119.
Katz O, 2019, Arxiv, DOI arXiv:1905.08325.
Lacomis J, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P640, DOI 10.1109/ASE.2019.00064.
Liu YH, 2019, Arxiv, DOI {[}arXiv:1907.11692, 10.48550/arXiv.1907.11692, DOI 10.48550/ARXIV.1907.11692(APP.SCINITO.AI)].
NSA, 2020, GHIDRA.
Pei KX, 2020, Arxiv, DOI arXiv:2010.00770.
Qiu J, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P261, DOI 10.1109/SANER.2015.7081836.
Qiu J, 2016, IEEE T SOFTWARE ENG, V42, P187, DOI 10.1109/TSE.2015.2470241.
Ronghua Tian, 2010, 2010 5th International Conference on Malicious and Unwanted Software (MALWARE 2010), P23, DOI 10.1109/MALWARE.2010.5665796.
Schultz MG, 2001, P IEEE S SECUR PRIV, P38, DOI 10.1109/SECPRI.2001.924286.
Shin ECR, 2015, PROCEEDINGS OF THE 24TH USENIX SECURITY SYMPOSIUM, P611.
Shirani P, 2017, LECT NOTES COMPUT SC, V10327, P301, DOI 10.1007/978-3-319-60876-1\_14.
Song D, 2008, LECT NOTES COMPUT SC, V5352, P1, DOI 10.1007/978-3-540-89862-7\_1.
Tomassi DA, 2019, PROC INT CONF SOFTW, P339, DOI 10.1109/ICSE.2019.00048.
Vaswani A, 2017, ADV NEUR IN, V30.
Wang S, 2017, PROC IEEE INT CONF S, P388, DOI 10.1109/ICSME.2017.59.
Wang TY, 2006, IEEE C EVOL COMPUTAT, P3221.
Willems C, 2007, IEEE SECUR PRIV, V5, P32, DOI 10.1109/MSP.2007.45.
Ye YF, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3073559.
Ye YF, 2010, J INTELL INF SYST, V35, P1, DOI 10.1007/s10844-009-0086-7.
Ye YF, 2010, IEEE T SYST MAN CY C, V40, P298, DOI 10.1109/TSMCC.2009.2037978.
Ye YF, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1385.
Ye YF, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1043.},
  da = {2026-02-04},
  doc-delivery-number = {5L3GA},
  doi = {10.1109/TSE.2021.3106572},
  eissn = {1939-3520},
  funding-acknowledgement = {NSF CISE (SHF LARGE) {[}1414172]; Sandia National Laboratories; Dean's
Distinguished Graduate Fellowship, UC Davis},
  funding-text = {This work was supported in part by NSF CISE (SHF LARGE) under Grant
1414172, and in part by Sandia National Laboratories. The work of
Toufique Ahmed was supported by a Dean's Distinguished Graduate
Fellowship, UC Davis. This article was much improved as a result of
reviewers' comments, forwhich the authors are thankful.},
  issn = {0098-5589},
  journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
  journal-iso = {IEEE Trans. Softw. Eng.},
  keywords = {Libraries; Tools; Optimization; Databases; Reverse engineering;
Training; Malware; Reverse engineering; software modeling; deep learning},
  language = {English},
  month = {OCT 1},
  number = {10},
  number-of-cited-references = {46},
  oa = {Green Submitted},
  orcid-numbers = {Sawant, Anand/0000-0002-5816-8020
Ahmed, Toufique/0000-0002-4427-1350},
  pages = {3862-3876},
  publisher = {IEEE COMPUTER SOC},
  research-areas = {Computer Science; Engineering},
  times-cited = {6},
  title = {Learning to Find Usages of Library Functions in Optimized Binaries},
  type = {Article},
  unique-id = {WOS:000870301800008},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {4},
  volume = {48},
  web-of-science-categories = {Computer Science, Software Engineering; Engineering, Electrical \&
Electronic},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
  year = {2022}
}

@article{WOS:000970588900012,
  abstract = {The decompiler is one of the most common tools for examining executable
binaries without the corresponding source code. It transforms binaries
into high-level code, reversing the compilation process. Unfortunately,
decompiler output is far from readable because the decompilation process
is often incomplete. State-of-the-art techniques use machine learning to
predict missing information like variable names. While these approaches
are often able to suggest good variable names in context, no existing
work examines how the selection of training data influences these
machine learning models. We investigate how data provenance and the
quality of training data affect performance, and how well, if at all,
trained models generalize across software domains. We focus on the
variable renaming problem using one such machine learning model, DIRE.
We first describe DIRE in detail and the accompanying technique used to
generate training data from raw code. We also evaluate DIRE's overall
performance without respect to data quality. Next, we show how training
on more popular, possibly higher quality code (measured using GitHub
stars) leads to a more generalizable model because popular code tends to
have more diverse variable names. Finally, we evaluate how well DIRE
predicts domain-specific identifiers, propose a modification to
incorporate domain information, and show that it can predict identifiers
in domain-specific scenarios 23\% more frequently than the original DIRE
model.},
  address = {1601 Broadway, 10th Floor, NEW YORK, NY USA},
  affiliation = {Dramko, L (Corresponding Author), Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
Dramko, Luke; Lacomis, Jeremy; Yin, Pengcheng; Neubig, Graham; Vasilescu, Bogdan; Le Goues, Claire, Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
Schwartz, Ed, Carnegie Mellon Univ, Software Engn Inst, Pittsburgh, PA 15213 USA.
Allamanis, Miltiadis, Microsoft Res, Cambridge, England.},
  affiliations = {Carnegie Mellon University; Carnegie Mellon University; Microsoft;
Microsoft United Kingdom},
  article-number = {39},
  author = {Dramko, Luke and Lacomis, Jeremy and Yin, Pengcheng and Schwartz, Ed and
Allamanis, Miltiadis and Neubig, Graham and Vasilescu, Bogdan and Le
Goues, Claire},
  author-email = {lukedram@andrew.cmu.edu
jlacomis@cs.cmu.edu
pcyin@cs.cmu.edu
eschwartz@cert.org
miallama@microsoft.com
gneubig@cs.cmu.edu
vasilescu@cmu.edu
clegoues@cs.cmu.edu},
  cited-references = {Allamams M, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE (ONWARD!' 19), P143, DOI 10.1145/3359591.3359735.
Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695.
Allamanis M, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P38, DOI 10.1145/2786805.2786849.
Allamanis M, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P281, DOI 10.1145/2635868.2635883.
Allamanis Miltiadis., 2018, INT C LEARNING REPRE.
Alon U., 2019, ICLR.
Arnaoudova V, 2014, IEEE T SOFTWARE ENG, V40, P502, DOI 10.1109/TSE.2014.2312942.
Borges H, 2018, J SYST SOFTWARE, V146, P112, DOI 10.1016/j.jss.2018.09.016.
Chen QB, 2022, PROC INT CONF SOFTW, P2327, DOI 10.1145/3510003.3510162.
Chen Qibin, 2022, USENIX SECURITY S US.
Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044.
Cho Kyunghyun., 2014, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing EMNLP, P1724, DOI DOI 10.3115/V1/D14-1179.
Devanbu P, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P543, DOI 10.1109/ICSE.2015.190.
Durfina L, 2013, WORK CONF REVERSE EN, P449, DOI 10.1109/WCRE.2013.6671321.
Eager MichaelJ., 2012, Introduction to the DWARF Debugging Format{''}. In.
Gellenbeck E. M., 1991, Empirical Studies of Programmers: Fourth Workshop, P65.
Ghidra, 2019, GHIDR DEC.
Gilmer J, 2017, PR MACH LEARN RES, V70.
Gousios G, 2013, IEEE WORK CONF MIN S, P233, DOI 10.1109/MSR.2013.6624034.
Gowda T, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P3955.
He JX, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P1667, DOI 10.1145/3243734.3243866.
Hex-Rays, 2019, HEXRAYS DEC.
Hindle A, 2012, PROC INT CONF SOFTW, P837, DOI 10.1109/ICSE.2012.6227135.
Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI {[}10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1].
Jaffe A, 2018, INT C PROGRAM COMPRE, P20, DOI 10.1145/3196321.3196330.
JHU/APL Staff, 2019, ASS LAB LIB STAT AN.
Kang HJ, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P1, DOI 10.1109/ASE.2019.00011.
Karampatsis RM, 2020, PROC INT CONF SOFTW, P1073, DOI 10.1145/3377811.3380342.
Katz DS, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2018), P346, DOI 10.1109/SANER.2018.8330222.
Koyuncu Anil, 2019, INT C SOFTWARE ENG I, P1.
Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66.
Lacomis J, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P640, DOI 10.1109/ASE.2019.00064.
Lawrie D, 2006, INT C PROGRAM COMPRE, P3, DOI 10.1109/ICPC.2006.51.
Lee K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8424.
Li Y., 2016, INT C LEARNING REPRE.
Liu H, 2015, IEEE T SOFTWARE ENG, V41, P887, DOI 10.1109/TSE.2015.2427831.
Luong T., 2015, P 2015 C EMPIRICAL M, P1412, DOI DOI 10.18653/V1/D15-1166.
Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607.
Nitin Vikram, 2021, DIRECT TRANSFORMER B, P48.
Nussbaum Lucas, 2010, Proceedings of the 2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010), P52, DOI 10.1109/MSR.2010.5463277.
Press W.H., 2002, NUMERICAL RECIPES C, V2nd.
Le Q, 2014, PR MACH LEARN RES, V32, P1188.
Rabin MRI, 2021, INFORM SOFTWARE TECH, V135, DOI 10.1016/j.infsof.2021.106552.
Raychev V, 2015, ACM SIGPLAN NOTICES, V50, P111, DOI {[}10.1145/2676726.2677009, 10.1145/2775051.2677009].
RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0.
Salesky E, 2020, MACH TRANSL, V34, P41, DOI 10.1007/s10590-019-09243-8.
Salviulo F., 2014, Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering, P48, DOI DOI 10.1145/2601248.2601251.
Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605.
Schwartz Edward J., 2013, Proceedings of the 22nd USENIX Security Symposium. Security `13, P353.
Spinellis D, 2020, IEEE WORK CONF MIN S, P523, DOI 10.1145/3379597.3387496.
Trockman A, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P511, DOI 10.1145/3180155.3180209.
van Emmerik Michael James, 2007, THESIS U QUEENSLAND.
Vasilescu B, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P683, DOI 10.1145/3106237.3106289.
Vaswani A, 2017, ADV NEUR IN, V30.
Wang W., 2016, P 1 C MACH TRANSL, P505.
Yakdan K, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23185.
Yakdan K, 2016, P IEEE S SECUR PRIV, P158, DOI 10.1109/SP.2016.18.},
  da = {2026-02-04},
  doc-delivery-number = {D7OR1},
  doi = {10.1145/3546946},
  eissn = {1557-7392},
  funding-acknowledgement = {Software Engineering Institute; National Science Foundation
{[}CCF-1815287, CCF-1910067]; NVIDIA Corporation {[}P6000 GPU]},
  funding-text = {This material is based upon work supported in part by the Software
Engineering Institute and National Science Foundation (NSF awards
CCF-1815287 and CCF-1910067). We also gratefully acknowledge hardware
support (Quadro P6000 GPU) from the NVIDIA Corporation.},
  issn = {1049-331X},
  journal = {ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY},
  journal-iso = {ACM Trans. Softw. Eng. Methodol.},
  keywords = {Machine learning; decompilation; data provenance},
  language = {English},
  month = {APR},
  number = {2},
  number-of-cited-references = {57},
  oa = {Bronze},
  orcid-numbers = {Lacomis, Jeremy/0000-0003-0653-5738
Le Goues, Claire/0000-0002-3931-060X
Vasilescu, Bogdan/0000-0003-4418-5783},
  publisher = {ASSOC COMPUTING MACHINERY},
  research-areas = {Computer Science},
  times-cited = {5},
  title = {DIRE and its Data: Neural Decompiled Variable Renamings with Respect to
Software Class},
  type = {Article},
  unique-id = {WOS:000970588900012},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {1},
  volume = {32},
  web-of-science-categories = {Computer Science, Software Engineering},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
  year = {2023}
}

@article{WOS:001217002000001,
  abstract = {Adequately selecting variable names is a difficult activity for
practitioners. In 2018, Jaffe et al. proposed the use of statistical
machine translation (SMT) to suggest descriptive variable names for
decompiled code. A large corpus of decompiled C code was used to train
the SMT model. Our paper presents the results of a partial replication
of Jaffe's experiment. We apply the same technique and methodology to a
dataset made of code written in the Pharo programming language. We
selected Pharo since its syntax is simple - it fits on half of a
postcard - and because the optimizations performed by the compiler are
limited to method scope. Our results indicate that SMT may recover
between 8.9\% and 69.88\% of the variable names depending on the
training set. Our replication concludes that: (i) the accuracy depends
on the code similarity between the training and testing sets; (ii) the
simplicity of the Pharo syntax and the satisfactory decompiled code
alignment have a positive impact on predicting variable names; and (iii)
a relatively small code corpus is sufficient to train the SMT model,
which shows the applicability of the approach to less popular
programming languages. Additionally, to assess SMT's potential in
improving original variable names, ten Pharo developers reviewed 400 SMT
name suggestions, with four reviews per variable. Only 15 suggestions
(3.75\%) were unanimously viewed as improvements, while 45 (11.25\%)
were perceived as improvements by at least two reviewers, highlighting
SMT's limitations in providing suitable alternatives.},
  address = {125 London Wall, London, ENGLAND},
  affiliation = {Alcocer, JPS (Corresponding Author), Pontificia Univ Catolica Chile, Sch Engn, Dept Comp Sci, Santiago, Chile.
Alcocer, Juan Pablo Sandoval; Neyem, Andres, Pontificia Univ Catolica Chile, Sch Engn, Dept Comp Sci, Santiago, Chile.
Neyem, Andres, Natl Ctr Artificial Intelligence CENIA, Santiago 7820436, Chile.
Camacho-Jaimes, Harold; Galindo-Gutierrez, Geraldine, Univ Catolica Boliviana, Exact Sci \& Engn Res Ctr CICEI, Cochabamba, Bolivia.
Bergel, Alexandre, RelationalAI, Zurich, Switzerland.
Ducasse, Stephane, Univ Lille, INRIA, CNRS, Cent Lille,UMR 9189 CRIStAL, Lille, France.},
  affiliations = {Pontificia Universidad Catolica de Chile; Universite de Lille; Centrale
Lille; Centre National de la Recherche Scientifique (CNRS); Inria},
  article-number = {101271},
  author = {Alcocer, Juan Pablo Sandoval and Camacho-Jaimes, Harold and
Galindo-Gutierrez, Geraldine and Neyem, Andres and Bergel, Alexandre and
Ducasse, Stephane},
  author-email = {juanpablo.sandoval@uc.cl},
  cited-references = {{[}Anonymous], 1999, Code conventions for the Java programming language.
Avidan E, 2017, INT C PROGRAM COMPRE, P55, DOI 10.1109/ICPC.2017.27.
Bacchelli Alberto., 2010, Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering (ICSE), P375.
Bavishi R, 2018, Arxiv, DOI {[}arXiv:1809.05193, DOI 10.48550/ARXIV.1809.05193].
Beniamini G, 2017, INT C PROGRAM COMPRE, P45, DOI 10.1109/ICPC.2017.18.
Bera C., 2013, IWST.
Black A.P., 2009, PHARO EXAMPLE.
BREUER PT, 1994, ACM T PROGR LANG SYS, V16, P1613, DOI 10.1145/186025.186093.
Butler S, 2015, PROC IEEE INT CONF S, P41, DOI 10.1109/ICSM.2015.7332450.
Chen QB, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P4327.
CIFUENTES C, 1995, SOFTWARE PRACT EXPER, V25, P811, DOI 10.1002/spe.4380250706.
Cifuentes C., 1993, P 19 CONFERENCIA LAT, P257.
Cifuentes Cristina., 1994, Reverse compilation techniques.
Daka E, 2017, PROCEEDINGS OF THE 26TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA'17), P57, DOI 10.1145/3092703.3092727.
Deissenböck F, 2005, PROG COMPREHEN, P97, DOI 10.1109/WPC.2005.14.
Dietterich T, 1995, ACM COMPUT SURV, V27, P326, DOI 10.1145/212094.212114.
Durfina L, 2013, WORK CONF REVERSE EN, P449, DOI 10.1109/WCRE.2013.6671321.
F.S. Foundation, 2021, GNU coding standards.
Gengbiao Chen, 2010, Proceedings 17th Working Conference on Reverse Engineering (WCRE 2010), P150, DOI 10.1109/WCRE.2010.24.
Goldberg A., 1989, Addison-Wesley series in computer science.
Gresta R, 2021, PROCEEDINGS OF THE 20TH BRAZILIAN SYMPOSIUM ON SOFTWARE QUALITY, SBOS 2021, DOI 10.1145/3493244.3493258.
Jaffe A, 2018, INT C PROGRAM COMPRE, P20, DOI 10.1145/3196321.3196330.
Katz DS, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2018), P346, DOI 10.1109/SANER.2018.8330222.
Koehn P., 2007, ACL, DOI {[}10.3115/1557769.1557821, DOI 10.3115/1557769.1557821].
Lacomis J, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P640, DOI 10.1109/ASE.2019.00064.
Lawrie D, 2006, SIXTH IEEE INTERNATIONAL WORKSHOP ON SOURCE CODE ANALYSIS AND MANIPULATION, PROCEEDINGS, P139.
Lawrie D, 2006, INT C PROGRAM COMPRE, P3, DOI 10.1109/ICPC.2006.51.
Lawrie D, 2007, INNOV SYST SOFTW ENG, V3, P303, DOI 10.1007/s11334-007-0031-2.
Lv XF, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P252, DOI 10.1109/IAEAC.2017.8054016.
Miecznikowski J, 2002, LECT NOTES COMPUT SC, V2304, P111.
NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4.
Raychev V, 2015, ACM SIGPLAN NOTICES, V50, P111, DOI {[}10.1145/2676726.2677009, 10.1145/2775051.2677009].
Roy D, 2020, IEEE INT CONF AUTOM, P287, DOI 10.1145/3324884.3416622.
Schankin A, 2018, INT C PROGRAM COMPRE, P31, DOI 10.1145/3196321.3196332.
Schwartz Edward J., 2013, Proceedings of the 22nd USENIX Security Symposium. Security `13, P353.
Sedano T, 2016, CONF SOFTW ENG EDUC, P111, DOI 10.1109/CSEET.2016.36.
Shudrak M, 2012, UKSIM EURO SYMP COMP, P115, DOI 10.1109/EMS.2012.20.
Stitt G, 2005, IEEE IC CAD, P547, DOI 10.1109/ICCAD.2005.1560127.
Triola M.F., 2004, ELEMENTARY STAT.
Uni Yarmouk., 2013, International Journal of Software Engineering and Its Applications, V7, P441, DOI DOI 10.14257/IJSEIA.2013.7.6.38.
Van Emmerik M, 2004, 11TH WORKING CONFERENCE ON REVERSE ENGINEERING, PROCEEDINGS, P27.
Vasilescu B, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P683, DOI 10.1145/3106237.3106289.
Yakdan K, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23185.
Yakdan K, 2016, P IEEE S SECUR PRIV, P158, DOI 10.1109/SP.2016.18.
Yakdan K, 2013, PROCEEDINGS OF THE 2013 8TH INTERNATIONAL CONFERENCE ON MALICIOUS AND UNWANTED SOFTWARE: THE AMERICAS (MALWARE), P95, DOI 10.1109/MALWARE.2013.6703690.},
  da = {2026-02-04},
  doc-delivery-number = {PW0M5},
  doi = {10.1016/j.cola.2024.101271},
  earlyaccessdate = {APR 2024},
  eissn = {2665-9182},
  funding-acknowledgement = {ANID FONDECYT Iniciacion {[}11220885]; National Center for Artificial
Intelligence {[}CENIA FB210017]},
  funding-text = {Juan Pablo Sandoval Alcocer thanks ANID FONDECYT Iniciacion 11220885 for
supporting this article. Andres Neyem is supported by the National
Center for Artificial Intelligence (CENIA FB210017, Basal ANID) . Juan
Pablo also thanks the Programa de Insercion Academica 2022,
Vicerrectoria Academica y Prorrectoria, at the Pontificia Universidad
Catolica de Chile.},
  issn = {2590-1184},
  journal = {JOURNAL OF COMPUTER LANGUAGES},
  journal-iso = {J. Comput. Lang.},
  keywords = {Statistical machine translation; Decompiled code; Identifiers; Variable
names; Readability},
  language = {English},
  month = {JUN},
  number-of-cited-references = {45},
  oa = {Green Submitted},
  orcid-numbers = {Galindo-Gutierrez, Geraldine/0009-0002-3801-5227
Ducasse, Stéphane/0000-0001-6070-6599
Sandoval Alcocer, Juan Pablo/0000-0002-8335-4351},
  publisher = {ELSEVIER SCI LTD},
  research-areas = {Computer Science},
  researcherid-numbers = {Sandoval Alcocer, Juan Pablo/CAA-0465-2022
Neyem, Andres/D-2145-2014},
  times-cited = {0},
  title = {On the use of statistical machine translation for suggesting variable
names for decompiled code: The Pharo case},
  type = {Article},
  unique-id = {WOS:001217002000001},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {2},
  volume = {79},
  web-of-science-categories = {Computer Science, Software Engineering},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
  year = {2024}
}

@article{WOS:001332656400001,
  abstract = {Decompilation is a widely utilized technique in reverse engineering,
aimed at restoring binary code to human-readable high-level language
code. However, the readability of the output from traditional
decompilers is often poor. With advancements in language models, several
learning-based decompilation methods have emerged. Nevertheless, the
probabilistic nature of language models leads to outputs whose
correctness cannot be guaranteed, necessitating further analysis by
engineers to identify the corresponding functionality of the code.
Inspired by compiler toolchains, we propose a novel approach to enhance
the effectiveness of language models in decompilation tasks. Traditional
rule-based methods and learning-based techniques are fused together in
our approach, drawing insights from both paradigms. Specifically, we
present a pre-trained sequence-to-sequence model called IRaDT tailored
to refine decompilation outputs at the intermediate representation
level. Through this hybridization, we aim to address the limitations of
existing methodologies and achieve more accurate and robust
decompilation. We construct a diverse decompilation dataset targeting IR
and evaluated IRaDT based on this dataset. The experimental results
indicate that IRaDT has the ability to improve the readability of IR
while ensuring its compileability, achieving a 74\% improvement compared
to RetDec and a 93\% improvement compared to ChatGPT.},
  address = {5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE},
  affiliation = {Li, YZ (Corresponding Author), Beijing Univ Posts \& Telecommun Beijing, Sch Cyberspace Secur, Beijing, Peoples R China.
Li, Yuzhang; Wang, Chunlu, Beijing Univ Posts \& Telecommun Beijing, Sch Cyberspace Secur, Beijing, Peoples R China.
Xu, Tao, Tsinghua Univ, Dept Comp Sci \& Technol, Beijing, Peoples R China.},
  affiliations = {Tsinghua University},
  author = {Li, Yuzhang and Xu, Tao and Wang, Chunlu},
  author-email = {yuzhang.lee@outlook.com
xtao@tsinghua.edu.cn
wangcl@bupt.edu.cn},
  cited-references = {{[}Anonymous], 2024, GHIDRA SOFTWARE REVE.
{[}Anonymous], 2024, IDA Pro: A Powerful Disassembler, Decompiler and a Versatile Debugger.
{[}Anonymous], 2024, Clang: A C Language Family Frontend for LLVM.
{[}Anonymous], 2024, The LLVM Compiler Infrastructure.
Armengol-Estapé J, 2024, INT SYM CODE GENER, P67, DOI 10.1109/CGO57630.2024.10444788.
Cummins C., 2023, ARXIV.
Cummins C, 2021, PR MACH LEARN RES, V139.
da Silva AF, 2021, INT SYM CODE GENER, P378, DOI 10.1109/CGO51591.2021.9370322.
Devlin J., 2018, arXiv.
Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536.
Fu C, 2019, ADV NEUR IN, V32.
Fu ZH, 2023, AAAI CONF ARTIF INTE, P12799.
Guo D., 2021, INT C LEARNING REPRE.
Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212.
Hosseini I., 2022, P WORKSH BIN AN RES.
Hu E.J ..., 2022, ICLR.
Jiang N., 2023, ArXiv.
Katz D. S., 2018, USING RECURRENT NEUR, P346.
Lewis M., 2020, P 58 ANN M ASS COMPU, P7871, DOI 10.18653/v1/2020.acl-main.703.
Mou LL, 2016, AAAI CONF ARTIF INTE, P1287.
Niu CG, 2023, PROC INT CONF SOFTW, P2136, DOI 10.1109/ICSE48619.2023.00180.
OpenAI, 2024, GPT-4 Technical Report.
Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135.
Radford Alec., 2019, Language Models are Unsupervised Multitask Learners, V1, P9.
Raffel C, 2020, J MACH LEARN RES, V21.
Retdec, 2024, RETARGETABLE MACHINE.
Roziere B., 2022, INT C LEARN REPR.
Shazeer N, 2018, PR MACH LEARN RES, V80.
Song KT, 2019, PR MACH LEARN RES, V97.
Tan H., 2024, arXiv.
Vaswani A, 2017, ADV NEUR IN, V30.
Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696.},
  da = {2026-02-04},
  doc-delivery-number = {P1V6S},
  doi = {10.1142/S0218194024500463},
  earlyaccessdate = {OCT 2024},
  eissn = {1793-6403},
  funding-acknowledgement = {Key Laboratory of Trustworthy Distributed Computing and Service, MoE
(Beijing University of Posts and Telecommunications)},
  funding-text = {This research is supported by Key Laboratory of Trustworthy Distributed
Computing and Service, MoE (Beijing University of Posts and
Telecommunications).},
  issn = {0218-1940},
  journal = {INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING},
  journal-iso = {Int. J. Softw. Eng. Knowl. Eng.},
  keywords = {Decompilation; LLVM immediate representation; pre-trained language
model; neural machine translation},
  language = {English},
  month = {DEC},
  number = {12},
  number-of-cited-references = {32},
  pages = {1971-1992},
  publisher = {WORLD SCIENTIFIC PUBL CO PTE LTD},
  research-areas = {Computer Science; Engineering},
  times-cited = {1},
  title = {IRaDT: LLVM IR as Target for Efficient Neural Decompilation},
  type = {Article},
  unique-id = {WOS:001332656400001},
  usage-count-last-180-days = {2},
  usage-count-since-2013 = {6},
  volume = {34},
  web-of-science-categories = {Computer Science, Artificial Intelligence; Computer Science, Software
Engineering; Engineering, Electrical \& Electronic},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
  year = {2024}
}

@article{WOS:001623665300001,
  abstract = {The goal of decompilation is to convert compiled low-level code (e.g.,
assembly code) back into high-level programming languages, enabling
analysis in scenarios where source code is unavailable. This task
supports various reverse engineering applications, such as vulnerability
identification, malware analysis, and legacy software migration. The
end-to-end decompilation method based on large language models (LLMs)
reduces reliance on additional tools and minimizes manual intervention
due to its inherent properties. However, previous end-to-end methods
often lose critical information necessary for reconstructing control
flow structures and variables when processing binary files, making it
challenging to accurately recover the program's logic. To address these
issues, we propose the ReF Decompile method, which incorporates the
following innovations: (1) The Relabeling strategy replaces jump target
addresses with labels, preserving control flow clarity. (2) The Function
Call strategy infers variable types and retrieves missing variable
information from binary files. Experimental results on the
Humaneval-Decompile Benchmark demonstrate that ReF Decompile surpasses
comparable baselines and achieves state-of-the-art (SOTA) performance of
61.43\%.},
  address = {MDPI AG, Grosspeteranlage 5, CH-4052 BASEL, SWITZERLAND},
  affiliation = {Zhu, QF; Che, WX (Corresponding Author), Harbin Inst Technol, Res Ctr Social Comp \& Interact Robot, Harbin 150001, Peoples R China.
Feng, Yunlong; Li, Bohan; Zhu, Qingfu; Che, Wanxiang, Harbin Inst Technol, Res Ctr Social Comp \& Interact Robot, Harbin 150001, Peoples R China.
Shi, Xiaoming, East China Normal Univ, Sch Comp Sci \& Technol, Shanghai 200062, Peoples R China.},
  affiliations = {Harbin Institute of Technology; East China Normal University},
  article-number = {4442},
  author = {Feng, Yunlong and Li, Bohan and Shi, Xiaoming and Zhu, Qingfu and Che,
Wanxiang},
  author-email = {ylfeng@ir.hit.edu.cn
bhli@ir.hit.edu.cn
xmshi@cs.ecnu.edu.cn
qfzhu@ir.hit.edu.cn
car@ir.hit.edu.cn},
  cited-references = {Armengol-estape Jordi, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P50, DOI 10.1145/3520312.3534867.
Armengol-Estape J, 2024, Arxiv, DOI {[}arXiv:2305.12520, 10.48550/ARXIV.2305.12520 2305.12520, DOI 10.48550/ARXIV.2305.125202305.12520].
Balakrishnan G, 2007, LECT NOTES COMPUT SC, V4349, P1.
Basque ZL, 2024, PROCEEDINGS OF THE 33RD USENIX SECURITY SYMPOSIUM, SECURITY 2024, P361.
Chen M., 2021, Evaluating large language models trained on code, DOI DOI 10.48550/ARXIV.2107.03374.
Dao T., 2024, P INT C LEARNING REP.
Feng YL, 2024, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: EMNLP 2024, P6603.
Guo DY, 2024, Arxiv, DOI {[}arXiv:2401.14196, DOI 10.48550/ARXIV.2401.14196].
Hosseini Iman., 2022, arXiv, DOI {[}DOI 10.48550/ARXIV.2212.08950, 10.48550/arXiv.2212.08950].
Hu E.J., 2022, P INT C LEARNING REP.
Hu P., 2024, P 2024 NETWORK DISTR, VVolume 267622140.
Hui BY, 2024, Arxiv, DOI arXiv:2409.12186.
Jiang N, 2024, Arxiv, DOI arXiv:2311.13721.
Katz DS, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2018), P346, DOI 10.1109/SANER.2018.8330222.
Kirchner K, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2017), DOI 10.1145/3098954.3103152.
Lacomis Jeremy, 2019, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). Proceedings, P628, DOI 10.1109/ASE.2019.00064.
Lippincott T., 2020, P 15 ANN INT C ALLIA.
Loshchilov I., 2019, P 7 INT C LEARNING R.
OpenAI, 2023, Arxiv, DOI {[}arXiv:2303.08774, 10.48550/arXiv.2303.08774, DOI 10.48550/ARXIV.2303.08774].
Roziere B, 2024, Arxiv, DOI {[}arXiv:2308.12950, DOI 10.48550/ARXIV.2308.12950].
Schwartz Edward J., 2013, Proceedings of the 22nd USENIX Security Symposium. Security `13, P353.
Tan HZ, 2024, 2024 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, EMNLP 2024, P3473.
Vaswani A., 2017, ADV NEUR IN, P30, DOI DOI 10.48550/ARXIV.1706.03762.
Wang G., 2024, P INT C LEARNING REP.
Wang R., 2017, P NDSS.
Wei T, 2007, LECT NOTES COMPUT SC, V4634, P170.
Weyssow M., 2025, ACM Transactions on Software Engineering and Methodology.
Wolf T, 2020, Arxiv, DOI {[}arXiv:1910.03771, DOI 10.48550/ARXIV.1910.03771].
Wong WK, 2023, Arxiv, DOI {[}arXiv:2310.06530, 10.48550/arXiv.2310.06530, DOI 10.48550/ARXIV.2310.06530].
Zheng YW, 2024, Arxiv, DOI {[}arXiv:2403.13372, DOI 10.48550/ARXIV.2403.13372].},
  da = {2026-02-04},
  doc-delivery-number = {F5618},
  doi = {10.3390/electronics14224442},
  funding-acknowledgement = {National Natural Science Foundation of China (NSFC) {[}62236004,
62206078, 62441603, 62476073]},
  funding-text = {This research was funded by the National Natural Science Foundation of
China (NSFC), grant numbers 62236004, 62206078, 62441603 and 62476073.},
  issn = {2079-9292},
  journal = {ELECTRONICS},
  journal-iso = {Electronics},
  keywords = {large language model; code generation},
  language = {English},
  month = {NOV 14},
  number = {22},
  number-of-cited-references = {30},
  oa = {gold},
  orcid-numbers = {Li, Bohan/0000-0003-1168-8018
冯, 云龙/0000-0002-0561-8841},
  publisher = {MDPI},
  research-areas = {Computer Science; Engineering; Physics},
  researcherid-numbers = {Shi, Xiaoming/AAU-4105-2021
XIN, WANG/KGK-5385-2024
朱, 庆福/HGE-1466-2022},
  times-cited = {1},
  title = {Interactive End-to-End Decompilation via Large Language Models},
  type = {Article},
  unique-id = {WOS:001623665300001},
  usage-count-last-180-days = {1},
  usage-count-since-2013 = {1},
  volume = {14},
  web-of-science-categories = {Computer Science, Information Systems; Engineering, Electrical \&
Electronic; Physics, Applied},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
  year = {2025}
}

@article{WOS:001639031400025,
  abstract = {Decompiler is a specialized type of reverse engineering tool extensively
employed in program analysis tasks, particularly in program
comprehension and vulnerability detection. However, current Solidity
smart contract decompilers face significant limitations in
reconstructing the original source code. In particular, the bottleneck
of SOTA decompilers lies in inaccurate function identification,
incorrect variable type recovery, and missing contract attributes. These
deficiencies hinder downstream tasks and understanding of the program
logic. To address these challenges, we propose SmartHalo, a new
framework that enhances decompiler output by combining static analysis
(SA) and large language models (LLM). SmartHalo leverages the
complementary strengths of SA's accuracy in control and data flow
analysis and LLM's capability in semantic prediction. More specifically,
SmartHalo constructs a new data structure - Dependency Graph (DG), to
extract semantic dependencies via static analysis. Then, it takes DG to
create prompts for LLM optimization. Finally, the correctness of LLM
outputs is validated through symbolic execution and formal verification.
Evaluation on a dataset consisting of 465 randomly selected smart
contract functions shows that SmartHalo significantly improves the
quality of the decompiled code, compared to SOTA decompilers (e.g.,
Gigahorse). Notably, integrating GPT-4o mini with SmartHalo further
enhances its performance, achieving a precision of 91.32\% and a recall
of 87.38\% for function boundaries, a precision of 90.40\% and a recall
of 88.82\% for variable types, and a precision of 80.66\% and a recall
of 91.78\% for contract attributes.},
  address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
  affiliation = {Nan, YH (Corresponding Author), Sun Yat Sen Univ, Sch Software Engn, Zhuhai 519082, Peoples R China.
Nan, YH (Corresponding Author), Guangdong Engn Technol Res Ctr Blockchain, Zhuhai 519082, Peoples R China.
Liao, Zeqin; Nan, Yuhong; Gao, Zixu; Liang, Henglong; Hao, Sicheng; Ren, Peifan; Zheng, Zibin, Sun Yat Sen Univ, Sch Software Engn, Zhuhai 519082, Peoples R China.
Liao, Zeqin; Nan, Yuhong; Gao, Zixu; Liang, Henglong; Hao, Sicheng; Ren, Peifan; Zheng, Zibin, Guangdong Engn Technol Res Ctr Blockchain, Zhuhai 519082, Peoples R China.},
  affiliations = {Sun Yat Sen University},
  author = {Liao, Zeqin and Nan, Yuhong and Gao, Zixu and Liang, Henglong and Hao,
Sicheng and Ren, Peifan and Zheng, Zibin},
  author-email = {liaozq8@mail2.sysu.edu.cn
nanyh@mail.sysu.edu.cn
gaozx9@mail2.sysu.edu.cn
lianghlong@mail2.sysu.edu.cn
haosch@mail2.sysu.edu.cn
renpf@mail2.sysu.edu.cn
zhzibin@mail.sysu.edu.cn},
  cited-references = {Al-Yarimi FAM, 2025, TSINGHUA SCI TECHNOL, V30, P978, DOI 10.26599/TST.2024.9010051.
Badihi S, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE `20), P13, DOI 10.1145/3368089.3409757.
Chen QB, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P4327.
Chen T, 2022, IEEE T SOFTWARE ENG, V48, P3066, DOI 10.1109/TSE.2021.3078342.
Consensys, Mythril.
Contro F, 2021, INT C PROGRAM COMPRE, P127, DOI 10.1109/ICPC52881.2021.00021.
David Y, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428293.
de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3\_24.
Dramko L, 2024, PROCEEDINGS OF THE 33RD USENIX SECURITY SYMPOSIUM, SECURITY 2024, P379.
ethereum, Ethereum virtual machine.
etherscan, EtherScan.
Gao H, 2021, ISSTA `21: PROCEEDINGS OF THE 30TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P607, DOI 10.1145/3460319.3464804.
github, Tree-sitter.
github, Smart contract statistic.
Grech N, 2022, P ACM PROGRAM LANG, V6, DOI 10.1145/3527321.
Grech N, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276486.
Grech N, 2019, PROC INT CONF SOFTW, P1176, DOI 10.1109/ICSE.2019.00120.
He JH, 2023, Arxiv, DOI arXiv:2301.12695.
He JX, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P1667, DOI 10.1145/3243734.3243866.
Hu P., 2024, P 2024 NETWORK DISTR.
Jaffe A, 2018, INT C PROGRAM COMPRE, P20, DOI 10.1145/3196321.3196330.
Jin Xin, 2022, CCS `22: Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, P1631, DOI 10.1145/3548606.3560612.
Lacomis Jeremy, 2019, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). Proceedings, P628, DOI 10.1109/ASE.2019.00064.
Lai EM, 2020, 2020 4TH INTERNATIONAL CONFERENCE ON CRYPTOGRAPHY, SECURITY AND PRIVACY (ICCSP 2020), P110, DOI 10.1145/3377644.3377650.
Li X., Fundamental Res..
Li YC, 2024, P ACM PROGRAM LANG, V8, DOI 10.1145/3689711.
Liao Zeqin, 2024, Proceedings of the ACM on Software Engineering, V1, DOI {[}10.1145/3643738, 10.1145/3643738].
Liao ZQ, 2023, PROCEEDINGS OF THE 32ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2023, P980, DOI 10.1145/3597926.3598111.
Liao ZQ, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P752, DOI 10.1145/3533767.3534222.
Liu H, 2024, PROCEEDINGS OF THE 33RD USENIX SECURITY SYMPOSIUM, SECURITY 2024, P3585.
Ma W, 2024, Arxiv, DOI {[}arXiv:2403.16073, DOI 10.48550/ARXIV.2403.16073].
Pang CB, 2021, P IEEE S SECUR PRIV, P833, DOI 10.1109/SP40001.2021.00012.
Pei K., 2020, arXiv.
Peng JX, 2024, CHINESE J ELECTRON, V33, P128, DOI 10.23919/cje.2022.00.228.
Peng Y, 2023, IEEE INT CONF AUTOM, P988, DOI 10.1109/ASE56229.2023.00031.
Person Suzette., 2008, P 16 ACM SIGSOFT INT, P226, DOI 10.1145/1453101.1453131.
solidity.readthedocs, Solidity.
soliditylang, Solidity release changelogs.
Su J, 2023, CHINESE J ELECTRON, V32, P531, DOI 10.23919/cje.2022.00.103.
Suiche M., 2017, Porosity: A Decompiler For Blockchain-Based Smart Contracts Bytecode.
Sun JL, 2022, TSINGHUA SCI TECHNOL, V27, P27, DOI 10.26599/TST.2020.9010036.
Sun KR, 2023, PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023, P796, DOI 10.1145/3611643.3616270.
Wang W, 2025, TSINGHUA SCI TECHNOL, V30, P769, DOI 10.26599/TST.2024.9010019.
Wang Y., 2025, Fundamental Res., P1.
Wang Zexu, 2024, Proceedings of the ACM on Software Engineering, V1, DOI {[}10.1145/3643734, 10.1145/3643734].
Williams-King D, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P133, DOI 10.1145/3373376.3378470.
xblock.pro, Ethereum open-source smart contract.
Xing Su, 2025, Proceedings of the ACM on Software Engineering, V2, DOI {[}10.1145/3729373, 10.1145/3729373].
Yang S., 2024, PROC IEEEACM 46 INT, P1.
Yao JY, 2024, CHINESE J ELECTRON, V33, P1063, DOI 10.23919/cje.2023.00.233.
Zhang Z., 2019, PROC ACM PROGRAM, P1.
Zhang Z, 2021, P IEEE S SECUR PRIV, P813, DOI 10.1109/SP40001.2021.00051.
Zhao KS, 2023, PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023, P745, DOI 10.1145/3611643.3616343.
Zheng ZB, 2024, IEEE T SOFTWARE ENG, V50, P1360, DOI 10.1109/TSE.2024.3383422.
Zhou SF, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2793.
Zhou Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1371.},
  da = {2026-02-04},
  doc-delivery-number = {U8690},
  doi = {10.1109/TSE.2025.3623325},
  eissn = {1939-3520},
  funding-acknowledgement = {National Key Research and Development Program of China
{[}2023YFB2704100]; National Natural Science Foundation of China
{[}62572497]; NSFC-RGC Collaborative Research {[}62461160332]; Guangdong
Zhujiang Talent Program {[}2023QN10X561]},
  funding-text = {This work was supported in part by the National Key Research and
Development Program of China under Grant 2023YFB2704100, in part by the
National Natural Science Foundation of China under Grant 62572497, in
part by NSFC-RGC Collaborative Research under Grant 62461160332, and in
part by Guangdong Zhujiang Talent Program under Grant 2023QN10X561},
  issn = {0098-5589},
  journal = {IEEE TRANSACTIONS ON SOFTWARE ENGINEERING},
  journal-iso = {IEEE Trans. Softw. Eng.},
  keywords = {Smart contracts; Codes; Optimization; Source coding; Static analysis;
Large language models; Accuracy; Training; Semantics; Annotations; Smart
contract; decompilation; static analysis; large language model},
  language = {English},
  month = {DEC},
  number = {12},
  number-of-cited-references = {56},
  orcid-numbers = {Zixu, gao/0009-0004-9665-5075
Liang, Henglong/0009-0008-9570-1067
Hao, Sicheng/0009-0009-5747-1093},
  pages = {3574-3590},
  publisher = {IEEE COMPUTER SOC},
  research-areas = {Computer Science; Engineering},
  researcherid-numbers = {Nan, Yuhong/AAX-1436-2020},
  times-cited = {1},
  title = {Augmenting Smart Contract Decompiler Output Through Fine-Grained
Dependency Analysis and LLM-Facilitated Semantic Recovery},
  type = {Article},
  unique-id = {WOS:001639031400025},
  usage-count-last-180-days = {3},
  usage-count-since-2013 = {3},
  volume = {51},
  web-of-science-categories = {Computer Science, Software Engineering; Engineering, Electrical \&
Electronic},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
  year = {2025}
}

@article{WOS:001657340000001,
  abstract = {The proliferation of binary vulnerabilities in the software supply chain
has become a critical security challenge. Existing vulnerability
detection approaches-including dynamic analysis, static analysis, and
decompilation-assisted analysis-all suffer from limitations such as
insufficient coverage, high false-positive and false-negative rates, or
poor compatibility. Although decompilation technology can serve as a
bridge connecting binary-code and source-code vulnerability detection
tools, current schemes suffer from inadequate semantic restoration
quality and lack of tool compatibility. To address these issues, this
paper proposes LLMVulDecompiler, a binary decompilation model based on
fine-tuned large language models designed to generate high-precision
decompiled code that integrates directly with source-code static
analysis tools. We construct a dedicated training and evaluation dataset
that covers multiple compiler optimization levels (e.g., O0-O3) and a
diverse set of program functionalities. We adopt a two-stage fine-tuning
strategy that involves first building foundational decompilation
capabilities, then enhancing vulnerability-specific features.
Additionally, we design a low-cost inference pipeline and establish
multi-dimensional evaluation criteria, including restoration similarity,
compilation success rate, and functional correctness. Experimental
results show that the model significantly outperforms baseline models in
terms of average edit distance, compilation success rate, and black-box
test pass rate on the HumanEval-C benchmark. In tests on 12 real-world
CVE (Common Vulnerabilities and Exposures) instances, the approach
achieved a detection accuracy of 91.7\%, with substantially reduced
false-positive and false-negative rates. This study demonstrates the
effectiveness of specialized fine-tuning of large language models for
binary decompilation and vulnerability detection, offering a new pathway
for binary security analysis.},
  address = {MDPI AG, Grosspeteranlage 5, CH-4052 BASEL, SWITZERLAND},
  affiliation = {Mao, DM (Corresponding Author), China Elect Technol Grp Corp, Res Inst 30, Chengdu 610093, Peoples R China.
Wang, Yidan; Mao, Deming; Han, Ye; Tao, Rui, China Elect Technol Grp Corp, Res Inst 30, Chengdu 610093, Peoples R China.},
  affiliations = {China Electronics Technology Group},
  article-number = {8},
  author = {Wang, Yidan and Mao, Deming and Han, Ye and Tao, Rui},
  author-email = {wangyd19257@cetcsc.com
mdm1201@126.com},
  cited-references = {Armengol-estape Jordi, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P50, DOI 10.1145/3520312.3534867.
Armengol-Estapé J, 2024, INT SYM CODE GENER, P67, DOI 10.1109/CGO57630.2024.10444788.
BigCode Project, 2024, StarCoder2.
Burk K, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P2765.
ByteDance Doubao, 2024, AI Chatbot.
Chen M., 2021, Evaluating large language models trained on code, DOI DOI 10.48550/ARXIV.2107.03374.
Chukkol AHA, 2024, Arxiv, DOI arXiv:2408.07181.
Dutra R, 2024, ACM T SOFTW ENG METH, V33, DOI 10.1145/3628157.
Engel D, 2023, LECT NOTES COMPUT SC, V14066, P3, DOI 10.1007/978-3-031-38828-6\_1.
Feng YL, 2025, ELECTRONICS-SWITZ, V14, DOI 10.3390/electronics14224442.
Fevid E., 2024, Authorea Prepr, DOI {[}10.36227/techrxiv.172565769.90012316, DOI 10.36227/TECHRXIV.172565769.90012316].
github, 2025, Tencent CodeAnalysis.
github, 2023, WPeace-HcH WPeChatGPT Version 2.3.
Guo DY, 2024, Arxiv, DOI {[}arXiv:2401.14196, DOI 10.48550/ARXIV.2401.14196].
He JX, 2021, CCS `21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2526, DOI 10.1145/3460120.3484813.
Hex-Rays, 2025, SA IDA Pro: A Cross-Platform Multi-Processor Disassembler and Debugger.
Hosseini Iman., 2022, arXiv, DOI {[}DOI 10.48550/ARXIV.2212.08950, 10.48550/arXiv.2212.08950].
Hui BY, 2024, Arxiv, DOI arXiv:2409.12186.
Jiang N, 2024, Arxiv, DOI arXiv:2311.13721.
Katz DS, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2018), P346, DOI 10.1109/SANER.2018.8330222.
Katz O, 2019, Arxiv, DOI arXiv:1905.08325.
Li D, 2024, MACH LEARN KNOW EXTR, V6, P1087, DOI 10.3390/make6020050.
Li RY, 2023, Arxiv, DOI arXiv:2305.06161.
Li YZ, 2024, INT J SOFTW ENG KNOW, V34, P1971, DOI 10.1142/S0218194024500463.
Liu Z., 2022, P INT C ALGORITHMS A, P392.
Luo Z., 2023, P NDSS.
Massarelli L, 2022, IEEE T DEPEND SECURE, V19, P2259, DOI 10.1109/TDSC.2021.3051852.
Meta Code Llama, 2023, Official Webpage for Code Llama, a Code Generation LLM Developed by Meta.
National Security Agency (NSA), 2021, Ghidra (Open-Source Reverse Engineering Tool).
Ollama Wizard Coder, 2023, Ollama Library Webpage for Wizard Coder (Code Generation Model Based on Code Llama); Multiple Versions Available: Initial Release (2023-09-07) and 33B Version (2024-01-04).
Poeplau S, 2021, 28TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2021), DOI 10.14722/ndss.2021.23118.
Roziere B, 2024, Arxiv, DOI {[}arXiv:2308.12950, DOI 10.48550/ARXIV.2308.12950].
Sang Q, 2024, P IEEE S SECUR PRIV, P3998, DOI 10.1109/SP54263.2024.00045.
Schwartz Edward J., 2013, Proceedings of the 22nd USENIX Security Symposium. Security `13, P353.
She XY, 2024, IEEE INT CONF AUTOM, P481, DOI 10.1145/3691620.3695020.
Tan HZ, 2024, Arxiv, DOI arXiv:2403.05286.
Ul Haq I, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3446371.
Verbeek F, 2024, PROCEEDINGS OF THE 2024 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, CCS 2024, P2786, DOI 10.1145/3658644.3690244.
Wei XY, 2024, J NETW COMPUT APPL, V232, DOI 10.1016/j.jnca.2024.104020.
Wong WK, 2023, Arxiv, DOI {[}arXiv:2310.06530, 10.48550/arXiv.2310.06530, DOI 10.48550/ARXIV.2310.06530].
Xiao Y, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2021), P213, DOI 10.1109/SANER50967.2021.00028.
Yan H, 2021, COMPUT SECUR, V108, DOI 10.1016/j.cose.2021.102286.
Yang SG, 2023, ACM T SOFTW ENG METH, V32, DOI 10.1145/3604608.
Yang Y., 2023, P INT S DEPENDABLE S, P351.
Zheng PL, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P740, DOI 10.1145/3533767.3534395.
Zheng YW, 2024, Arxiv, DOI {[}arXiv:2403.13372, DOI 10.48550/ARXIV.2403.13372].},
  da = {2026-02-04},
  doc-delivery-number = {AU9AJ},
  doi = {10.3390/electronics15010008},
  funding-acknowledgement = {30th Research Institute of China Electronics Technology Group
Corporation; Sichuan Provincial Major Scientific and Technological
Special Project on Artificial Intelligence {[}2024ZDZX007]},
  funding-text = {This research was funded by the Sichuan Provincial Major Scientific and
Technological Special Project on Artificial Intelligence under Grant
2024ZDZX007. The APC was funded by the 30th Research Institute of China
Electronics Technology Group Corporation.},
  issn = {2079-9292},
  journal = {ELECTRONICS},
  journal-iso = {Electronics},
  keywords = {decompilation; vulnerability detection; large language models; fine
tuning; binary code},
  language = {English},
  month = {DEC 19},
  number = {1},
  number-of-cited-references = {46},
  oa = {gold},
  publisher = {MDPI},
  research-areas = {Computer Science; Engineering; Physics},
  times-cited = {0},
  title = {Research on Binary Decompilation Optimization Based on Fine-Tuned Large
Language Models for Vulnerability Detection},
  type = {Article},
  unique-id = {WOS:001657340000001},
  usage-count-last-180-days = {3},
  usage-count-since-2013 = {3},
  volume = {15},
  web-of-science-categories = {Computer Science, Information Systems; Engineering, Electrical \&
Electronic; Physics, Applied},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
  year = {2025}
}

@article{Wu2023,
  abstract = {Large language models (LLMs) have undergone rapid evolution and achieved remarkable results in recent times. OpenAI's ChatGPT, backed by GPT-3.5 or GPT-4, has gained instant popularity due to its strong capability across a wide range of tasks, including natural language tasks, coding, mathematics, and engaging conversations. However, the impacts and limits of such LLMs in system security domain are less explored. In this paper, we delve into the limits of LLMs (i.e., ChatGPT) in seven software security applications including vulnerability detection/repair, debugging, debloating, decompilation, patching, root cause analysis, symbolic execution, and fuzzing. Our exploration reveals that ChatGPT not only excels at generating code, which is the conventional application of language models, but also demonstrates strong capability in understanding user-provided commands in natural languages, reasoning about control and data flows within programs, generating complex data structures, and even decompiling assembly code. Notably, GPT-4 showcases significant improvements over GPT-3.5 in most security tasks. Also, certain limitations of ChatGPT in security-related tasks are identified, such as its constrained ability to process long code contexts. },
  author = {Wu, Fangzhou AND Zhang, Qingzhao AND Bajaj, Priya, Ati AND Bao, Tiffany AND Zhang, Ning AND Wang, "Fish", Ruoyu AND Xiao, Chaowei},
  doi = {https://doi.org/10.48550/arXiv.2312.05275},
  howpublished = {\url{https://arxiv.org/pdf/2312.05275}},
  month = {dec},
  note = {},
  title = {Exploring the Limits of ChatGPT in Software Security Applications},
  year = {2023}
}

@article{Xie2025,
  abstract = {Demonstrating quantum advantage using conventional quantum algorithms remains challenging on current noisy gate-based quantum computers. Automated quantum circuit synthesis via quantum machine learning has emerged as a promising solution, employing trainable parametric quantum circuits to alleviate this. The circuit ansatz in these solutions is often designed through reinforcement learning-based quantum architecture search when the domain knowledge of the problem and hardware are not effective. However, the interpretability of these synthesized circuits remains a significant bottleneck, limiting their scalability and applicability across diverse problem domains. This work addresses the challenge of explainability in quantum architecture search (QAS) by introducing a novel genetic programming-based decompiler framework for reverse-engineering high-level quantum algorithms from low-level circuit representations. The proposed approach, implemented in the open-source tool DeQompile, employs program synthesis techniques, including symbolic regression and abstract syntax tree manipulation, to distill interpretable Qiskit algorithms from quantum assembly language. Validation of benchmark algorithms demonstrates the efficacy of our tool. By integrating the decompiler with online learning frameworks, this research potentiates explainable QAS by fostering the development of generalizable and provable quantum algorithms. },
  author = {Xie, Shubing AND Sarkar, Aritra AND Feld, Sebastian},
  doi = {https://doi.org/10.48550/arXiv.2504.08310},
  howpublished = {\url{https://arxiv.org/pdf/2504.08310}},
  month = {apr},
  note = {},
  title = {DeQompile: quantum circuit decompilation using genetic programming for explainable quantum architecture search},
  year = {2025}
}

@article{Xu2024,
  abstract = {Decompilation aims to recover the source code form of a binary executable. It has many security applications, such as malware analysis, vulnerability detection, and code hardening. A prominent challenge in decompilation is to recover variable names. We propose a novel technique that leverages the strengths of generative models while mitigating model biases. We build a prototype, GenNm, from pre-trained generative models CodeGemma-2B, CodeLlama-7B, and CodeLlama-34B. We finetune GenNm on decompiled functions and teach models to leverage contextual information. GenNm includes names from callers and callees while querying a function, providing rich contextual information within the model's input token limitation. We mitigate model biases by aligning the output distribution of models with symbol preferences of developers. Our results show that GenNm improves the state-of-the-art name recovery precision by 5.6-11.4 percentage points on two commonly used datasets and improves the state-of-the-art by 32% (from 17.3% to 22.8%) in the most challenging setup where ground-truth variable names are not seen in the training dataset. },
  author = {Xu, Xiangzhe AND Zhang, Zhuo AND Su, Zian AND Huang, Ziyang AND Feng, Shiwei AND Ye, Yapeng AND Jiang, Nan AND Xie, Danning AND Cheng, Siyuan AND Tan, Lin AND Zhang, Xiangyu},
  doi = {https://doi.org/10.48550/arXiv.2306.02546},
  howpublished = {\url{https://arxiv.org/pdf/2306.02546}},
  month = {dec},
  note = {},
  title = {Symbol Preference Aware Generative Models for Recovering Variable Names from Stripped Binary},
  year = {2024}
}

@article{Zhou2025,
  abstract = {Decompiling Rust binaries is challenging due to the language's rich type system, aggressive compiler optimizations, and widespread use of high-level abstractions. In this work, we conduct a benchmark-driven evaluation of decompilation quality across core Rust features and compiler build modes. Our automated scoring framework shows that generic types, trait methods, and error handling constructs significantly reduce decompilation quality, especially in release builds. Through representative case studies, we analyze how specific language constructs affect control flow, variable naming, and type information recovery. Our findings provide actionable insights for tool developers and highlight the need for Rust-aware decompilation strategies. },
  author = {Zhou, Zixu},
  doi = {https://doi.org/10.48550/arXiv.2507.18792},
  howpublished = {\url{https://arxiv.org/pdf/2507.18792}},
  month = {jul},
  note = {},
  title = {Decompiling Rust: An Empirical Study of Compiler Optimizations and Reverse Engineering Challenges},
  year = {2025}
}

@article{Zou2025,
  abstract = {As one of the key tools in many security tasks, decompilers reconstruct human-readable source code from binaries. Yet, despite recent advances, their outputs often suffer from syntactic and semantic errors and remain difficult to read. Recently, with the advent of large language models (LLMs), researchers began to explore the potential of LLMs to refine decompiler output. Nevertheless, our study of these approaches reveals their problems, such as introducing new errors and relying on unreliable accuracy validation. In this paper, we present D-LIFT, an enhanced decompiler-LLM pipeline with a fine-tuned LLM using code quality-aware reinforcement learning. Unlike prior work that overlooks preserving accuracy, D-LIFT adheres to a key principle for enhancing the quality of decompiled code: preserving accuracy while improving readability. Central to D-LIFT, we propose D-Score, an integrated code quality assessment system to score the decompiled source code from multiple aspects, and use it to guide reinforcement learning fine-tuning and to select the best output during inference. In line with our principle, D-Score assigns low scores to any inaccurate output and only awards higher scores for readability to code that passes the accuracy check. Our implementation, based on Ghidra and a range of LLMs, demonstrates significant improvements for the accurate decompiled code from the coreutils and util-linux projects. Compared to baseline LLMs without D-Score-driven fine-tuning, our trained LLMs produce 55.3% more improved decompiled functions, as measured by D-Score. Overall, D-LIFT improves the quality of 68.2% of all the functions produced by the native decompiler. },
  author = {Zou, Muqi AND Cai, Hongyu AND Wu, Hongwei AND Basque, Leonahenahe, Zion AND Khan, Arslan AND Celik, Berkay AND Dave AND Tian AND Bianchi, Antonio AND Ruoyu AND Wang AND Xu, Dongyan},
  doi = {https://doi.org/10.48550/arXiv.2506.10125},
  howpublished = {\url{https://arxiv.org/pdf/2506.10125}},
  month = {aug},
  note = {},
  title = {D-LiFT: Improving LLM-based Decompiler Backend via Code Quality-driven Fine-tuning},
  year = {2025}
}
