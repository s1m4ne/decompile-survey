{"key": "WOS:001657340000001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "binary decompilation model based on fine-tuned large language models designed to generate high-precision decompiled code", "explanation": "LLM が中心手法として低水準のバイナリ入力からコンパイル可能なソースコード（高水準表現）を直接生成しているため、Core Decompilation に該当します。"}], "reasoning": "本稿はバイナリを入力とし、LLM を活用して高精度なデコンパイルコードを生成することを主目的としている。生成されたコードはコンパイル成功率や機能的正確性で評価されており、IC0 の条件を満たすため、サーベイの対象として採択すべきです。", "model": "openai/gpt-oss-120b", "tokens_used": 3256, "latency_ms": 24489}}
{"key": "WOS:001623665300001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "The goal of decompilation is to convert compiled low-level code (e.g., assembly code) back into high-level programming languages... end-to-end decompilation method based on large language models (LLMs)", "explanation": "抽象から、LLM を用いてアセンブリ等の低水準コードから直接高水準言語のコードを生成することが目的と示されているため、Core decompilation に該当する。"}], "reasoning": "本稿は低水準コード（アセンブリ）を入力とし、LLM を中心手法として高水準言語のコードを直接生成するエンドツーエンド手法を提案している。目的はコード復元・可読化であり、IC0 をすべて満たすためインクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 23726}}
{"key": "WOS:001503249300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our method utilizes the Ghidra decompiler in conjunction with a custom-built transpiler to reconstruct highlevel C++ source code from binary executables.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、従来の Ghidra デコンパイラとトランスパイラのみが用いられているため、EC1 の『No ML/LLM』に該当し除外と判断した。"}], "reasoning": "本稿はバイナリからソースコードへの変換に Ghidra デコンパイラと独自トランスパイラを利用しており、ML/LLM が手法の中心に含まれていない。したがって、Decompilation Survey の採択基準で必須とされる『LLM/ML を中核手法として使用』条件を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3329, "latency_ms": 26723}}
{"key": "WOS:001332656400001", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "refine decompilation outputs at the intermediate representation level", "explanation": "LLM/ML を用いて既存デコンパイラの中間表現 (LLVM IR) 出力を改善している点が、デコンパイラ出力の可読性・コンパイル可能性向上という目的に合致するため"}, {"code": "in_core", "evidence": "aimed at restoring binary code to human‑readable high‑level language code", "explanation": "バイナリ（低水準入力）から高水準表現（IR）を生成・再構成することを目的としていることが、Core デコンパイルに該当するため"}], "reasoning": "本論文は、LLM/ML を中心手法とし、バイナリ等の低水準入力から LLVM IR という高水準中間表現を生成または既存のデコンパイル出力を改善することを目的としている。LLM による出力の可読性とコンパイル可能性の向上は、デコンパイルの復元・可読化という核心目的に合致するため、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3468, "latency_ms": 37205}}
{"key": "WOS:001217002000001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "decompiled C code was used to train the SMT model", "explanation": "アブストラクトは入力として「decompiled C code」すなわち既に逆コンパイルされたコードを用いると明示しており、低水準のバイナリやアセンブリは含まれていないため、低水準入力の要件を満たさない"}], "reasoning": "本論文は統計的機械翻訳（SMT）を用いてデコンパイル後のコードの変数名を推測する研究であり、ML 手法は使用されているものの、入力はすでにデコンパイルされた高水準コードである。サーベイの定義では低水準表現（バイナリ/アセンブリ等）からの入力が必須であるため、除外基準 EC2 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3423, "latency_ms": 31417}}
{"key": "WOS:001174314700019", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "subsequent detection of their similarity ... detection of functionally similar fragments of program code", "explanation": "アブストラクトが示す主目的はバイナリ断片の類似性検出であり、コードの復元や生成ではなく分類/検知であるため除外基準 EC3 に該当します。"}], "reasoning": "本論文はバイナリからデコンパイルした疑似コードを用いて類似コード検出を行う手法を提案していますが、主たる目的はコードの復元や高水準表現の生成ではなく、類似性の検出（分類）です。したがって、デコンパイル自体は前処理に過ぎず、Decompilation Survey の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3113, "latency_ms": 28734}}
{"key": "WOS:001027789500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We decompiled and analysed 420 open-source applications by extending an existing tool", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されておらず、従来の静的解析ツールを拡張しているだけなので、EC1 に該当し除外します。"}, {"code": "ex_no_code_generation", "evidence": "We study the viability of looking for known energy patterns in applications by decompiling them and analysing the resulting code", "explanation": "研究目的はエネルギーパターンの検出（分類）であり、コードの復元・生成や可読化が主目的ではないため EC3 でも除外対象です。"}], "reasoning": "本論文はデコンパイルしたコードを用いたエネルギーパターン検出を行うもので、機械学習・LLM を用いた手法は示されていません。また、復元や高水準コード生成が目的ではなく、パターン検出という分類タスクに焦点を当てているため、包含基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3490, "latency_ms": 29142}}
{"key": "WOS:000935184700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We have performed ... study of Android decompilation failure rates", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用についての記述がなく、単に既存デコンパイラの性能評価を行っていることから、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は既存の Android デコンパイラの失敗率を大規模に測定する実証研究であり、ML/LLM を手法として使用していない。したがって、Decompilation Survey Screening Rules の除外基準 EC1（No ML/LLM）に該当し、include の対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3206, "latency_ms": 22323}}
{"key": "WOS:000900131300002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "BinVulDet ... is a binary level vulnerability detection tool ...", "explanation": "論文の目的はバイナリの脆弱性検出であり、コードの復元や生成が主目的ではなく分類タスクであるため、除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリからデコンパイルした疑似コードを入力として、BiLSTM‑attention により脆弱性を検出する手法を提案しています。復元・可読化といったコード生成が目的ではなく、脆弱性の有無を分類することが主目的であるため、デコンパイルの出力生成を目的とした研究ではなく除外基準 (ex_no_code_generation) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3255, "latency_ms": 25753}}
{"key": "springer_10_1007_978_981_96_4731_6_16", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "translate low-level PL into accurate high-level PL", "explanation": "低水準言語（バイナリ）から高水準言語（C/C++）への変換を目的とし、Transformer ベースのニューラルネットワークで直接コード生成を行っているため、Core Decompilation に該当する"}], "reasoning": "本稿はバイナリなど低水準表現を入力とし、Transformer を用いたニューラル機械翻訳で C/C++ のソースコードを生成する手法を提案している。ML/LLM が中心手法であり、復元・可読化が主目的であることから包含基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3223, "latency_ms": 27806}}
{"key": "10.1145/3650212.3652144", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we systematically evaluate current mainstream decompilers’ semantic consistency and readability", "explanation": "要旨ではデコンパイラの評価と改善提案のみが述べられ、ML/LLM の使用について言及がなく、ルールベースの評価研究であるため除外と判断しました"}], "reasoning": "本論文は既存デコンパイラの評価と改善アイデアを提示しているが、機械学習や大規模言語モデルを手法の中心に用いている記述がない。したがって、インクルード基準の IC0（LLM/ML が中核手法）を満たさず、除外基準 EC1（ML/LLM を使用していない）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3023, "latency_ms": 19015}}
{"key": "10795101", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present Erase, the first approach to reverse the self-recursive inlining optimization technique.", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が記載されておらず、手法はアルゴリズム的な最適化逆転であるため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本論文はバイナリのインライン化最適化を逆転させる手法を提案しており、デコンパイル出力の可読性向上を目的としているが、機械学習や大規模言語モデルを利用した記述がなく、EC1（ML/LLM を使用していない）に該当するため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3248, "latency_ms": 26513}}
{"key": "WOS:000672841700001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "converts low-level PL into high-level PL while acquiring legibility", "explanation": "低水準プログラム言語（バイナリ・アセンブリ）を入力とし、注意機構を持つニューラル機械翻訳で高水準コードを直接生成しているため、Core Decompilation に該当する。"}], "reasoning": "論文はバイナリやアセンブリといった低水準表現を入力とし、注意ベースのニューラル機械翻訳（ML手法）で高水準ソースコードを生成することを目的としている。目的がコードの復元・可読化であり、生成されたコードはコンパイル可能なレベル（L1）に相当するため、Include 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3144, "latency_ms": 21269}}
{"key": "WOS:000557871300009", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we assess the strategies of eight Java decompilers ... We propose a new decompiler called Arlecchino", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されておらず、従来のルールベース/統計的手法によるデコンパイラの評価と新規デコンパイラの提案のみであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は Java バイトコードからソースコードへのデコンパイル手法の比較と新規デコンパイラの提案を行っているが、機械学習や大規模言語モデルを中心手法として用いた記述がなく、排除基準 EC1（ML/LLM を使用していない）に該当する。そのためインクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3251, "latency_ms": 25163}}
{"key": "8930870", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We study the effectiveness of eight Java decompilers ...", "explanation": "本文は既存のJavaデコンパイラを評価する研究であり、ML/LLM を用いた手法について言及していないため、EC1 に該当し除外と判断した。"}], "reasoning": "本論文は Java バイトコードデコンパイラの品質比較を行う実証的調査であり、ML/LLM を利用したデコンパイル手法の提案や改善を行っていない。したがって、除外基準 EC1（ML/LLM を使用していない）に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3022, "latency_ms": 19409}}
{"key": "WOS:000541153400012", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we introduce the use of a decompiled source code for malicious code classification", "explanation": "要旨はデコンパイルしたコードを用いたマルウェア分類であり、復元・コード生成が目的ではなく分類が主目的であるため除外基準EC3に該当します"}], "reasoning": "本論文はAPKをデコンパイルした後、そのソースコードを用いてマルウェアの分類・検出を行うことに焦点を当てており、デコンパイル自体の復元や可読化が目的ではありません。したがって、デコンパイルのコード生成・再構築を目的とした研究とはみなされず、除外基準EC3（コード生成・復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3191, "latency_ms": 24093}}
{"key": "WOS:000582272700012", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "Reditus is based on the observation that an engineering software has a built-in decompiler that can transform the control logic into its source-code.", "explanation": "要旨からは機械学習・大規模言語モデルの使用が示されておらず、単に既存の組み込みデコンパイラを利用しているだけなので、EC1 に該当し除外します。"}], "reasoning": "本論文は低水準の制御ロジックをネットワークトラフィックから抽出し、既存の組み込みデコンパイラでソースコードに変換する手法を提案していますが、ML/LLM を手法の中核として利用している記述がなく、除外基準 EC1（No ML/LLM）に該当します。そのためインクルードではなく除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3137, "latency_ms": 21898}}
{"key": "WOS:001616881300004", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "MalSFF ... employs six different classifiers ... for malware detection.", "explanation": "目的がマルウェア検出であり、コード生成や可読化は行わないため、復元・生成が主目的ではないと判断した。"}], "reasoning": "本稿はバイナリを逆コンパイルして特徴抽出に利用するが、最終目的は画像ベースのマルウェア分類であり、コードの復元・可読化を目的としたデコンパイルではない。そのため除外基準 EC3（コード生成・復元目的でない）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3364, "latency_ms": 29134}}
{"key": "Kumar2018", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We evaluate 13 obfuscators using a dataset of 16 programs...", "explanation": "要約中に機械学習や大規模言語モデルの利用は言及されておらず、従ってML/LLMが使用されていないと判断したため。"}, {"code": "ex_survey_or_meta", "evidence": "We systematically study CFO techniques proposed for Java programs...", "explanation": "本稿は既存手法の体系的な調査・分類を目的としており、サーベイ論文に該当するため。"}], "reasoning": "本文はJavaプログラムに対する制御フロー難読化手法の体系的調査であり、機械学習やLLMの利用は示されていない。また、サーベイ・レビュー的性格が強く、デコンパイルをMLで行う研究ではないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3291, "latency_ms": 27463}}
{"key": "WOS:001571912000001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "ensemble-based classification... detection framework", "explanation": "抽象ではコード生成や復元ではなく、マルウェア検出・分類が目的と明示されているため、デコンパイルの主目的を満たさないと判断した。"}], "reasoning": "本論文はAndroidアプリのAPKをデコンパイルして得た静的特徴を用い、機械学習ベースの分類器でマルウェアを検出することが主目的です。LLM/MLは検出モデルに使われており、低水準コードから高水準コードを生成するデコンパイル手法そのものには関与していません。そのため、ICを満たさず、除外基準 EC3（コード生成・復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3246, "latency_ms": 23958}}
{"key": "WOS:001561843400001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "proposes ... hybrid malware detection model ... outperforms existing malware detection methods", "explanation": "要旨はマルウェア検出のための分類モデルを提案しており、コードの復元・生成を目的としていないため、EC3 に該当します。"}], "reasoning": "本稿はバイナリやオペコード列を用いたマルウェア検出手法を提案しており、デコンパイルによる高水準コードの復元や可読化を目的としていません。したがって、コード生成・復元を目的としない分類タスクであり、除外基準 EC3（コード生成・復元意図なし）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3334, "latency_ms": 27562}}
{"key": "WOS:001560856600001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a dual-innovation strategy integrating bioinspired structural engineering and composite property synergy.", "explanation": "要旨に機械学習・大規模言語モデルの使用が全く記載されておらず、従って本調査の対象外です。"}, {"code": "ex_out_of_scope", "evidence": "bioinspired gradient pores and composite synergy in negative Poisson aramid/cellulose aerogels for oil‑water separation and thermal insulation", "explanation": "研究対象は材料・エンジニアリングであり、デコンパイル（低水準コードから高水準コードへの復元）とは無関係です。"}], "reasoning": "本稿は材料科学に関する研究であり、低水準プログラム表現から高水準コードへの復元を目的とした手法や機械学習・LLMの利用が示されていないため、デコンパイル調査のスコープから外れます。", "model": "openai/gpt-oss-120b", "tokens_used": 3292, "latency_ms": 24472}}
{"key": "WOS:001556094500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present novel techniques for estimating the number, as well as the boundaries, of compile-units in binary executables.", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が言及されておらず、従来のアルゴリズムによる手法とみなせるため、EC1 に該当します。"}], "reasoning": "本稿はバイナリからコンパイルユニットを推定する手法を提案していますが、ML/LLM を用いたことが明示されていません。したがって、Decompilation Survey の採択基準である LLM/ML 中核手法の使用が欠如しているため除外 (exclude) と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3381, "latency_ms": 24126}}
{"key": "WOS:001539888300001", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.62, "reason_codes": [{"code": "uns_unclear_input", "evidence": "Our methodology includes decompilation, source code analysis, automated translation using ChatGPT", "explanation": "アブストラクトでは「decompilation」を行うと述べているが、入力がバイナリやアセンブリといった低水準表現なのか、既存の C/C++ ソースコードなのかが明示されていないため、低水準入力の有無が不明である"}], "reasoning": "LLM を用いた自動翻訳は示されているものの、対象となる入力が低水準表現かどうかが抽象だけでは判断できない。低水準入力が確認できれば Core decompilation として include になる可能性はあるが、現時点では情報が不足しているため uncertain とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3291, "latency_ms": 30400}}
{"key": "WOS:001551990000001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "integrating blockchain, zero-knowledge proofs, and smart contract (SC) obfuscation", "explanation": "要旨では機械学習や大規模言語モデルの利用は言及されず、手法はブロックチェーンとゼロ知識証明に限定されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は産業制御システム向けの防御モデルを提案しており、ML/LLM を用いたデコンパイル手法や高水準コード生成とは無関係である。要旨に機械学習の記述がなく、デコンパイルは防御対象であって生成目的ではないため、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3253, "latency_ms": 26538}}
{"key": "WOS:001517603500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "classify compiler versions using compiled executable files", "explanation": "アブストラクトはバイナリからコンパイラバージョンを分類することを目的としており、コード生成や復元は行わないため"}], "reasoning": "本稿はバイナリからコンパイラバージョンを識別する分類手法を提案しており、デコンパイル（高水準コードの復元）を目的としていない。したがって、デコンパイル調査の採択基準を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 21492}}
{"key": "WOS:001450844300001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "training and evaluating the ability to detect Android malware", "explanation": "論文の主目的はマルウェア検出という分類であり、コードの生成や復元を目的としていないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は APK をデコンパイルして API コールグラフを生成し、機械学習でマルウェアを分類することが目的です。デコンパイルは下流タスクの前処理に過ぎず、復元・可読化といったデコンパイルの本来目的を満たしていないため、除外基準 EC3（コード生成・復元目的でない）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3388, "latency_ms": 22695}}
{"key": "WOS:001429826200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Our approach involves decompiling .NET executables, parsing the resulting code, and extracting standard .NET method names.", "explanation": "要旨はメソッド名を抽出してマルウェア検出モデルに利用することであり、復元・高水準コード生成が目的ではなく分類が主目的なので、コード生成・復元意図が absent であると判断した。"}], "reasoning": "本稿は .NET 実行ファイルをデコンパイルしてメソッド名を取得し、機械学習でマルウェアか否かを判定する手法を提案している。デコンパイルは特徴抽出の前処理であり、復元や可読化といったデコンパイル本来の目的がなく、分類タスクが主目的となっているため、除外基準 EC3（コード生成・復元意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3257, "latency_ms": 27097}}
{"key": "WOS:001397990500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we introduce a decoding algorithm that utilizes a sliding window approach", "explanation": "本文ではスライディングウィンドウを用いたデコードアルゴリズムを提案しており、機械学習やLLMの使用は示されていないため、ex_no_ml に該当する。"}], "reasoning": "本稿は FPGA ビットストリームの圧縮解除手法をアルゴリズム的に提案しているが、機械学習／LLM を用いた手法は記述されていない。また、出力は高水準コードや擬似コードではなく、圧縮解除されたバイナリであり、Decompilation Survey の対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3201, "latency_ms": 28723}}
{"key": "WOS:001498227900001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "based on sensitive data flow analysis of decompiled code", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、従来の静的解析手法に基づくと判断したため。"}], "reasoning": "本稿はIoTデバイス向けの指向性ファズング手法を提案しており、デコンパイルしたコードを解析対象としているものの、ML/LLM を中心手法として用いていない。したがって除外基準 EC1 (ex_no_ml) に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 21804}}
{"key": "WOS:001403092200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "code similarity detection identifies code by analyzing similarities in syntax, semantics, and structure", "explanation": "本文はコード類似性の検出を目的としており、ソースコードやバイナリから高水準コードを生成・復元することを目的としていないため、コード生成・復元の意図がなく除外基準EC3に該当します。"}], "reasoning": "本稿はバイナリとソースの表現を統一し類似度測定を行う手法を提案しているが、デコンパイルによるコード復元や可読化が主目的ではなく、類似性検出という分類タスクに焦点を当てている。したがって、デコンパイル研究のインクルード基準を満たさず除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3462, "latency_ms": 32086}}
{"key": "WOS:001377798100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the analyst must study these data, evaluate them, and properly identify and classify suspicious activities and applications", "explanation": "論文は脆弱性の検出やログ解析といった分類・検知が主目的であり、コードを生成・復元することは目的としていないため"}, {"code": "ex_no_lowlevel_input", "evidence": "the (decompiled) source code of potentially malicious applications", "explanation": "入力として言及されているのは「decompiled source code」であり、低水準バイナリやアセンブリからの直接入力ではなく、高水準コードの分析に留まっているため"}], "reasoning": "本稿はLLMを用いてセキュリティアナリストの支援を行うことを目的としており、低水準バイナリからの復元やコード生成は行っていない。したがってデコンパイルの核心的目的や手法を満たさず、除外基準 EC3（コード生成・復元が目的でない）および EC2（低水準入力がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3233, "latency_ms": 29908}}
{"key": "WOS:001350308700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Static taint analysis is a widely used method to identify vulnerabilities in Android applications.", "explanation": "要旨では機械学習・LLM の利用は言及されず、従来の静的解析手法のみが用いられているため、ML/LLM が使われていないと判断した。"}], "reasoning": "本論文は Android アプリを Jimple へデコンパイルし、ラベリングされたタントフローネットワークを用いた静的解析を提案しているが、機械学習や大規模言語モデルを用いた手法は記載されていない。したがって、Decompilation Survey の対象となる「ML/LLM を中核としたデコンパイル」には該当せず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3356, "latency_ms": 28270}}
{"key": "WOS:001263763900001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "classification method based on decompiled features", "explanation": "要旨は逆コンパイルで得た特徴を用いたマルウェア分類であり、コードの復元や生成を目的としていないため、コード生成/再構成の意図がないと判断した。"}], "reasoning": "本稿はAndroidマルウェアの変種生成と分類を目的とした adversarial training フレームワークを提案しており、低水準バイナリから高水準コードを復元する decompilation 研究ではない。ML/LLM はサンプル生成や画像変換に使われているが、復元・可読化やソースコード生成の目的がなく、除外基準 EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3375, "latency_ms": 32664}}
{"key": "WOS:001247013900001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "we carried out both a dynamic and a static analysis of decompiled Locker.CB!tr ransomware source code", "explanation": "要旨に機械学習や大規模言語モデルの利用が記載されておらず、単なる動的・静的解析のみであるため、EC1 に該当し除外します"}], "reasoning": "本稿はランサムウェアの通信を逆解析し復旧手法を提示していますが、ML/LLM を用いた手法は示されていません。したがって、Decompilation Survey の採択基準を満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3203, "latency_ms": 24230}}
{"key": "WOS:001237837300001", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This article offers a thorough examination and organized summary of the pertinent material of smart contract security analysis.", "explanation": "要旨はスマートコントラクトのセキュリティに関する調査・総括であり、研究成果の提示ではなくサーベイであるため、除外基準 EC4 に該当します。"}], "reasoning": "本稿はスマートコントラクトセキュリティに関する包括的なサーベイであり、LLM/ML を用いたデコンパイル手法の研究ではありません。したがって除外基準 (ex_survey_or_meta) に基づき除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3009, "latency_ms": 18689}}
{"key": "WOS:001166549700001", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Lipids in food components were decompiled by an analysis of the maximum common substructures.", "explanation": "「decompiled」は化学構造の分解を指しており、低水準バイナリから高水準コードを生成するデコンパイルとは無関係なので本サーベイの範囲外です。"}], "reasoning": "本文は食品化学物質の多様性解析であり、プログラムのバイナリやアセンブリを対象としたデコンパイル研究ではありません。LLM/ML を用いたコード復元や型・命名回復といった要件も示されていないため、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3316, "latency_ms": 29162}}
{"key": "WOS:001320166600005", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "graph methods have been implemented in C++", "explanation": "本文はグラフアルゴリズムを C++ で実装しており、機械学習・大規模言語モデルの利用が示されていないため、ML/LLM が使用されていないと判断しました。"}], "reasoning": "この研究はトランジスタレベルの SPICE 回路を階層的な論理ゲートネットワークへ変換するデコンパイル手法を提案していますが、手法は C++ 実装のグラフアルゴリズムであり、機械学習や大規模言語モデルは使用されていません。したがって、デコンパイルに ML/LLM が中核手法として用いられているという採択基準を満たさないため、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2958, "latency_ms": 21059}}
{"key": "WOS:001136012000001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The proposed method ... implements a convolutional neural network for malware classification using images.", "explanation": "本文は画像化したハッシュを用いたマルウェア分類が目的であり、コードの復元や高水準表現の生成は行っていないため、コード生成・復元を目的としたデコンパイル研究には該当しません。"}], "reasoning": "本稿は Android APK を画像に変換し CNN でマルウェアを分類する手法を提案しており、ML は分類タスクに用いられていますが、デコンパイルによるコード復元や可読化を目的としていません。そのため、Include 基準を満たさず Exclude 基準（コード生成・復元意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3087, "latency_ms": 24232}}
{"key": "10299644", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a new method for Android ransomware classification was proposed... implements a Convolutional Neural Network (CNN) for malware classification", "explanation": "要旨はマルウェアをクラス分類することが目的であり、コードや高水準表現の復元・生成を行う意図が示されていないため、EC3 に該当し除外します。"}], "reasoning": "本論文は APK を画像化し CNN でランサムウェアかどうかを判別する分類手法を提案しており、デコンパイルによるソース復元や可読化を目的としていません。そのため、出力がコード生成や高水準表現の再構築ではなく、分類ラベルのみであることから除外基準 EC3 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3214, "latency_ms": 27055}}
{"key": "WOS:001094893100006", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "A novel program code obfuscation approach involving the x86 mode switching is proposed in the paper.", "explanation": "要旨では機械学習やLLMの使用について言及されておらず、ML/LLMが手法の中心でないためEC1に該当します。"}, {"code": "ex_out_of_scope", "evidence": "The details and existing applications of x86 mode switching are reviewed, as well as the possible consequences of using this switching to the reverse engineering tools.", "explanation": "研究の目的はコード保護・オブフュスケーションであり、デコンパイルや高水準コード復元を目的としていないため範囲外です。"}], "reasoning": "本稿は x86 モードスイッチングを用いたプログラムコードのオブフュスケーション手法を提案しており、機械学習やLLMを用いたデコンパイル研究とは無関係です。したがって、ML/LLM不使用（EC1）およびデコンパイルの範囲外（EC5）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3190, "latency_ms": 32358}}
{"key": "WOS:001191292200001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "by using a recurrent neural network-a reservoir computer-to decompile, code and compile analogue computations.", "explanation": "リカレントニューラルネットワーク（ML 手法）を用いて低レベルのニューラルマシンコードから直接高レベルのプログラム表現を生成しているため、Core Decompilation に該当します。"}, {"code": "in_type_recovery", "evidence": "decompiling the reservoir's internal representation and dynamics into an analytic basis of its inputs", "explanation": "内部表現（低水準）を解析的な基底（型やシグネチャに相当）へ変換している点が型／属性回復に該当します。"}], "reasoning": "本論文はリカレントニューラルネットワークという機械学習手法を中心に、低水準のニューラルマシンコード（内部表現）を高レベルの解析表現やプログラムへ変換（デコンパイル）し、さらにそれをコンパイルして実行可能なプログラムを生成している。入力が低水準であり、目的がコードの復元・可読化であること、ML が核となっていることから、Include 基準を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3515, "latency_ms": 37805}}
{"key": "WOS:000998226600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "A 1-D convolutional neural network and fully connected layers are used for further feature extraction and classification, respectively.", "explanation": "要旨はマルウェア検出・分類が目的であり、コードや擬似コードの生成・復元は行わないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は decompiled APK から関数呼び出しグラフを抽出し、GCN を用いたマルウェア検出を行う手法を提案しています。目的は高水準コードの復元や可読化ではなく、悪意あるアプリの分類であるため、デコンパイル研究の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3478, "latency_ms": 32288}}
{"key": "WOS:000995629300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we also discuss the importance of preventing client and server decompilation during its implementation", "explanation": "要旨ではML/LLMを用いたデコンパイル手法について触れておらず、単にデコンパイル防止を論じているだけなので、本サーベイの対象外です。"}], "reasoning": "本稿はデータプライバシー保護アルゴリズムの提案であり、デコンパイルは防止対象として言及されるのみで、ML/LLM を用いたデコンパイルや高水準コード生成の研究ではありません。そのため除外基準 EC1 (No ML/LLM) に該当し、include できません。", "model": "openai/gpt-oss-120b", "tokens_used": 3085, "latency_ms": 20420}}
{"key": "WOS:000976384800001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We first decompile the Android application to generate a function call graph (FCG)... feed into a graph convolutional network (GCN) for malware detection.", "explanation": "アブストラクトでは、デコンパイルは機能呼び出しグラフを作成する前処理として言及されており、主目的はマルウェア検出という分類タスクであり、コード生成・復元が目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本論文はデコンパイルをマルウェア検出のための特徴抽出ステップとして利用しており、復元・可読化・高水準コード生成を目的としていないため、除外基準 EC3（コード生成・復元が主目的でない）に該当します。そのため include ではなく exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3196, "latency_ms": 25231}}
{"key": "WOS:000985293800001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "This paper aims to detect vulnerabilities via the Bug Injection framework and transfer learning techniques.", "explanation": "概要から本研究の主目的が脆弱性検出（分類）であり、コードの復元や高水準表現の生成が明示されていないため、コード生成・再構築の意図がないと判断した。"}], "reasoning": "本文はスマートコントラクトの脆弱性検出を目的としており、バイトコードをアセンブリにデコンパイルする工程は特徴抽出の一部に過ぎません。復元・可読化といった高水準コード生成が主目的でないため、除外基準 EC3（コード生成・復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3479, "latency_ms": 31123}}
{"key": "WOS:000998081700001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "syntactic information ... in Java code", "explanation": "アブストラクトは Java のソースコードを対象としており、バイナリやアセンブリなどの低水準表現が入力であることが示されていないため、低水準入力の要件を満たさないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "run different interpretable ... machine learning algorithms to mine the syntactic information", "explanation": "目的は構文情報のマイニング・分析であり、コードの復元・生成（デコンパイル）を行うことが主目的ではないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿は Java ソースコードの構文パターンを機械学習で分析することが目的であり、入力が低水準表現（バイナリ・アセンブリ等）ではなく、コードを高水準表現に復元するデコンパイルの研究目的も示されていない。そのため、スクリーニング基準の除外基準 EC2 と EC3 に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3199, "latency_ms": 25717}}
{"key": "WOS:000885209600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to distinguish malicious applications from benign applications... Random Forest (RF) and Convolutional Neural Networks (CNN) to train a permission-based classifier and an API call sequence-based classifier", "explanation": "要旨はマルウェア検出のための分類器構築であり、コードの生成や復元は行っていないため、コード生成・復元を目的としたデコンパイル研究ではないと判断した。"}], "reasoning": "本論文はデコンパイルツールを特徴抽出に利用しているものの、主たる目的は権限情報と API 呼び出しシーケンスを用いたマルウェア検出であり、LLM/ML は分類器の学習に使用されている。復元・可読化といったデコンパイルの目的がなく、コード生成や高水準表現の取得は行っていないため、除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3276, "latency_ms": 25848}}
{"key": "WOS:000849409500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "machine learning classification algorithms are used to classify the malicious and benign applications.", "explanation": "要旨では機械学習でマルウェアを分類することが目的であり、低水準コードから高水準コードや擬似コードを生成・復元する目的が記載されていないため、コード生成・復元意図がないと判断しました。"}], "reasoning": "本論文は Android アプリケーションを画像化しテクスチャ特徴を抽出してマルウェア検出を行う手法を提案しており、デコンパイルやコード復元を目的としていません。入力はバイナリから画像への変換であり、出力は悪質/正常のラベルであるため、デコンパイル研究の包括基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3079, "latency_ms": 20983}}
{"key": "WOS:000838998100001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "we first generated a malware variant dataset using the obfuscation technique based on the disassembly and decompilation of malware", "explanation": "要旨ではデコンパイルは従来の手法で行われており、ML/LLM がデコンパイル工程に用いられている記述がないため"}, {"code": "ex_no_code_generation", "evidence": "a BERT pretrained model for malware detection was constructed", "explanation": "本研究の主目的はマルウェア検出・分類であり、コード生成や再構成が目的ではないため"}], "reasoning": "本稿はマルウェア変種データセットの構築とそれを用いた検出モデルの提案が中心で、デコンパイルはデータ生成の前処理として従来手法で実施されています。デコンパイル工程に機械学習や大規模言語モデルは使用されておらず、復元・可読化が研究目的でもないため、デコンパイルに関するサーベイの採択基準を満たさないと判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3338, "latency_ms": 31970}}
{"key": "WOS:000849434800002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The method proposed in this paper does not need to decompile the Android APK installation package.", "explanation": "目的がマルウェアのマルチクラス分類であり、コードの復元や高水準表現の生成は行っていないため除外基準EC3に該当します。"}, {"code": "ex_out_of_scope", "evidence": "deep neural network automatically obtains the RGB image texture features to realize the multiple classifications of the Android malware family", "explanation": "研究の焦点は画像ベースのマルウェア検出であり、デコンパイルやソース復元とは無関係なためスコープ外です。"}], "reasoning": "本稿はAndroid APK から DEX と XML を画像化し、ディープラーニングでマルチクラスマルウェア検出を行う手法を提案しています。デコンパイルやコード生成が目的ではなく、低水準バイナリから高水準コードを復元する研究ではないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3430, "latency_ms": 29679}}
{"key": "WOS:000864735500003", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "The arrival of the Bourbons to the Hispanic Monarchy brought with it new ways of conceiving of the society...", "explanation": "研究は歴史的社会構造の分析であり、デコンパイルやバイナリ解析とは無関係であるため、サーベイの範囲外です。"}, {"code": "ex_no_ml", "evidence": "The analysis of the census ... and of the decompiled documentation of the General Archive of the Nation ...", "explanation": "要旨に機械学習や大規模言語モデルの使用についての記述がなく、ML 手法は使用されていないと判断できます。"}], "reasoning": "本稿は18世紀コロンビアの人口歴史を扱う社会史研究であり、低水準バイナリやコードを対象としたデコンパイルや機械学習技術の利用は示されていません。そのため、デコンパイル調査の対象外（ex_out_of_scope）かつML不使用（ex_no_ml）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3281, "latency_ms": 32118}}
{"key": "WOS:000804579300001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the classification phase, long short term memory based electro search optimization (LSTM-ESO) is employed to detect the unknown mobile applications as benign or malicious.", "explanation": "要旨からは、LLM/MLはマルウェア検知の分類に使われており、コードの復元や高水準表現の生成は目的として示されていないため、コード生成・復元の意図がなく除外基準 EC3 に該当する"}], "reasoning": "本稿は Android アプリを Androguard でデコンパイルし特徴抽出を行った後、LSTM‑ESO によりマルウェアか否かを分類することが主目的であり、デコンパイル結果を高水準コードに変換・復元することは目的に含まれない。したがって、コード生成・復元を目的としないため除外 (ex_no_code_generation) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3246, "latency_ms": 26927}}
{"key": "WOS:000798201400013", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The Stacked-Long Short-Term Memory (S-LSTM) deep learning model is designed to predict possible clones.", "explanation": "本文はクローン検出という分類タスクが主目的であり、低水準コードから高水準コードを生成することを目的としていないため、コード生成/復元の意図がないと判断した。"}], "reasoning": "本稿はAPK/DEX をデコンパイルして得た Java ソースを特徴抽出に利用し、深層学習でクローン判定を行う分類研究である。ML 手法はデコンパイルそのものではなくクローン予測に用いられており、デコンパイル（コード復元・生成）を目的としていないため除外基準 EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3314, "latency_ms": 31571}}
{"key": "WOS:000771288000001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Sensor switches monitor the chassis status at all times and upload event logs to a cloud server", "explanation": "本文や要旨に機械学習・大規模言語モデルの使用が言及されておらず、従来のハードウェアセンサーによる監視が中心であるため、ML/LLM が使われていないと判断した。"}], "reasoning": "本稿は物理的な改ざん検知システムの提案であり、バイナリやアセンブリ等の低水準入力から高水準コードを復元することを目的としていない。さらに、機械学習や大規模言語モデルを手法の中心に用いる記述もなく、デコンパイル研究の範囲外であるため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3057, "latency_ms": 20533}}
{"key": "WOS:000867635500021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "introduces a Bigdata assisted energy conversion model (BD-ECM)", "explanation": "要旨ではML/LLMの使用について言及されておらず、エネルギー変換モデルの提案であるため、ML/LLMを中核手法としたデコンパイル研究ではないと判断した。"}], "reasoning": "本稿はエネルギー変換モデルとその評価に関する研究であり、低水準バイナリやアセンブリからの高水準コード生成を目的とした手法ではない。さらに、機械学習や大規模言語モデルの利用が示されていないため、デコンパイルに関わる基準を満たさず除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3076, "latency_ms": 20742}}
{"key": "WOS:000748533600001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "specifically decompilation", "explanation": "アブストラクトでは逆エンジニアリングとしてデコンパイルを言及しているが、機械学習や大規模言語モデルの使用は全く示されていないため、EC1 に該当し除外と判断した。"}], "reasoning": "本稿は Flash アートの移行のためにデコンパイルを用いると述べているが、手法として ML/LLM が使われている記述がない。デコンパイルは対象だが、ルールでは ML/LLM が中核であることが必須条件なので除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3009, "latency_ms": 20285}}
{"key": "WOS:000737527800001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "features that cannot be obtained through decompilation", "explanation": "アブストラクトでは逆コンパイルで取得できない特徴を用いると述べており、入力が低水準バイナリやアセンブリではなく高レベルの特徴であるため、低水準入力がないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "aim to improve performance of Android malware detection", "explanation": "目的はマルウェア検出の精度向上であり、コードの復元や生成を目的としていないため、コード生成/再構築の意図がないと判断した。"}], "reasoning": "本論文は Android マルウェア検出のためのクラス不均衡学習手法を提案しており、入力は逆コンパイルで取得できない高レベル特徴であることが示されている。デコンパイルや低水準から高水準コードへの変換を目的としていないため、除外基準 EC2（低水準入力なし）および EC3（コード生成目的なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3250, "latency_ms": 28339}}
{"key": "WOS:000691101100002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "uses ... deep learning network for classification and discrimination", "explanation": "要旨はデコンパイルしたコードを特徴ベクトル化し、深層学習でマルウェアかどうかを分類することが目的であり、コードの復元・生成は行わないため、EC3に該当します。"}], "reasoning": "本文は APK をデコンパイルして得たコードをベクトル化し、深層ネットワークでマルウェア検出を行う手法を提案しています。ML の利用は検出（分類）に限定されており、低水準コードから高水準コードへの復元や可読化といったデコンパイルの核心目的がないため、除外基準 EC3（コード生成・復元意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3361, "latency_ms": 31574}}
{"key": "WOS:000709490700009", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Finally, convolution neural network is used to classify the fused samples.", "explanation": "要旨は融合された特徴をCNNで分類することであり、コードの復元・生成が目的ではなく分類が主目的なので除外基準EC3に該当します。"}], "reasoning": "本稿はマルウェアの分類を目的としており、低水準表現から高水準コードを生成するデコンパイルではなく、特徴抽出後のラベル予測を行っています。そのため、復元・可読化を目的としたML/LLM手法ではなく、分類タスクに焦点を当てているため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3088, "latency_ms": 24935}}
{"key": "WOS:000695854600007", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "provides the stochastic generation of large amounts of standard C code", "explanation": "アブストラクトは低水準表現（バイナリやアセンブリ）ではなく、標準Cソースコードを生成することを目的としているため、デコンパイルの入力条件を満たさないと判断した。"}], "reasoning": "本論文は低水準コードから高水準コードを復元するデコンパイル手法を提案しているわけではなく、むしろ高水準のCコードを大量に生成するツールを紹介している。入力が低水準表現でないことから、Decompilation Survey の対象外と判断する。", "model": "openai/gpt-oss-120b", "tokens_used": 3289, "latency_ms": 31565}}
{"key": "WOS:000658941200001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a new Android malware identification approach based on malicious subgraph mining", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、手法はサブグラフマイニングと記述されているため、ML/LLM が使われていないと判断した。"}], "reasoning": "本研究はデコンパイルされたファイルから構造情報を抽出し、サブグラフマイニングによるマルウェア検出を目的としている。目的は分類・検知であり、LLM/ML を中心手法として利用している記述がないため、除外基準 EC1（ML/LLM 未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3198, "latency_ms": 26646}}
{"key": "WOS:000649389100006", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Control flow-based feature extraction method has the ability to detect malicious code...", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、従来のアルゴリズムによる特徴抽出のみが記述されているため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "fast extraction of control flow-based features with polynomial time O(N-2)...", "explanation": "論文の目的はマルウェア検出のための特徴抽出であり、コードの復元や高水準表現の生成は行わないため、コード生成・復元の意図がないと判定した。"}], "reasoning": "本稿は低水準コードから特徴を抽出しマルウェア検出を行う手法を提案しているが、機械学習/LLM の利用やデコンパイルによる高水準コード生成は行っていない。したがって、デコンパイル調査の対象外と判断し除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3080, "latency_ms": 24428}}
{"key": "WOS:000632639400003", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The model classifies an unknown application as benign or malicious based on the log likelihood score generated.", "explanation": "本文の主目的はマルウェアの検出・分類であり、デコンパイルによるコード生成や復元ではないため、コード生成/再構成の意図がなく除外基準EC3に該当します。"}], "reasoning": "本稿はAndroidアプリをデコンパイルしてAPI情報を抽出し、その特徴を用いてHMMでマルウェア判別を行う手法を提案しています。デコンパイルは特徴抽出の前処理に過ぎず、研究の目的は高水準コードの復元や可読化ではなく分類です。そのため、Decompilation Surveyのインクルード基準を満たさず、除外（ex_no_code_generation）と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3337, "latency_ms": 34662}}
{"key": "WOS:000604998900011", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "design of batik patterns ... cannot satisfy the visual cognitive needs of consumers", "explanation": "アブストラクトはバティック模様の設計・生成に関するもので、入力は低水準バイナリやアセンブリではなく高レベルのデザインパラメータであるため、デコンパイルの対象外です。"}, {"code": "ex_out_of_scope", "evidence": "generative design method for batik patterns based on shape grammar, and relies on the artificial neural network (ANN)", "explanation": "研究の目的はパターンの生成と視覚認知価値の最適化であり、逆解析やコード復元とは無関係なためスコープ外です。"}], "reasoning": "本稿はバティック模様の生成手法を提案しており、低水準のバイナリやアセンブリから高水準コードを復元するデコンパイルとは無関係です。入力も出力もデコンパイルの定義に合致しないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3324, "latency_ms": 28098}}
{"key": "WOS:000606730100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "designed to predict potential cloned applications by training features", "explanation": "要旨はクローンアプリの検出・予測が目的であり、デコンパイルによる高水準コード生成や復元を行う意図が示されていないため、コード生成/再構築が目的ではないと判断した。"}], "reasoning": "本稿は Android アプリのクローン検出を目的とした手法を提案しており、デコンパイルは分析の前処理として利用されるに過ぎない。復元・可読化といったデコンパイルの主目的がなく、ML は分類モデルとして使用されているため、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3256, "latency_ms": 25985}}
{"key": "WOS:000618528800004", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The pipeline is based on IFCL, an intermediate firewall language equipped with a formal semantics, and it is implemented in an open source tool called FWS.", "explanation": "要旨では機械学習や大規模言語モデルの利用が全く言及されておらず、形式的手法とZ3ソルバーのみが使用されているため、EC1 の「ML/LLM を用いていない」に該当します。"}], "reasoning": "本稿はファイアウォール設定の逆変換・解析・トランスコンパイルを行うシステムを提案していますが、手法は形式的モデリングとSMT ソルバーに基づくもので、機械学習や LLM は使用されていません。したがって本サーベイの採択基準（LLM/ML を中核としたデコンパイル）を満たさないため、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3368, "latency_ms": 26408}}
{"key": "WOS:000611120200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the detection and classification of malicious apps can be realized.", "explanation": "本文はマルウェアの検出・分類を目的としており、コード生成や復元は行わないため、デコンパイルの主目的を満たさないと判断した。"}], "reasoning": "本稿は Android アプリをデコンパイルして関数呼び出しグラフを生成し、その構造特徴を用いたマルウェア検出を提案している。ML/LLM はグラフ畳み込みネットワークによる分類に用いられているが、低水準コードから高水準コードを生成・復元することが目的ではなく、コード生成や可読化などのデコンパイル成果は提示されていない。そのため除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3279, "latency_ms": 31373}}
{"key": "WOS:000589187000048", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "a set of free or inexpensive tools was used to retrieve and disassemble the monitor's onboard software", "explanation": "抽象からは機械学習や大規模言語モデルの使用は言及されておらず、従来のツールのみで解析しているため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿は BIS モニタのファームウェアを手作業で取得・逆アセンブルし、従来のツールで解析する手法を報告しているが、機械学習や大規模言語モデルを中心手法として使用していない。したがって、インクルード基準の IC0（ML/LLM の使用）が満たされず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3359, "latency_ms": 21888}}
{"key": "WOS:000602074600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "perform classification", "explanation": "アブストラクトはマルウェアの分類を目的としており、コードの復元や高水準表現の生成は行っていないため、デコンパイルの主目的であるコード生成・再構築が欠如していると判断した。"}], "reasoning": "本研究はバイナリから opcode を抽出し、浅層ニューラルネットワークでマルウェアを分類することに焦点を当てており、デコンパイルによるソースや擬似コードの生成・復元を目的としていない。そのため、除外基準 EC3（コード生成・再構築が主目的でない）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3155, "latency_ms": 22997}}
{"key": "WOS:000592654700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "applying the social network analysis by R packages, which include k-core decomposition", "explanation": "本文は R パッケージによる社会ネットワーク解析を行っており、機械学習や大規模言語モデルの使用は示されていないため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "data connectedness via the decompilation and the examination of the application programming interface of terminal applications", "explanation": "対象は API やデータ接続性の分析であり、バイナリ・アセンブリなどの低水準コードは入力として示されていないため、低水準入力が欠如していると判断した。"}], "reasoning": "本稿は中国の配車プラットフォームにおけるデータアクセスと競争構造の実証分析であり、機械学習・LLM の利用やバイナリ等の低水準入力から高水準コードを生成することを目的としていない。したがって、デコンパイル調査の対象外であり、除外基準の ex_no_ml と ex_no_lowlevel_input に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3417, "latency_ms": 31893}}
{"key": "WOS:000597138700009", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.91, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "deep learning model ... to detect cloned apps", "explanation": "本文はクローン検出という分類タスクが主目的であり、コード生成や高水準表現の復元を目的としていないため、コード生成/復元意図が欠如していると判断した。"}], "reasoning": "本稿はAndroidアプリのクローン検出を目的とした深層学習ベースの手法を提案しており、デコンパイルは前処理として利用されるものの、復元・可読化が主目的ではない。したがって、デコンパイルの主要目的である高水準コードの生成・再構成が行われていないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3204, "latency_ms": 23498}}
{"key": "WOS:000565246000013", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a novel Android mobile malware detection system is proposed ... the malicious program can be detected more accurately", "explanation": "アブストラクトはマルウェア検出・分類を目的としており、コードの復元や高水準表現の生成を行わないため、コード生成・再構築の意図がなく除外基準EC3に該当します。"}], "reasoning": "本論文は opcode シーケンスを用いたマルウェア検出を目的としており、LLM/ML は分類モデルとして使用されています。デコンパイルによるコード復元や可読化といった出力生成を行わないため、除外基準 ex_no_code_generation に該当し、include ではなく exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3114, "latency_ms": 22521}}
{"key": "WOS:000570595700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a two-phase detection scheme ... locality-sensitive hashing (LSH) algorithm ...", "explanation": "要旨では LSH やミニハッシュといった手法しか述べられており、機械学習や LLM の利用は示されていないため、EC1 に該当します。"}], "reasoning": "本稿は Android アプリのクローン検出手法を提案しており、機械学習/LLM を用いたデコンパイルやコード生成は行っていません。入力はバイナリやアセンブリではなく、アプリの UI レイアウト情報を利用した類似度比較であり、デコンパイルの目的や手法とは無関係です。したがって除外基準 ex_no_ml に基づき除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3108, "latency_ms": 22168}}
{"key": "WOS:000569691600001", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_input", "evidence": "different tasks ... LaTeX decompilation", "explanation": "アブストラクトでは LaTeX デコンパイル がタスクの一つと記載されているが、入力がバイナリやアセンブリなどの低水準表現であることが明示されていないため、低水準入力の有無が不明です。"}, {"code": "uns_unclear_output", "evidence": "LaTeX decompilation", "explanation": "LaTeX が生成されることは示唆されているが、生成された出力が L1‑L4 のどれに該当するか（コンパイル可能なソースか、擬似コードか、属性だけか）が抽象だけでは判断できません。"}], "reasoning": "本稿はエンコーダ‑デコーダを用いた LaTeX デコンパイル を扱うと述べているが、低水準入力（バイナリ・アセンブリ等）の有無と、生成される出力の具体的レベルが抽象からは判断できないため、採択か除外かを決定できません。", "model": "openai/gpt-oss-120b", "tokens_used": 3585, "latency_ms": 40661}}
{"key": "WOS:000536764600007", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "by replacing the program instructions with virtual instructions that an adversary is unfamiliar with", "explanation": "アブストラクトではML/LLMの利用について言及がなく、純粋にコード仮想化による難読化手法を提案しているため、ML/LLM が使われていないと判断した。"}], "reasoning": "本論文は Android アプリ向けのコード仮想化手法を提案しており、デコンパイル自体は保護技術の一部として言及されるだけで、ML/LLM を用いた高水準コード生成や復元は目的としていない。したがって、Decompilation Survey の対象外（ML/LLM 未使用）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3231, "latency_ms": 23361}}
{"key": "WOS:000508186400109", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper proposes a process to automate the decompilation of all the applications on a user's mobile device", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用についての記述がなく、デコンパイルは従来の自動化手法で行われているとみなせるため、ML/LLM が使用されていないと判断し除外基準 EC1 に該当します。"}], "reasoning": "本稿は Android アプリの自動デコンパイルと脆弱性評価を提案していますが、手法として機械学習や大規模言語モデルが用いられている旨の記載がなく、ML/LLM を中心としたデコンパイル研究の範囲外です。そのため除外基準 EC1（ML/LLM 不使用）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3038, "latency_ms": 22416}}
{"key": "WOS:000495504500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Finally, TensorFlow with Keras deep learning model is designed to predict clones in Android applications.", "explanation": "抽象からは主目的がクローン判定（分類）であり、復元やコード生成を目的としていないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は Android アプリのクローン検出を目的とした分類システムを提案しており、デコンパイルは特徴抽出の前処理に過ぎません。復元・可読化といったコード生成目的がなく、DECOMPILATION の主要目的から外れるため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3262, "latency_ms": 26701}}
{"key": "WOS:000497359300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a dynamic method to solve this issue based on our novel automatic traversal model", "explanation": "アブストラクトでは手法が動的解析とトラバーサルアルゴリズムであると述べられ、機械学習や大規模言語モデルの使用は言及されていないため、ML/LLM が用いられていないと判断した"}], "reasoning": "本稿は Android アプリの SSL 脆弱性検出を目的とした動的解析手法を提案しており、機械学習や LLM を用いたデコンパイルやコード復元とは無関係です。入力はバイナリかもしれないが、目的は分類・検出であり、デコンパイルの生成・復元を行う研究ではないため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3259, "latency_ms": 24937}}
{"key": "WOS:000460845200059", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "using Min Hashing techniques applied to applications' meta-data", "explanation": "アブストラクトでは機械学習やLLMの利用が言及されておらず、単純なハッシュ手法のみが使用されているため、EC1に該当します。"}, {"code": "ex_no_lowlevel_input", "evidence": "meta-data publicly available at Google Play", "explanation": "入力はバイナリやアセンブリ等の低水準表現ではなく、Google Play のメタデータであるため、EC2に該当します。"}, {"code": "ex_no_code_generation", "evidence": "detect Repackaged versions of Android apps", "explanation": "本研究の目的はコードの復元や生成ではなく、再パッケージングされたアプリの検出であるため、EC3に該当します。"}], "reasoning": "本稿は低水準バイナリ等を入力とせず、ML/LLM を用いた手法でもなく、コードの復元や生成を目的としていないため、デコンパイル調査の対象外です。したがって除外 (exclude) と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3133, "latency_ms": 27935}}
{"key": "WOS:000463843700059", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Polycyclic saturated heterocycles ... are assembled by iterative couplings ... the target structures ... decompiled into the constituent building blocks and assembly sequences.", "explanation": "本文は化学合成と構造予測に関するもので、バイナリやアセンブリなどの低水準コードを対象としていないため、デコンパイルの範囲外です。"}], "reasoning": "本稿は化学分野の合成手法と分子構造予測を扱っており、低水準プログラム表現やML/LLM を用いたコード復元とは無関係です。したがってデコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2904, "latency_ms": 17420}}
{"key": "WOS:000450592600010", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "predicting defects in apks", "explanation": "要旨はバイナリから特徴を抽出し欠陥を予測する分類タスクであり、コードや高水準表現の生成・復元を目的としていないため"}], "reasoning": "本稿は Android APK のバイナリ（smali）から特徴を抽出し、深層ニューラルネットワークで欠陥を予測する分類研究です。デコンパイルによる高水準コードの復元や可読化が目的ではなく、コード生成・再構築の意図がないため除外基準 EC3 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3272, "latency_ms": 27200}}
{"key": "WOS:000448653700147", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This study uses a dynamic analysis method to inspect an executing app", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、動的解析のみが用いられているため、ML/LLM が使用されていないと判断しました。"}, {"code": "ex_no_code_generation", "evidence": "It is then determined whether or not the ad lib is from a trusted ad network using comparisons of graph similarities.", "explanation": "目的はネットワーク振る舞いの類似性比較による分類であり、低水準コードから高水準コードを生成・復元することは行っていないため、コード生成・復元の意図がないと判断しました。"}], "reasoning": "本論文は APK の動的ネットワーク振る舞いを解析し、類似性比較によって広告ライブラリを識別する手法を提案しています。機械学習・LLM の利用がなく、コードの復元・生成を目的としたデコンパイル研究ではないため、除外基準 EC1 と EC3 に該当し、除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3339, "latency_ms": 30700}}
{"key": "WOS:000435804100020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We evaluate 30 code similarity detection techniques and tools...", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、単なるツール比較・評価であるため、ML/LLM を利用したデコンパイル研究ではないと判断した。"}], "reasoning": "本稿はコード類似性解析ツールの比較実験を行う評価研究であり、デコンパイルは正規化手法として言及されるだけで、LLM/ML を核としたデコンパイル手法の提案や改善は行っていない。したがって、除外基準 EC1（ML/LLM 不使用）に該当し、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3438, "latency_ms": 29655}}
{"key": "WOS:000425569100004", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We measure ``difficulty'' by utilizing software complexity metrics and the ``slow'' in CPU cycles.", "explanation": "要旨はオブファスケーションの性能コスト測定と最適化に関するもので、コードの復元や高水準表現の生成を目的としていないため、コード生成・再構築の意図がないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "its Java bytecode is easier to decompile and to reconstruct the original Java source code.", "explanation": "デコンパイルについて言及はあるものの、研究の中心はオブファスケーションの性能評価であり、デコンパイル自体の手法やLLM/MLによるコード復元は対象外であるため、スコープ外と判断した。"}], "reasoning": "本論文は Android アプリのオブファスケーションによる性能コストを測定・最適化することが主目的であり、低水準入力から高水準コードを生成するデコンパイル手法や LLM/ML の活用は行っていない。したがって、デコンパイルサーベイの対象外であり、除外 (exclude) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3554, "latency_ms": 38933}}
{"key": "WOS:000448568500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a classifier is trained for the malware detection and classification tasks", "explanation": "要約では、LLM/ML を用いてデコンパイル結果から特徴を抽出し、マルウェアの検出・分類を行うことが目的であり、コードやソースの再構成・生成は行わないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿は Dalvik バイナリをデコンパイルして得た opcode シーケンスを特徴として利用し、マルウェアの検出・分類を行う静的解析手法を提案している。目的は復元や可読化ではなく分類であり、LLM/ML がデコンパイル結果の再構成に使われているわけではない。したがって、除外基準 EC3（コード生成・復元意図がない）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3091, "latency_ms": 24406}}
{"key": "WOS:000428354700001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "takes a stacking ensemble for malware classification", "explanation": "アブストラクトでは、提案手法はマルウェアの検出・分類を目的としており、低水準コードから高水準コードを生成することは述べられていないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本論文はマルウェア検出を目的とした分類手法を提案しており、デコンパイルによるコード生成・復元を行う目的が示されていない。したがって、Decompilation Survey の対象外であり除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3098, "latency_ms": 22863}}
{"key": "WOS:000419845600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect malware through method block sequences", "explanation": "アブストラクトでは LSTM を用いてマルウェアを検出することが目的と記述されており、コードの復元・可読化といった生成・再構築は行わないため、コード生成・復元を目的としたデコンパイル研究ではないと判断した。"}], "reasoning": "本稿は低水準の opcode 系列を入力として LSTM によりマルウェアか否かを分類する手法を提案している。目的はマルウェア検出という分類タスクであり、復元・可読化などの高水準コード生成を目的としていないため、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3228, "latency_ms": 27602}}
{"key": "WOS:000412054600026", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "features ... are extracted from the decompiled source codes", "explanation": "入力として扱われているのはデコンパイル済みのソースコードであり、低水準表現（バイナリ・アセンブリ・バイトコード等）ではないため除外基準 EC2 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "focus on extracting the fine-grained features to maximize the information of Android malware detection", "explanation": "研究の目的はマルウェア検出のための特徴抽出・選択であり、コードの復元や生成は行わないため除外基準 EC3 にも該当します。"}], "reasoning": "本稿はデコンパイルされたソースコードから特徴を抽出し、マルウェア検出モデルを構築することが主目的であり、低水準入力から高水準コードを生成する decompilation 手法や LLM/ML を用いたコード復元を行っていません。したがって、除外基準に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3320, "latency_ms": 32285}}
{"key": "WOS:000403121900083", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "A software program written in Adobe AIR ... controlled the opening time of the solenoid valves", "explanation": "本文では機械学習や大規模言語モデルの使用は言及されておらず、従ってML/LLMが中心手法であるという条件を満たさないため"}, {"code": "ex_no_lowlevel_input", "evidence": "the digital movie is recorded by a webcam ... the movie is decompiled into frames", "explanation": "入力は映像（デジタルムービー）であり、バイナリ・アセンブリ・バイトコードといった低水準コードではないため"}], "reasoning": "本稿はデジタルムービーをフレームに分解して滴定を自動化する手法を紹介しており、デコンパイルの定義で要求される低水準コードから高水準コードへの復元や、ML/LLMを用いた手法とは無関係です。そのため除外基準（ML未使用、低水準入力なし）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3310, "latency_ms": 23173}}
{"key": "WOS:000399815400003", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "employs a systematic method to identify and analyse security threats at API level", "explanation": "抽象からは機械学習や大規模言語モデルの使用が示されておらず、従ってML/LLMを用いない論文として除外基準 EC1 に該当します"}], "reasoning": "本稿はAndroidアプリのAPIレベルのセキュリティ認証手法を提案していますが、ML/LLM を中心手法として使用している記述がなく、デコンパイルは入力として利用されているものの、復元やコード生成を目的とした機械学習手法が欠如しています。そのため、除外基準「No ML/LLM (ex_no_ml)」に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3123, "latency_ms": 22203}}
{"key": "WOS:000396087900059", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "we proposed an approach to mine dynamic noteworthy functions (DNFM) in software execution sequences.", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、単なるアルゴリズム・パターン抽出手法なので、EC1 に該当し除外します。"}], "reasoning": "本論文は実行トレースから注目関数を抽出する手法を提案しており、ML/LLM を用いた手法は記載されていない。そのため、除外基準 EC1（No ML/LLM）に該当し、デコンパイルを目的とした LLM/ML 研究とはみなされない。", "model": "openai/gpt-oss-120b", "tokens_used": 3085, "latency_ms": 20775}}
{"key": "WOS:000397194600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "search for patterns in binary code... automatic extraction of patterns from native code", "explanation": "アブストラクトはバイナリからパターンを抽出することが目的であり、ソースコードや擬似コード等の高水準表現を生成することは示されていないため、復元・可読化を目的としたデコンパイルとは異なります。"}], "reasoning": "本稿はバイナリコードからパターンを自動抽出するプラットフォームを提案しており、出力はパターン情報でありコードや高水準表現の生成を目的としていません。したがって、デコンパイルの目的（復元・可読化）を満たさないため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3123, "latency_ms": 27860}}
{"key": "springer_10_1007_978_3_031_94448_2_6", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we presented a novel framework for empirically evaluating C-based decompilers", "explanation": "要旨では既存デコンパイラの評価フレームワークを述べており、ML/LLM を手法として用いている記述がなく、EC1 に該当するため除外します。"}], "reasoning": "本稿は WebAssembly バイナリから生成された C コードの品質評価を行う比較研究であり、ML/LLM を用いたデコンパイル手法の提案や実装が示されていません。そのため、Include Criteria の ML/LLM 使用要件を満たさず、除外基準 EC1（No ML/LLM）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3242, "latency_ms": 27260}}
{"key": "springer_10_1007_978_3_031_97620_9_14", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "machine learning to predict missing names, types, and other abstractions in decompiled code", "explanation": "ML を用いてデコンパイルされたコードの名前や型などを予測し、可読性や情報を改善することが主目的であるため、デコンパイラ出力の強化に該当します。"}, {"code": "in_type_recovery", "evidence": "machine learning to predict missing names, types, and other abstractions in decompiled code", "explanation": "抽象化された型情報の復元が研究対象の一部であるため、型回復に該当します。"}, {"code": "in_variable_naming", "evidence": "machine learning to predict missing names, types, and other abstractions in decompiled code", "explanation": "識別子（変数・関数名）の予測が目的の一つであるため、変数・関数名の復元に該当します。"}], "reasoning": "本稿はバイナリを入力とし、機械学習（LLM/ML）を用いてデコンパイル後のコードの名前や型といった高水準情報を予測・改善することを目的としているため、デコンパイラ出力の改善（in_decompiler_enhancement）として採択します。型回復や識別子名復元も主要な対象であるため、補助的に in_type_recovery と in_variable_naming を付与しています。", "model": "openai/gpt-oss-120b", "tokens_used": 3775, "latency_ms": 50650}}
{"key": "springer_10_1007_978_981_96_9849_3_19", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "first LLM that significantly improves the decompilation output quality of C programs on the ARM platform", "explanation": "LLM が低水準の ARM バイナリから直接 C 言語の高水準コードを生成し、復元・可読化を目的としているため Core Decompilation に該当します。"}, {"code": "ex_no_ml", "evidence": "", "explanation": ""}], "reasoning": "本稿は ARM バイナリを入力とし、LLM を中心手法として C 言語ソース（L1）を生成することを目的としている。復元品質や再コンパイル可能性の向上を評価している点から、Decompilation Survey の Inclusion 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3147, "latency_ms": 23166}}
{"key": "springer_10_1007_s00521_024_10735_9", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "we present a single-pass end-to-end neural decompilation system ... from the assembly code", "explanation": "LLM/ML がアセンブリという低水準入力から直接高水準コードを生成している点が Core Decompilation に該当するため"}, {"code": "in_control_structure", "evidence": "addressing important programming constructs like switch statements, function definitions, and function calls", "explanation": "制御構造（switch 文等）の復元を目的の一つとして明示しているので Control Structure Recovery のコードも付与"}], "reasoning": "本稿はアセンブリコードを入力とし、深層学習モデル（コピー機構付き）で高水準ソースコードを直接生成するエンドツーエンドのデコンパイル手法を提案しています。目的がコードの復元・可読化であり、ML が手法の核心であるため Include 基準を満たします。また、switch 文などの制御構造の復元にも言及している点から、in_control_structure も補助的に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3310, "latency_ms": 32650}}
{"key": "springer_10_1007_978_3_031_71602_7_3", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "pairs of transformer weights and corresponding RASP programs", "explanation": "アブストラクトでは入力として「transformer weights」（ニューラルネットワークのパラメータ）を示しており、バイナリやアセンブリなどの低水準表現ではないため、定義上の低水準入力が存在しないと判断した。"}, {"code": "ex_no_ml", "evidence": "we then build and train a model, with the aim of recovering the RASP code", "explanation": "本研究はMLモデルを用いているが、低水準入力が欠如しているため除外基準が優先し、MLの有無だけで採択はできない。"}], "reasoning": "タイトルとアブストラクトからは、入力がトランスフォーマーの重み（高水準のモデルパラメータ）であり、デコンパイル対象と定義されたバイナリ/機械語等の低水準表現ではないことが明らかです。そのため、低水準入力が欠如していると判断し、除外基準 ex_no_lowlevel_input に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3287, "latency_ms": 33323}}
{"key": "springer_10_1007_978_3_031_49266_2_18", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "the proposed method can be applied to any decompiler and programming language", "explanation": "要旨からはML手法がバイナリやアセンブリといった低水準表現を直接入力としている記述がなく、既存デコンパイラの出力（高水準コード）に対して適用されることが示唆されるため、低水準入力の条件を満たさないと判断した。"}], "reasoning": "本稿は既存デコンパイラの出力コードをLLMで修正する手法を提案しているが、LLMが直接低水準表現（バイナリ/アセンブリ/バイトコード）を入力としている記述が抽象からは得られない。したがって、Decompilation Survey Screening Rulesの低水準入力要件を満たさず、除外基準EC2に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3600, "latency_ms": 48013}}
{"key": "springer_10_1007_978_981_99_8703_0_13", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "automatised decompilation, dataset validation, unification", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が記載されておらず、従来の自動化ツールとみなせるため、EC1 に該当し除外と判断した。"}], "reasoning": "本稿は Android アプリの大量デコンパイルとデータセット前処理を行うツールを紹介しているが、ML/LLM を用いた手法についての記述がなく、Decompilation Survey の採択基準である「LLM または ML を中核手法として使用」条件を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3028, "latency_ms": 21291}}
{"key": "springer_10_1007_978_3_031_45933_7_15", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we take the triplet features from both binary pseudo-code and source code functions as input... improves the accuracy of binary and source code matching", "explanation": "本文はバイナリ疑似コードとソースコードを用いた関数マッチングを目的としており、コードの生成・復元は行わないため、コード生成・再構成が主目的であるEC3に該当します。"}], "reasoning": "本研究はデコンパイルで得た疑似コードを特徴抽出に利用し、バイナリとソース関数のマッチング（類似度評価）を行うことが目的です。コードの復元や可読化といったデコンパイルの主目的がなく、生成・再構成を伴わないため除外基準EC3（コード生成・復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3374, "latency_ms": 45383}}
{"key": "springer_10_1186_s42400_026_00552_z", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to extract critical APIs and detect Android malware", "explanation": "要旨は decompiled APK から API を抽出しマルウェア検出を行うことであり、コードの復元・生成が主目的ではなく分類が目的なので除外基準 EC3 に該当する"}], "reasoning": "本論文は decompiled APK を入力として GNN によるマルウェア検出を行う研究であり、生成や復元を目的としたデコンパイルではない。したがって、LLM/ML が用いられていてもコード生成・復元が主目的でないため除外 (ex_no_code_generation) と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3098, "latency_ms": 38586}}
{"key": "springer_10_1007_978_981_95_4142_3_1", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify Ponzi schemes directly from Ethereum bytecode... detect suspicious fund flow patterns", "explanation": "要旨はバイトコードからポンジスキームを検出することが目的であり、コードの復元や高水準表現の生成は行わず、分類・検出が主目的なので除外基準EC3に該当します"}], "reasoning": "本研究はバイトコードを中間表現に変換し、LLMで解釈させてポンジ契約を検出する手法を提示していますが、出力は高水準コードや擬似コードではなく検出結果です。デコンパイルによるコード復元・生成が主目的でないため、除外基準EC3（コード生成・復元が目的でない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3241, "latency_ms": 42491}}
{"key": "springer_10_1007_978_981_95_0129_8_27", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detecting consistency between application privacy policies and behaviors", "explanation": "論文の目的はプライバシーポリシーと実際の動作の不一致を検出することであり、コードの復元や高水準表現の生成を行わないため、コード生成／復元の意図がなく EC3 に該当します"}], "reasoning": "本研究は低水準の Android バイトコードを入力に NLP を用いてプライバシー漏洩の検出を行うことを目的としており、デコンパイルによるソースコードや擬似コードの生成・再構成を行わないため、インクルード基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3291, "latency_ms": 46623}}
{"key": "springer_10_1007_978_981_95_3543_9_9", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "MDetector runs corresponding detection logic via datalog analysis.", "explanation": "概要からは機械学習・LLM の利用が示されておらず、ルールベースのデータロッグ解析のみと記述されているため、ML/LLM が使われていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "MDetector initiates a high-performance decompilation engine to disassemble and convert contract bytecode into intermediate code.", "explanation": "デコンパイルは中間コードへの変換に留まり、コードの復元・可読化・コンパイル可能なソース生成が目的ではなく、バックドア検出が主目的であるため、コード生成/再構成の意図がないと判断した。"}], "reasoning": "本稿は Ethereum ERC-20 コントラクトのバックドア検出を目的としたツールであり、手法はデータロッグによる静的解析で機械学習やLLMは使用していない。また、デコンパイルはバイトコードを中間表現に変換するだけで、ソースコードや擬似コードの生成を目的とした復元作業ではないため、デコンパイル研究の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3377, "latency_ms": 51206}}
{"key": "springer_10_1007_978_94_024_2308_2_7", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "examines key techniques such as code decompilation, binary analysis, and dynamic behavior monitoring", "explanation": "要旨に機械学習や大規模言語モデルの利用が記載されておらず、従来の手法のみを議論しているためML/LLMが使用されていないと判断した。"}, {"code": "ex_survey_or_meta", "evidence": "This paper examines key techniques ... highlighting their applications in securing IoT devices, traditional software, and mobile applications", "explanation": "技術全体を概観し、事例や応用を紹介する形式であり、調査・レビュー的な性格が強いため除外対象とした。"}], "reasoning": "タイトルと要旨からは、機械学習や大規模言語モデルを用いたデコンパイル手法についての研究ではなく、逆向きエンジニアリング全般を概観するレビュー的論文であることが読み取れる。したがって、Decompilation Surveyの採択基準を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3152, "latency_ms": 47145}}
{"key": "springer_10_1007_978_3_031_77941_1_4", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "we introduce JaxDecompiler, a tool that transforms any JAX function into an editable Python code", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用が明記されておらず、単なるツール変換であると読み取れるため、ML/LLM を用いていないと判断し除外基準 EC1 に該当します。"}], "reasoning": "本論文は JAX の中間表現 Jaxpr から Python ソースへ変換するツールを紹介していますが、手法として機械学習や LLM が中心である旨の記述がなく、ルールベースやコンパイル手法と解釈されます。そのため、デコンパイルに LLM/ML が必須とされる本サーベイの採択基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3089, "latency_ms": 45248}}
{"key": "springer_10_1007_978_981_96_4245_8_31", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "combination of decompilation and packet capture techniques is used", "explanation": "要旨からは機械学習・大規模言語モデルの使用が示唆されず、従来のデコンパイル手法のみが言及されているため、ML/LLMが用いられていないと判断した。"}], "reasoning": "本稿はVRデバイスのフォレンジックに焦点を当て、デコンパイルは解析手段の一つとして用いられているが、機械学習や大規模言語モデルを手法の中心に据えていない。したがって、除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3013, "latency_ms": 36169}}
{"key": "springer_10_1007_978_3_030_89051_3_16", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a new tool DarkSea , the first tool capable of verifying reachability, termination and LTL of lifted binaries.", "explanation": "本文は検証ツールの提案であり、ML/LLM の利用について言及がなく、ルールの EC1（ML/LLM 未使用）に該当するため除外と判断した。"}], "reasoning": "この論文はビットベクタプログラムやデコンパイルされたバイナリの検証手法を提案しており、機械学習や大規模言語モデルを用いたデコンパイル手法は示されていない。したがって、除外基準 EC1（ML/LLM 未使用）に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3115, "latency_ms": 40821}}
{"key": "springer_10_1007_978_981_97_8749_4_1", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LSTM is employed to analyze software intent for determining the presence of malware.", "explanation": "本文はマルウェアの有無を判定することが主目的であり、コードの復元や可読化を目的とした生成・再構成は行っていないため、コード生成・復元意図が欠如していると判断した。"}], "reasoning": "本論文は Android アプリをデコンパイルして特徴抽出を行うが、最終目的はマルウェア検出という分類タスクであり、デコンパイル自体は前処理に過ぎない。デコンパイルによる高水準コード生成や復元が主たる研究貢献ではないため、除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3144, "latency_ms": 44147}}
{"key": "springer_10_1007_978_3_031_64171_8_1", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "The approach is based on symbolically executing an abstract semantics that includes binary-level exception-related function calls.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されておらず、シンボリック実行のみが手法として挙げられているため、EC1に該当し除外と判断した。"}], "reasoning": "本稿は低水準バイナリから例外情報を含む制御フローグラフを生成する手法を提案しているが、ML/LLM を利用した手法が示されていない。Decompilation Survey の採択基準では、LLM/ML が中心手法であることが必須条件となっているため、除外基準 ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3229, "latency_ms": 46489}}
{"key": "springer_10_1007_978_981_97_0811_6_15", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "It decompiles the application software and applies PCA ... a Stacking-based ensemble machine learning algorithm is used to classify the visualized images", "explanation": "要旨ではデコンパイルに機械学習や大規模言語モデルは用いられておらず、ML は画像分類にのみ使用されているため、EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "it visualises the decompiled data to greyscale and RGB image", "explanation": "デコンパイルの目的はコードの復元ではなく可視化とマルウェア検出であり、コード生成・再構築の意図がないため EC3 に該当します。"}], "reasoning": "本稿はデコンパイルをマルウェア検出の前処理として利用しており、デコンパイル自体に LLM/ML を用いたり、復元・可読化を目的としていない。そのため、Decompilation Survey のインクルード基準を満たさず除外と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3231, "latency_ms": 50099}}
{"key": "springer_10_1007_978_3_030_80825_9_7", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify code reuse in malware via a novel machine learning-based encoding mechanism at the function-level", "explanation": "本文は機械学習を用いてコード再利用を検出することが目的であり、低水準バイナリから高水準コードを生成・復元することは行っていないため、コード生成／復元の意図がないと判断した。"}], "reasoning": "本稿はマルウェアのコード再利用検出を目的としたシステムを提案しており、デコンパイルによるソース復元や可読化を行う研究ではない。目的が分類・検出であり、コード生成や高水準表現の復元が主たる目標ではないため、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3344, "latency_ms": 50908}}
{"key": "springer_10_1007_978_981_99_1157_8_55", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the method first decompiles the target file... then apply the extracted information to vulnerability mining.", "explanation": "要旨ではデコンパイルは脆弱性マイニングの前処理として言及されており、コード生成や復元が主目的ではないため、除外基準 EC3 に該当します。"}], "reasoning": "本稿はデコンパイル結果を脆弱性検出に利用する手法であり、デコンパイル自体の復元・可読化やコード生成を目的としていない。そのため、デコンパイルの目的が主たる研究課題である本サーベイの採択基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3442, "latency_ms": 57790}}
{"key": "springer_10_1007_978_981_19_9379_4_39", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Accuracy of 0.9880 and F 1-score of 0.9843 have been achieved during performance evaluation.", "explanation": "この記述は抽象的に分類・検知の性能評価を示しており、コードの復元や生成を目的としていないため、除外基準 EC3 に該当します。"}], "reasoning": "本稿は文字列暗号化による難読化を検出するために、逆コンパイルされたコードから特徴を抽出しマルウェア検出を行う手法を提案しているが、目的はコードの復元や可読化ではなく検知であり、コード生成・再構築が主目的ではない。したがって除外基準 EC3（コード生成・復元が目的でない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3170, "latency_ms": 47342}}
{"key": "springer_10_1007_978_3_031_25803_9_7", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We augment P-Code and define a complete, executable, formal semantics for it.", "explanation": "本文は形式的セマンティクスの定義とインタプリタ構築について述べており、ML/LLM の使用は示唆されていないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿は Ghidra の P‑Code に対する形式的セマンティクスを提案する研究であり、機械学習や大規模言語モデルを手法の中心に用いていません。そのため、デコンパイルに ML/LLM を利用するという本サーベイの対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 42844}}
{"key": "springer_10_1007_978_3_031_37963_5_22", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "The process consists of a few steps. First step is a process of decompilation of JVM and its translation to internal abstract syntax tree...", "explanation": "要約では機械学習や大規模言語モデルの使用が言及されておらず、規則ベースの手法のみが説明されているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿はバイトコードをASTへ変換し並列化コードを生成するフレームワークを提案しているが、機械学習やLLM を手法の中心に用いている記述がない。したがって、Decompilation Survey の Inclusion Criteria を満たさず、Exclude Criteria の EC1 (No ML/LLM) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3081, "latency_ms": 41770}}
{"key": "springer_10_1007_978_3_031_36096_1_1", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.83, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "new research directions have proposed various promising automatic methods, primarily based on machine learning and symbolic execution techniques.", "explanation": "本文は新しい研究方向を紹介しているだけであり、独自のML/LLM手法を提案しているわけではなく、サーベイ・レビュー論文と判断したため除外しました。"}], "reasoning": "アブストラクトは保護されたソフトウェアのリバースエンジニアリングに関する既存手法や研究動向を述べており、著者独自のデコンパイル手法やML/LLMの具体的適用例が示されていないため、サーベイ/レビュー論文とみなして除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3234, "latency_ms": 52796}}
{"key": "springer_10_1007_978_3_031_21333_5_105", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "train a recurrent neural network for malware detection tasks", "explanation": "論文の主目的はマルウェア検出という分類であり、コードや高水準表現の生成・復元を行う意図が示されていないため、コード生成/復元が目的の除外基準に該当します。"}, {"code": "ex_no_ml", "evidence": "using the CodeT5 pre-trained language model ... train a recurrent neural network", "explanation": "本研究はMLを用いていますが、MLは分類モデルの構築に使用されており、デコンパイル自体の手法としては利用していないため、MLがデコンパイル中心でない点を指摘します。"}], "reasoning": "本稿はデコンパイル手法の開発や改善を目的とせず、デコンパイルされた Java コードを入力としてマルウェア検出モデルを訓練する点に焦点を当てている。デコンパイルは前処理に過ぎず、コードの復元や可読化といった出力生成の目的がないため、本サーベイの採択基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3333, "latency_ms": 53035}}
{"key": "springer_10_1007_978_3_030_58768_0_14", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Formal methods are used during three phases of the decompilation process", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用が言及されておらず、形式手法のみが用いられているため、ML/LLM を使用していないと判断した。"}], "reasoning": "本論文は形式手法による制御フロー回復・シンボリック実行・変数解析を用いた C コードのデコンパイル手法を提案しているが、機械学習や LLM に関する記述がなく、ルールの除外基準 EC1（ML/LLM 未使用）に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 2960, "latency_ms": 38590}}
{"key": "springer_10_1007_978_3_031_06764_8_41", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "use ... graph matching network ... as the basis for detection", "explanation": "本文はマルウェア検出を目的としており、コードの復元・生成は行わないため、デコンパイルの主目的であるコード生成が欠如している。"}, {"code": "ex_no_lowlevel_input", "evidence": "call relationships between functions are extracted from the decompiled APK files", "explanation": "入力はすでにデコンパイルされた APK から抽出した関数呼び出しグラフであり、低水準バイナリやアセンブリといった低レベル表現ではない。"}], "reasoning": "本稿はデコンパイル結果を利用したマルウェア検出手法を提案しており、ML/LLM は使用しているものの、低水準入力から高水準コードを生成することが目的ではない。デコンパイルは前処理に過ぎず、出力はコードではなく振る舞いグラフであるため、除外基準 EC3（コード生成・復元が目的でない）および EC2（低水準入力がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3441, "latency_ms": 57070}}
{"key": "springer_10_1007_978_3_030_95918_0_5", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "apply LSTM for Android malware detection using source code decompiled from the Android Application Package (APK).", "explanation": "目的はマルウェア検出（分類）であり、コードの復元や高水準表現の生成ではなく検知が主目的なので、コード生成・復元の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文は LSTM を用いたマルウェア検出という分類タスクに焦点を当てており、デコンパイル結果を入力として利用しているものの、出力は高水準コードや構造化表現ではなく検出ラベルです。したがって、デコンパイルの復元・可読化を目的とした研究ではなく、除外基準 EC3（コード生成・復元が目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3097, "latency_ms": 41769}}
{"key": "springer_10_1007_978_981_19_0019_8_2", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify malicious android apps using object-oriented software metrics and supervised machine learning techniques", "explanation": "目的はマルウェアの分類であり、コードの復元や生成を行うことが主目的ではないため、コード生成/再構築が意図されていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "retrieve object-oriented software metrics from the decompiled android app", "explanation": "入力はすでにデコンパイルされたアプリのメトリクスであり、低水準表現（バイナリ・アセンブリ等）からの入力ではないため除外基準に該当する。"}], "reasoning": "本論文はデコンパイルそのものではなく、デコンパイル済みコードから抽出したメトリクスを用いたマルウェア分類を目的としている。入力は低水準コードではなく高水準のデコンパイル結果であり、コード生成や復元を行わないため、Decompilation Survey の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3218, "latency_ms": 48629}}
{"key": "springer_10_1007_978_3_030_73429_9_8", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "In the classification process, an integrated learning model ... is used to effectively detect unknown APK samples.", "explanation": "要旨は分類器によるマルウェア検出であり、復元・ソースコード生成を目的としていないため除外基準 EC3 に該当する"}], "reasoning": "本稿はデコンパイルを API 抽出の前処理として利用しているが、主目的は抽出した特徴量でのマルウェア検出であり、コード生成や高水準表現の復元ではない。したがってデコンパイルの復元目的の研究とはみなせず、除外すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3053, "latency_ms": 42921}}
{"key": "springer_10_1007_978_981_15_9647_6_95", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "AndRev tool is used to decompile apks in batch mode.", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く記載されておらず、従来のバッチスクリプト方式のみであるため、EC1 に該当し除外と判断した。"}], "reasoning": "本稿は Android アプリのパーミッション抽出を目的とした静的解析ツールの紹介であり、デコンパイルはバッチスクリプトで実施されているが、ML/LLM を用いた手法は示されていない。したがって、インクルード基準の IC0 を満たさず、除外基準 ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 41982}}
{"key": "springer_10_1007_978_981_16_0965_7_4", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a generic malware detection process is proposed using machine learning ... decompilation, feature mining and machine learning", "explanation": "要旨はマルウェア検出が目的であり、デコンパイルは特徴抽出のための前処理であって高レベルコードの生成や復元を目指していないため、コード生成・復元が主目的ではないと判断した。"}], "reasoning": "本論文はAndroidアプリのマルウェア検出を目的としており、デコンパイルは特徴抽出のステップとして使用されるだけで、LLM/ML を用いたコード復元や高レベル表現の生成を行っていない。したがって、デコンパイルの目的（復元・可読化）を満たさず、除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3203, "latency_ms": 47618}}
{"key": "springer_10_1007_978_3_030_63128_4_42", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "The network can be used for ... compile and decompile", "explanation": "アブストラクトではバイナリやアセンブリといった低水準入力について言及されておらず、decompile が単なる応用例として取り上げられているだけなので、低水準入力が存在しないと判断した。"}], "reasoning": "本稿は auto‑encoder の構造と学習手法に関する研究であり、低水準コード（バイナリ/アセンブリ）を入力として LLM/ML を用いて高水準コードを復元することを目的としていない。抽象的に “compile and decompile” と記載されているが、具体的なデコンパイル手法や入力の詳細が示されていないため、除外基準 EC2 に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3307, "latency_ms": 52214}}
{"key": "springer_10_1007_s12652_020_02196_4", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "apply it to classify malware", "explanation": "論文の目的はバイトコードを画像化しCNNでマルウェアか否かを分類することであり、コードの復元や高水準表現の生成は行っていないため、コード生成/再構築の意図がなく除外基準EC3に該当します。"}], "reasoning": "本稿はバイトコード画像を用いたマルウェア検出を提案しており、低水準入力はあるものの出力はマルウェア/正常のラベルであり、デコンパイルによる高水準コード復元を目的としていません。したがって、コード生成・再構築が主目的でない点から除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2993, "latency_ms": 41764}}
{"key": "springer_10_1007_978_3_030_65299_9_5", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "performing frequency analysis based on the decompiled APK... classification using machine learning", "explanation": "要旨はデコンパイルされた APK から特徴を抽出し機械学習でマルウェア分類を行うことであり、コードの復元・生成が目的ではないため除外基準 EC3 に該当する"}], "reasoning": "本論文はデコンパイルされた APK を特徴抽出の素材として用い、ML によるマルウェア分類を目的としている。コードの再構成や高水準表現の生成を目指すものではなく、復元・可読化が主目的でないため、Decompilation Survey の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3265, "latency_ms": 51376}}
{"key": "springer_10_1134_s106373971903003x", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The method is implemented as a C++ program; it recognizes subcircuits ...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が一切言及されておらず、従ってML/LLMが手法の中核でないため除外基準EC1に該当します。"}], "reasoning": "本研究はトランジスタレベルの回路をゲートレベルに変換する手法をC++で実装していると述べており、機械学習やLLMの利用は示されていません。デコンパイル調査の対象はML/LLMを用いた手法に限るため、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2917, "latency_ms": 41073}}
{"key": "springer_10_1007_978_981_13_0311_1_29", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we have constructed mobile apps identification system that applies the signature self-verification server monitoring method", "explanation": "要旨では機械学習や大規模言語モデルの利用について触れられておらず、提案手法は署名自己検証に基づくものであり、ML/LLM が使用されていないと判断したため"}], "reasoning": "本稿は Android アプリの偽装検出を署名自己検証システムで実現することを目的としており、機械学習や大規模言語モデルを用いた手法が記述されていない。そのため、Decompilation Survey の包括基準（LLM/ML が中心手法）を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3204, "latency_ms": 52457}}
{"key": "springer_10_1007_978_3_030_22038_9_6", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Shade employs a classification algorithm with 42 unique features ... to detect control logic injection attacks", "explanation": "要旨は攻撃検知を目的とした分類であり、低水準コードを高水準表現に復元することやコード生成は行っていないため、コード生成・復元意図が欠如していると判断した。"}], "reasoning": "本論文はPLC のメモリ状態を監視し、分類アルゴリズムで攻撃パケットを検出することが主目的であり、デコンパイルやソースコード・擬似コードの生成を行わない。したがって、デコンパイル調査のインクルード基準（IC）を満たさず、除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3190, "latency_ms": 46186}}
{"key": "springer_10_1007_978_3_030_21373_2_10", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "This paper proposes an Android malware detection method... extracts the permission features and API features by decompiling the APK file, and then uses ... an ensemble learning model ... to quickly and accurately detect unknown APKs.", "explanation": "要旨では、デコンパイルは特徴抽出のための前処理であり、ML は検出モデルにのみ使われており、コードの復元・生成が目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はデコンパイルを特徴抽出手段として利用しており、LLM/ML がデコンパイル自体の復元やコード生成に使われていない。目的はマルウェア分類であり、デコンパイルの生成・再構成が主目的ではないため、除外基準に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 49260}}
{"key": "springer_10_1007_978_3_030_24907_6_29", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Our method regards the decompiled codes of an application as a text document", "explanation": "入力として低水準バイナリやアセンブリではなく、既にデコンパイルされたコードを使用しているため除外基準 EC2 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "Machine learning is considered as a potential solution for promoting the performance of malware detection", "explanation": "目的がマルウェア検出という分類・検知であり、コードの復元・生成が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はデコンパイルされたコードをテキストとして扱い、トピックモデルで特徴抽出しマルウェア検出を行う研究です。入力が低水準表現でなく、目的もコード生成や可読化ではなく検知であるため、除外基準を満たし除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3168, "latency_ms": 50406}}
{"key": "springer_10_1007_978_3_030_11935_5_68", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "decompiled, and illustrated by the digital competences extensions", "explanation": "抽象的に \"decompiled\" とあるが、対象は教育分野のデジタルコンピテンシーであり、低水準コードや機械語のデコンパイルとは無関係なので本サーベイの範囲外と判断した。"}, {"code": "ex_no_ml", "evidence": "The paper points out to digital competence as an essential part of the competence model", "explanation": "要旨に機械学習や大規模言語モデルの利用に関する記述がなく、ML/LLM を用いた研究ではないため除外基準に該当する。"}], "reasoning": "本稿は教師のデジタルコンピテンシーの開発に関する教育研究であり、低水準バイナリ等の入力やコード生成を目的としたデコンパイル手法とは無関係です。また、機械学習や大規模言語モデルの使用も示されていません。したがって、本サーベイの対象外（ex_out_of_scope）およびML未使用（ex_no_ml）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 2964, "latency_ms": 46320}}
{"key": "springer_10_1007_978_3_030_30215_3_20", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Laddis ... is a binary-logic decompiler ... developed with extensive manual reverse engineering effort", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、手作業のリバースエンジニアリングに基づくデコンパイラであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は PLC のバイナリロジックを既存のデコンパイラで復元し、高レベルコードに変換するフレームワークを提案しているが、機械学習や大規模言語モデルを手法の中心に用いている記述がない。そのため、除外基準 EC1 (No ML/LLM) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3279, "latency_ms": 46526}}
{"key": "springer_10_1007_978_3_030_24268_8_22", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "A Survey of Software Reverse Engineering Applications", "explanation": "タイトルと概要から本稿はサーベイ論文であり、調査・レビューが主目的であるため除外基準 EC4 に該当します。"}, {"code": "ex_no_ml", "evidence": "Abstract does not mention any machine learning or large language model techniques.", "explanation": "要旨にML/LLMの利用が記載されていないため、除外基準 EC1 にも該当します。"}], "reasoning": "本論文はソフトウェアリバースエンジニアリング全般の調査（サーベイ）であり、ML/LLM を用いたデコンパイル手法の提案や評価は行っていません。そのため、除外基準（サーベイ論文、ML 非使用）のどちらも満たすため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3008, "latency_ms": 44143}}
{"key": "springer_10_1007_978_3_030_44041_1_75", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a bottom-up approach to extract intents from network configurations.", "explanation": "要旨は低レベル設定から意図を抽出する手法を示すだけで、ML/LLM の使用について言及がなく、機械学習を用いていないと判断できるため除外基準 EC1 に該当する。"}], "reasoning": "本稿はネットワーク構成から高レベル意図へ変換する手法を提案しているが、機械学習や大規模言語モデルを利用している記述がなく、ルールベース／アルゴリズム中心のアプローチとみなされる。したがって、デコンパイル調査の対象となるML/LLMを中核とした研究ではなく、除外基準 ex_no_ml に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3174, "latency_ms": 47278}}
{"key": "springer_10_1007_978_3_030_05057_3_32", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "SoProtector includes a real-time monitor to detect malicious functions in binary code.", "explanation": "抽象からは機械学習や大規模言語モデルの使用が示されておらず、単なるバイナリ解析・モニタリングであるため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は Android のネイティブ層 SO ファイルに対するセキュリティ分析とマルウェア検出を目的としており、機械学習や LLM を用いた手法は記載されていない。デコンパイルや高水準コード生成を目指す研究ではないため、除外基準 EC1（ML/LLM 未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2963, "latency_ms": 40998}}
{"key": "springer_10_1007_978_3_319_89500_0_56", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we design an offline static detection ...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されておらず、ルールベースの静的検出とみなされるため、EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "offline static detection ... the code decompile, the function call relationship and the judgement rules", "explanation": "研究の目的は脆弱性検出であり、コード生成や復元を行うことはなく、EC3（コード生成目的がない）に該当します。"}], "reasoning": "本論文は Storm の acker 失敗脆弱性を検出するためのオフライン静的解析手法を提案しており、機械学習/LLM の利用が示されていないため、デコンパイルを中心とした ML 手法のサーベイ対象外です。また、目的は検出・防御であり、コード生成や高水準表現の復元は行わないため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3181, "latency_ms": 51530}}
{"key": "springer_10_1007_978_981_10_7605_3_125", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a way to modify the debugging option of the Android manifest file to “true” without decompiling the app.", "explanation": "抽象からは機械学習や大規模言語モデルの使用が全く言及されておらず、EC1（ML/LLM を使用していない）に該当するため除外と判断した。"}], "reasoning": "本稿は Android アプリのマニフェストをデコンパイルせずに直接書き換える手法を提案しているが、手法に機械学習や大規模言語モデルは用いられていない。Decompilation に関わるが、対象は手動／ビットレベル編集であり、LLM/ML を中心としたデコンパイル研究の範囲外である。したがって除外 (ex_no_ml) とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3100, "latency_ms": 49394}}
{"key": "springer_10_1007_978_3_319_52709_3_13", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper shows how the lack of formalization has led to varying interpretations of structured CFGs.", "explanation": "要旨には機械学習や大規模言語モデルの利用について言及がなく、純粋に形式化と理論的考察のみを扱っているため、EC1 に該当します。"}], "reasoning": "本稿は構造化制御フローグラフの形式化手法を提案する理論研究であり、ML/LLM を利用したデコンパイル手法や復元・可読化を目的とした実装は示されていません。したがって、デコンパイルに関わる LLM/ML 手法を中心としたサーベイの採択基準を満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3106, "latency_ms": 48521}}
{"key": "springer_10_1007_978_981_10_6385_5_23", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect malware accurately... analyzes malware binary directly without any decompiler", "explanation": "論文はバイナリを入力としてマルウェア検出という分類タスクを行っており、コードの復元や高水準表現の生成を目的としていないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は機械学習を用いたバイナリテクスチャ特徴によるマルウェア分類手法を提案しており、デコンパイルやソースコードの復元を目的としていません。そのため、コード生成・復元を主目的とする本サーベイの採択基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3017, "latency_ms": 43835}}
{"key": "springer_10_1007_978_3_319_69471_9_27", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach leverages the fact all except floating operands in Dex are stored in a 32-bit register...", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く記載されておらず、従来のビット操作による変換手法のみが述べられているため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "DexPro, a novel bytecode level code obfuscation system for Android applications.", "explanation": "本研究はコード難読化を目的としており、デコンパイルや高水準コード復元を行うことが主目的ではないため、デコンパイル調査の範囲外とみなした。"}], "reasoning": "要旨は Android バイトコードの難読化手法を提案しており、機械学習や LLM を用いたデコンパイルやコード復元の研究ではない。入力は低水準バイトコードだが、目的が復元・可読化ではなく難読化であり、ML 手法の記述もないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3316, "latency_ms": 53357}}
{"key": "springer_10_1007_978_3_319_68690_5_12", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a static analysis technique called SAAD", "explanation": "要旨では機械学習や大規模言語モデルの利用は言及されておらず、従来の静的解析手法のみが説明されているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "SAAD decompiles APK file into Dalvik bytecodes files and then performs resource leak analysis", "explanation": "デコンパイルは解析の前処理として行われているが、出力はバイトコードであり、ソースコードや擬似コードの生成・復元が目的ではなくバグ検出が主目的であるため、コード生成/再構築の意図がないと判断した。"}], "reasoning": "本稿は Android アプリのエネルギー欠陥検出を目的とした静的解析手法を提案しており、ML/LLM を用いた手法は提示されていない。また、デコンパイルはバイトコード取得の前処理に過ぎず、高水準コードの生成や復元は行わないため、デコンパイル研究の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3257, "latency_ms": 50095}}
{"key": "springer_10_1007_978_981_10_6385_5_32", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a method of identifying kernel struct layout based on brute-force matching", "explanation": "抽象からは機械学習・大規模言語モデルの使用が示唆されておらず、単なるブルートフォース手法であるため、EC1 に該当して除外と判断した。"}], "reasoning": "本稿は Linux カーネル構造体のレイアウト推定をブルートフォースマッチングで行う手法を提案しているが、機械学習や LLM を用いた記述が全くない。したがって、Decompilation Survey のインクルード基準（LLM/ML が中核手法）を満たさず、除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3015, "latency_ms": 44899}}
{"key": "10.1145/3719027.3765040", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This work presents the first large‑scale study on human‑assisted Python decompilation...", "explanation": "アブストラクトからは機械学習やLLMの使用が言及されておらず、手動でのパッチ適用や調査が中心であるため、ML/LLMを用いた研究ではないと判断した。"}], "reasoning": "本稿は Python バイトコードのデコンパイル結果に対する人間の修正作業を大規模に調査する実証研究であり、機械学習や大型言語モデルを手法の中核として用いていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、include には該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 3153, "latency_ms": 45388}}
{"key": "10.1145/3719027.3760714", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.87, "reason_codes": [{"code": "ex_no_ml", "evidence": "HarvETHter sources knowledge of the Ethereum blockchain and leverages it to decompile smart contracts to Solidity source code.", "explanation": "要旨に機械学習や大規模言語モデルの使用について言及がなく、従来の知識ベース手法と読むため、ML/LLM が中心手法でないと判断した。"}], "reasoning": "要旨では低水準のEVMバイトコードを入力とし、Solidityソースコードを出力するデコンパイラであることは示されているが、機械学習やLLMを手法の中核として利用している記述がない。したがって除外基準 EC1（ML/LLM 未使用）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3114, "latency_ms": 54290}}
{"key": "10.1145/3772368", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we introduce codealign, a novel instruction-level code equivalence technique designed for neural decompilers... more detailed than existing evaluation metrics", "explanation": "要旨はニューラルデコンパイラの評価手法を提案しており、コード生成や復元そのものは目的としていないため、コード生成・復元が主目的でない点から EC3 に該当し除外と判断した。"}], "reasoning": "本稿はニューラルデコンパイラの評価手法（コード等価性チェック）を提案しており、実際に低水準入力から高水準コードを生成・復元することが目的ではない。デコンパイルそのものを行う研究ではなく、評価指標の提示に留まるため、コード生成・復元が主目的でないという除外基準 EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3169, "latency_ms": 52485}}
{"key": "10.1145/3733822.3764675", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "benchmark study of five decompilers, focusing on their ability to infer types", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及されておらず、既存デコンパイラの評価のみを行っているため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿はバイナリ型推論のベンチマークであり、機械学習・LLM を手法の中心に据えていない。デコンパイルの改善を目的とした ML 手法が提示されていないため、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3110, "latency_ms": 47220}}
{"key": "10.1145/3733822.3764668", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "we introduce the ideco framework for improving the decompilation of non-C programming languages.", "explanation": "低水準バイナリから生成されたデコンパイル結果をルールと GPT‑4 系の LLM で書き換え、可読性を向上させることが目的であるため、既存デコンパイラ出力の改善に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "using GPT-4o and GPT-4.1-mini ... reverse engineering task is easier to solve when its decompilation is processed by ideco.", "explanation": "GPT‑4 系の LLM を核心手法として利用し、デコンパイル結果を改善している点が本コードの根拠です。"}], "reasoning": "本論文はバイナリ（低水準入力）を対象に、GPT‑4 系の大規模言語モデルとルールベースのリライティングで既存デコンパイラの出力を改善する手法を提案している。デコンパイルの復元・可読化を目的としており、ML/LLM が中心技術であるため、Include 判定かつ in_decompiler_enhancement に分類されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3396, "latency_ms": 64656}}
{"key": "10.1145/3708821.3733877", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we perform the first comprehensive empirical study on state-of-the-art C decompilers using our framework, DiscScope, which employs symbolic execution and differential analysis", "explanation": "引用文からは、MLやLLMの使用は言及されず、シンボリック実行と差分解析のみが用いられているため、ML/LLMが中心手法でないことが分かります。"}], "reasoning": "本稿は既存のCデコンパイラを評価する実証研究であり、ML/LLM を手法の中核に用いていないため除外対象です。デコンパイル自体の生成や改善を目的としておらず、評価・エラータクソノミーの構築が主目的です。", "model": "openai/gpt-oss-120b", "tokens_used": 3057, "latency_ms": 46151}}
{"key": "10.1145/3749988", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "transformer encoder-decoder model for neural decompilation ... reverse engineer math equations from binaries", "explanation": "抽象的にバイナリを入力とし、Transformer により高水準の数式表現（ソース様）を直接生成しているため、Core decompilation に該当します。"}], "reasoning": "本稿はバイナリ実行ファイルを入力として、Transformer ベースのニューラルデコンパイラで数式という高水準表現を生成することを目的としており、ML 手法が中心に用いられています。低水準入力・高水準出力・復元目的がすべて満たされるため、インクルードと判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3208, "latency_ms": 46147}}
{"key": "10.1145/3699674", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This article proposes the REMaQE automated framework for reverse engineering of math equations from binary executables.", "explanation": "アブストラクトに機械学習やLLMの利用についての記述がなく、手法は従来の解析フレームワークとみなせるため、ML/LLMが使用されていないと判断し除外基準 EC1 に該当します。"}], "reasoning": "本稿はバイナリから数式を復元するフレームワークを提案していますが、手法として機械学習や大規模言語モデルの使用が明示されていません。したがって、デコンパイルにML/LLMが核心的手法として用いられているという条件を満たさず、除外基準 ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3193, "latency_ms": 49676}}
{"key": "10.1145/3728958", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "automatically correcting decompiler outputs into compilable versions", "explanation": "LLM を用いて既存デコンパイラの出力（低水準擬似コード）を可読かつコンパイル可能なソースに改善しているため、IC2 の Decompiler Enhancement に該当する"}], "reasoning": "本研究は LLM を中心手法として、デコンパイラが生成した擬似コードを再修正しコンパイル可能な C ソースに変換する手法を提案している。入力はバイナリ由来の低水準表現（デコンパイラ出力）で、目的はコードの再コンパイル可能性を回復することであり、Decompilation の核心的課題に該当するため include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3544, "latency_ms": 59129}}
{"key": "10.1145/3728935", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Shrnkr, a static-analysis-based decompiler", "explanation": "要旨では手法が静的解析ベースであると明示されており、ML/LLM の利用が示されていないため除外基準 EC1 に該当します。"}], "reasoning": "本稿は Ethereum VM バイナリのデコンパイルを対象とし、静的解析を中心とした新しいコンテキスト感度手法を提案していますが、機械学習や大規模言語モデルの使用は言及されていません。したがって、ML/LLM を中核手法とする本サーベイの採択基準を満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3113, "latency_ms": 44734}}
{"key": "10.1145/3729373", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "the first LLMs-based EVM decompilation pipeline, which aims to ... lift it into smart contract code.", "explanation": "抽象記述は低水準のEVMバイトコードを入力とし、LLMを用いて高水準のSolidityコード（コンパイル可能なソース）を生成しているため、Core Decompilation に該当する。"}, {"code": "in_type_recovery", "evidence": "semantic enhancement based on a novel type-aware graph model to infer stripped variables during compilation", "explanation": "型情報の推論・復元を目的とした手法が明示されており、Type Recovery の要素も含んでいる。"}], "reasoning": "本論文はEVMバイトコードという低水準入力からLLMを中心手法として高水準のSolidityソースコードを生成することを目的としているため、Decompilation Survey のコア対象に該当する。さらに、型情報の推論を行う構成要素があるため、Type Recovery も補助的に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3244, "latency_ms": 52992}}
{"key": "10.1145/3696410.3714790", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "LLM-powered web application that decompiles smart contract bytecodes on Sui into ... re-compilable source code", "explanation": "抽象から、低水準のバイトコードを入力とし、LLM を中心手法で人間可読かつ再コンパイル可能なソースコード（L1）を生成しているため、Core Decompilation に該当する。"}], "reasoning": "本稿はバイトコード（低水準入力）を LLM を用いて直接高水準ソースコード（L1）へ変換する手法を提案しており、目的も復元・可読化・再コンパイルである。除外基準に該当せず、Include 基準をすべて満たすため、'include' と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3224, "latency_ms": 45392}}
{"key": "10.1145/3722041.3723097", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "predict vulnerabilities ... leveraging ... neural decompilation and predicting vulnerabilities through deep learning on the decompiled source code", "explanation": "要旨から、デコンパイルは脆弱性予測という分類タスクの補助手段として用いられており、復元・可読化そのものが研究の主目的ではないため、コード生成・再構成が主目的とはみなせません。"}], "reasoning": "本稿はバイナリからニューラルデコンパイルを行い得られたコードを用いて脆弱性予測を行うことが主目的であり、デコンパイル自体の復元・可読化が主要な研究目的ではない。そのため、除外基準EC3（コード生成・復元が主目的でない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3504, "latency_ms": 68686}}
{"key": "10764949", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "decompile Wasm binary code into a higher-level, more comprehensible source code representation", "explanation": "LLM を中心手法として、低水準の Wasm バイナリを入力に高水準のソースコード（L1/L2）を生成しているため、Core Decompilation に該当する。"}, {"code": "in_decompiler_enhancement", "evidence": "traditional decompilers often struggle with producing readable outputs ... WaDec markedly outperforms current state-of-the-art tools", "explanation": "既存デコンパイラの出力と比較し、可読性や再コンパイル可能性を大幅に改善している点がデコンパイラ強化に該当する。"}], "reasoning": "本稿は低水準の WebAssembly バイナリを入力とし、LLM を用いて高水準のソースコードへ直接変換する手法を提案している（IC0 の全条件を満たす）。また、従来デコンパイラの課題を LLM で克服し、可読性や再コンパイル性を向上させている点から、Core Decompilation と Decompiler Enhancement の両側面が認められる。", "model": "openai/gpt-oss-120b", "tokens_used": 3317, "latency_ms": 50806}}
{"key": "10.1145/3643744", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "extracting pre-defined features from an abstract syntax tree", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用が言及されておらず、単に手作りの特徴抽出による指標作成と説明されているため、ML/LLM が利用されていないと判断した。"}], "reasoning": "本稿はデコンパイル後のコード可読性を評価する指標を提案しているが、低水準入力から高水準コードを生成することや、ML/LLM を手法の中心に用いることは示されていない。したがって、Decompilation Survey の採択基準を満たさず除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3209, "latency_ms": 48397}}
{"key": "10.1145/3649860", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We conduct the study by investigating 333 unique bugs from three popular Java decompilers.", "explanation": "要旨では機械学習や大規模言語モデルの利用が全く言及されておらず、従来のバグ調査・差分テスト手法のみであるため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿は Java デコンパイラのバグを体系的に調査し、JD-Tester という差分テストフレームワークを提示しているが、機械学習や大規模言語モデルを手法の核として使用していない。したがって、Decompilation Survey のインクルード基準 (IC0) を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3247, "latency_ms": 44851}}
{"key": "10.1145/3591237", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "hardware loop rerolling leverages clone detection and program synthesis techniques", "explanation": "抽象からは機械学習や大規模言語モデルが使用されている旨の記述がなく、ルールベースのクローン検出とプログラム合成が中心であるため、ML/LLM が使われていないと判断した。"}], "reasoning": "本稿はハードウェアのネットリストを対象にループ再構成を行う手法を提案しているが、手法は クローン検出 と プログラム合成 に基づくものであり、LLM や機械学習の利用が示されていない。したがって、Decompilation Survey の採択基準で必須とされる「LLM/ML が中核手法として使われている」条件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3168, "latency_ms": 49433}}
{"key": "10.1145/3546946", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_variable_naming", "evidence": "State-of-the-art techniques use machine learning to predict missing information like variable names.", "explanation": "本稿は機械学習で変数名を予測し、デコンパイル結果の変数／関数名を復元することを主目的としているため、変数命名（Variable Naming）に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "The decompiler ... transforms binaries into high-level code, ... output is far from readable.", "explanation": "デコンパイラの出力が可読性に欠ける点を機械学習で改善する研究であり、既存デコンパイラ出力の品質向上（Decompiler Enhancement）に該当します。"}], "reasoning": "論文はバイナリから生成されたデコンパイラ出力を対象に、機械学習（ML）を用いて変数名を自動付与し可読性を高める手法を提案しています。入力は低水準バイナリ由来のデコンパイルコードで、目的はコード復元・可読化であるため、スクリーニング基準の Core/Peripheral のいずれにも該当し、include と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3571, "latency_ms": 65414}}
{"key": "10.1109/ASE.2019.00064", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_variable_naming", "evidence": "We propose the Decompiled Identifier Renaming Engine (DIRE), a novel probabilistic technique for variable name recovery", "explanation": "抽象から、変数名（識別子）を復元することが主目的であることが明示されているため、in_variable_naming が最も具体的なコードです。"}, {"code": "in_decompiler_enhancement", "evidence": "uses both lexical and structural information recovered by the decompiler", "explanation": "既存のデコンパイラが生成した高水準コードを入力として利用し、名前付けを改善しているので decompiler enhancement に該当します。"}], "reasoning": "本論文は低水準バイナリからデコンパイルされたコードに対し、ニューラルネットワークを用いて変数・関数名を自動的に復元する手法を提案している。入力はデコンパイラ出力であり、ML 手法が中心に用いられ、目的はコードの可読性向上＝復元であるため、インクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3436, "latency_ms": 63097}}
{"key": "10.1145/3582016.3582058", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "decompiler-based collaboration could leverage the strength of existing parallelizing compilers", "explanation": "要旨に機械学習・大規模言語モデルの使用は記述されておらず、従来のコンパイラベースのデコンパイル手法のみが述べられているため、ML/LLM が用いられていないと判断し、除外基準 EC1 に該当します。"}], "reasoning": "本稿は LLVM-IR から C/OpenMP へのデコンパイルを行うシステムを提案していますが、機械学習や大規模言語モデルを手法の中心として使用している記述が抽象からは確認できません。したがって、除外基準 EC1（ML/LLM 未使用）に該当し、調査対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3244, "latency_ms": 52490}}
{"key": "Cao2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "NeurDP uses a graph neural network (GNN) model to convert LPL to an intermediate representation (IR)", "explanation": "GNNはML/LLMの手法であり、低水準バイナリ(LPL)を高水準表現に変換してデコンパイルを実現しているため、Core Decompilationに該当します。"}], "reasoning": "本論文はバイナリ（低水準入力）を対象に、GNNを用いた学習ベースの手法で高水準コードを生成することを目的としている。デコンパイルの復元・可読化が主目的であり、MLが手法の中心にあるため、Include 基準を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3294, "latency_ms": 53815}}
{"key": "10.1145/3527321", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "employing several high-precision techniques and making them scalable", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、従来の解析技術のみで実装されていると判断できるため、EC1 に該当し除外します"}], "reasoning": "本稿はイーサリアムバイトコードを入力とし、高精度な静的解析手法でデコンパイルを実現していますが、ML/LLM を用いた旨の記述がなく、ルールの除外基準 EC1（ML/LLM 未使用）に該当するため除外と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3190, "latency_ms": 48017}}
{"key": "10.1145/3320269.3384766", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The algorithm is designed from the ground up with the goal of producing C code that is both goto-free...", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く言及されておらず、従来のアルゴリズムによる再構築であると示唆されるため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿はバイナリから制御フローグラフを再構築し、読みやすい C コードを生成する手法を提案しているが、機械学習や大規模言語モデルの利用は記載されていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1（ML/LLM 未使用）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3130, "latency_ms": 52194}}
{"key": "10.1145/3395363.3397370", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We test decompilation correctness to present an up-to-date understanding regarding modern C decompilers.", "explanation": "本文では既存のCデコンパイラの正確性を評価しており、ML/LLM を用いた手法について言及していないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿は C デコンパイラの出力を評価・バグ検出する調査研究であり、機械学習や大規模言語モデルを手法の中心に用いていません。そのため、除外基準「No ML/LLM (ex_no_ml)」に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3127, "latency_ms": 42562}}
{"key": "8973072", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "assigns variables meaningful names ... using statistical machine translation approaches to choose natural identifiers", "explanation": "抽象から、変数名の復元を主目的として統計的機械翻訳（ML手法）を用いているため、変数/関数命名の研究に該当する。"}, {"code": "in_decompiler_enhancement", "evidence": "Existing decompilers can reconstruct ... but typically use meaningless placeholder variables. ... our technique ... improves the decompiler output", "explanation": "既存のデコンパイラ出力（プレースホルダー変数）を入力として、LLM/ML により可読性を向上させるデコンパイラ強化手法である。"}], "reasoning": "本論文は、デコンパイルされたコードの変数名を統計的機械翻訳（ML）で自然な名前に置き換える手法を提案しており、変数命名の復元を主目的としている。入力はデコンパイラの出力であり、出力は意味的に改善された高水準コードであるため、Core の Decompiler Enhancement（特に Variable Naming）に該当し、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3677, "latency_ms": 71821}}
{"key": "10.1145/3236794", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "All our prototypes have been implemented in OCaml", "explanation": "本稿はOCamlで実装されたコンパイラ・合成アルゴリズムを提案しており、機械学習や大規模言語モデルの使用は示されていないため除外基準 EC1 に該当します。"}], "reasoning": "本文は関数型言語による CAD コンパイラと逆コンパイル手法を理論的に設計・実装することに焦点を当てており、ML／LLM を用いた手法は提示されていません。したがって、Decompilation Survey の対象外（ex_no_ml）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3214, "latency_ms": 52039}}
{"key": "10.1145/3375894.3375895", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a new approach that leverages the human analyst expertise to overcome decompilation challenges.", "explanation": "要旨に機械学習や大規模言語モデルの使用は一切記載されておらず、手法は人間アナリストとGDB拡張によるものであるため、ML/LLM が用いられていないと判断しました。"}], "reasoning": "本稿はデバッグ指向のマルウェアデコンパイル手法とそれを実装した RevEngE を提案していますが、機械学習や大規模言語モデルを用いたという記述がなく、完全にルールベース／ツールベースのアプローチです。したがって、Decompilation Survey の採択条件である「LLM/ML を中核手法として使用」要件を満たさないため除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3181, "latency_ms": 49806}}
{"key": "10.1145/3319535.3363255", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "automatically stitches the results from multiple decompilers together", "explanation": "抽象では機械学習・LLM の利用が全く記述されておらず、従来のデコンパイラを組み合わせる手法だけなので、EC1 に該当し除外と判断した。"}], "reasoning": "本論文は複数の既存デコンパイラの出力を統合するシステムを提案しており、LLM や機械学習を手法の中心として用いていない。したがって、Decompilation Survey の除外基準 EC1（No ML/LLM）に該当し、include ではなく exclude と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 2963, "latency_ms": 46684}}
{"key": "10.1145/3735971", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to detect Ponzi contracts... we decompile bytecodes into higher-order representations to analyze control flows and state variable dependencies", "explanation": "抽象的にはバイトコードを高次表現に変換していますが、最終目的はポンジ契約の検出であり、コードの復元や可読化が主目的ではないため、コード生成/再構成の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイトコードをグラフ表現に変換し、コントラスト学習でポンジ詐欺コントラクトを分類することが主目的です。デコンパイルは分析の前処理として用いられますが、生成された高水準コードや擬似コードの提供・復元を目的としていないため、デコンパイル研究の範囲外と判断されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3426, "latency_ms": 58280}}
{"key": "10.1145/3719027.3765144", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose new obfuscation schemes tailored for DNN binaries", "explanation": "本文は DNN バイナリを難読化する手法を提案しており、ML/LLM を用いた手法は記述されていないため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は DNN バイナリの逆コンパイル（デコンパイル）を防止するための難読化手法を提案しているが、LLM や機械学習を手法の中心に用いていない。したがって、Decompilation Survey のインクルード基準を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3148, "latency_ms": 48665}}
{"key": "10.1145/3719027.3765089", "action": "keep", "reason": "uns_unclear_method", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_method", "evidence": "leveraging probabilistic constraints to estimate the likelihood of each function signature recovery result produced by decompilers", "explanation": "抽象からは機械学習やLLMが使用されたことが明示されておらず、手法が統計的手法か規則ベースか判別できないため不明と判断した。"}, {"code": "uns_unclear_output", "evidence": "parameter type recovery", "explanation": "出力は関数シグネチャやパラメータ型の回復と記述されているが、L1‑L3 のコード生成か L4 の属性回復かが曖昧で、採択基準を満たすか判断できない。"}], "reasoning": "本稿はバイナリから関数シグネチャを回復する手法を提案しているが、手法が機械学習／LLM に基づくかが要旨からは読み取れない。出力が高水準属性（型情報）である可能性はあるが、レベル判定が不明確なため、現時点では include か exclude かを決定できない。", "model": "openai/gpt-oss-120b", "tokens_used": 3690, "latency_ms": 74836}}
{"key": "10.1145/3719027.3762169", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present JaDX-ACVTool, a plugin that bridges this gap by integrating code coverage information from ACVTool directly into JaDX-GUI.", "explanation": "要旨では機械学習や大規模言語モデルの使用が全く言及されておらず、単なるプラグインによるコードカバレッジ統合であるため、EC1の『ML/LLM を用いていない』に該当し除外と判断した。"}], "reasoning": "本論文は Android アプリのリバースエンジニアリング支援ツールを提示しているが、低レベルバイナリから高レベルコードを復元するためにML/LLM を使用していない。したがって、本サーベイの対象外（ex_no_ml）と判定する。", "model": "openai/gpt-oss-120b", "tokens_used": 3064, "latency_ms": 55552}}
{"key": "10.1145/3746252.3761266", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "ORCAS takes binary functions ... and scores their semantic similarity more robustly.", "explanation": "抄録はバイナリ関数間の類似度をスコア付けすることを目的としており、コードの復元や高水準表現の生成を行わないため、コード生成／再構成を目的としたデコンパイル研究ではありません。"}], "reasoning": "本論文はバイナリコードの類似性分析を行う手法を提案しており、低水準入力から高水準コードを生成することを目的としていないため、デコンパイルの範囲外です。したがって、除外基準 EC3（コード生成・復元が主目的でない）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3256, "latency_ms": 55064}}
{"key": "10.1145/3733817.3762702", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an empirical evaluation of the Tigress obfuscator...", "explanation": "アブストラクトに機械学習やLLMの使用が記載されておらず、評価は手法の実装によるものであるため、ML/LLM が用いられていないと判断し ex_no_ml としました。"}], "reasoning": "本稿は Tigress オブフスケータの効果を実証的に評価するもので、機械学習やLLM を手法の中心に用いていない。したがってデコンパイルを ML/LLM で行う研究という本サーベイの対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3084, "latency_ms": 55025}}
{"key": "10.1145/3733822.3764673", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_type_recovery", "evidence": "We aim to analyze the types and roles of structural elements from the binary...", "explanation": "バイナリを入力とし、構造体メンバの型情報を推測することが主目的であり、LLM/ML（GNN）が中心手法として用いられているため、タイプ回復研究に該当します。"}], "reasoning": "本稿はバイナリレベルのデータフローグラフを入力とし、グラフニューラルネットワークで構造体メンバの型や役割を推測することを目的としている。入力が低水準であり、ML 手法が中心で、生成ではなく型情報の復元を行う点が「type recovery」の基準を満たすため、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3298, "latency_ms": 57435}}
{"key": "10.1145/3733822.3764672", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "In reverse engineering our goal is to build systems that help people to understand software.", "explanation": "抄録に機械学習や大規模言語モデルの使用が言及されておらず、ML/LLM を用いた手法が全く示されていないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿はソフトウェア理解度の測定手法を提案する評価研究であり、デコンパイルそのものや LLM/ML を用いたコード復元を目的としていません。低水準バイナリ入力から高水準コードを生成するような ML 手法が示されていないため、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2910, "latency_ms": 49043}}
{"key": "10.1145/3765521", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "labels each instruction as Inlined or Not inlined and recovers the inlined-function boundaries", "explanation": "論文の目的は命令レベルでインライン関数を検出・ラベル付けすることであり、ソースコードや擬似コードの生成・復元は行わないため、コード生成・再構築の目的がなく EC3 に該当する"}], "reasoning": "本研究はバイナリ命令を入力とし、機械学習でインライン関数の境界を検出する分類タスクに焦点を当てている。出力はインラインか否かのラベルであり、高水準コードや擬似コードの生成は行わないため、デコンパイルの直接的な生成・復元を目的とした研究とはみなせず、除外基準 EC3（コード生成・再構築目的なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3993, "latency_ms": 84699}}
{"key": "10.1145/3759425.3763397", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Recent efforts that leverage Large Language Models (LLMs) for vulnerability detection are still limited...", "explanation": "本文はバイナリレベルでの脆弱性検出を目的としており、コードの復元・生成を行うことが主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は LLM を用いたバイナリの脆弱性検出フレームワークを提案しており、低レベルコードを高レベルソースに復元することを目的としていません。デコンパイルの目的であるコード生成・可読化が示されていないため、インクルード基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3174, "latency_ms": 57508}}
{"key": "10.1145/3759425.3763387", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.88, "reason_codes": [{"code": "in_variable_naming", "evidence": "automate function renaming ... assigning meaningful function names", "explanation": "要約は LLM を用いてデコンパイルされたコードから関数名を自動付与することを目的としているため、変数/関数命名の回復が主目的と判断できる。"}], "reasoning": "本稿は組み込みファームウェアのデコンパイル結果を入力とし、LLM（ChatGPT）を用いて関数名を自動的に付与する手法を提案している。入力は低水準のデコンパイルコードで、出力は関数名という高水準属性（L4）であり、復元・可読化を目的としているため、IC0 を満たし、IC4（in_variable_naming）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3495, "latency_ms": 70668}}
{"key": "10.1145/3757735", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "This article presents a taxonomy categorizing and describing the main techniques used to secure Android applications.", "explanation": "アブストラクトは Android アプリの保護手法の分類・分析に焦点を当てており、デコンパイルや LLM/ML を用いたコード復元とは無関係であるため、サーベイの対象外と判断した。"}], "reasoning": "本文は Android アプリの保護技術の分類と実態調査を目的としており、低水準バイナリから高水準コードを生成するデコンパイル研究とは関係がない。したがって除外基準（範囲外）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3043, "latency_ms": 51339}}
{"key": "10.1145/3696630.3731468", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "The European Union (EU) has a process to assess the conformity of specific products …", "explanation": "本論文はEUの適合性評価プロセスや規制遵守を扱っており、デコンパイルやコード復元とは無関係です。"}, {"code": "ex_no_ml", "evidence": "Technical requirements are challenging to understand from legal texts, and certification processes rely solely on manufacturer documentation.", "explanation": "要旨に機械学習や大規模言語モデルの利用は記載されておらず、ML手法が中心ではないため除外します。"}], "reasoning": "要旨はサイバーフィジカルシステムのソフトウェア適合性評価と欧州規制遵守に焦点を当てており、デコンパイルや低水準コードからの高水準表現生成に関する研究ではありません。また、機械学習やLLMの使用についても言及がないため、スクリーニング基準の除外条件に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3272, "latency_ms": 58764}}
{"key": "10.1145/3696630.3728508", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify compliance issues", "explanation": "本論文はLLMを用いてSmaliコードからGDPR違反を検出することが目的であり、コードの復元・擬似コード生成などの高水準表現の生成を行わないため、コード生成・再構築が主目的ではないと判断した。"}], "reasoning": "本文は低水準のSmaliコードを入力とし、LLMでプライバシー規制違反を検出することに焦点を当てている。デコンパイルによる高水準コードや構造の生成を目的としていないため、本調査の除外基準EC3（コード生成・再構築が主目的でない）に該当し、除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3182, "latency_ms": 55590}}
{"key": "10.1145/3728911", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "hashes binaries into program-level representations through large language model (LLM)-generated function embeddings", "explanation": "抽象からは LLM が埋め込みを生成して類似度解析を行うことが示されており、コードの復元・可読化といったデコンパイル目的の生成は行っていないため、コード生成・復元が目的でないと判断した。"}], "reasoning": "本研究はバイナリの類似性評価のために LLM を用いて関数埋め込みを生成し、ハッシュ化して検索効率を高めることが目的であり、低水準入力から高水準コードや擬似コードを生成するデコンパイルとは目的が異なる。そのため、デコンパイルの復元・可読化を目的とした研究ではなく、除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3142, "latency_ms": 50621}}
{"key": "10.1145/3755881.3755883", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "function identification in Ethereum smart contract bytecode", "explanation": "要旨はバイトコードから関数を識別することに焦点を当てており、ソースコードや擬似コードの生成・復元を目的としていないため、コード生成・再構成の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイトコードの関数境界を特定する手法を提案しており、デコンパイルによる高水準コード生成や復元を目的としていません。したがって、コード生成・再構成を主目的としないという除外基準に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3183, "latency_ms": 58800}}
{"key": "10.1145/3715780", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "generate ... summaries ... produce customized summaries tailored to multiple intents", "explanation": "アブストラクトはバイナリコードから自然言語の要約を生成することが目的であり、ソースコードや擬似コードといった高水準プログラム表現の復元・生成ではないため、復元/コード生成を主目的とするデコンパイルの条件を満たさない。"}], "reasoning": "本研究はバイナリコードの要約生成を目的としており、出力は自然言語テキストでありコードやAST等の高水準プログラム表現ではない。したがってデコンパイルの核心目的（コード復元・再構築）に該当せず、除外基準 EC3（コード生成・復元目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3375, "latency_ms": 61115}}
{"key": "10.1145/3756681.3756954", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "We evaluate CCCI using 289 Java snippets, extracted from over 819 operational scripts", "explanation": "要約から入力が Java ソースコード（高水準言語）であることが示されており、低水準バイナリやアセンブリが存在しないため、デコンパイルの定義を満たさないと判断した。"}], "reasoning": "本稿は LLM を用いたコード補完手法であり、入力は高水準の Java ソースコードである。デコンパイルは低水準表現から高水準表現への復元を目的とするが、本研究はその範囲外であるため除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3127, "latency_ms": 53778}}
{"key": "10.1145/3732771.3742724", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our work introduces Alpakka, a source-to-source compiler for Android's Smali syntax.", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、従来のコンパイラ技術のみで構成されていると判断できるため、ML/LLM が用いられていないとみなす。"}], "reasoning": "本稿は Smali からのソース変換とリソースリーク検出・自動修正を行うツールを紹介しているが、機械学習や大規模言語モデルに関する記述がなく、ML 手法を中心としたデコンパイル研究の条件を満たさない。そのため除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3191, "latency_ms": 60374}}
{"key": "10.1145/3732771.3742714", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "automatically selecting and translating JS snippets into Wasm", "explanation": "抽象から入力が JavaScript ソースコード（高水準）であり、バイナリやアセンブリといった低水準表現ではないため、デコンパイルの定義を満たさないと判断した。"}], "reasoning": "本研究は JavaScript を高水準ソースとして受け取り、WebAssembly という低水準バイナリへ変換（トランスパイル）するもので、デコンパイル（低水準→高水準）の目的や手法とは逆方向である。したがって、本サーベイの対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3120, "latency_ms": 54589}}
{"key": "10.1145/3713081.3731745", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "decompiled Android malware code presents unique challenges for analysis", "explanation": "アブストラクトは低水準バイナリやアセンブリではなく、すでにデコンパイルされたコードを対象としているため、低水準入力が存在しないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "evaluate the effectiveness of Code LLMs in Android malware analysis", "explanation": "目的はコード生成や復元ではなく、マルウェア分析・機能特定の評価であり、コード生成・復元の意図がない。"}], "reasoning": "本稿はデコンパイルされた Android マルウェアコードを入力として LLM の分析性能をベンチマークする研究であり、低水準バイナリから高水準コードを生成することが目的ではない。したがって、Decompilation Survey のインクルード基準（低水準入力とコード生成・復元目的）を満たさず、除外基準の「低水準入力がない」および「コード生成目的でない」に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3354, "latency_ms": 67100}}
{"key": "10.1145/3713081.3731728", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Binary Code Similarity Detection (BCSD) ... to efficiently compare binary code functions across architectures", "explanation": "アブストラクトはバイナリ関数の類似性比較を目的としており、コードの復元や生成を行う記述がなく、復元・可読化が主目的ではないため除外基準EC3に該当します。"}], "reasoning": "本論文はバイナリの類似性検出を目的とした手法であり、低水準コードから高水準コードを生成するデコンパイルとは無関係です。MLは用いられていますが、出力は類似度スコアでありコード復元や可読化を目的としていないため、除外基準 ex_no_code_generation に基づき除外しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3052, "latency_ms": 59602}}
{"key": "10.1145/3722572.3727926", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "In this work, we integrate an energy-aware networking stack with reverse-engineered Wi-Fi drivers...", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が一切記載されておらず、手法は従来のリバースエンジニアリングであると推測できるため、EC1の \"No ML/LLM\" に該当し除外します。"}], "reasoning": "本稿は閉源のWi‑Fiドライバを手作業または従来技術でリバースエンジニアリングし、スタティック解析に利用することを目的としているが、ML/LLM を用いた手法は示されていない。したがって、Decompilation Survey の採択基準である LLM/ML の中核使用が欠如しているため除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3266, "latency_ms": 62326}}
{"key": "10.1145/3702977", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose ReuNify to improve Soot-based static analysis coverage ... ReuNify converts Hermes bytecode to Soot’s intermediate representation.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く示されておらず、従来の変換手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は Hermes バイトコードを Soot の中間表現に変換する手法を提案しており、低水準入力から高水準 IR への変換自体はデコンパイルに近いが、機械学習・LLM を用いる記述がないため、除外基準 EC1（ML/LLM 未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3108, "latency_ms": 58130}}
{"key": "10.1145/3723498.3723739", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper examines the emergence and rise of speculative game design communities on itch.io", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く言及されておらず、デコンパイル目的のML手法が用いられていないと判断したため"}, {"code": "ex_no_lowlevel_input", "evidence": "developers on itch build projects for fantasy consoles—such as PICO-8 and Bitsy", "explanation": "入力はゲーム開発・ファンタジーコンソールであり、バイナリやアセンブリといった低水準表現が示されていないため"}], "reasoning": "本稿はゲームデザインやファンタジーコンソールの文化的分析を対象としており、低水準コードのデコンパイルやML/LLM を用いたコード復元に関する記述が全くない。したがって、デコンパイル調査の包含基準を満たさず除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3318, "latency_ms": 64145}}
{"key": "10.1145/3672608.3707995", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "through selective concrete execution of arbitrary functions within a x86_64 GNU/Linux binary", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、手法は具体的実行に基づくため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は ELF バイナリを実行時にライブラリ化し、具体的実行から関数プロトタイプを復元する手法を提案しているが、機械学習・LLM を中心手法として使用していない。したがって、Decompilation Survey の包括基準（IC0）を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3145, "latency_ms": 63237}}
{"key": "10.1145/3732365.3732428", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a novel approach combining static analysis with fuzzing techniques", "explanation": "本文は静的解析とファジングの組み合わせを提案しており、機械学習や大規模言語モデルの利用は言及されていないため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "static reverse engineering to fully understand the structural characteristics of inputs ... guide the seed file mutation technique", "explanation": "目的は構造情報を利用したシード変異とファジングの効率化であり、ソースコードや擬似コードなどの高水準表現を生成することはなく、コード生成・復元が主目的ではないため除外する。"}], "reasoning": "本研究は UEFI ファームウェアの構造解析とファジング支援を対象としており、機械学習・LLM の利用やデコンパイルによる高水準コード生成は行っていない。したがって、デコンパイル調査の対象外となり、除外 (exclude) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3144, "latency_ms": 63626}}
{"key": "10.1145/3726101.3726103", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we propose a system which employs a hybrid approach of analysis to better detect malware ... determining whether the APK ... is malicious or benign", "explanation": "要旨はAndroid APKを分類してマルウェアか否かを判定することが目的であり、コードの復元や高水準表現の生成は行わないため、コード生成/再構成を目的としたデコンパイル研究ではない。"}], "reasoning": "本稿はMLを用いたマルウェア検出システムの提案であり、低水準バイナリから高水準コードを生成することが目的ではない。デコンパイルの目的（復元・可読化）に該当しないため、除外基準EC3（コード生成・再構成意図がない）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3072, "latency_ms": 59132}}
{"key": "10.1145/3704857", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Guarded Kleene Algebra with Tests (GKAT) provides a sound and complete framework...", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及せず、形式手法のみを扱っているため、ML/LLM が用いられていないと判断しました。"}], "reasoning": "本稿は GKAT を拡張した形式的手法 CF‑GKAT による制御フロー変換の検証を提案しており、ML/LLM を用いたデコンパイルやコード生成に関する記述が全くありません。したがって、除外基準 EC1 (No ML/LLM) に該当し、レビュー対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3026, "latency_ms": 57205}}
{"key": "10.1145/3658644.3691386", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "we focus on the lifting from assembly to the IR P-Code ... We leverage machine-learned x86-64 semantics", "explanation": "アブストラクトはアセンブリという低水準入力から P‑Code という高水準 IR（L3）へ変換し、機械学習ベースのセマンティクスを核心手法として用いているため、Core decompilation に該当します。"}], "reasoning": "本稿はアセンブリから高水準の P‑Code IR への変換（デコンパイル）を目的とし、機械学習によるセマンティックモデルを主要手法として利用しています。入力が低水準で出力が L3 の高水準表現である点から、Decompilation Survey のインクルード基準を満たすと判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3235, "latency_ms": 66186}}
{"key": "10.1145/3658644.3690244", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an approach to lift position-independent x86-64 binaries to symbolized NASM.", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が言及されておらず、従来の形式的検証手法のみが記述されているため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿はバイナリをシンボライズされたアセンブリにリフトし、形式的に正当性を証明する手法を提案しているが、機械学習や大規模言語モデルを使用していない。したがって、Decompilation Survey の包括基準（IC0）が満たされないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3070, "latency_ms": 61473}}
{"key": "10.1145/3658644.3670340", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_variable_naming", "evidence": "recover both names and types for local variables and user-defined data structures", "explanation": "抽象から、LLMを用いて変数や構造体の名前を復元することが主目的であると分かるため、変数/関数命名回復に該当する"}, {"code": "in_type_recovery", "evidence": "recover both names and types for local variables and user-defined data structures", "explanation": "同じ記述で型（type）情報の復元も目的としているため、型回復研究にも該当する"}], "reasoning": "本稿はストリップドバイナリ（低水準入力）を対象に、LLMを中心手法として変数名と型情報を復元することを目的としている。出力は名前や型といった高水準属性（L4）であり、Peripheral 条件を満たすため採択対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3253, "latency_ms": 68446}}
{"key": "10.1145/3686215.3690147", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.84, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LLMs ... bypassing evasion techniques ... correctly identify methods of bypassing evasive techniques", "explanation": "論文はLLMを用いてマルウェアの回避手法を突破する方法を提示しており、目的はコードの復元やソース生成ではなく回避支援であるため、コード生成／復元目的がなく除外基準EC3に該当します。"}], "reasoning": "本稿はLLMがマルウェアの回避技術を回避する手順を示すことに焦点を当てており、低水準バイナリから高水準コードを生成するデコンパイル目的とは異なる。したがって、コード生成・復元を主目的としないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3387, "latency_ms": 71597}}
{"key": "10.1145/3646547.3688433", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We develop a semi-automated general methodology involving off-the-shelf tools", "explanation": "本文はオフ・ザ・シェルフのツールを用いた手法と述べており、機械学習や大規模言語モデルの使用が示されていないため、EC1に該当します。"}, {"code": "ex_no_lowlevel_input", "evidence": "We assume that the on-device firmware is inaccessible, e.g., read-protected", "explanation": "対象はファームウェアが取得できない前提であり、低水準バイナリやアセンブリを入力として扱っていないため、EC2に該当します。"}], "reasoning": "本稿はIoTデバイスのセットアップ時の情報漏洩を評価するセキュリティ調査であり、デコンパイルや高水準コード復元を目的としたML/LLM手法は含まれません。また、入力として低水準バイナリやアセンブリを扱っていないため、デコンパイル調査の範囲外です。", "model": "openai/gpt-oss-120b", "tokens_used": 3159, "latency_ms": 66142}}
{"key": "10.1145/3691620.3695502", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_type_recovery", "evidence": "Type recovery in stripped binaries is a critical and challenging task in reverse engineering", "explanation": "抑揚された低水準バイナリから型情報を復元することが目的であり、ML 手法を用いているため、デコンパイルの周辺対象である型回復に該当します。"}], "reasoning": "本稿はバイナリを入力とし、機械学習（few‑shot 学習）を中心手法として型情報を予測することを目的としている。入力は低水準バイナリ、出力は高水準属性（型）であり、デコンパイルに直接寄与する型回復研究として包括対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3400, "latency_ms": 75540}}
{"key": "10.1145/3691620.3695271", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose MalHug, an end-to-end pipeline ... combines dataset loading script extraction, model deserialization, in-depth taint analysis, and heuristic pattern matching", "explanation": "要旨からは機械学習・大規模言語モデルを用いた手法が示されておらず、従来の静的解析やヒューリスティック手法のみであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は事前学習モデルハブに対する悪意あるコード汚染攻撃の検出・分類を目的としたセキュリティ調査とツールの提案であり、デコンパイル（低水準バイナリから高水準コードの生成）やそれに LLM/ML を用いる研究ではない。抽象からは機械学習技術の使用が確認できないため、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3299, "latency_ms": 66608}}
{"key": "10.1145/3689711", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "VarLifter interprets every read or written field of a data region as at least one potential variable, and ... progressively refines the variable types based on the variable behaviors", "explanation": "要約では機械学習や大規模言語モデルの使用について言及されておらず、完全にルールベースの解析手法と記述されているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿はバイトコードから変数と型を復元する手法を提案しているが、抽象からは機械学習や大規模言語モデルを利用したことが示されていない。したがって、Decompilation Survey の包括基準である「LLM/ML を中核手法として使用」要件を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3304, "latency_ms": 67181}}
{"key": "10.1145/3678890.3678892", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we surveyed 21 professional malware analysts ... to hear their opinions about existing tools, practices, and the challenges they face", "explanation": "要旨は実務アナリストへのアンケート調査であり、研究はレビュー/サーベイ的性格なので除外基準 EC4 に該当します"}, {"code": "ex_no_ml", "evidence": "The paper does not mention any machine‑learning or LLM techniques", "explanation": "要旨中に ML/LLM の使用が示されていないため除外基準 EC1 も満たします"}], "reasoning": "本稿はマルウェア分析者へのアンケート調査であり、LLM/ML を用いたデコンパイルやコード再構成を対象としていません。したがってサーベイ/レビュー論文として除外基準 EC4、さらに機械学習手法を使用していないことから除外基準 EC1 に該当し、インクルード対象外です。", "model": "openai/gpt-oss-120b", "tokens_used": 3095, "latency_ms": 62827}}
{"key": "10.1145/3698062.3698068", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "introduces a novel Android malware detection approach that leverages Long Short-Term Memory (LSTM) networks to scrutinize native code opcodes", "explanation": "本文は LSTM を用いたマルウェア検出（分類）であり、低水準コードから高水準コードや擬似コードを生成することは目的としていないため、コード生成・復元の意図がなく除外基準 EC3 に該当する。"}], "reasoning": "本稿は Android のネイティブコードから特徴を抽出し LSTM でマルウェアかどうかを判定する分類手法を提案しており、デコンパイルやコード復元を目的としていない。したがって、復元・可読化を目的とした LLM/ML 手法ではなく、除外基準 ex_no_code_generation に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3009, "latency_ms": 62285}}
{"key": "10.1145/3650212.3680301", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We therefore present SJA, a new jump table analysis technique ...", "explanation": "アブストラクト内に機械学習や大規模言語モデルの利用についての記述がなく、従来の静的解析手法のみが述べられているため、ML/LLM を使用していないと判断しました。"}], "reasoning": "本稿はバイナリ中のジャンプテーブルを解析する静的手法を提案しており、機械学習や大規模言語モデルを用いた手法ではない。したがって、Decompilation Survey の包括基準（IC0）を満たさず、除外基準 EC1（No ML/LLM）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2961, "latency_ms": 59321}}
{"key": "10.1145/3650212.3652133", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The generator uses static analysis techniques to deduce the correct calling sequences and parameters", "explanation": "抄録では機械学習や大規模言語モデルの使用が言及されず、静的解析のみが記載されているため、EC1に該当し除外と判断した。"}], "reasoning": "本稿は Android のクローズドソースネイティブライブラリ向けの自動ハーネス生成とファジングフレームワークを提案しており、デコンパイルやコード復元を目的とした研究ではない。また、手法として機械学習・LLM が用いられている記述がなく、ルールベースの静的解析に限定されているため、除外基準 EC1（ML/LLM を使用していない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3235, "latency_ms": 67395}}
{"key": "10.1145/3678232.3678233", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We aim to develop a higher-order unification‑based proof search procedure using the meta language Elpi", "explanation": "本文はメタ言語 Elpi を用いた高階統一手法を提案しており、機械学習や大規模言語モデルの使用は言及されていないため"}, {"code": "ex_no_lowlevel_input", "evidence": "Elpi offers an encoding of Coq terms that is suitable for meta programming", "explanation": "入力は Coq の高水準項のエンコーディングであり、バイナリやアセンブリといった低水準表現ではないため"}], "reasoning": "この研究はプログラムのデコンパイルやバイナリから高水準コードへの変換を目的としておらず、機械学習・LLM を手法の中心に据えていない。さらに入力は低水準バイナリやアセンブリではなく、形式体系（Coq の項）であるため、Decompilation Survey の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3835, "latency_ms": 72486}}
{"key": "10.1145/3677999.3678276", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "partition our Haskell programs (almost) for free", "explanation": "入力はHaskellの高水準ソースコードであり、バイナリやアセンブリといった低水準表現が含まれていないため、除外基準EC2に該当します。"}, {"code": "ex_no_ml", "evidence": "Using rewrite rules and specialisation to get GHC to partition", "explanation": "手法はRewrite RulesとSpecialisationであり、機械学習や大規模言語モデルは使用されていないため、除外基準EC1に該当します。"}], "reasoning": "本稿は低水準バイナリから高水準コードへの復元を目的としたデコンパイル研究ではなく、Haskellプログラムの分割手法を提示しているだけです。入力は高水準ソースであり、ML/LLMも用いられていないため、全てのインクルード基準を満たさず除外されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3060, "latency_ms": 65966}}
{"key": "10.1145/3700058.3700123", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "provides a comprehensive review of the types of smart contract security vulnerabilities and the development of detection techniques", "explanation": "本文はML/LLMを用いた手法について言及せず、従来の静的・動的解析だけを述べているため、ML/LLMが使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "proposes a combined dynamic and static detection method for integer overflow vulnerabilities", "explanation": "目的は脆弱性の検出であり、コードの復元や高水準表現の生成ではないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "この論文はスマートコントラクトの脆弱性検出手法をレビューし、静的・動的解析を組み合わせた検出手法を提案しているが、ML/LLM を用いた手法や低水準バイナリから高水準コードを生成するようなデコンパイルの目的は示されていない。したがって、除外基準 (EC1, EC3) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3005, "latency_ms": 66913}}
{"key": "10.1145/3664476.3664486", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "large-scale analysis of TEE utilization in Android applications", "explanation": "本稿はTEE機能の実装・利用状況を調査するもので、デコンパイルやコード復元を目的としておらず、サーベイ対象外です。"}, {"code": "ex_no_ml", "evidence": "we introduce Mobsec Analytika, a framework tailored for large‑scale app examinations", "explanation": "要旨に機械学習や大規模言語モデルの利用は言及されておらず、ML/LLM が手法の中核でないため除外基準に該当します。"}], "reasoning": "本論文はAndroidアプリにおけるTEE機能の利用状況を統計的に調査するもので、低水準バイナリから高水準コードを復元するデコンパイル研究とは無関係です。また、手法として機械学習やLLMを用いていないため、サーベイの対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3119, "latency_ms": 68346}}
{"key": "10.1145/3663530.3665020", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "our pilot study reviews prevalent data challenges across various SE tasks", "explanation": "アブストラクトはデータ課題の調査・レビューを目的としたサーベイであり、デコンパイルやコード生成の研究ではないため除外基準の Survey/Review に該当します"}], "reasoning": "本稿は自動ソフトウェア工学タスクのデータ課題を調査するパイロットサーベイであり、低水準コードからの高水準復元やLLM/ML を用いたデコンパイル手法の提示・評価は行っていません。したがって Decompilation Survey の対象外であり、除外基準（ex_survey_or_meta）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2894, "latency_ms": 62899}}
{"key": "10.1145/3652588.3663324", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Loop analysis is a key component of static analysis tools.", "explanation": "要旨は静的解析手法について述べており、機械学習や大規模言語モデルの使用は示唆されていないため、ML/LLM が使われていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "Misconceptions about Loops in C", "explanation": "対象は C 言語のソースコード上のループであり、バイナリやアセンブリなどの低水準表現が入力とは明示されていないため、低水準入力がないと判断した。"}], "reasoning": "本稿は C 言語のループに関する静的解析の誤解や例を提示しており、デコンパイルや高水準コード復元を目的とした機械学習手法は登場しない。入力はソースコードレベルであり、低水準表現やML/LLM の利用が欠如しているため、除外基準に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3074, "latency_ms": 71961}}
{"key": "10.1145/3714393.3726486", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "faulty code ... from Android Java classes and Manifest files", "explanation": "アブストラクトはJavaソースやXMLマニフェストを対象としており、低水準表現（バイナリ・アセンブリ等）は含まれていないため、低水準入力の要件を満たさないと判断した"}, {"code": "ex_no_code_generation", "evidence": "automatically fixing bugs ... we evaluated LLMs as APR tools", "explanation": "研究の目的はバグ修正（APR）であり、デコンパイルにおける高水準コードの復元・生成ではなく、修復コードの生成であるためコード生成・復元の意図がないと判断した"}], "reasoning": "本稿はAndroidアプリのソースコードとXMLマニフェストを対象にしたバグ修正データセットの提示と、LLMを用いた自動プログラム修復の評価であり、低水準バイナリからの高水準コード復元を目的としたデコンパイル研究ではない。入力が低水準表現でないこと、目的がデコンパイルではなく修復であることから除外基準に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3225, "latency_ms": 72320}}
{"key": "10.1145/3631971", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach is based on automated program transformation to manipulate Java bytecode...", "explanation": "アブストラクトは機械学習や大規模言語モデルの使用について言及しておらず、手法は自動プログラム変換であるため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は Java バイトコードに対する自己デバッグ化による保護手法を提案しており、機械学習や大規模言語モデルを用いたデコンパイルやコード生成は行っていない。したがって、Include 基準の「LLM/ML が中核手法として使われている」要件を満たさず、除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3308, "latency_ms": 71066}}
{"key": "10.1145/3597503.3639153", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We implement BlockWatchdog using cross-contract static dataflow techniques", "explanation": "本文は静的データフロー解析手法のみを用いており、機械学習やLLMは使用していないため、IC0 の「ML/LLM が中核手法」の条件を満たさないと判断した。"}], "reasoning": "この論文はスマートコントラクトのリエントランシー脆弱性検出を目的とした静的解析ツールであり、機械学習や大規模言語モデルを利用していない。したがって、デコンパイル調査の採択基準である LLM/ML を中心とした手法を用いた研究ではなく、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3122, "latency_ms": 65140}}
{"key": "10.1145/3597503.3639140", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose PrettySmart, a bytecode-level Permission re-delegation vulnerability detector for Smart contracts.", "explanation": "本文はバイトコードから脆弱性を検出するツールを提案しており、機械学習やLLMの利用は言及されていないため、EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "detect whether adversaries could manipulate the privileged token management functionalities", "explanation": "目的は脆弱性の検出・判定であり、コードや高水準表現の生成・復元が主目的ではないため、EC3 に該当します。"}], "reasoning": "この論文はスマートコントラクトのバイトコードを対象に脆弱性検出を行うもので、機械学習・LLM を用いたデコンパイルやコード生成は行われていない。したがって、除外基準 EC1（ML/LLM未使用）および EC3（コード生成・復元が目的でない）に該当し、サーベイ対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3163, "latency_ms": 68131}}
{"key": "10.1145/3659211.3659272", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose an improvement scheme for OLLVM obfuscation", "explanation": "要旨に機械学習や大規模言語モデルの使用が示されておらず、従来のオブフスケーション手法のみが議論されているため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "improves the degree of obfuscation of OLLVM and increases the difficulty of reverse engineering", "explanation": "本研究はコードの難読化を目的としており、低水準入力から高水準コードを生成・復元すること（デコンパイル）の意図がなく、コード生成・復元が主目的ではないため除外基準に該当する。"}], "reasoning": "本稿は LLVM ベースのコード難読化手法の改善を提案しており、機械学習・LLM の利用が示されていない上、目的も難読化でありコードの復元や生成を行うデコンパイル研究ではない。したがって除外基準 (ex_no_ml, ex_no_code_generation) に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3147, "latency_ms": 70154}}
{"key": "10.1145/3611643.3617852", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "utilizes a Java dynamic analysis tool to record calls to core Java libraries", "explanation": "アブストラクトは低水準表現（binary/asm/bytecode）ではなく、Java ライブラリ呼び出しのトレースを入力としているため、デコンパイルの入力条件を満たさない"}, {"code": "ex_no_code_generation", "evidence": "effective method source code retrieval from a candidate set", "explanation": "目的はソースコードの検索・取得であり、コードを生成・復元することが主目的ではないため、コード生成/復元の目的要件を満たさない"}], "reasoning": "本稿は動的トレースを用いたコード検索手法であり、低水準バイナリやアセンブリを入力とした復元・生成を目的としていない。そのため、デコンパイル調査のインクルード基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3066, "latency_ms": 70784}}
{"key": "10.1145/3611643.3616343", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_type_recovery", "evidence": "leverages deep learning techniques to automatically infer function signatures", "explanation": "深層学習（ML／LLM）が中心手法として用いられ、関数シグネチャという型情報を復元することが主目的であるため、タイプリカバリに該当する。"}], "reasoning": "本稿はバイトコード（低水準入力）を IR に変換し、深層学習を用いて関数シグネチャや戻り値の型情報を自動推論する手法を提案している。目的は型情報の復元であり、コード生成や可読化そのものは対象外だが、型回復はデコンパイルの周辺要素として本サーベイの包含基準を満たす。したがって include と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3455, "latency_ms": 80528}}
{"key": "10.1145/3605762.3624432", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "their actions in researching the safety of miniapp web interfaces are limited", "explanation": "アブストラクトは Miniapp の Web インターフェースの安全性を対象としており、バイナリやアセンブリといった低水準表現は扱っていないため、デコンパイルの入力要件を満たさないと判断した。"}], "reasoning": "本稿は Miniapp のセキュリティリスクと脆弱性分析に関する研究であり、低水準コードから高水準表現を生成するデコンパイルとは無関係です。ML/LLM の使用やコード生成・復元目的も示されていないため、除外基準 (EC2) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3057, "latency_ms": 65866}}
{"key": "10.1145/3605762.3624428", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose JSLibD, an automated extraction method for third-party libraries in miniapps.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が記述されておらず、従来のヒューリスティック手法のみであるため、EC1に該当すると判断しました。"}], "reasoning": "本論文はミニアプリのサードパーティライブラリ検出をヒューリスティック手法で行うもので、機械学習・LLM を用いたデコンパイルやコード生成を目的としていないため、除外基準 EC1 (No ML/LLM) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2957, "latency_ms": 63201}}
{"key": "10.1145/3603273.3635055", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "soft attention to fuse two modalities features to finish classification", "explanation": "アブストラクトからは、LLM/ML を用いてコードを復元・生成する目的ではなく、マルウェアの分類を行うことが主目的と示されているため、コード生成・再構成の意図がなく除外します。"}], "reasoning": "本稿は Android アプリのバイトコード画像と関数呼び出しグラフを用いたマルウェア検出（分類）手法を提案しており、デコンパイルや高水準コードの復元を目的としていない。したがって、Include 基準を満たさず、Exclude 基準の「コード生成・復元が主目的でない」(ex_no_code_generation) に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3067, "latency_ms": 66574}}
{"key": "10.1145/3652628.3652786", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we present a novel Android app repackaging classification method", "explanation": "論文の目的はリパッケージされたアプリの分類であり、コードの復元・生成を行うことが主目的ではないため、コード生成・復元の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿は低レベルの smali から特徴埋め込みを抽出し、リパッケージ検出のための分類モデルを構築することに焦点を当てている。デコンパイル（高水準コードの復元）や出力の生成は行わず、ML は分類タスクに使用されているだけであるため、除外基準に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3120, "latency_ms": 69697}}
{"key": "10.1109/ASE56229.2023.00099", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_input", "evidence": "Decompilation is a widely used process ... lifting assembly code to a higher-level C-like language, pseudo-code.", "explanation": "要約だけでは、提案手法が直接バイナリ/アセンブリを入力として使用するのか、既に生成された疑似コードを入力として使用するのかが不明であるため、低水準入力の有無が判定できない。"}, {"code": "uns_unclear_output", "evidence": "downstream tasks, including code summarization, variable name recovery, function name recovery, and similarity detection.", "explanation": "出力が変数名・関数名の回復（属性のみ）か、実際の高水準コード生成かが要約だけでは判定できず、L1‑L4 のどれに該当するかが不明である。"}], "reasoning": "要約からは、手法が低水準バイナリやアセンブリを直接入力として使用し、コード生成（L1‑L3）を行うか、疑似コード上で属性回復（L4）を行うかが明確でない。ML/LLM の使用は示されているが、判定に必要な入力・出力情報が不足しているため、include か exclude かを決められず uncertain とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3552, "latency_ms": 87681}}
{"key": "10.1145/3650215.3650347", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_variable_naming", "evidence": "binary function naming is a code analysis task that generates functional descriptions of functions", "explanation": "抽象的に関数名（属性）を復元することが主目的であり、変数・関数名の回復に該当するため"}, {"code": "ex_no_code_generation", "evidence": "establish a mapping between the AST and the binary function names to realize the prediction function", "explanation": "出力がコードではなく関数名という属性であり、コード生成（L1-L3）ではないが、属性回復はPeripheralとして許容される"}], "reasoning": "本研究はバイナリを入力とし、ニューラル翻訳モデルで関数名（高水準属性）を予測する手法であり、ML が中心手法として用いられ、目的も逆解析支援のための名前復元である。低水準入力と属性出力の組み合わせはPeripheral条件を満たすため、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3360, "latency_ms": 78188}}
{"key": "10.1145/3617686", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a compilation tool ... based on the low-level virtual machine (LLVM) compiler infrastructure", "explanation": "要旨では機械学習・LLMの利用が全く言及されておらず、従来のコンパイラ基盤（LLVM）を用いたコンパイル支援ツールであり、ML/LLM が手法の中核ではないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿は LLVM IR を用いたコードオフローディング用コンパイルツールを提案しており、デコンパイルやコード復元を目的としていません。また、機械学習や大規模言語モデル（LLM）の使用が示されていないため、Decompilation Survey の採択基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3065, "latency_ms": 64651}}
{"key": "10.1145/3623759.3624544", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "We introduce Pancake, a new language for verifiable, low-level systems programming...", "explanation": "要旨に機械学習・大規模言語モデルの使用が言及されておらず、従来の言語設計と検証コンパイラに関する研究であるため、ML/LLM を用いていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "low-level systems programming, especially device drivers", "explanation": "入力としてバイナリやアセンブリ等の低水準コードは示されず、対象は新言語で記述された高水準コードであるため、低水準入力が存在しないと判断した。"}], "reasoning": "本稿はデコンパイルや逆コンパイルを目的とした研究ではなく、検証可能な低レベルシステム向け新言語の設計と検証コンパイラの提示に関するものである。機械学習や大規模言語モデルの利用も記載されていないため、除外基準（ML未使用、低水準入力なし）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3067, "latency_ms": 70663}}
{"key": "10.1145/3617184.3630160", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper presents a method for recognizing traffic from encrypted webshells...", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、従来の手法によるトラフィック解析のみであるため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "identifying the encryptions and keys used in the Webshell files... decrypting the ciphertext, keys, and passwords in malicious traffic.", "explanation": "目的は暗号化されたトラフィックの検出・復号であり、バイナリやアセンブリからソースコードや擬似コードを生成するような「復元・コード生成」ではないため、コード生成を伴うデコンパイルには該当しない。"}], "reasoning": "本稿は暗号化された WebShell のトラフィック検出と復号に焦点を当てており、機械学習や LLM を用いた手法は示されていない。また、出力は復号された文字列であり、バイナリから高水準コードを生成するデコンパイルの目的や成果物（L1-L4）には該当しない。したがって除外基準に合致する。", "model": "openai/gpt-oss-120b", "tokens_used": 3082, "latency_ms": 72143}}
{"key": "10.5555/3615924.3615947", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "code similarity detection in binaries ... embeddings ... used as inputs to an RNN Siamese neural network, enhancing the learning process for code similarity detection", "explanation": "要旨はバイナリの類似性を検出し脆弱性を発見することであり、コード生成や高水準表現の復元を目的としていないため、コード生成・復元志向の基準を満たさない"}], "reasoning": "本稿はバイナリの類似性を学習モデルで検出し脆弱性を特定することが中心で、デコンパイルによるコード復元や高水準表現の生成を目的としていない。したがって、コード生成/復元意図が欠如している点から除外基準 EC3 に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3206, "latency_ms": 74308}}
{"key": "10.1145/3597926.3598124", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose DeFiTainter, an inter-contract taint analysis framework for detecting price manipulation vulnerabilities.", "explanation": "抄録からは機械学習や大規模言語モデルの使用が全く示されておらず、従来の静的解析手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はスマートコントラクトの価格操作脆弱性検出を目的とした taint analysis フレームワークを提案しており、機械学習やLLM の活用は記載されていない。デコンパイルや高水準コード生成を目的とした研究ではなく、脆弱性検出が主目的であるため、除外基準 EC1 に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3073, "latency_ms": 68451}}
{"key": "10.1145/3597926.3598068", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present DITWO, a differential testing framework to uncover missed optimizations (MO) of wasm optimizers.", "explanation": "抽象からは機械学習や大規模言語モデルの使用が全く言及されておらず、従って本サーベイの除外基準 EC1 に該当します。"}], "reasoning": "本論文は WebAssembly の最適化不足を検出するための差分テストフレームワークを提案しており、ML/LLM を利用したデコンパイル手法とは無関係です。入力は C ソースから生成された wasm バイナリで、目的は最適化の欠落の特定であり、コード生成や復元は行わないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3113, "latency_ms": 66388}}
{"key": "10.1145/3571786.3573015", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "We aim to develop a reflection for algebraic effects and handlers.", "explanation": "概要に機械学習や大規模言語モデルの使用が記述されておらず、ML/LLM が手法として使われていないため除外基準 EC1 に該当します。"}, {"code": "ex_no_lowlevel_input", "evidence": "we use the simplest CPS translation as the compiling function", "explanation": "入力はバイナリやアセンブリといった低水準表現ではなく、CPS 変換という高水準の理論的変換であるため除外基準 EC2 にも該当します。"}], "reasoning": "本稿は効果ハンドラ向けのコンパイル/デコンパイル間のリフレクションという理論的概念を扱っており、機械学習や大規模言語モデルを用いた手法は示されていません。また、入力は低水準コードではなく CPS 変換という高水準表現であるため、デコンパイル調査の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3302, "latency_ms": 82625}}
{"key": "10.1145/3550355.3552396", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose the OSATE Declarative-Instance Mapping Tool (OSATE-DIM1), an Eclipse plugin...", "explanation": "本文では機械学習や大規模言語モデルの使用は言及されておらず、従ってML/LLMが手法の中核であるという条件を満たさないため除外します。"}, {"code": "ex_no_lowlevel_input", "evidence": "instance model ... computed from a base 'declarative' model", "explanation": "入力はバイナリやアセンブリといった低水準表現ではなく、AADL の宣言的モデルから生成されたインスタンスモデルであり、低水準入力の条件を満たさないため除外します。"}], "reasoning": "本稿は AADL モデルのビュー更新問題を解決するツールの提案であり、低水準コードやバイナリから高水準コードを生成するデコンパイルや ML/LLM を用いた手法とは無関係です。そのため、除外基準 EC1 と EC2 に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3175, "latency_ms": 71592}}
{"key": "10.1145/3551349.3561339", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "The approach is based on clone detection and implemented in our prototype APK-Simplifier.", "explanation": "抄本検出はルールベース手法であり、LLM や機械学習の使用が示されていないため除外基準 EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "to differentiate an app’s code from a library’s code.", "explanation": "研究目的はコードの分離であり、コード生成や高水準表現の復元を行うことが主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は Android アプリのコードとライブラリコードを区別する手法を提案しており、LLM/ML を用いたデコンパイルやコード生成は行っていません。したがって、除外基準（ML 未使用、コード生成目的なし）に該当し、インクルード対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 72705}}
{"key": "10.1145/3551349.3559505", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "knowledge of event-activity transitions from the previous testing runs, i.e., executing which events can reach which activities", "explanation": "アブストラクトは低水準バイナリやアセンブリではなく、GUI イベントとアクティビティ遷移を入力としているため、デコンパイルの低レベル入力要件を満たさないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "We propose a probabilistic model to memorize and leverage this knowledge during testing, and design a model-based guided testing strategy", "explanation": "研究の目的はテスト実行のガイドであり、コードの復元・生成は行わないため、コード生成・再構築を目的としたデコンパイルとは無関係である。"}], "reasoning": "本稿は Android アプリの GUI テストを強化するためのモデルベース手法と強化学習アルゴリズムを提案しており、入力は低レベルのバイナリやアセンブリではなく GUI イベント情報です。また、コードの復元や擬似コード生成といったデコンパイルの目的も示されていません。そのため、除外基準 EC2（低レベル入力なし）および EC3（コード生成目的なし）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3276, "latency_ms": 76309}}
{"key": "10.1145/3544902.3546240", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect supply chain vulnerabilities ... based on pseudo-code and Graph Matching Network", "explanation": "要旨は擬似コードを特徴抽出してグラフマッチングで脆弱性を検出することにあり、コードの復元・生成は目的に含まれないため除外基準 EC3 に該当します。"}], "reasoning": "本論文は擬似コードを入力特徴として用い、機械学習による脆弱性検出を目的としているため、デコンパイルによるコード復元や高水準表現生成を目的としていません。したがって、復元・生成意図がないことから除外基準 EC3 に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3161, "latency_ms": 68973}}
{"key": "10.1145/3556223.3556257", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "goal of malware family classification based on the static features of Android applications", "explanation": "要旨はマルウェアのファミリ分類を行うことであり、コードの復元や高水準表現の生成を目的としていないため、コード生成／復元の意図がなく除外基準EC3に該当します。"}], "reasoning": "本論文は静的特徴（opcode 画像）を用いたマルウェア検出・分類を目的としており、デコンパイルやソースコード復元を目指す研究ではない。したがって、ML を使用しているものの目的がコード生成や高水準表現の再構築ではないため、除外基準 ex_no_code_generation に基づき除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2990, "latency_ms": 66190}}
{"key": "10.1145/3533767.3534222", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "static analysis at the bytecode level", "explanation": "本文はバイトコードを用いた静的解析であり、機械学習や大規模言語モデルの使用は記載されていないため、ML/LLM を用いていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "detecting cross-contract vulnerability", "explanation": "目的は脆弱性検出であり、コードの復元・生成や高水準表現の生成を行わないため、復元・生成意図が存在しないと判断した。"}], "reasoning": "本研究はバイトコードレベルの静的解析によりスマートコントラクトの脆弱性を検出するもので、機械学習やLLM を使用していない点、またコード生成や高水準表現の復元を目的としていない点から、デコンパイル調査の対象外（除外）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3185, "latency_ms": 72360}}
{"key": "10.1145/3502718.3524744", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "challenge students to develop tools that automatically detect and exploit program vulnerabilities", "explanation": "アブストラクトには機械学習や大規模言語モデルの使用が言及されておらず、ML/LLM を用いた手法がないと判断したため。"}], "reasoning": "本稿は学部向けバイナリリバースエンジニアリングコースとそのコンテストの設計・経験報告であり、機械学習やLLM を用いたデコンパイル手法については記載がない。したがって、Decompilation Survey の採択基準を満たさないと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 2942, "latency_ms": 69594}}
{"key": "10.1145/3524452", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "adopts LLVM, extends CRIU, and integrates with Docker", "explanation": "本文は LLVM や CRIU などの従来ツールを用いたコンテナ移行システムであり、機械学習・LLM の利用が言及されていないため、ML/LLM 不使用の除外基準に該当します。"}], "reasoning": "本論文は異種 ISA 間でコンテナ化されたバイナリを移行するシステムを提案しており、目的は実行環境の移行でありデコンパイルやコード復元ではありません。また、機械学習や大規模言語モデルを手法として用いている記述がなく、除外基準 EC1（ML/LLM 不使用）に該当するため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3190, "latency_ms": 69912}}
{"key": "10.1145/3498361.3538938", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "combining control theory with program analysis using symbolic execution and data flow analysis", "explanation": "抽象ではシンボリック実行やデータフロー解析といった従来的手法のみが示されており、ML/LLM の使用が明記されていないため除外基準 EC1 に該当します。"}], "reasoning": "本稿はバイナリから制御関数や変数を回復する手法を提案していますが、主要手法として機械学習・大規模言語モデルを用いていないため、デコンパイル調査の対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3197, "latency_ms": 69233}}
{"key": "10.1145/3548636.3548651", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Neural network is used to classify the fused features.", "explanation": "本文はマルウェア検出のための分類を目的としており、低水準コードの復元や高水準コード生成を行わないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿は Android アプリの N‑gram 特徴を用いたマルウェア検出モデルを提案しており、目的は分類である。デコンパイルや高水準コードの再構成を目的とした出力はなく、低水準バイナリからのコード生成も行っていないため、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3031, "latency_ms": 70541}}
{"key": "10.1145/3520312.3534867", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "pairs real-world C code taken from GitHub with IO examples", "explanation": "アブストラクトは入力として GitHub から取得した C ソースコードを扱っており、バイナリやアセンブリといった低水準表現が存在しないため、デコンパイルの対象外です。"}], "reasoning": "本論文は実行可能な C 関数データセットの構築と評価に関するもので、入力は高水準の C ソースコードです。デコンパイル（低水準から高水準への変換）を目的とした研究ではなく、ML 用データセット提供が主目的であるため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3045, "latency_ms": 68978}}
{"key": "10.1145/3519939.3523702", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present the first approach to provably overapproximative x86-64 binary lifting.", "explanation": "要旨では機械学習や大規模言語モデルの使用が全く言及されておらず、形式手法によるリフティングであるため、ML/LLM が中核手法でないことが明らかです。"}], "reasoning": "本論文はバイナリリフティングと形式検証に焦点を当てており、機械学習やLLM を用いた手法が示されていない。そのため、Decompilation Survey の包括基準（IC0）を満たさず、除外基準 EC1（No ML/LLM）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3092, "latency_ms": 71331}}
{"key": "10.1145/3519939.3523449", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_type_recovery", "evidence": "recovering precise, high-level parameter and return types for WebAssembly functions", "explanation": "抽象内で型・シグネチャの復元を目的としており、低水準のWebAssemblyバイナリから高水準の型情報を予測するため、タイプリカバリ（IC3）に該当する。"}], "reasoning": "本稿はWebAssemblyバイナリという低水準入力から、ニューラルシーケンス‑ツー‑シーケンスモデルを用いて関数のパラメータ・戻り値型という高水準属性を復元することを目的としている。ML/LLM が手法の中心であり、復元の目的が分類や検出ではなく型回復であるため、include の判定となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3233, "latency_ms": 75369}}
{"key": "10.1145/3488932.3497764", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Decompilers are tools designed to recover a high-level language representation (typically in C code) from program binaries.", "explanation": "要旨ではデコンパイラの従来手法のみを述べており、機械学習やLLMの利用について言及がなく、EC1 に該当するため除外と判断した。"}], "reasoning": "本稿は既存デコンパイラの性能評価と脆弱性検出への応用を検証しており、ML/LLM を手法の中核として使用していない。したがって、除外基準 EC1 (No ML/LLM) に該当し、サーベイ対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3190, "latency_ms": 73373}}
{"key": "10.1145/3510454.3516854", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "static analysis of Android apps to detect both API invocation compatibility issues and API callback compatibility issues", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、従来の静的解析手法のみを用いているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "detect both API invocation compatibility issues and API callback compatibility issues", "explanation": "研究目的は互換性問題の検出であり、ソースコードや擬似コードの生成・復元は行っていないため、コード生成・復元が目的ではない。"}], "reasoning": "本稿は Android アプリの API 互換性問題を検出するための静的解析手法を提案しており、機械学習／LLM の利用や低レベルバイナリから高レベルコードへの復元を目的としていない。したがって、デコンパイルを中心とした本サーベイの範囲から外れ、除外基準 (ex_no_ml, ex_no_code_generation) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3121, "latency_ms": 76195}}
{"key": "10.1145/3507657.3528555", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we design a novel automated tool, PITracker, to detect the PendingIntent vulnerabilities", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、従来の静的解析手法のみであると判断できるため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "detect the PendingIntent vulnerabilities", "explanation": "研究の目的は脆弱性検出であり、コードや高水準表現の生成・復元を行う目的ではないため、コード生成・再構築を目的としたデコンパイル研究ではない。"}], "reasoning": "本論文は Android アプリの PendingIntent 脆弱性を検出する静的解析ツールを提案しており、機械学習や LLM を用いた手法は記述されていない。さらに目的は脆弱性検出であり、低水準コードから高水準コードを生成するデコンパイルやコード復元とは無関係であるため、除外基準 EC1 と EC3 に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3168, "latency_ms": 77437}}
{"key": "10.1145/3520084.3520103", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper proposed the de-obfuscation method against for DNR (dynamic name resolution) obfuscation method.", "explanation": "要旨からは機械学習や大規模言語モデルの利用が示されておらず、従来の静的/動的解析手法のみが言及されているため、EC1（ML/LLM未使用）に該当します。"}], "reasoning": "本文は DNR という動的名前解決の難読化手法に対する逆難読化手法を提案しており、機械学習や LLM を用いたアプローチは示されていません。したがって、Decompilation Survey の採択基準（IC0）を満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2874, "latency_ms": 67133}}
{"key": "10.1145/3486860", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This article provides the first systematic review of existing binary code fingerprinting approaches", "explanation": "本文は既存手法の体系的レビューを目的としているため、デコンパイルの新規手法や実装を提示しておらず、調査論文に該当します。"}, {"code": "ex_no_code_generation", "evidence": "extracting fingerprints ... reveals the functionality, authorship, libraries used, and vulnerabilities", "explanation": "要旨は指紋抽出や特徴解析を扱っており、低水準コードから高水準コードを生成すること（コード生成・復元）を目的としていません。"}], "reasoning": "本稿はバイナリコード指紋付与手法のサーベイであり、デコンパイルやコード再構成を目的とした研究ではない。LLM/ML を用いた新規手法の提示もなく、コード生成・復元の意図が無いことから除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3141, "latency_ms": 75372}}
{"key": "10.5555/3507788.3507824", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "We propose a method of control flow obfuscation using the InvokeDynamic instruction with native call site bootstrapping.", "explanation": "本文は制御フローの難読化手法の提案であり、デコンパイルやコード復元を目的としていないため、調査対象外です。"}, {"code": "ex_no_ml", "evidence": "Modern obfuscation techniques aim to prevent reverse engineering and unauthorized use ...", "explanation": "要旨に機械学習や大規模言語モデルの使用は言及されておらず、ML/LLM が手法の中核ではないため除外します。"}], "reasoning": "この論文は JVM バイトコードの制御フロー難読化手法を提案しており、デコンパイルや高水準コード生成を目的としていません。また、機械学習や大規模言語モデルの利用も示されていないため、デコンパイル調査の範囲外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3073, "latency_ms": 74386}}
{"key": "10.1145/3490725.3490733", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect malicious applications ... locate malicious code ... graph convolution algorithm ... to find malicious nodes", "explanation": "本稿はマルウェア検出と悪意コードの位置特定を目的としており、コードの復元・擬似コード生成などの出力は行わないため、コード生成・復元を目的としたデコンパイルの条件を満たさないと判断した。"}], "reasoning": "本論文はAndroidアプリの関数呼び出しグラフ上でマルウェア検出と悪意コードの位置特定を行う手法を提案しており、低水準バイナリから高水準コードを生成するデコンパイルの目的（復元・可読化）がなく、コード生成や再構成を行わないため除外基準 EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3397, "latency_ms": 85014}}
{"key": "10.1145/3428151", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "proposed MulDroid, an efficient ... malware threat detection framework", "explanation": "アブストラクトはマルウェアの検出・分類が目的であり、コードの生成や復元は示されていないため、コード生成・復元を目的としない点で除外基準 EC3 に該当します。"}], "reasoning": "本稿は Android マルウェア検出を目的としたディープラーニングベースのフレームワークを提案しており、低水準バイナリから高水準コードを復元するデコンパイルの目的や出力は示されていません。したがって、デコンパイル研究の対象外であり、除外（ex_no_code_generation）と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3144, "latency_ms": 72699}}
{"key": "10.1145/3479394.3479399", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "The results of this work could potentially be used for compiler optimisations", "explanation": "本稿はコンパイラ最適化や代数的効果の形式的理論を扱っており、デコンパイルやバイナリから高水準コードへの復元とは無関係です。"}, {"code": "ex_no_ml", "evidence": "We present a novel reduction theory for Moggi’s computational λ-calculus...", "explanation": "手法は形式的意味論・CPS 翻訳であり、機械学習や大規模言語モデルは使用されていません。"}, {"code": "ex_no_lowlevel_input", "evidence": "The delimited-control operator shift0 has been formally shown to capture the operational semantics of deep handlers for algebraic effects.", "explanation": "入力は低水準表現（バイナリ・アセンブリ等）ではなく、λ項や計算ラムダ項といった高水準記号表現です。"}], "reasoning": "本稿はプログラミング言語理論に関する研究であり、デコンパイルの目的や低水準コードからの復元を扱っていないため除外します。また、機械学習・LLM の使用も記載されていません。", "model": "openai/gpt-oss-120b", "tokens_used": 3195, "latency_ms": 76317}}
{"key": "10.1145/3468264.3468607", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.9, "reason_codes": [{"code": "in_type_recovery", "evidence": "recovering types for both function arguments and variables", "explanation": "バイナリから型情報を復元することが主目的であり、ML を用いて低水準入力から高水準属性（型）を生成しているため、IC3 のタイプ回復に該当します。"}], "reasoning": "本論文はバイナリを入力とし、ニューラルネットワークを用いて変数や関数引数の型を推定する手法を提案しています。入力が低水準表現であり、ML が中心手法で、目的が型回復という高水準属性の復元であるため、Decompilation Survey の包含基準を満たします。", "model": "openai/gpt-oss-120b", "tokens_used": 3457, "latency_ms": 83129}}
{"key": "10.1145/3465481.3470077", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "framework aimed to inject a malicious payload in two or more different Android applications", "explanation": "本論文は Android アプリへのマルウェアペイロード注入を目的としており、低水準バイナリから高水準コードを復元する decompilation とは無関係です。"}, {"code": "ex_no_ml", "evidence": "We perform an experimental analysis by submitting the generated colluding application to different 79 anti‑malware", "explanation": "アブストラクトからは機械学習・LLM の使用が全く示されておらず、従って ML 手法が用いられていないと判断します。"}, {"code": "ex_no_lowlevel_input", "evidence": "inject a malicious payload in two or more different Android applications", "explanation": "入力は高レベルの Android アプリであり、バイナリ・アセンブリ・バイトコードといった低水準表現が提示されていないため除外基準に該当します。"}], "reasoning": "本稿は Android アプリへのコラボレーティブマルウェア注入フレームワークを提案するもので、デコンパイル（低水準コードから高水準コードへの復元）や ML/LLM 手法の利用が全く記述されていません。そのため、スクリーニング基準の除外項目（範囲外、ML未使用、低水準入力なし）に該当し、除外と判定します。", "model": "openai/gpt-oss-120b", "tokens_used": 3271, "latency_ms": 76937}}
{"key": "10.1145/3465481.3470040", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The model was trained end-to-end ... to perform the classification.", "explanation": "要旨は再パッケージ型マルウェアの検出（分類）を目的としており、コードの復元や高水準表現の生成は行わないため、コード生成/復元意図がないと判断した。"}], "reasoning": "本論文はマルウェア検出のためのマルチビュー学習による分類手法を提案しており、デコンパイルや高水準コードの生成を目的としていない。したがって、デコンパイル調査の除外基準 EC3（コード生成・復元が主目的でない）に該当し、exclude と判断する。", "model": "openai/gpt-oss-120b", "tokens_used": 3040, "latency_ms": 70151}}
{"key": "10.1145/3461666", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The process requires an efficient extraction of authorship attributes ... the proposed approach ... facilitates large‑scale, format‑independent ... software authorship identification.", "explanation": "要旨からはコードの生成・復元ではなく、バイナリやソースから著者を判別することが目的であるため、復元・可読化を伴うコード生成がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文はバイナリやソースコードから著者を特定する著者帰属（authorship attribution）を目的としており、デコンパイルによる高水準コードの生成や復元を目指すものではありません。したがって、コード生成・再構築を目的としないという除外基準 EC3 に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3322, "latency_ms": 72935}}
{"key": "10.1145/3453483.3454091", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we use propositional logic for specifying dependencies", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用について言及がなく、論理式による手法のみが記述されているため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿は Java バイトコードのサイズ削減手法を提案しており、ML/LLM を利用したデコンパイルやコード復元を目的としていない。抽象的に機械学習の活用が示されていないため、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3090, "latency_ms": 73545}}
{"key": "10.1145/3338906.3338956", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a general strategy for reducing such graphs. We combine this with a novel algorithm for reduction called Binary Reduction", "explanation": "要旨からは機械学習や大規模言語モデルの利用が全く記載されておらず、純粋にアルゴリズム的手法のみが述べられているため、ML/LLM を用いていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "This enabled us to create and submit short bug reports for three Java bytecode decompilers", "explanation": "研究の目的はバイトコードの削減・デバッグ入力の短縮であり、低水準入力から高水準ソースコードや擬似コードを生成すること（復元・可読化）を目指すものではないため、コード生成・復元が目的とは言えない。"}], "reasoning": "本稿は Java バイトコードの依存グラフを削減するアルゴリズムを提案しており、ML/LLM を用いた手法は示されていない。また目的はデバッグ入力の縮小であり、デコンパイルによる高水準コード生成や復元とは無関係なので、除外基準 EC1 と EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3176, "latency_ms": 80511}}
{"key": "10.1145/3453483.3454033", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach combines a configurable proof term transformation with a decompiler from proof terms to suggested tactic scripts.", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用が言及されておらず、従ってML/LLMが手法の中核でないため除外基準EC1に該当すると判断した。"}], "reasoning": "本稿はCoqの証明項からタクティックスクリプトへの変換手法を提案しているが、機械学習やLLMの利用が明示されていない。デコンパイルの対象は証明項であるものの、ML/LLMが中心でないため本サーベイの採択基準を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3175, "latency_ms": 80562}}
{"key": "10.1145/3411764.3445535", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose IGScript, a novel script-based interaction grammar tool, ... and then develop a code generator (decompiler)", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用が言及されておらず、従来のコンパイラ/デコンパイラ手法のみが記述されているため、ML/LLM が使用されていないと判断しました。"}, {"code": "ex_no_lowlevel_input", "evidence": "translate the interactive data exploration animations back into script codes", "explanation": "入力は「インタラクティブなデータ探索アニメーション」であり、バイナリやアセンブリといった低水準表現ではないため、低水準入力が存在しないと判断しました。"}], "reasoning": "本稿は科学データプレゼンテーション用のスクリプト言語とそのコンパイラ/デコンパイラを提案しているが、機械学習やLLM を手法の中心に据えていない上、入力は低水準バイナリ等ではなく高レベルのアニメーション表現である。そのため、デコンパイル調査の対象となる条件を満たさないと判断し除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3239, "latency_ms": 80690}}
{"key": "10.1145/3411764.3445249", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Modern visualization tools aim to allow data analysts to easily create exploratory visualizations.", "explanation": "要旨はデータ可視化とデータ変換に関するもので、バイナリやアセンブリといった低水準入力やコード復元を扱っておらず、デコンパイルの範囲外です。"}], "reasoning": "本稿はデータ可視化のための合成支援ツールを提案しており、低水準コードから高水準コードへの変換や LLM/ML を用いたデコンパイル技術とは無関係です。そのため、スクリーニング基準の除外条件（範囲外）に該当し除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3078, "latency_ms": 76474}}
{"key": "10.1145/3422337.3450321", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose OBFUS, a web-based tool that can easily apply obfuscation techniques", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が記載されておらず、従来のルールベース/ツール的手法のみと判断できるため"}, {"code": "ex_no_code_generation", "evidence": "the low-level obfuscator decompiles binary programs into LLVM IR. This LLVM IR program is obfuscated and the LLVM IR program is recompiled to become an obfuscated binary program", "explanation": "本研究の目的はコードの難読化であり、復元・可読化・高水準コード生成が主目的ではなく、コード生成・再構築の意図が無いと判断できるため"}], "reasoning": "本稿はソフトウェア難読化ツールの提案であり、低水準バイナリを LLVM IR に変換して再度コンパイルする工程は復元目的ではなく難読化目的です。また、機械学習や大規模言語モデルの使用は示されていません。従って、Decompilation Survey の包括基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3093, "latency_ms": 80096}}
{"key": "10.1145/3442381.3450138", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This paper presents a comprehensive empirical study of 8,461 unique WebAssembly binaries...", "explanation": "論文は実証的調査を行っており、手法の提案や実装はなく、サーベイ/実証研究に該当するため除外します。"}, {"code": "ex_no_ml", "evidence": "We study the security properties, source languages, and use cases of the binaries...", "explanation": "要旨に機械学習や大規模言語モデルの利用記述がなく、ML/LLM を用いた手法が提示されていないため除外基準 EC1 に該当します。"}], "reasoning": "本稿は WebAssembly バイナリの実証的調査であり、デコンパイル手法や ML/LLM の適用についての研究ではない。したがって、Survey/Review の除外基準と、ML 未使用の除外基準の両方に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3273, "latency_ms": 79455}}
{"key": "10.1145/3441296", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We are pleased to present the proceedings of the 2021 ACM SIGPLAN Workshop...", "explanation": "要旨ではML/LLMの使用について言及がなく、単なる論文集の紹介であるためMLが利用されていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "Relevant topics range from ... decompilation, program generation, and abstract interpretation.", "explanation": "対象はワークショップ全体のトピック紹介であり、低水準入力（バイナリ/アセンブリ等）に関する具体的な研究は示されていない。"}, {"code": "ex_no_code_generation", "evidence": "Relevant topics range from ... decompilation, program generation, and abstract interpretation.", "explanation": "復元・コード生成を目的とした研究成果ではなく、ワークショップの概要提示であるためコード生成・再構築の意図が示されていない。"}], "reasoning": "本稿はPEPM 2021 の会議録紹介であり、個別の研究成果やML/LLM を用いたデコンパイル手法の記述が全くない。そのため、低水準入力から高水準コードを生成することを目的としたMLベースの研究ではなく、除外基準 (EC1~EC3) に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3313, "latency_ms": 85323}}
{"key": "10.1145/3324884.3418905", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "enhance the results of taint analysis with call graph concatenation", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、従来のタイント分析手法だけを用いているため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "dynamically detect clipboard access behaviour ... static data flow analysis", "explanation": "入力はアプリの実行時振る舞いやデータフローであり、バイナリやアセンブリといった低水準表現ではないため、低水準入力が存在しないと判断した。"}], "reasoning": "本稿は Android アプリのクリップボードアクセスを動的検知と静的データフロー解析で評価するもので、機械学習や大規模言語モデルは使用していない。また、扱う対象は実行時振る舞いやコードレベルの解析であり、バイナリやアセンブリといった低水準入力も含まれないため、デコンパイル調査の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3080, "latency_ms": 77507}}
{"key": "10.1145/3428277", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "harnessing SMT solvers", "explanation": "アブストラクトでは SMT ソルバーを用いた静的解析しか言及されておらず、機械学習や大規模言語モデルの使用は示されていないため、EC1 に該当し除外します。"}], "reasoning": "本論文はスマートコントラクトのモジュラリティ検証のためにバイトコードを中間表現へ変換し SMT ソルバーで解析する手法を提示しているが、ML/LLM を利用した手法は示されていない。したがって、Decompilation Survey の対象である ML/LLM を中核としたデコンパイル研究ではなく、除外基準 EC1（ML/LLM 未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3261, "latency_ms": 80166}}
{"key": "10.1145/3372297.3417251", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present an efficient technique to detect virtual inheritance in C++ binaries", "explanation": "要旨からは機械学習やLLMの使用が言及されておらず、従来の解析手法のみであるため、ML/LLMを用いない研究と判断した。"}], "reasoning": "本論文はバイナリから仮想継承情報を検出・回復する手法を提示していますが、機械学習や大規模言語モデルを利用している記述がなく、ルールの Exclude Criteria EC1 に該当します。そのため除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3216, "latency_ms": 79334}}
{"key": "10.1145/3321705.3329833", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We implemented a prototype of DeClassifier using Binary Analysis Platform (BAP) and evaluated DeClassifier against 16 binaries...", "explanation": "本文では BAP を用いた静的バイナリ解析のみが述べられ、機械学習／LLM の利用は言及されていないため、EC1 に該当し除外します。"}], "reasoning": "本研究は C++ バイナリからクラス継承関係を推測する手法を提案していますが、手法は BAP を用いた従来のバイナリ解析であり、ML/LLM を中心手法として用いていません。したがって、Decompilation Survey の対象となる「ML／LLM を用いたデコンパイル」には該当せず除外されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3111, "latency_ms": 78262}}
{"key": "10.1145/3416262", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "MadMax combines a smart contract decompiler and semantic queries in Datalog.", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、従来の静的解析手法のみであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はガス枯渇脆弱性検出のための静的解析手法を提案しており、デコンパイラは補助的に用いられるだけで、機械学習やLLM を中核手法として使用していない。したがって、Decompilation Survey の採択基準 (IC) を満たさず、除外基準の EC1（No ML/LLM）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3210, "latency_ms": 81335}}
{"key": "10.1145/3276486", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach combines a control-flow-analysis-based decompiler and declarative program-structure queries.", "explanation": "要旨では ML／LLM の利用が言及されておらず、従来の静的解析とデコンパイラのみが用いられているため、EC1 に該当し除外と判断した。"}], "reasoning": "本稿はガス不足脆弱性の検出を目的とした静的解析手法を提案しており、LLM または機械学習を主要手法として用いていない。デコンパイラは分析の補助として使用されているが、ML/LLM が中心でないため、インクルード基準を満たさず除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3247, "latency_ms": 80097}}
{"key": "10.1145/3395363.3404365", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose EShield, an automated security enhancement tool ... replaces original instructions ... with anti-patterns", "explanation": "アブストラクトに機械学習・LLMの使用が記載されておらず、手法は規則ベースのバイトコード改変であるため、EC1に該当し除外します。"}], "reasoning": "本研究はスマートコントラクトのバイトコードを改変し逆コンパイルを困難にする保護手法を提案しており、ML/LLM を用いたデコンパイルや復元は目的としていません。したがって、ルールの除外基準 EC1（ML/LLM を使用していない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2976, "latency_ms": 76871}}
{"key": "10.1145/3405962.3405980", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we developed a classification dataset... applied various machine learning algorithms and we propose a combination of algorithms which provides high accuracy", "explanation": "抽象からはコード生成や復元が目的ではなく、マルウェア検出のための分類・評価であるため、デコンパイルの目的を満たさないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "attackers... decompiling or infecting anti-malware... we developed a classification dataset", "explanation": "研究対象は偽アンチマルウェアの検出であり、デコンパイルそのものやその改善を目的としていないため、サーベイのスコープ外と判断した。"}], "reasoning": "本稿は偽の Android アンチマルウェア製品を検出するためのデータセット作成と機械学習分類手法の提案に焦点を当てており、低水準バイナリから高水準コードを復元するデコンパイルの研究目的や手法が含まれていない。したがって、除外基準（コード生成・復元目的がない、スコープ外）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3120, "latency_ms": 83125}}
{"key": "10.1145/3385412.3386012", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Equality Saturation with semantics-preserving CAD rewrites", "explanation": "抽象では機械学習や大規模言語モデルの利用が全く言及されておらず、手法はシンボリックな等価飽和に基づくため、ML/LLM が中心手法でないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "decompiling low-level triangle meshes to Constructive Solid Geometry (CSG) expressions", "explanation": "入力が三角形メッシュという幾何データであり、コード・バイナリ等の低水準表現ではないため、定義されたデコンパイルの範囲外とみなした。"}], "reasoning": "本稿は機械学習や大規模言語モデルを用いず、等価飽和というシンボリック手法でメッシュから CSG へ変換する手法を提案している。さらに入力はプログラムバイナリ等の低水準コードではなく三角形メッシュであり、デコンパイルの定義対象外であるため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3344, "latency_ms": 90609}}
{"key": "10.1145/3371307.3371312", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach is based on a series of periodic checks on the execution environment", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、単純なルールベースのチェックに依存しているため、ML/LLM が使用されていないと判断しました。"}, {"code": "ex_no_code_generation", "evidence": "to identify attempts of malicious reverse engineering on Android apps", "explanation": "研究目的は逆向きエンジニアリングの試みを検出することであり、コードの復元や高水準表現の生成（decompilation）を目的としていないため、コード生成・復元の意図がありません。"}], "reasoning": "本文は Android アプリの実行環境を定期的にチェックし、悪意あるリバースエンジニアリングの試みを検出する手法を提案しています。機械学習や LLM を用いた手法は示されておらず、目的もコードの復元や可読化ではなく検出であるため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3061, "latency_ms": 80391}}
{"key": "10.1145/3338503.3357725", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "In this tutorial, the Ghidra software reverse engineering framework will be presented, its characteristics highlighted...", "explanation": "要旨はチュートリアルであり、機械学習や大規模言語モデルの利用について全く言及していないため、ML/LLM を用いたデコンパイル研究ではないと判断した。"}], "reasoning": "この論文は Ghidra の使い方を紹介するチュートリアルであり、機械学習や大規模言語モデルを手法の中心に据えていない。したがって、本サーベイのインクルード基準（IC）を満たさず、除外基準 EC1（ML/LLM 未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3040, "latency_ms": 80507}}
{"key": "10.1145/3341161.3350841", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "method ... uses the decompiled files ... to classify a suspicious application", "explanation": "論文の目的はマルウェアの分類であり、コードの生成・復元を行う意図が示されていないため"}, {"code": "ex_no_lowlevel_input", "evidence": "uses the decompiled files of an application", "explanation": "入力として利用されているのはすでにデコンパイルされたファイルであり、低水準表現（バイナリ/アセンブリ等）ではないため"}], "reasoning": "本稿はデコンパイル済みファイルを用いたテキストマイニングによるマルウェア分類手法を提案しており、目的は分類でコード復元や可読化を行うことではない。また入力は高水準のデコンパイル結果であり、低水準バイナリは扱っていない。したがってデコンパイル研究の対象外と判断し、除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3330, "latency_ms": 86930}}
{"key": "10.1145/3340422.3343639", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "features extracted from intermediate code representations obtained using decompilation of APK file are used for providing requisite input data to develop the models for predicting android malware applications.", "explanation": "本研究はデコンパイルした中間表現から特徴を抽出し、マルウェア検出の分類器を学習させることが目的であり、ソースコードや疑似コードの生成・復元を行う目的がないため、コード生成・再構築意図がなく除外基準 EC3 に該当する。"}], "reasoning": "論文はデコンパイルを特徴抽出の前処理として利用し、最終目的はマルウェア予測という分類タスクである。デコンパイルによる高水準コードの復元や生成が主目的ではなく、ML は分類器構築に用いられているため、除外基準『No Code Generation / Reconstruction Intent』に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3262, "latency_ms": 86560}}
{"key": "10.1145/3306204", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Our approach learns a probabilistic model from \"Big Code\" and uses this model to predict properties of new, unseen programs.", "explanation": "アブストラクトはソースコード（JavaScript）を対象としており、バイナリやアセンブリなどの低水準表現が入力であることが示されていないため、低水準入力の条件を満たさないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "we built a scalable prediction engine called JSNICE for solving two kinds of tasks ... predicting (syntactic) names of identifiers and predicting (semantic) type annotations of variables.", "explanation": "目的は識別子名や型注釈の予測であり、コードやソースの復元・生成ではなく、属性推測であるため、コード生成・復元を主目的とする基準を満たさない。"}], "reasoning": "本研究はソースコード上の属性（名前・型）を機械学習で予測するもので、入力が低水準表現（バイナリ等）ではなく、復元・コード生成を目的としていないため、Decompilation Surveyの採択基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3150, "latency_ms": 82076}}
{"key": "10.1145/3293880.3294102", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "generating formally proven equivalence theorems between decompiled x86-64 machine code and big step semantics", "explanation": "低水準のバイナリを入力とし、機械学習で得た意味情報を用いて高水準のビッグステップセマンティクス（高レベルIR）を直接生成しているため、Core Decompilation に該当します。"}, {"code": "ex_no_ml", "evidence": "leveraging machine‑learned semantics to build a formal machine model", "explanation": "抽象中に「machine‑learned semantics」と記載されており、ML/LLM が手法の中核であることが示されています。"}], "reasoning": "本論文は x86‑64 バイナリという低水準入力から、機械学習を用いて高水準の意味表現（big step semantics）を生成する手法を提示しているため、Decompilation Survey の Core Decompilation 研究に該当します。ML の利用が明示されている点と、生成物が高レベルのプログラム意味表現である点から include と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3390, "latency_ms": 94364}}
{"key": "10.1145/3212480.3212487", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a way to decompile 64-bit ARM binaries to their LLVM intermediate representation (IR).", "explanation": "抄録からは機械学習・LLM が用いられている旨の記述がなく、従来の静的解析手法のみが述べられているため、ML/LLM 非使用と判断しました。"}], "reasoning": "本稿は iOS バイナリを LLVM IR にデコンパイルし、静的解析で暗号使用の誤りを検出する手法を提案していますが、機械学習や大規模言語モデルを手法の中心に据えている記述がなく、除外基準 EC1（ML/LLM 不使用）に該当します。そのため include せず exclude と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3106, "latency_ms": 80093}}
{"key": "10.1145/3191737", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we employ a range of techniques, such as protocol analysis, software decompiling, and both static and dynamic embedded code analysis", "explanation": "抄録ではデコンパイルは行われていますが、機械学習・LLM が手法の中心として言及されておらず、EC1 に該当するため除外します。"}], "reasoning": "本稿は Fitbit の脆弱性分析を目的とし、デコンパイルは従来の静的・動的解析手法で実施されています。ML/LLM の使用が示されていないため、Decompilation Survey の採択基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3060, "latency_ms": 77882}}
{"key": "10.1145/3176258.3176319", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We have developed the first decompiler for ladder logic programs.", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用が全く言及されていないため、ML/LLM が手法の中心であるという条件を満たさないと判断した。"}], "reasoning": "本稿は ladder logic 用のデコンパイラを提示しているが、手法として機械学習や大規模言語モデルを使用している記述がない。したがって、本サーベイの採択基準 (IC0) の「LLM/ML が中核手法」であることを満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3194, "latency_ms": 85087}}
{"key": "10.1145/3098954.3103152", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "by using the open source decompiler Dagger", "explanation": "要旨は既存のデコンパイラ Dagger を使用してバイナリを LLVM IR に変換しており、ML/LLM を手法の中心に据えていないため除外基準 EC1 に該当します。"}], "reasoning": "本稿はバイナリを LLVM IR に変換し静的解析を行う手法を提案していますが、MLや大規模言語モデルの使用は言及されていません。したがって、デコンパイルに ML/LLM が必須とされる本サーベイの包含基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3021, "latency_ms": 80686}}
{"key": "Kim2023", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Malware detection on binary executables ... on a CNN based malware detector", "explanation": "要旨はバイナリを入力としてマルウェア検出（分類）を行うことを目的としており、コードの復元や高水準表現の生成は含まれないため、コード生成/再構成意図がないと判断した。"}], "reasoning": "本稿はバイナリレイアウトを用いた特徴量設計とCNNによるマルウェア検出手法を提案しており、目的は分類である。デコンパイルやコード復元を行うことは示されていないため、除外基準 EC3（コード生成・再構成意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2992, "latency_ms": 84269}}
{"key": "10.1145/3019612.3019926", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "it is necessary to detect theft by measuring application similarity", "explanation": "本文は盗難検出のための類似度測定が主目的であり、コードの復元や生成を行う目的がないため、除外基準EC3に該当する"}, {"code": "ex_no_ml", "evidence": "using text mining", "explanation": "要旨では機械学習やLLMの利用が明示されておらず、単なるテキストマイニングと記述されているため、除外基準EC1に該当する可能性が高い"}], "reasoning": "この論文はAndroid実行ファイルの類似性測定を目的としており、デコンパイルによる高水準コード生成や復元を行う研究ではない。また、要旨からはML/LLMの使用が明確に示されていないため、デコンパイル調査の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3413, "latency_ms": 94801}}
{"key": "10.1145/3720524", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We formalize the process of binary lifting with heuristic‑based assumptions...", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が全く言及されておらず、従来の形式手法のみが扱われているため、ML/LLM が使用されていないと判断しました。"}], "reasoning": "本論文はバイナリリフティングの形式的正当性をヒューリスティック変換で定式化し、検証手法を提示していますが、機械学習やLLM を手法の中核として用いる記述がなく、除外基準 EC1（No ML/LLM）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3043, "latency_ms": 81046}}
{"key": "10.1145/3342195.3387550", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Existing binary lifting tools are based on static disassembly and thus have to rely on heuristics… we present BinRec, a new approach to heuristic‑free binary recompilation…", "explanation": "要旨からは機械学習や大規模言語モデルの使用は示されておらず、従来の静的・動的解析手法のみが述べられているため、ML/LLM が中核手法であるという条件を満たさないと判断した。"}], "reasoning": "本稿は動的トレースを用いたバイナリリフティングと再コンパイル手法を提案しており、機械学習やLLMは用いられていない。したがって、Decompilation Survey のインクルード基準（ML/LLM の使用）を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3093, "latency_ms": 81551}}
{"key": "10.1145/3474369.3486865", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.85, "reason_codes": [{"code": "in_core", "evidence": "predict stack frame size from its function body alone", "explanation": "低水準のバイナリ関数からスタックフレームサイズという高水準属性を予測している点が、LLM/ML を用いたデコンパイル（低水準入力から高水準情報生成）に該当するため"}], "reasoning": "本論文はバイナリ関数（低水準入力）を Transformer により解析し、スタックフレームサイズという高水準の属性情報を予測する手法を提案している。ML 手法が中心であり、目的はバイナリのリバースエンジニアリング支援であるため、Decompilation Survey の対象として include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3502, "latency_ms": 97996}}
{"key": "10.1145/3597503.3639100", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "binary-to-source SCA identifies the third-party source projects contained in binary files via binary source code matching", "explanation": "論文はバイナリとソースコードのマッチングによるライブラリ検出を目的としており、バイナリからソースコードを生成・復元することは主目的ではないため、コード生成／復元の意図が欠如していると判断した"}], "reasoning": "本研究はバイナリとソースコードの類似性を評価し、再利用されたライブラリを検出することに焦点を当てている。デコンパイルとしての高水準コード生成や復元は行わず、MLは埋め込み生成に用いられるが、目的がコード復元ではなくマッチングであるため、除外基準EC3に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3413, "latency_ms": 90688}}
{"key": "10.1145/3494110.3528244", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "craft adversarial malware to evade detection ... focus ... generating adversarial Windows samples to evade dynamic analysis", "explanation": "要旨はマルウェアの敵対的生成と回避手法の検討であり、低水準バイナリから高水準コードを復元するデコンパイルとは無関係であるため、スコープ外と判断した。"}], "reasoning": "本稿はマルウェア検知回避を目的とした敵対的サンプル生成に関する位置付け論文であり、デコンパイル（低水準から高水準コードの復元）に関する研究ではない。したがって除外基準（ex_out_of_scope）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3105, "latency_ms": 86854}}
{"key": "10.1145/3519939.3523719", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose Lasagne, an end-to-end static binary translator with precise translation rules between x86 and Arm concurrency semantics.", "explanation": "本文は静的バイナリ翻訳器を規則ベースで設計しており、LLM/ML の利用が示されていないため除外基準 EC1 に該当します。"}], "reasoning": "本稿は低水準バイナリを別アーキテクチャへ翻訳する静的バイナリトランスレーション手法を提案しているが、機械学習や大規模言語モデルを手法の中核として用いている記述がなく、除外基準 EC1（ML/LLM を使用しない）に該当するため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3143, "latency_ms": 85744}}
{"key": "10.1145/3691620.3695012", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose React, the first patch presence test approach on IR-level.", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く記述されておらず、従来のシンボリック実行とSMTソルバーに基づく手法であることから、ML/LLM が用いられていないと判断した。"}], "reasoning": "本研究はバイナリのパッチ有無をIRレベルで判定する手法であり、シンボリック実行とSMT ソルバーを用いた静的解析が中心です。要旨からは機械学習や大規模言語モデルの利用が示唆されていないため、除外基準 EC1（ML/LLM 未使用）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3210, "latency_ms": 86684}}
{"key": "springer_10_1007_978_981_96_2042_5_59", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The deep learning classification model processes the deduplicated IR ... for malware classification.", "explanation": "目的がマルウェアの分類・検出であり、復元や高水準コード生成を目指すものではないため、コード生成・再構成の意図がないと判断した。"}], "reasoning": "本稿はマルウェア検出を目的とした手法を提案しており、低水準バイナリから IR を生成する工程は特徴抽出のための前処理である。デコンパイルの主目的であるコードの復元・可読化とは異なるため、除外基準 EC3（コード生成・再構成意図の欠如）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3171, "latency_ms": 85395}}
{"key": "springer_10_1007_978_3_031_20738_9_4", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the similarity of two binary code snippets can measured by the cosine similarity of their encoded vectors", "explanation": "要旨はバイナリ関数間の類似度を測定することにあり、コードやソースの生成・復元を目的としていないため、コード生成／再構成の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリを LLVM-IR にリフトし、ニューラルネットワークで埋め込みベクトルを生成して類似度を計算する手法を提案していますが、出力は類似度スコアであり、デコンパイルによる高水準コード生成や復元を目的としていません。したがって、デコンパイル調査の対象外（コード生成・復元意図がない）と判断し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3169, "latency_ms": 87979}}
{"key": "WOS:001256552500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "methodology for machine learning classification models...detects malware but also classifies its variants", "explanation": "抽象からはコード生成や高水準表現の復元を目的としていないことが読み取れ、主目的がマルウェアの検出・分類であるため除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリリフティングと opcode エントロピーを用いた特徴抽出に基づき、機械学習でマルウェアの検出とバリアント分類を行う手法を提案しています。デコンパイルやコード再構成を目的としていないため、Decompilation Survey の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3033, "latency_ms": 85775}}
{"key": "WOS:000712025300005", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "learning the IR Sequence which reflects malicious behavior pattern using deep learning model for sequence learning", "explanation": "要旨はIRシーケンスを用いたマルウェアの分類・検出に焦点を当てており、コード生成や復元が目的ではないため、コード生成・再構築意図がなく除外基準EC3に該当します。"}], "reasoning": "本論文はバイナリリフティングで得た中間表現を用いたマルウェア分類手法を提案しており、LLM/MLは利用されているものの目的は復元・可読化ではなく分類です。デコンパイルの主要目的である高水準コード生成や再構築が行われていないため、除外基準EC3に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3037, "latency_ms": 85811}}
{"key": "Achamyeleh2026", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "summarizes a binary's control flow... supplied to a general-purpose LLM... raises average object file compilability", "explanation": "抽象度の高いバイナリ情報を LLM に与えて直接高水準コードを生成し、コンパイル可能性を向上させているため、コアデコンパイルに該当する。"}, {"code": "in_decompiler_enhancement", "evidence": "supplied to a general-purpose LLM, along with raw decompiler output", "explanation": "既存デコンパイラの出力を入力に取り、LLM がコードの可読性・コンパイル可能性を改善している点からデコンパイラ強化にも該当する。"}], "reasoning": "本稿はバイナリを低水準入力とし、LLM を中心手法として高水準かつコンパイル可能なコードを生成する枠組みを提案している。LLM が既存デコンパイラ出力を改善しつつ、バイナリ情報を活用して直接コード生成を行うため、コアデコンパイルかつデコンパイラ強化の両側面を持つ研究と判断できる。", "model": "openai/gpt-oss-120b", "tokens_used": 3623, "latency_ms": 103109}}
{"key": "9520296", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "our learned labeling model can be combined with an existing decompilation tool, Ghidra, to achieve substantially improved performance in function call recovery", "explanation": "この記述は、MLモデルがバイナリ（低水準入力）から関数呼び出し情報を抽出し、既存デコンパイラの出力を改善することを示しており、デコンパイラ強化研究に該当するため"}], "reasoning": "本論文はバイナリを入力とし、機械学習を中心手法として関数呼び出しの復元を行い、Ghidra との組み合わせでデコンパイル結果を向上させることを目的としている。低水準入力、ML 手法、デコンパイル支援という三条件を満たすため、インクルードと判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3498, "latency_ms": 100573}}
{"key": "10123452", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We extend large pre-trained language models of source code to summarise de-compiled binary functions.", "explanation": "本文はデコンパイルされたコードから自然言語の要約を生成することが目的であり、コードや高水準表現の再構成・生成は行わないため、コード生成・復元目的がないと判断した。"}, {"code": "ex_no_ml", "evidence": "Fine-tune the CodeT5 base model with CAPYBARA to create BinT5.", "explanation": "実際にはML/LLMは使用しているが、除外判定はコード生成目的の欠如に基づくため、主要な除外コードは ex_no_code_generation となる。"}], "reasoning": "この論文はデコンパイルされたバイナリ関数を入力として自然言語要約を生成することに焦点を当てており、復元やソースコード生成といったデコンパイルの本来目的とは異なる。したがって、出力がコードではなく要約である点から除外基準 EC3（コード生成・復元意図がない）に該当し、exclude と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3517, "latency_ms": 99501}}
{"key": "Arasteh2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify modules in stripped binaries and associate them with high-level natural language descriptions", "explanation": "アブストラクトはバイナリからモジュールを検出し自然言語で説明することを目的としており、ソースコードや擬似コードなどの高水準コード生成を行わないため、コード生成・復元の目的がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文はバイナリを入力に LLM を用いてモジュールを特定し自然言語で要約するシステムを提案していますが、出力はコードではなく説明文です。デコンパイルにおける高水準コード（L1〜L4）の生成・復元が目的でないため、除外基準 EC3（コード生成・復元目的でない）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3252, "latency_ms": 92216}}
{"key": "Armengol-Estapé2022", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "produce x86 assembler from C code", "explanation": "アブストラクトはCコード（高水準）を入力とし、x86アセンブリ（低水準）を出力しているため、低水準入力がなくデコンパイルの定義を満たさないと判断した。"}], "reasoning": "本論文は高水準のCコードから低水準のx86アセンブリへ変換する「ニューラルコンパイル」を対象としており、デコンパイル（低水準→高水準）の対象外である。入力が低水準表現でないことは除外基準 EC2（ex_no_lowlevel_input）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3014, "latency_ms": 89301}}
{"key": "10444788", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "Small Language model Decompiler ... generate programs that are more readable and accurate", "explanation": "LLM を用いて低水準のアセンブリから直接高水準コード（可読なプログラム）を生成しているため、Core Decompilation に該当する。"}, {"code": "in_type_recovery", "evidence": "augmented with a type inference engine", "explanation": "型推論エンジンを組み込んで、コンテキスト外の型を推定・復元している点が Type Recovery に該当する。"}], "reasoning": "本稿は最適化されたアセンブリを入力とし、シーケンス‑ツー‑シーケンス Transformer（小規模言語モデル）を中心手法として高水準ソースコードを生成する decompiler を提案している。低水準入力、ML 手法の使用、コード復元・可読化という目的がすべて満たされているため、Include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3436, "latency_ms": 99233}}
{"key": "Arranz-Olmos2025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We develop CT-RetDec, a CT analysis tool based on a modified version of the LLVM-based decompiler RetDec.", "explanation": "抄録に機械学習や大規模言語モデルの使用が言及されておらず、従来のデコンパイラ改変のみであるため、EC1 に該当し除外する。"}], "reasoning": "本稿はバイナリを対象とした定数時間解析のために既存デコンパイラを改変・評価する内容であり、ML/LLM を手法の中核として用いていない。従って、除外基準 EC1（No ML/LLM）に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3281, "latency_ms": 89151}}
{"key": "Banerjee2021", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_variable_naming", "evidence": "infer variable names in decompiled code based on Masked Language Modeling", "explanation": "要旨はデコンパイルされたコードから変数名を復元することを目的としており、変数/関数命名の回復が主目的であるため"}, {"code": "in_decompiler_enhancement", "evidence": "takes raw decompiler output ... as input, and enriches it using our proposed finetuning technique", "explanation": "入力が既存デコンパイラの出力であり、LLM/BERT によりその可読性・命名を改善している点からデコンパイラ出力の強化に該当する"}], "reasoning": "本稿は、バイナリから得られたデコンパイラ出力を入力とし、LLM（BERT/Transformer）を用いて変数名を予測・復元する手法を提案している。目的はコードの可読性向上と変数名の回復であり、ML が中心手法である点から decompilation のコアタスクの一部（命名回復）として採択対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3596, "latency_ms": 107062}}
{"key": "Bielik2020", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Machine learning ... has been recently used to successfully address many tasks in the domain of code such as finding and fixing bugs, code completion, decompilation, type inference and many others.", "explanation": "アブストラクトはコードタスク全般を取り上げているが、入力がバイナリやアセンブリといった低水準表現であることは明記されておらず、ソースコードやトークン列が前提と推測されるため低水準入力がないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "we explore this issue by: (i) instantiating adversarial attacks for code ... (ii) showing that ... neural models for code are vulnerable ... (iii) combining existing and novel techniques to improve robustness while preserving high accuracy.", "explanation": "研究の目的はコードモデルの adversarial robustness の評価と改善であり、デコンパイルやコード生成・復元そのものを行うことが主目的ではないため、コード生成・復元意図が欠如していると判断した。"}], "reasoning": "本稿はコードに対する敵対的攻撃とロバストネス向上を扱うもので、バイナリ等の低水準入力から高水準コードを復元することを目的としていない。したがってデコンパイル研究の包括基準を満たさず、除外基準の '低水準入力がない' と 'コード生成・復元が主目的でない' に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3138, "latency_ms": 94221}}
{"key": "Bu2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect vulnerabilities directly from bytecode", "explanation": "アブストラクトはバイトコードから脆弱性を検出することを目的としており、コードの復元や高水準表現の生成は行わないため、コード生成・再構成が主目的ではないと判断した。"}], "reasoning": "本論文はバイトコードを入力として BERT と CFG を用いた脆弱性検出（分類）手法を提案している。デコンパイルや高水準コードの生成・再構成を目的としていないため、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3121, "latency_ms": 87470}}
{"key": "Butz2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we fill this gap by proposing SPN2BN, an algorithm that decompiles an SPN into a BN", "explanation": "要旨ではアルゴリズムによる手法を述べており、ML／LLM の利用は言及されていないため除外基準 EC1 に該当します。"}, {"code": "ex_no_lowlevel_input", "evidence": "decompiles an SPN into a BN", "explanation": "入力は SPN（高水準の確率モデル）であり、低水準バイナリやアセンブリといった定義上の low‑level 入力ではないため除外基準 EC2 に該当します。"}], "reasoning": "本研究は SPN という高水準モデルをベイズネットワークへ変換するアルゴリズムを提案しており、ML/LLM を用いた手法ではなく、入力も低水準コードではないため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3261, "latency_ms": 92039}}
{"key": "Caliskan2017", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "using a novel set of features that include ones obtained by decompiling the executable binary to source code", "explanation": "デコンパイルは特徴抽出のために用いられており、目的はプログラマの著者推定という分類であり、コードの復元や可読化は行っていないため除外対象となります"}], "reasoning": "本論文はバイナリをデコンパイルして得たコードを特徴として使用し、機械学習でプログラマの著者性を判別することが主目的です。デコンパイルはコードの復元や可読化を目的としたものではなく、分類タスクの前処理として利用されているため、Decompilation Survey の採択基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3421, "latency_ms": 97807}}
{"key": "10174218", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "augmenting decompiled code with variable names and types", "explanation": "抽象的に変数名や関数名を復元することが主目的と明記されているため、変数/関数命名回復に該当します。"}, {"code": "in_type_recovery", "evidence": "predict semantic information contained in the original source code", "explanation": "変数の型情報を予測・復元することが研究の主要目的であるため、型回復に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "leveraging decompiler output tokens and variable size information", "explanation": "既存のデコンパイラ（Hex‑Rays, Ghidra）の出力を入力として利用し、LLMで可読性や型・命名情報を向上させているため、デコンパイラ出力の強化研究です。"}], "reasoning": "本稿はバイナリから得られたデコンパイラ出力を入力に、TransformerベースのML手法で変数名と型情報を予測・付加することを目的としている。入力は低水準バイナリ由来のトークンであり、出力は高水準属性（名前・型）で、デコンパイルの可読化・意味回復に直接貢献するため、スクリーニング基準の Core/Peripheral いずれかに該当し、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3560, "latency_ms": 108818}}
{"key": "Chakraborty2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Mapping programs from one architecture to another plays a key role ... we develop correct and efficient translations ...", "explanation": "概要には機械学習や大規模言語モデルの使用について言及がなく、従来の翻訳・デコンパイル手法の実装に関する記述のみあるため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿はアーキテクチャ間の並行性マッピング手法を提案しており、低水準コードの変換やフェンス挿入に焦点を当てているが、機械学習や大規模言語モデルを中核技術として使用している記述がない。したがって、Include 基準を満たさず、除外基準の EC1（No ML/LLM）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2994, "latency_ms": 84733}}
{"key": "Chawla2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "first decompiles Windows executable into a C code ... and then leverages LLMs to perform the classification.", "explanation": "要旨ではLLMは分類（malware detection）に使われており、デコンパイル後のコード生成や復元が目的ではないため、コード生成・再構成が主目的であるEC3に該当します。"}], "reasoning": "本論文はLLMを用いたマルウェア検知の分類タスクに焦点を当てており、デコンパイルは前処理としてのみ利用されています。復元・可読化・高水準コード生成といったデコンパイルの核心的目的がなく、コード生成・再構成が主目的でないため除外基準EC3に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3188, "latency_ms": 94759}}
{"key": "Chen2025", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.85, "reason_codes": [{"code": "in_variable_naming", "evidence": "function name recovery ... on the decompiled pseudo code", "explanation": "アブストラクトは関数名の復元を目的としており、名前付けの改善が主要なタスクであるため"}, {"code": "in_type_recovery", "evidence": "variable type inference on the decompiled pseudo code", "explanation": "変数型の推論・復元が明示的に評価対象となっているので、型回復研究に該当します"}, {"code": "in_decompiler_enhancement", "evidence": "LLM ... leverages ... to improve reasoning capabilities ... on decompiled pseudo code", "explanation": "既存のデコンパイラ出力（疑似コード）を入力とし、LLM が名前や型情報を付加して可読性を向上させているため"}], "reasoning": "本稿はバイナリから得られた疑似コードを対象に、関数名や変数型を自動復元するLLMを提案している。低水準入力（バイナリ）に対し、LLM が高水準属性（名前・型）を付与することでデコンパイル結果を強化しており、IC2／IC3／IC4 に該当するためインクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3515, "latency_ms": 105675}}
{"key": "Chen2021", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "improving the quality of decompiler output that automatically generates meaningful variable names and types", "explanation": "既存のデコンパイラ出力を入力とし、ML 手法で変数名や型を付与して可読性を向上させる手法であるため、IC2（Decompiler Enhancement）に該当します。"}, {"code": "in_variable_naming", "evidence": "automatically generates meaningful variable names", "explanation": "研究の主目的の一つが変数名の復元であるため、最も具体的なコードとして in_variable_naming を付与します。"}, {"code": "in_type_recovery", "evidence": "automatically generates meaningful ... types", "explanation": "変数型の復元も主要な貢献であり、L4 属性の回復に該当するため補助コードとして追加します。"}], "reasoning": "本稿は decompiler の出力を入力に取り、機械学習を用いて変数名と型を自動的に付与し、コードの可読性と情報量を向上させる手法を提案している。低レベル入力ではないが、既存デコンパイラ出力の改善という目的は本サーベイのコア対象（Decompiler Enhancement）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3761, "latency_ms": 118254}}
{"key": "8443103", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "We conduct network and application vulnerability analyses ... including application binary decompilation", "explanation": "要旨ではバイナリデコンパイルを利用した脆弱性分析を行っていると述べられていますが、機械学習や大規模言語モデルの使用は言及されていないため、ML/LLM が用いられていないと判断しました。"}], "reasoning": "本稿は IoT 玩具のセキュリティ評価を目的としており、バイナリデコンパイルは分析手段の一つに過ぎません。LLM/ML が中心手法として扱われていないため、Decompilation Survey の採択基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 2968, "latency_ms": 89269}}
{"key": "Chukkol2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "transform raw binary code into pseudocode using CodeT5", "explanation": "バイナリ（低水準入力）を LLM（CodeT5）で直接擬似コード（L2）に変換しており、復元・逆解析支援が目的なので Core Decompilation に該当する"}], "reasoning": "本文はバイナリを入力とし、LLM（CodeT5）を用いて擬似コードを生成することを主要手法として記述しているため、Decompilation Survey の Core デコンパイル領域に該当します。目的は高水準表現の取得による脆弱性検出支援であり、復元・可読化を目的とした研究と判断できるため、include としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3359, "latency_ms": 101873}}
{"key": "Cristea2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We propose an approach that leverages large language models (LLMs) to detect binary malware ... and ... LLM-based CVE classification.", "explanation": "本文はマルウェア検出と CVE 付与を目的としており、コードの復元や高水準表現の生成が主目的ではないため、コード生成/再構成の意図がなく除外基準 EC3 に該当する。"}], "reasoning": "本論文は LLM を用いたマルウェア検出と CVE 关联付けを目的としており、デコンパイル自体は前処理として利用されているものの、復元・可読化といった高水準コード生成が主目的ではない。したがって除外基準 EC3（コード生成・復元が主目的でない）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3315, "latency_ms": 97336}}
{"key": "David2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.96, "reason_codes": [{"code": "in_core", "evidence": "transform Ethereum Virtual Machine (EVM) bytecode into human-readable and semantically faithful Solidity code", "explanation": "LLM が低水準の EVM バイトコードから Solidity ソースコード（L1）を直接生成しているため、Core Decompilation に該当する。"}, {"code": "in_type_recovery", "evidence": "precise function signatures", "explanation": "関数シグネチャの正確な復元は型情報の回復であり、Type Recovery の目的を満たす。"}], "reasoning": "本稿は低水準のバイトコードを入力とし、LLM を中核手法として人間が読める Solidity ソースを生成することを目的としている。入力・手法・目的すべてが Inclusion Criteria を満たすため、Core Decompilation として採択する。", "model": "openai/gpt-oss-120b", "tokens_used": 3454, "latency_ms": 100858}}
{"key": "Dramko2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "a new neural decompilation approach to finetune any LLM into a neural decompiler capable of generating the appropriate user-defined type definitions alongside the decompiled code", "explanation": "LLM を用いて低水準入力（暗黙的にバイナリ／アセンブリ）からソースコード（L1）と型定義を直接生成しているため、Core Decompilation に該当する"}, {"code": "in_type_recovery", "evidence": "generating the appropriate user-defined type definitions alongside the decompiled code", "explanation": "生成対象にユーザー定義型の復元が含まれ、型回復が主要目的の一部となっているため"}], "reasoning": "本稿は LLM を中心手法として、バイナリやアセンブリ等の低水準表現からソースコードと型情報を生成するニューラルデコンパイラを提案している。生成されたコードは可読性を向上させることを目的としており、デコンパイルの核心的研究に該当する。型定義の復元も重要な貢献であるため、in_core と in_type_recovery の両コードを付与した。", "model": "openai/gpt-oss-120b", "tokens_used": 3389, "latency_ms": 101475}}
{"key": "Enders2022", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We developed a variety of improvements over the previous academic state-of-the-art decompiler and some novel algorithms to enhance readability and comprehension", "explanation": "抽象からは機械学習や大規模言語モデルの使用が言及されておらず、従来のアルゴリズムによる改善のみが説明されているため、ML/LLM が手法の中核でないと判断した。"}], "reasoning": "本稿は既存デコンパイラのアルゴリズム的改良とユーザー調査による評価に焦点を当てており、機械学習や大規模言語モデルを用いた手法が示されていない。したがって、インクルード基準の IC0（LLM/ML が中核手法）を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3185, "latency_ms": 91525}}
{"key": "Escalada2021", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_type_recovery", "evidence": "inferring the high-level type returned by functions", "explanation": "関数の戻り値型を高レベルに推定することが主目的であり、型回復に該当するため"}, {"code": "in_decompiler_enhancement", "evidence": "improving existing decompilers", "explanation": "既存デコンパイラの出力（型情報）を機械学習で向上させることが目的で、デコンパイラ強化に該当する"}], "reasoning": "本稿はバイナリから抽出したパターンを入力とし、教師あり機械学習で関数の戻り値型を予測することでデコンパイラの型情報を改善する。低水準入力、ML 手法、復元目的の三条件を満たし、型回復（Peripheral 条件）として採択基準を満たすため include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3399, "latency_ms": 103585}}
{"key": "Fang2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "decompile complex WebAssembly code into readable C++ snippets", "explanation": "抽象記述から、低水準のWebAssemblyを入力とし、LLMを用いてC++という高水準コードを直接生成しているため、コアデコンパイル研究に該当します。"}], "reasoning": "本論文はWebAssemblyというバイナリレベルの入力から、LLMとプログラム解析を組み合わせてC++ソースコードを生成する手法を提案しており、目的も復元・可読化です。LLM が手法の中核であり、出力はコンパイル可能なコード（L1）に該当するため、インクルード基準を満たします。", "model": "openai/gpt-oss-120b", "tokens_used": 2965, "latency_ms": 87506}}
{"key": "Feng2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "end-to-end decompile method based on large language models (LLMs) reduces reliance on additional tools", "explanation": "LLM を中心手法として低水準コードから高水準コードを直接生成しており、コアデコンパイルに該当するため"}, {"code": "in_type_recovery", "evidence": "The Function Call strategy infers variable types and retrieves missing variable information from binary files", "explanation": "関数呼び出し戦略で変数型を推測しバイナリから情報を取得している点が型回復に該当するため"}], "reasoning": "本論文は LLM を用いたエンドツーエンドのデコンパイル手法で、低水準コードから高水準コードを生成し、さらに型情報の回復も行う。以上の点からコアデコンパイル研究として採択と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3380, "latency_ms": 102699}}
{"key": "Feng2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "Decompilation transforms compiled code back into a high-level programming language ... aligns assembly code with source code at the statement level", "explanation": "低水準のバイナリ/アセンブリを入力とし、LLM が高レベルのソースコードを直接生成する手法を提案しているため、Core Decompilation に該当します。"}], "reasoning": "アブストラクトは、コンパイル済みコード（アセンブリ）から高水準言語への復元を目的とし、LLM を中心とした手法（sc²dec と FAE）で実現していることを示しています。これらはデコンパイルの生成（L1-L3）を直接行う研究であり、除外基準に該当しません。", "model": "openai/gpt-oss-120b", "tokens_used": 3377, "latency_ms": 102232}}
{"key": "Fu2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "Coda ... end-to-end neural-based framework for code decompilation ... generating an abstract syntax tree (AST)", "explanation": "抽象構文木 (AST) を生成することは L1‑L3 の高水準表現に該当し、低水準バイナリ入力から直接 LLM/ML がコードを復元しているため core decompilation と判断した。"}], "reasoning": "本稿はバイナリ実行ファイルを入力とし、ニューラルネットワークを中心手法として AST を出力するエンドツーエンドのデコンパイル手法を提案している。入力が低水準、出力が高水準コード表現、目的が復元である点が IC0 を満たすため、include と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3213, "latency_ms": 90990}}
{"key": "Gao2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.87, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we present DecompileBench, the first comprehensive framework that enables effective evaluation of decompilers... using LLM-as-Judge to quantify the effectiveness of decompilers", "explanation": "要旨はデコンパイラの評価・ベンチマーク構築であり、コードの復元や生成が目的ではなく、LLMは評価者（ジャッジ）として使われているため、コード生成・復元を目的とした研究ではないと判断した。"}], "reasoning": "本稿はデコンパイラの評価基盤を提案するベンチマーク論文であり、低水準入力から高水準コードを生成することや既存デコンパイラ出力を改善することが目的ではない。LLMは評価者として使用されており、復元・可読化を行う手法ではないため、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3232, "latency_ms": 94735}}
{"key": "Green2024", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_type_recovery", "evidence": "predict variable names and types", "explanation": "要旨は変数の型を予測することが主目的であると明示しているため、型回復に該当します。"}, {"code": "in_variable_naming", "evidence": "predict variable names and types", "explanation": "同時に変数名の復元も目的としているため、識別子命名回復にも該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "matching sequences of decompiler tokens to those found in training data", "explanation": "入力はデコンパイラが出力したトークンで、ML によりその出力を型・名前情報で補強しているため、デコンパイラ出力の強化研究です。"}], "reasoning": "本稿はデコンパイラが失った変数の型と名前を機械学習ベースで予測し、デコンパイル結果を改善することを目的としている。入力はデコンパイラトークン（低水準表現に由来）であり、出力は型情報と識別子名という高水準属性であるため、Peripheral な decompiler enhancement として採択対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3597, "latency_ms": 113777}}
{"key": "He2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "RETROFIT achieves around twice the BLEU score ... in binary summarization across decompilation levels", "explanation": "要旨はバイナリの要約を行うことにあり、コードやソースの生成・再構成が目的ではないため、コード生成/復元の意図がないと判断した。"}], "reasoning": "本稿は継続学習手法を提案し、マルウェア検出やバイナリ要約に適用したと述べているが、低水準入力から高水準コードを生成する目的は示されていない。要約は自然言語生成であり、デコンパイル（コード復元）とは範囲外であるため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3317, "latency_ms": 97411}}
{"key": "Hosseini2022", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "using techniques from neural machine translation to automate the process in decompilation", "explanation": "ニューラル機械翻訳（ML 手法）を用いてアセンブリという低水準入力から C 以外の高水準ソースコードを直接生成しているため、Core Decompilation に該当します。"}], "reasoning": "本稿はアセンブリを入力とし、ニューラル機械翻訳を中心手法として高水準ソースコード（L1/L2）を生成するデコンパイラを提案している。入力が低水準表現で、目的がソースコード復元であり、ML/LLM が核心技術であることが要旨から明らかなので、Include 基準を満たし、in_core が最も適切な理由コードです。", "model": "openai/gpt-oss-120b", "tokens_used": 3175, "latency_ms": 93832}}
{"key": "Hussain2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect vulnerabilities within these binary files", "explanation": "本文の主目的はバイナリの脆弱性検出であり、コードの復元や高水準表現の生成ではなく分類・検出が中心なので、ICに該当せず除外基準 EC3 に該当する"}], "reasoning": "本稿は LLM を用いてストリップドバイナリから脆弱性を検出することを目的としており、デコンパイルによるコード復元や高水準表現の生成は主要な目標ではない。したがってコード生成・復元を目的とした decompilation 研究ではなく、除外基準 EC3（コード生成・復元意図がない）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3308, "latency_ms": 96549}}
{"key": "Jiang2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_core", "evidence": "we assess model performance across ... decompilation", "explanation": "抽象的に「decompilation」をタスクとして評価しているため、低水準のIRから高水準コードを生成することが目的であり、LLM が中心手法として用いられていると判断した。"}, {"code": "ex_no_code_generation", "evidence": "LLMs exhibit competence in parsing IR syntax and identifying high-level structures", "explanation": "本文はLLMがコード生成に成功しているかを評価しており、生成自体が主要な成果ではなく評価対象であるため、生成意図が二次的であることを示す。"}], "reasoning": "本文は低水準の中間表現(IR)を入力とし、LLM を用いて decompilation タスクを実施しているため、コアデコンパイル研究に該当する。ただし、主たる貢献が新手法の提案ではなく LLM の能力評価である点から、生成意図が二次的であることを補足的に指摘した。", "model": "openai/gpt-oss-120b", "tokens_used": 3671, "latency_ms": 116159}}
{"key": "Jiang2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "Nova outperforms existing techniques on binary code decompilation ...", "explanation": "抽象から、Nova はバイナリを入力としてアセンブリコードを生成し、デコンパイルを直接実行しているため、LLM が低水準入力から高水準（L2）表現を生成する Core Decompilation に該当する。"}, {"code": "ex_no_ml", "evidence": "", "explanation": ""}], "reasoning": "本論文はバイナリコード（低水準入力）からアセンブリコード（高水準表現）を生成する生成型 LLM を提案しており、目的がコード復元・可読化である。したがって、Decompilation Survey の Core Decompilation 条件を満たすと判断し、include とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3176, "latency_ms": 95738}}
{"key": "Katz2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "we used our framework to decompile both LLVM IR and x86 assembly to C code", "explanation": "抽象化では低水準表現（LLVM IR、x86 アセンブリ）を入力とし、C ソースという高水準コードを出力しており、ニューラル機械翻訳（ML）を中心手法としているため、Core Decompilation に該当する"}], "reasoning": "本稿は低水準コード（LLVM IR, x86 アセンブリ）から高水準の C ソースコードへ自動的に変換するニューラル機械翻訳手法を提案している。ML が中核であり、目的も復元・可読化であるため、Decompilation Survey の採択基準を満たす。したがって include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3166, "latency_ms": 95445}}
{"key": "KC2023", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we survey the NMT for code generation literature, cataloging the variety of methods", "explanation": "本文は既存研究のサーベイであり、オリジナルのデコンパイル手法や評価を提示していないため除外基準に該当します"}], "reasoning": "本稿は Neural Machine Translation を用いたコード生成の文献調査であり、実装されたデコンパイル手法や実験結果を提示していません。サーベイ・レビュー論文は除外基準 EC4 に該当するため、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2861, "latency_ms": 85601}}
{"key": "8080433", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "We use genre-related corpora (including fantasy books and decompiled games) to create language models suitable to this domain.", "explanation": "抽象では低水準表現（バイナリ・アセンブリ等）を入力として扱っている記述がなく、テキストデータを用いた言語モデル構築であるため、低水準入力が存在しないと判断した。"}], "reasoning": "本稿はテキストベースのゲームエージェントの構築を目的としており、デコンパイルや低水準コードから高水準表現への変換を行う研究ではない。抽象からは低水準入力が示されておらず、デコンパイルの範囲外と判断したため除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3092, "latency_ms": 95216}}
{"key": "Li2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "NeuroDeX ... perform ... model reconstruction. NeuroDeX can recover DNN executables into high-level models", "explanation": "LLM を用いてバイナリ（DNN 実行ファイル）から高レベルのモデル表現を直接生成しているので Core Decompilation に該当します。"}, {"code": "in_type_recovery", "evidence": "perform operator type recognition, operator attribute recovery", "explanation": "LLM が演算子の型や属性を復元することが主要目的の一つであるため、Type Recovery の要素も含まれます。"}], "reasoning": "本稿は低レベルの DNN 実行バイナリを入力とし、LLM を中心手法として高レベルのモデル（コードや構造）へ復元することを目的としています。出力は高レベルモデルであり、復元・再構成の意図が明確なため、Core Decompilation に該当し、さらに演算子型の復元も行うため Type Recovery の側面も含みます。", "model": "openai/gpt-oss-120b", "tokens_used": 3385, "latency_ms": 103931}}
{"key": "Li2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "fault-tolerant Java decompiler based on machine translation models", "explanation": "「Java decompiler」という表現は低水準のバイトコードを入力として高水準のソースコードを生成することを示しており、目的が復元・可読化であるため Core decompilation に該当します"}, {"code": "ex_no_ml", "evidence": "based on attention-based Neural Machine Translation (NMT) and Transformer architectures", "explanation": "本文は注意機構を持つ NMT と Transformer を用いた機械学習手法を中心にしていることを示しているため、ML/LLM が中核手法であることが確認できます"}], "reasoning": "本稿は Java バイトコードなどの低水準表現を入力とし、注意型 NMT／Transformer を用いて高水準ソースコードを直接生成する手法を提案している。目的はデコンパイルの復元・可読化であり、出力はソースコード（L1）に相当するため、Core decompilation (in_core) に該当し、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3773, "latency_ms": 120579}}
{"key": "Li2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "directly prompting vanilla code LLMs struggles to accurately identify security patches from binary patches", "explanation": "抽象ではLLMはバイナリパッチを分類・検出することが主目的であり、コードや高水準表現の生成は行わないため、コード生成・復元の意図がなく除外基準EC3に該当します。"}], "reasoning": "本研究はバイナリパッチのセキュリティパッチ検出という分類タスクに焦点を当てており、低水準入力から高水準コードを生成するデコンパイル目的ではない。したがって、コード生成・復元を伴わないため除外基準ex_no_code_generationに該当し、excludeと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3186, "latency_ms": 93476}}
{"key": "9282282", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "by leveraging symbolic execution and NLP (Natural Language Processing) techniques", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、従来のシンボリック実行とNLP手法のみと記載されているため、EC1に該当します。"}, {"code": "ex_no_code_generation", "evidence": "generate descriptions for the bytecodes of smart contracts", "explanation": "出力はコードや擬似コードではなく自然言語の説明であり、復元・コード生成が目的ではないため、EC3に該当します。"}], "reasoning": "本稿はバイトコードから自然言語による説明を生成することを目的としており、機械学習／LLM を用いない点と、コードや擬似コードの生成を行わない点から、本サーベイの対象である decompilation（低水準から高水準コード生成）には該当しません。", "model": "openai/gpt-oss-120b", "tokens_used": 3209, "latency_ms": 99458}}
{"key": "Liang2021", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "translate low-level PL into ... high-level PL", "explanation": "低水準バイナリ等を入力として、ニューラル機械翻訳で C/C++ などの高水準コードを直接生成しているため、Core Decompilation に該当します。"}, {"code": "in_variable_naming", "evidence": "semantic information (e.g., meaningful variable names)", "explanation": "生成されたコードが意味的な変数名を含むことを目的としているので、変数/関数名の復元も主要目的の一部です。"}], "reasoning": "本論文はバイナリ等の低水準表現を入力とし、ニューラル機械翻訳（ML 手法）で C/C++ のソースコードを生成することを目的としている。コード生成と意味情報（変数名）の回復が明示されており、Decompilation Survey の Inclusion 条件を満たす Core decompilation 研究であると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3308, "latency_ms": 99496}}
{"key": "11207559", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "enhances decompiler output by combining static analysis (SA) and large language models (LLM)", "explanation": "LLM を用いて既存のスマートコントラクトデコンパイラの出力を改善している点が、IC2（Decompiler Enhancement）に該当するため"}, {"code": "in_type_recovery", "evidence": "precision of 90.40% and a recall of 88.82% for variable types", "explanation": "変数型の復元精度を評価・向上させていることから、型回復（IC3）にも該当する"}], "reasoning": "本研究はバイトコード等の低水準表現から生成されたデコンパイル結果を、静的解析で作成した依存関係グラフと LLM により semantically に最適化する手法を提案している。目的はコードの可読化・型情報の回復であり、LLM/ML が中心手法として使用されているため、スクリーニング基準を満たす include と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3522, "latency_ms": 107614}}
{"key": "Liu2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "end-to-end decompilation methods powered by large language models (LLMs) ... generate highly readable source code", "explanation": "LLM を中核手法として低水準バイナリから高水準ソースコードを直接生成しているため、Core Decompilation に該当します。"}, {"code": "in_control_structure", "evidence": "incorporates control flow graphs (CFG) and explicit data mappings to improve LLM-based decompilation", "explanation": "CFG とデータマッピングを用いて制御構造の復元・構造化を強化している点が Control Structure Recovery に該当します。"}], "reasoning": "本稿はバイナリを入力とし、LLM を中心に用いてソースコード（L1）を生成するエンドツーエンドのデコンパイル手法を提案している。さらに制御フロー情報を組み合わせて構造化を改善しているため、Core Decompilation と Control Structure Recovery の両側面を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3384, "latency_ms": 100745}}
{"key": "Liu2022", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "BTD takes DNN executables and outputs full model specifications, including types of DNN operators, network topology, dimensions, and parameters", "explanation": "低水準の実行ファイルから高水準のモデル仕様を生成しており、LLM/ML を用いたデコンパイルそのものなので Core decompilation に該当する"}, {"code": "in_type_recovery", "evidence": "outputs full model specifications, including types of DNN operators, ... dimensions, and parameters", "explanation": "出力に型情報やパラメータが含まれ、型・シグネチャの復元が主要目的の一部となっているため"}], "reasoning": "本稿はバイナリ（DNN 実行ファイル）を入力とし、機械学習ベースの手法で高水準のモデル記述（演算子種別・ネットワーク構造・次元・パラメータ）を復元する decompiler を提案している。低水準入力と復元目的が明確で、ML が中心手法として使用されているため、Core decompilation とみなす。型情報の復元も含むため、type recovery の側面も併記する。", "model": "openai/gpt-oss-120b", "tokens_used": 3629, "latency_ms": 114316}}
{"key": "Manuel2025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "CodableLLM ... automates the creation and curation of datasets by mapping decompiled functions to their corresponding source functions.", "explanation": "要旨ではデコンパイルにML/LLMを用いることは言及されず、既存のデコンパイラを活用してデータセットを作成するだけなので、ML/LLM が中核手法ではないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "process enhances the alignment between decompiled and source code representations, facilitating the development of large language models ...", "explanation": "目的はデコンパイル結果とソースコードのマッピング・データセット生成であり、バイナリから高水準コードを生成すること（コード復元・生成）が主目的ではないため除外基準に該当する。"}], "reasoning": "本稿は既存デコンパイラの出力を利用してデコンパイル結果とソースコードを対応付け、LLM 用データセットを作成するフレームワークの提示であり、デコンパイル自体にML/LLM を用いた手法やコード生成・復元を目的としていない。そのため、Include 基準を満たさず Exclude 基準（ML/LLM 不使用、コード生成意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3437, "latency_ms": 112820}}
{"key": "Manuel2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identifying; classifying; describing vulnerabilities", "explanation": "要旨は脆弱性の検出・分類を目的としており、コードの再構成や高水準表現の生成を目指すものではないため、除外基準EC3に該当する"}], "reasoning": "本論文はデコンパイルされたバイナリを入力としてLLMを用い、脆弱性の検出・分類を主目的としている。コード生成や復元といったデコンパイル目的ではなく、分類タスクが中心であるため除外基準EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3871, "latency_ms": 120877}}
{"key": "Mihajlenko2021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We developed the algorithms for the following operations: preprocessing assembly code, searching data accesses, extracting system values, decompiling arithmetic operations and recovering data types.", "explanation": "本文はアルゴリズムやテンプレートによる手法を述べており、機械学習・大規模言語モデルの使用は示されていないため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は AMD GPU のアセンブリから OpenCL への変換ツールを手作業のアルゴリズムで実装していると述べており、機械学習や大規模言語モデルを中心手法として使用していない。そのため除外基準 EC1 (No ML/LLM) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3071, "latency_ms": 95992}}
{"key": "Minn2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "generates dynamic instrumentation scripts that satisfy activation conditions", "explanation": "論文は動的インストゥルメンテーションスクリプトを生成してテストカバレッジを向上させることが目的であり、元コードの復元や高水準コード生成を行わないため、コード生成／復元目的ではないと判断した。"}], "reasoning": "本稿はデコンパイルされた Smali コードを利用してテスト入力を自動生成することに焦点を当てており、LLM が用いられているものの、低水準コードから高水準ソースや擬似コードを復元することが主目的ではない。したがって、デコンパイルのコード生成／復元という採択基準を満たさず、除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3643, "latency_ms": 113349}}
{"key": "Palmarini2024", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "\"decompiling its amortized knowledge to extract relevant program components\"", "explanation": "アブストラクトは低水準表現（バイナリやアセンブリ）からの入力ではなく、ニューラル検索ポリシーという高レベルの知識を“decompile”していると述べており、デコンパイルの操作的定義に合致しないため除外する。"}], "reasoning": "本論文は DreamCoder のニューラル検索ポリシーからプログラムコンポーネントを抽出する手法を提案しており、入力が低水準コードではない。したがって、デコンパイル調査の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3062, "latency_ms": 97814}}
{"key": "Pearce2022", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_input", "evidence": "identify the purpose, capabilities, and important variable names or values from code, even when the code is produced through decompilation", "explanation": "アブストラクトだけでは、LLM に与えられる入力がバイナリやアセンブリ等の低水準表現なのか、既にデコンパイルされた疑似コードなのかが判断できず、低水準入力の要件を満たすか不明であるため。"}], "reasoning": "本文だけでは入力が低水準表現かどうかが明確でないため、Peripheral 条件を満たすか判定できない。LLM を用いている点や変数名抽出という目的は deコンパイル支援に近いが、入力の具体性が不足しているため、現時点では保留 (uncertain) とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3840, "latency_ms": 126486}}
{"key": "Pordanesh2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LLM's performance in interpreting and explaining human-written and decompiled codes.", "explanation": "LLMがバイナリや逆コンパイルコードを解釈・説明することを評価しており、コード生成や復元が目的ではないため、除外基準EC3に該当する。"}], "reasoning": "アブストラクトはLLMを用いてバイナリや逆コンパイルコードの解釈・説明を行う評価研究であり、ソースコードや擬似コードを生成することが目的ではない。したがって、コード生成・復元を目的としたデコンパイル研究の要件を満たさないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3390, "latency_ms": 112384}}
{"key": "Qin2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose the first empirical study on the understandability of Java decompiled code...", "explanation": "アブストラクトは実証研究を述べており、ML/LLM を用いた手法についての記述がなく、ルールベースや手動解析のみと判断できるため"}], "reasoning": "本論文は Java デコンパイルコードの可読性を評価する実証研究であり、ML/LLM を用いたデコンパイル手法や出力生成は示されていない。したがって、Decompilation Survey の採択基準 (IC) を満たさず、除外基準の EC1（ML/LLM 未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3185, "latency_ms": 97816}}
{"key": "Rao2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We devise a method for register aggregation, to identify relationships between the data flip-flops in a netlist...", "explanation": "抽象からは機械学習や大規模言語モデルを用いた手法の記述がなく、純粋にアルゴリズム的手法であると判断したため、ML/LLM が使用されていないとみなします。"}], "reasoning": "本研究はハードウェアのゲートレベルネットリストから HDL へ逆変換する手法を提案していますが、機械学習や LLM を用いる旨の記述がありません。したがって、Decompilation Survey の採択基準で要求される「LLM/ML が中核手法として使われている」条件を満たさず、除外基準 EC1（ex_no_ml）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3112, "latency_ms": 94223}}
{"key": "Reis2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We provide an automated decompiler of Michelson smart contracts to Tezla.", "explanation": "要旨ではML/LLMの使用が全く言及されておらず、従来型の自動デコンパイラのみが記述されているため、LLM/MLを中核とした研究ではないと判断した。"}], "reasoning": "本稿はMichelsonスマートコントラクトをTezlaというIRに変換する自動デコンパイラを提示しているが、機械学習や大規模言語モデルの利用が明示されていない。デコンパイル自体は対象だが、サーベイの採択基準である「LLM/ML が中核手法」であることを欠くため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2964, "latency_ms": 96761}}
{"key": "10740475", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose Partially Recompilable Decompilation (PRD) lifts suspect binary functions to source", "explanation": "アブストラクトにMLやLLMの使用についての記述がなく、従来のバイナリ‐ソース変換手法のみが述べられているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿はバイナリ関数をソースコードに変換し修正する手法を提案しているが、機械学習や大規模言語モデルを中心手法として使用している記述が全くない。したがって、Decompilation Survey の包括基準（IC0）を満たさず、除外基準 EC1（No ML/LLM）に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3324, "latency_ms": 100950}}
{"key": "Saul2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "perform the first serious evaluation of ML binary function similarity models on Windows data", "explanation": "本研究はバイナリ関数の類似性評価を目的としており、コードの復元・生成を行わないため、コード生成・再構成が主目的でない（EC3）と判断した"}], "reasoning": "本論文はバイナリ関数の類似性検出ベンチマークを構築し、MLモデルの性能評価を行うことが主目的であり、低水準入力から高水準コードを生成するデコンパイル目的ではない。したがって、コード生成・復元を含まない点で除外基準 EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 98438}}
{"key": "Shang2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "introduce BinMetric ... to evaluate the performance of large language models on binary analysis tasks, including decompilation ...", "explanation": "アブストラクトは LLM のデコンパイル性能を測定するベンチマークを提案しており、実際のコード復元・生成が目的ではなく評価が主目的であるため、コード生成/復元の意図がないと判断した。"}], "reasoning": "本稿は LLM のバイナリ解析能力を評価するベンチマークの提示と実験結果の報告に焦点を当てており、LLM を用いた実際のデコンパイルや高水準コード生成を行う研究ではない。したがって、デコンパイルの復元・可読化を目的とした研究とはみなせず、除外基準 EC3（コード生成・復元意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3208, "latency_ms": 101113}}
{"key": "Shokri2023", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Then, we perform an evolutionary-based search to find the correct semantic for the created representation", "explanation": "本文では進化的探索を用いた手法を記述しており、ML/LLM の使用は言及されていないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿は組み込みバイナリから制御アルゴリズムを数式として再構成する手法を提案していますが、手法は静的解析と進化的探索であり、機械学習や大規模言語モデルは用いられていません。そのため、Decompilation Survey の採択基準である ML/LLM の使用が欠如しており、除外対象となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3247, "latency_ms": 107282}}
{"key": "8987703", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We classify .NET files as either benign or malicious by examining directed graphs...", "explanation": "要旨はマルウェア分類であり、復元・高水準コード生成が目的ではなく、ML は分類器 (random forest) に用いられているため、コード生成・復元の意図がなく除外基準 EC3 に該当する。"}], "reasoning": "本論文は .NET バイナリをデコンパイル後にグラフ化し、特徴ベクトル化してマルウェア分類を行う手法を提案している。目的は分類であり、LLM/ML を用いたデコンパイルやコード復元は行わないため、除外基準「コード生成・復元が主目的でない (ex_no_code_generation)」に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3320, "latency_ms": 107827}}
{"key": "Su2026", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode", "explanation": "低水準のトランザクション実行を入力とし、LLM を用いて擬似コードへ変換しているため、LLM/ML が中心手法で L1‑L3 レベルのコード生成を行うコアデコンパイル研究と判断した。"}], "reasoning": "本稿は低レベルのトランザクショントレースを入力とし、LLM のコード生成能力を活用して実行可能な PoC（擬似コード）へ変換する手法を提案している。入力が低水準表現であり、目的がコード復元・可読化であること、LLM が手法の核となっていることから、Include 基準を満たすコアデコンパイル研究 (in_core) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3611, "latency_ms": 118493}}
{"key": "Szafraniec2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "generating programming source code from IR", "explanation": "抽象では低水準の LLVM IR を入力とし、ML モデルで高水準のソースコードを生成すると明記されているため、Core Decompilation に該当する。"}], "reasoning": "本稿は低水準のコンパイラ中間表現 (LLVM IR) を入力とし、ニューラル機械翻訳を用いてソースコードを生成する手法を提案している。ML が中心手法であり、目的がコードの復元・可読化であることから、Decompilation Survey の採択基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3207, "latency_ms": 103984}}
{"key": "Tan2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "we introduce SK2Decompile, a novel two-phase approach to decompile from the skeleton (semantic structure) to the skin (identifier) of programs.", "explanation": "LLM を用いてバイナリから高水準の IR そして最終的にソースレベルのコードを生成しているため、Core Decompilation に該当します。"}, {"code": "in_variable_naming", "evidence": "apply an Identifier Naming model to produce meaningful identifiers which reflect actual program semantics", "explanation": "第二フェーズで識別子名付けを行っており、変数・関数名復元が重要なサブタスクとなっているため、Variable/FUNCTION Naming のコードも付与します。"}], "reasoning": "本稿はバイナリを入力とし、LLM/ML を中核手法として用いて高水準のコード（IR＋識別子付きソース）を生成する二段階デコンパイル手法を提案している。入力が低水準のバイナリであり、復元・可読化が目的である点から Inclusion 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3457, "latency_ms": 111984}}
{"key": "Tan2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "LLM4Decompile, the first ... trained to decompile binary code", "explanation": "LLMが低水準バイナリを入力として高水準ソースコードを直接生成することを目的としているため、Core Decompilation に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "refine the decompiled code from Ghidra and achieve a further 16.2% improvement", "explanation": "既存のデコンパイラ（Ghidra）の出力をLLMで改善・リファインしている点が Decompiler Enhancement に該当します。"}], "reasoning": "本論文はLLMを中心手法としてバイナリから直接ソースコードを生成する手法を提案しており、Decompilation の Core 研究に該当します。また、Ghidra の出力をLLMでリファインする記述があり、デコンパイラ出力の改善研究でもあるため、両方のコードを付与しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3164, "latency_ms": 102367}}
{"key": "Tan2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we introduce Decompile-Bench, the first open-source dataset comprising two million binary-source function pairs", "explanation": "本文はデコンパイル手法そのものではなく、バイナリとソースコードのペアを提供するデータセットを紹介しているため、復元・コード生成が主目的ではなく除外基準 EC3 に該当する。"}], "reasoning": "この論文は LLM デコンパイラの評価用データセットの構築を目的としており、実際に低水準入力から高水準コードを生成する手法を提示していない。したがって、デコンパイルのコード生成・復元を目的とした研究ではなく、除外基準の「コード生成・復元が主目的でない」に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3304, "latency_ms": 104798}}
{"key": "11029887", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an approach to formally proven correct binary-level pointer analysis.", "explanation": "要旨に機械学習／LLM の使用についての記述がなく、従来の形式的解析手法のみを述べているため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿はバイナリレベルのポインタ解析を形式検証し、解析結果の信頼性を保証する手法を提案しているが、機械学習や大規模言語モデルを利用した記述が存在しない。したがって、デコンパイル研究の対象となる「ML/LLM を中核手法とする」条件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2996, "latency_ms": 96755}}
{"key": "Wan2025", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "decompile raster images into programs composed of Bézier curves", "explanation": "アブストラクトでは入力がラスタ画像（ピクセル）であると述べられており、規則で定義されている低水準表現（binary/asm/bytecode 等）には該当しないため除外基準 EC2 に該当します。"}], "reasoning": "本稿は画像（ラスタデータ）を入力とし、ベジエ曲線プログラムを生成するタスクを『ビジュアルデコンパイラ』と呼んでいますが、スクリーニング規則で指定された低水準入力（バイナリ・アセンブリ等）ではありません。そのため、対象外 (exclude) と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3421, "latency_ms": 115359}}
{"key": "Wang2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "Binary decompilation ...; we propose ... leveraging in-context learning (ICL) to guide LLMs toward generating re-executable source code.", "explanation": "抽象から、低水準のバイナリを入力とし、LLM を用いて再コンパイル可能なソースコード（L1）を直接生成することが目的と示されているため、Core Decompilation に該当します。"}], "reasoning": "本稿はバイナリという低水準入力から、LLM を中心手法として再実行可能な高水準ソースコードを生成することを目的としている。目的はコードの復元・可読化・コンパイル可能性の向上であり、ICL4Decomp というハイブリッド手法で直接 L1 レベルの出力を提供する点が IC1（in_core）に該当する。したがって、スクリーニング基準に基づき「include」と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3182, "latency_ms": 105826}}
{"key": "Wang2023", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "proposes a graph neural network (GNN) based vulnerability detection for smart contracts", "explanation": "目的は脆弱性検出であり、コードの復元や可読化を行うことが主目的ではなく、単なる分類/検知であるため除外基準 EC3 に該当します。"}], "reasoning": "本論文はバイトコードを逆コンパイルしてオペコードを取得し、CFG を構築した上で GNN による脆弱性検出を行う手法を提案しています。デコンパイルは前処理として利用されており、復元・可読化など高水準コード生成が目的ではないため、デコンパイル・サーベイの採択基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3162, "latency_ms": 101181}}
{"key": "Wang2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "We propose ... a novel binary decompilation method ... fine-tunes an LLM using the reconstructed SALT to generate decompiled code.", "explanation": "LLM を中核手法として低水準のアセンブリ（バイナリ）からソースコードを直接生成しているため、Core Decompilation に該当します。"}], "reasoning": "本稿はバイナリ（アセンブリ）を入力とし、LLM を用いて高水準のソースコードを生成する手法を提案している。目的はコードの復元・可読化であり、ML/LLM が中心的手法として使用されているため、包括基準を満たし、in_core として採択します。", "model": "openai/gpt-oss-120b", "tokens_used": 3301, "latency_ms": 103617}}
{"key": "Wang2025", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "LLM-refined decompile tool to identify vulnerable functions", "explanation": "LLM を用いて既存のデコンパイラ出力を改善し、脆弱な関数を抽出している点が Decompiler Enhancement に該当するため"}], "reasoning": "本論文は Ethereum バイトコードという低水準入力を対象に、LLM を中心手法としてデコンパイルツールを改良し、可読性と脆弱関数の特定を行う。目的がコードの復元・可読化であり、LLM/ML が核心であることから Core/Peripheral の Decompiler Enhancement として採択すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3194, "latency_ms": 101482}}
{"key": "Wong2023", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "we investigate the feasibility of using LLMs to augment decompiler outputs, thus delivering recompilable decompilation.", "explanation": "LLM が既存のデコンパイラ出力（Cコード）に対して改善（再コンパイル可能に）を行う手法であり、IC2 の Decompiler Enhancement に該当するため"}], "reasoning": "本稿はバイナリをデコンパイルした C コードを入力とし、LLM を用いて再コンパイル可能な形に補強する手法を提案している。LLM が中心手法であり、目的は復元・可読化・再コンパイル可能なコード生成であるため、Decompilation Survey の対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3355, "latency_ms": 105670}}
{"key": "10594168", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "decompiling component is used to get the source of the procedure to be tested", "explanation": "要旨はマルウェア検出が主目的であり、デコンパイルはソース取得の前処理に過ぎず、コード生成や復元を目的としていないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はマルウェア検出手法の提案で、デコンパイルは検出のための入力取得手段として言及されるだけで、LLM/ML を用いたコードの復元や生成は行っていません。そのため、デコンパイルにおけるコード生成・復元の意図がないことから除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3600, "latency_ms": 121044}}
{"key": "Wu2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "even decompiling assembly code", "explanation": "アブストラクトはChatGPTを用いてアセンブリコードを高水準コードに変換（デコンパイル）していることを示しており、低水準入力からLLMが直接コード生成を行うため、Core Decompilation に該当します。"}], "reasoning": "本論文はLLM（ChatGPT）を中心手法として、アセンブリという低水準入力からコードを生成するデコンパイルを実施している点で、IC0 を満たすコアデコンパイル研究と判断できる。目的がコード復元・可読化であり、LLM利用が明示されているため、clusion 基準を満たすと評価した。", "model": "openai/gpt-oss-120b", "tokens_used": 3278, "latency_ms": 108110}}
{"key": "Xie2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "reverse-engineering high-level quantum algorithms from low-level circuit representations", "explanation": "低水準の量子回路（量子アセンブリ言語）を入力とし、LLM/ML（遺伝的プログラミング）で高水準の Qiskit アルゴリズムコードを生成しているため、Core Decompilation に該当します。"}, {"code": "ex_no_ml", "evidence": "genetic programming-based decompiler framework", "explanation": "遺伝的プログラミングは進化的アルゴリズムであり、機械学習手法の一種とみなせるため、ML が中核手法として使用されています。"}], "reasoning": "本論文は量子アセンブリ言語という低水準表現から、遺伝的プログラミングという機械学習手法を用いて Qiskit の高水準コードを生成するデコンパイル手法を提案している。目的は高レベルアルゴリズムの可読化・復元であり、出力はコンパイル可能なソースコード（L1）に相当するため、Core Decompilation に該当し、インクルードと判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3314, "latency_ms": 111055}}
{"key": "Xu2024", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_variable_naming", "evidence": "recover variable names from stripped binary", "explanation": "抽象からバイナリ（低水準）から変数名という高水準属性を復元することが主目的であり、LLM を中心手法としているため、変数/関数名復元に該当します。"}, {"code": "ex_no_code_generation", "evidence": "recover the source code form of a binary executable", "explanation": "出力は変数名という属性のみであり、コンパイル可能なコードは生成しないため、コード生成ではなく属性復元（L4）にあたります。"}, {"code": "ex_no_ml", "evidence": "We build a prototype, GenNm, from pre-trained generative models CodeGemma-2B, CodeLlama-7B", "explanation": "生成系 LLM を利用しており、ML/LLM が手法の中核であることが示されています。"}], "reasoning": "本論文は低水準のバイナリを入力とし、LLM を用いて変数名を復元する手法を提案しているため、decompilation の周辺タスク（属性復元）として本サーベイの対象に含めます。変数名復元は主要目的であり、LLM の使用が明示されているため、include と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3517, "latency_ms": 118071}}
{"key": "You2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "depyf decompiles bytecode generated by PyTorch back into equivalent source code", "explanation": "要旨では機械学習や大規模言語モデルの利用が全く言及されておらず、単純にバイトコードを逆コンパイルするツールとして説明されているため、ML/LLM が手法の中核でないと判断した。"}], "reasoning": "本論文は Python バイトコードをソースコードへ逆コンパイルするツールを紹介しているが、機械学習や大規模言語モデルを用いた手法は記載されていない。したがって、Decompilation Survey の採択基準で求められる「LLM/ML が中核手法」という条件を満たさないため、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3006, "latency_ms": 98032}}
{"key": "10911787", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "CNN‑BiLSTM fusion model ... enhancing classification performance.", "explanation": "アブストラクトはマルウェアの検出・分類を目的としており、コードの復元や高水準表現の生成を行う記述がなく、デコンパイルの成果物生成が主目的ではないため除外します。"}], "reasoning": "本論文はバイナリを画像やオペコード列に変換し、CNN‑BiLSTM による分類モデルでマルウェア検出を行うことが主目的です。デコンパイルは特徴抽出の一部として利用されていますが、高水準コードの生成や復元を目的としていないため、除外基準 EC3（コード生成・復元目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3180, "latency_ms": 104671}}
{"key": "Zhang2026", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "make use of on-the-fly symbolic techniques via SAT solvers", "explanation": "要旨からは機械学習や大規模言語モデルの使用が言及されておらず、手法はシンボリックSATソルバに基づくため、ML/LLMが中心手法ではないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "efficient decision procedures for trace equivalence of GKAT automata", "explanation": "研究対象はGKATオートマトンの同値判定であり、低水準バイナリやアセンブリから高水準コードを復元するデコンパイルとは無関係なアルゴリズム的問題であるため、スコープ外と判断した。"}], "reasoning": "本稿はGKATオートマトンのトレース同値性判定手法を提案しており、ML/LLM を使用したデコンパイルやコード復元とは無関係である。抽象からは低水準入力やコード生成の意図が読み取れず、対象領域外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3090, "latency_ms": 106718}}
{"key": "Zhou2025", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_input", "evidence": "FidelityGPT ... enhances decompiled code accuracy and readability", "explanation": "抄録では低水準のバイナリやアセンブリが入力であることが明示されておらず、入力が既にデコンパイルされたコードとだけ記述されているため、IC0 の「低水準入力」の有無が判断できない。"}], "reasoning": "抄録からは LLM/RAG を用いてデコンパイル結果を修正・改善することは分かるが、入力がバイナリやアセンブリといった低水準表現であるかが記載されていない。したがって、インクルード基準の IC0 を満たすか判定できず、除外基準にも該当しないため、保留（uncertain）とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3965, "latency_ms": 132014}}
{"key": "Zhou2025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "In this work, we conduct a benchmark-driven evaluation of decompilation quality...", "explanation": "抄録ではML/LLMを用いた手法について言及されておらず、単に評価・ベンチマークを実施しているだけなので、ML/LLM不使用として除外します。"}], "reasoning": "本稿はRustバイナリのデコンパイル品質を評価する実証研究であり、手法としてMLや大規模言語モデルの利用が示されていません。そのため、デコンパイルにML/LLMを中心とした手法を用いるという本サーベイの採択基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2974, "latency_ms": 105053}}
{"key": "Zou2025", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "LLMs to refine decompiler output... enhanced decompiler-LLM pipeline", "explanation": "LLM が既存デコンパイラの出力を入力とし、可読性・正確性を向上させる手法であるため、decompiler enhancement に該当する。"}], "reasoning": "本稿はバイナリから生成されたデコンパイル結果を LLM で改善する手法を提案しており、LLM/ML がコア技術である点と目的がコードの復元・可読化である点から Inclusion の基準を満たす。従って `in_decompiler_enhancement` として採択する。", "model": "openai/gpt-oss-120b", "tokens_used": 3538, "latency_ms": 117731}}
{"key": "8109451", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We evaluate current Java bytecode decompilers.", "explanation": "要旨からは機械学習・LLM の使用が全く言及されておらず、従来のデコンパイラを評価するだけなので EC1 に該当し除外となります。"}], "reasoning": "本稿は既存の Java バイトコードデコンパイラの出力品質を評価する調査であり、ML/LLM を手法の中心に用いていないため、除外基準 EC1（No ML/LLM）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2888, "latency_ms": 99210}}
{"key": "8054016", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a technique to decompile the bytecode of PLC program. By introducing the instruction template and operand template, we propose a decompiling framework", "explanation": "要旨では機械学習や大規模言語モデルの利用は言及されておらず、テンプレートベースの手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はPLCバイトコードのデコンパイル手法をテンプレートベースで提案しているが、機械学習や大規模言語モデルを用いた記述がない。したがって、Decompilation Survey の採択基準で要求される LLM/ML の使用が欠如しているため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 2961, "latency_ms": 102734}}
{"key": "11208400", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a validation framework for iOS sandbox profile decompilers, specifically targeting the SandBlaster tool.", "explanation": "抄録では ML/LLM の使用について言及がなく、従来のツール評価と最適化のみを扱っているため、ML/LLM を用いていないと判断しました。"}], "reasoning": "本論文は iOS サンドボックスプロファイルのデコンパイル精度を評価・最適化するフレームワークを提案しており、機械学習や大規模言語モデルを手法の中心に用いていない。したがって、除外基準 EC1（ML/LLM 未使用）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3113, "latency_ms": 106195}}
{"key": "9425937", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Decompilers are indispensable tools... While a large proportion of methods in an app can typically be decompiled successfully, it is common that at least some methods fail to decompile.", "explanation": "要旨からは機械学習や大規模言語モデルを用いた手法についての記述がなく、単に既存デコンパイラの失敗率を測定する調査であるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は Android アプリのデコンパイル失敗率を実証的に測定する研究であり、ML/LLM を用いた手法の提案や実装がないため、インクルード基準の IC0 を満たさない。したがって除外基準 EC1（ML/LLM 不使用）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3227, "latency_ms": 103935}}
{"key": "9631736", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.87, "reason_codes": [{"code": "ex_no_ml", "evidence": "The purpose of the article is to develop a methodology that allows you to determine the java-module ... that does not contain a hidden digital watermark.", "explanation": "要旨ではデジタルウォーターマークの埋め込みと検出手法を述べており、機械学習や大規模言語モデルの使用は言及されていないため、EC1 に該当します。"}], "reasoning": "本稿は Java バイトコードへのウォーターマーク埋め込みとその耐性評価に焦点を当てており、ML/LLM を手法の中核として用いていません。そのため、除外基準 EC1 (ex_no_ml) に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2987, "latency_ms": 102931}}
{"key": "10649756", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This chapter explores the steps necessary to get started reverse engineering an application.", "explanation": "要旨には機械学習や大規模言語モデルの利用について言及がなく、単なる解説・概念紹介であるため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿はデコンパイルの概念と手順を説明する章であり、LLM や機械学習技術を中心手法として使用している記述がない。したがって、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、include の条件を満たさない。", "model": "openai/gpt-oss-120b", "tokens_used": 2874, "latency_ms": 99761}}
{"key": "10649762", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "The idea of decompiling is to recover original source code from advanced automated analysis of assembly code.", "explanation": "要旨には機械学習や大規模言語モデルの利用が全く言及されておらず、従来の解析手法だけが説明されているため、EC1に該当し除外します。"}], "reasoning": "要旨は逆アセンブリからのソース回復や構造復元といった従来のデコンパイル技術を述べているが、ML/LLM を中心手法として使用している記述がない。したがって、本サーベイの採択基準に合致せず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2987, "latency_ms": 103891}}
{"key": "10123564", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "the first and most comprehensive large-scale empirical study of smart contract decompilers", "explanation": "本文は既存デコンパイラを評価する調査研究であり、新たなML/LLM手法を提案していないため、サーベイ/レビューに該当します。"}, {"code": "ex_no_ml", "evidence": "we conduct ... empirical study of smart contract decompilers", "explanation": "要旨にMLやLLMの使用に関する記述がなく、手法は評価・測定のみであるため、ML/LLMを用いていないと判断します。"}], "reasoning": "この論文はスマートコントラクトデコンパイラの信頼性や課題を実証的に調査したサーベイであり、LLMや機械学習を用いた新手法の提案はありません。そのため除外基準の EC4（Survey/Review）および EC1（No ML/LLM）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3222, "latency_ms": 107766}}
{"key": "9464996", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "provides comments and observations regarding decompilation of a Pascal compiler", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及されておらず、従来の手法によるデコンパイルの考察のみであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "アブストラクトからは、BESM-6 のシミュレータ開発や Pascal コンパイラのデコンパイルについてのコメント・観察が中心であり、機械学習や大規模言語モデルを用いた手法は示されていない。したがって、除外基準 EC1 (No ML/LLM) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 2821, "latency_ms": 103065}}
{"key": "8668959", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "Based on the static analysis method, we propose a method for automatically collecting forensic artifact.", "explanation": "本文は静的解析に基づく手法を述べており、機械学習やLLMの使用は言及されていないため、EC1に該当し除外と判断した。"}], "reasoning": "本研究は Android アプリを静的解析でデコンパイルし、フォレンジック情報を抽出する手法を提案しているが、機械学習や大規模言語モデルを用いたと読む根拠がなく、LLM/ML が手法の中核でないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 2962, "latency_ms": 106197}}
{"key": "8330222", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "We present a novel technique for decompiling binary code snippets using a model based on Recurrent Neural Networks.", "explanation": "低水準のバイナリ入力から RNN を用いて直接ソースコード（高水準表現）を生成しているため、Core decompilation に該当します。"}, {"code": "in_control_structure", "evidence": "recovering control flow constructs", "explanation": "抽象中に「recovering control flow constructs」とあり、制御構造の復元が目的の一部であることが分かります。"}, {"code": "in_variable_naming", "evidence": "variable or function names", "explanation": "同じく抽象に「variable or function names」の復元が言及され、識別子名の回復が目的であることが示されています。"}], "reasoning": "本稿はバイナリを入力として RNN により高水準のコードを直接生成する手法を提案しており、ML が中心手法で低水準入力・復元目的を満たすためインクルードと判断しました。制御構造や変数・関数名の復元にも言及している点から、関連するサブカテゴリも併記しています。", "model": "openai/gpt-oss-120b", "tokens_used": 3476, "latency_ms": 119630}}
{"key": "7880502", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We study effects of compilation and decompilation to code clone detection in Java.", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用について言及がなく、ML/LLM が手法の中核でないため除外基準 EC1 に該当します。"}], "reasoning": "本論文はデコンパイルをコードクローン検出の正規化手段として利用しているだけで、ML/LLM を用いた復元やコード生成を目的としていません。そのため、除外基準「No ML/LLM (ex_no_ml)」に該当し、サーベイ対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3292, "latency_ms": 115148}}
{"key": "11023256", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "to create a Python decompiler that accommodates evolving language features and changes to the bytecode specification", "explanation": "抽象ではバイトコード（低水準入力）から Python ソースコード（高水準 L1 出力）を生成することを目的としており、NLP（データ駆動型）手法を中心に用いているため、Core Decompilation に該当します。"}], "reasoning": "本稿はバイトコードを入力とし、データ駆動型 NLP（ML）を用いて高水準の Python ソースコードを直接生成するフレームワークを提案している。目的はコードの復元・可読化であり、分類や検知ではないため、Include 基準を満たす Core Decompilation 研究と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3479, "latency_ms": 119015}}
{"key": "8811905", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Key to these improvements is Gigahorse's use of a declarative, logic‑based specification", "explanation": "抽象ではMLやLLMの利用が言及されておらず、代わりに宣言的ロジックベースの手法が中心であるため、除外基準EC1に該当します。"}], "reasoning": "本論文はEVMバイトコードを高レベルの3アドレスコードへ逆コンパイルする手法を提案していますが、手法は宣言的ロジックベースであり機械学習や大規模言語モデルは用いられていません。したがって、Decompilation Survey Screening Rulesの除外基準 EC1 (No ML/LLM) に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3189, "latency_ms": 108359}}
{"key": "10179314", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a precise and scalable symbolic analysis called fearless symbolic analysis", "explanation": "要旨はシンボリック解析手法を提案しており、ML/LLM の使用は言及されていないため、EC1 の『No ML/LLM』に該当します。"}], "reasoning": "本稿はバイナリから逆コンパイルされたコード上でクエリを記述しシンボリック解析を行うツールを紹介していますが、機械学習や大規模言語モデルを手法の中核として用いている記述がありません。そのため、除外基準 EC1 (No ML/LLM) に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3248, "latency_ms": 108440}}
{"key": "10179370", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "The core of our approach is the concept of Forensically Equivalent Transformation (FET) ...", "explanation": "要旨からは機械学習や大規模言語モデルの利用が全く示されず、変換手法はルールベースのプログラム変換であるため、IC の ML/LLM 条件を満たさず除外します。"}], "reasoning": "本稿は Python バイナリを変形してデコンパイル可能にする手法を提案しており、機械学習や LLM を用いたアプローチが記述されていません。したがって、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3056, "latency_ms": 105514}}
{"key": "10967090", "action": "keep", "reason": "in_control_structure", "details": {"decision": "include", "confidence": 0.85, "reason_codes": [{"code": "in_control_structure", "evidence": "many Java decompilers cannot recover originally lost sources, especially the selection statement, i.e., if statement... KNN is used to classify the proposed feature.", "explanation": "要約は低水準入力として Java bytecode を扱い、KNN などの機械学習で特徴を分類し、if 文という制御構造の復元を目的としているため、制御構造回復に該当します。"}], "reasoning": "本論文は Java バイトコードという低水準表現を入力とし、機械学習（GA と KNN）を用いて制御構造（if 文）を識別・復元する手法を提案している。目的はデコンパイルの精度向上であり、制御構造回復というコアテーマに該当するため、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3448, "latency_ms": 122801}}
{"key": "10986108", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "by replacing bytecode opcodes and adding certain Java programming language constructs that hinder decompilation", "explanation": "要旨に機械学習や大規模言語モデルの使用についての記述がなく、純粋に手法的にバイトコードを書き換えるだけであるため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "remains resilient to decompilation attacks aimed at its removal", "explanation": "研究の目的はデコンパイルを防止することであり、デコンパイルによる高水準コード復元や再構成を行うものではなく、サーベイの対象外とみなした。"}], "reasoning": "本稿はデジタル透かしを埋め込んでデコンパイルを困難にする手法を提案しているが、機械学習や大規模言語モデルを用いた手法は示されていない。また、目的はコード復元ではなく逆にデコンパイルを防ぐことであり、デコンパイル研究のコア対象から外れるため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3210, "latency_ms": 114789}}
{"key": "9589721", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "In this paper, we discuss an approach which allows an attacker to modify the control logic program ... employs a decompiler to convert the stolen compiled bytecode (low-level) to its decompiled version (high-level) e.g. Ladder Diagram LAD.", "explanation": "要旨では機械学習や大規模言語モデルの使用が全く言及されておらず、従来のデコンパイラを利用した攻撃手法を説明しているため、ML/LLM が中核手法でないことが明らかです。"}], "reasoning": "本稿は PLC 攻撃の実装を示すもので、デコンパイルは攻撃チェーンの一部として利用されていますが、ML/LLM を用いた手法は提示されていません。したがって、Decompilation Survey の採択基準（IC0）を満たさず、除外基準 EC1 (ex_no_ml) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3219, "latency_ms": 112485}}
{"key": "9453483", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "we show how to retrieve the Bytecode from the target and decompile the Bytecode to STL source code", "explanation": "要旨に機械学習・LLMの利用について言及がなく、従来の手法でバイトコードを逆コンパイルしているため、ML/LLM が用いられていないと判断しました。"}], "reasoning": "本論文は PLC の脆弱性を利用した攻撃手法を示すもので、バイトコードの逆コンパイルは行うが、ML/LLM を用いたデコンパイルは行っていません。したがって、デコンパイル研究のML/LLM コア手法という採択基準を満たさず、除外基準 EC1 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3162, "latency_ms": 112021}}
{"key": "11334528", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a novel file format-based anti-decompilation strategy ...", "explanation": "本文では機械学習や大規模言語モデルを用いた手法について言及せず、従来のファイルフォーマット変換による保護手法のみを述べているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "These methods include ... that deliberately trigger these vulnerabilities by introducing specific structural anomalies into APK files", "explanation": "目的はデコンパイルを防止することであり、コードの復元・生成・可読化といったデコンパイルの出力生成を意図していないため、コード生成・再構築の目的が欠如している。"}], "reasoning": "この論文は Android アプリの逆コンパイルを阻止する保護手法を提案しており、機械学習や大規模言語モデルを使用したデコンパイルやデコンパイラの改善に関する研究ではない。したがって、ML/LLM が用いられていない点と、コード生成・復元を目的としていない点から除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3387, "latency_ms": 116855}}
{"key": "10035436", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "we improve an existing decompilation tool by leveraging the characteristics of JNI programs", "explanation": "要旨からは機械学習・LLM の使用が言及されておらず、従来のデコンパイラ改良のみであるため、ML/LLM を中核手法としない研究と判断した。"}], "reasoning": "本文は既存のデコンパイラを JNI の特性に合わせて改善することに焦点を当てており、機械学習や大規模言語モデルを利用した手法は示されていない。したがって、Decompilation Survey の採択基準で要求される LLM/ML の使用が欠如しているため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3081, "latency_ms": 109678}}
{"key": "11068876", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "Recent advancements have employed AI to enhance decompiler output by recovering original variable names and types.", "explanation": "AI が変数名と型を復元することを目的としており、変数・関数名の回復が主目的であるため"}, {"code": "in_decompiler_enhancement", "evidence": "We conducted a user study ... to assess code comprehension both with and without AI-generated variable and type name assistance.", "explanation": "AI が生成した変数名・型情報で既存のデコンパイラ出力を改善し、その効果を評価しているため"}], "reasoning": "本稿はバイナリから生成されたデコンパイルコードに対し、LLM/AI により変数名や型情報を自動付与する手法を評価している。低水準入力からの属性回復（変数名・型）を目的としており、デコンパイル支援の一環として位置付けられるため、Peripheral 条件を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3751, "latency_ms": 131025}}
{"key": "11367734", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "We propose DECodeT5, a lightweight and efficient neural decompilation method for the C language... integrating a pre-trained assembly encoder... end-to-end decompilation tasks...", "explanation": "アブストラクトは、アセンブリ（低水準）入力から C ソース（高水準、コンパイル可能）を直接生成する手法を提示しており、LLM/ML が中心手法であるため、Core Decompilation に該当します。"}], "reasoning": "本稿はアセンブリコードを入力とし、LLM（CodeT5）を用いて C 言語のソースコードを生成するニューラルデコンパイラを提案している。目的は高水準コードの復元であり、LLM が中核技術として使用されているため、インクルード基準 (IC0) を満たし、Core Decompilation (in_core) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3167, "latency_ms": 111962}}
{"key": "10646727", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "predict meaningful variable names in decompilation output", "explanation": "Abstract では decompilation の出力に対して変数名を予測することが主目的と明示されているため、変数/関数名復元に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "modern decompilers ... cannot recover lost variable names", "explanation": "既存のデコンパイラ出力（C ソース）に対し、ML 手法で名前付けを改善する研究であり、デコンパイラ出力の強化に該当します。"}], "reasoning": "本稿はバイナリから生成されたデコンパイルコードに対し、LLM（BERT）を用いて変数名を予測し可読性を向上させることを目的としている。入力は低水準バイナリ由来のデコンパイル出力であり、ML 手法が中心に使われている点から Inclusion 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 4103, "latency_ms": 135270}}
{"key": "11334294", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "LLMs hold promise for PTX-to-CUDA de-compilation", "explanation": "抽象からPTX（低水準）をCUDA（高水準）に変換することが目的であり、LLM が中心手法として使用されているため、Core Decompilation に該当する"}], "reasoning": "本稿は低水準 PTX を入力とし、LLM を用いて可読性の高い CUDA ソースコードを直接生成することを目的としている。IC0 の条件（低水準入力、LLM 中核、復元目的）をすべて満たすため、in_core のカテゴリで include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3311, "latency_ms": 117111}}
{"key": "10531777", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a simulation execution based code extraction method", "explanation": "本文の要旨では機械学習や大規模言語モデルの使用が言及されておらず、シミュレーション実行によるコード抽出とヒューリスティック解析のみが述べられているため、ML/LLM が使われていないと判断した。"}], "reasoning": "本研究はPLC プログラムから制御ロジックを抽出するフレームワークを提案しているが、手法はシミュレーション実行やヒューリスティックデータフロー解析に基づくものであり、機械学習・LLM を中心手法として用いていない。したがって、Decompilation Survey の採択基準で要求される ML/LLM の使用が欠如しているため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3174, "latency_ms": 117464}}
{"key": "11334626", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "PseudoFix employs semantic retrieval ... combine this with the well-structured coding patterns learned by LLMs ... to efficiently refactor distorted pseudocode.", "explanation": "LLM が既存のデコンパイルされた疑似コードを入力として受け取り、構造歪みを修正し可読性を向上させる手法であるため、デコンパイラ出力の改善に該当する。"}, {"code": "in_control_structure", "evidence": "significantly outperforms ... in both temporary variable elimination and goto statement removal tasks.", "explanation": "制御構造（goto 文の除去）や構造化の修正が主要な目的の一つであるため、制御構造復元のカテゴリも当てはまる。"}], "reasoning": "本稿はバイナリから生成された C 疑似コードの構造歪みを LLM を用いて修正するフレームワークを提案しており、低水準入力から高水準表現への復元を目的としたデコンパイラ出力の改善研究に該当する。目的は可読性向上・構造復元であり、ML 手法が中心であるため include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3473, "latency_ms": 125159}}
{"key": "9282790", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach first uses a decompilation tool (remill) to extract low-level intermediate representation (LLVM) from the machine code.", "explanation": "要旨に機械学習や大型言語モデルの使用は記載されておらず、従来のツールとデータフロー解析のみで構成されているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は機械コードから LLVM IR への変換とその後のデータフロー解析・シンボリック実行に焦点を当てており、LLM や機械学習手法は使用していない。したがって、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3072, "latency_ms": 115826}}
{"key": "11050729", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "extending Ghidra Objective-C capabilities to improve decompilation accuracy", "explanation": "本文の要旨では機械学習や大規模言語モデルの使用が全く言及されておらず、従来の静的解析・プラグイン拡張のみが述べられているため、ML/LLM が中核手法でないことが判定できる。"}], "reasoning": "本論文は Objective-C バイナリに対する静的解析と Ghidra デコンパイラの拡張を扱っているが、機械学習や大規模言語モデルを用いた手法が記載されていない。したがって、Decompilation Survey の採択基準で要求される LLM/ML の使用が欠如しているため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3037, "latency_ms": 116035}}
{"key": "10515515", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "use of artificial intelligence in the field of genetic algorithms to restore the source code of software executed in the form of machine code", "explanation": "遺伝的アルゴリズム（ML の一種）で機械語から C ソースコード（コンパイル可能な高水準コード）を直接生成しており、デコンパイルのコア目標を満たすため in_core と判定した。"}], "reasoning": "本稿は機械コード（低水準入力）を遺伝的アルゴリズムという機械学習手法で解析し、C 関数のソースコード（L1 出力）を復元することを目的としている。復元されたコードは脆弱性分析に用いられる点から、復元・可読化が主目的であると判断できる。したがって、コアデコンパイル研究として include と評価する。", "model": "openai/gpt-oss-120b", "tokens_used": 3263, "latency_ms": 119492}}
{"key": "9833799", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This paper conducts an in-depth study of binary lifters ... We summarize our findings and make suggestions", "explanation": "本文はバイナリリフターの系統的調査・評価を行う SoK 論文であり、手法の提案や実装はなく調査研究であるため除外基準の Survey/Review に該当する。"}, {"code": "ex_no_ml", "evidence": "The abstract makes no mention of machine learning or LLM techniques.", "explanation": "要旨に機械学習や大規模言語モデルの利用が記載されていないため、ML/LLM が使用されていないことが確認でき、除外基準の No ML/LLM にも該当する。"}], "reasoning": "本稿はバイナリリフターの評価と応用に関する体系的調査（SoK）であり、機械学習やLLM を用いたデコンパイル手法の提案は行っていない。したがって、Survey/Review と No ML/LLM の除外基準に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3436, "latency_ms": 120885}}
{"key": "10773695", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present IRENE, a decompiler that produces recompilable decompilation for patching.", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が言及されていないため、ML/LLM が手法の中核であるという条件を満たさず、除外基準 EC1 に該当します。"}], "reasoning": "本稿はバイナリをデコンパイルして高レベル表現を生成するツールを提案していますが、手法として機械学習や大規模言語モデルを用いている記述がなく、ML/LLM が中心的手法であるという要件を満たしていません。そのため除外基準 ex_no_ml に基づき除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3124, "latency_ms": 115186}}
{"key": "10581196", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "Through a combination of automated processes and user-friendly features, our tool allows...", "explanation": "アブストラクトではML/LLMの利用について言及されておらず、単に自動化されたプロセスとUIを用いると記述されているため、ML/LLMが手法の中核であると判断できません。"}], "reasoning": "本論文はAPKのデコンパイル機能を提供するフォレンジックツールを紹介していますが、手法として機械学習や大規模言語モデルの活用は示されていません。したがって、Decompilation Survey Screening RulesのExclude Criteria（EC1: No ML/LLM）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 115504}}
{"key": "11185876", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a new technique for identifying abstract syntax tree components", "explanation": "要旨に機械学習や大型言語モデルの使用は言及されておらず、従ってML/LLMが手法の中核でないため除外します。"}], "reasoning": "本稿はAST上でスイッチ構造を回復する手法を提案しているが、機械学習やLLMの利用についての記述がなく、デコンパイルの改善にはMLが必須という本サーベイの採択基準を満たさない。そのため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3200, "latency_ms": 118031}}
{"key": "11129273", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we review existing methods, comparing them, while highlighting both their advantages and limitations", "explanation": "要旨は既存の制御フロー構造化手法の体系化・比較であり、実装やML/LLMを用いた新規手法の提案ではなく調査・レビュー論文なので、このコードが該当します"}], "reasoning": "本論文はDecompilersの制御フロー構造化に関するSoK（Survey）であり、ML/LLM を用いたデコンパイル手法の開発や改善を提示していません。そのため除外基準 EC4（Survey/Review）に該当し、include できません。", "model": "openai/gpt-oss-120b", "tokens_used": 3016, "latency_ms": 111438}}
{"key": "11352404", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we introduce a structural analysis algorithm specifically for PHP syntax", "explanation": "アブストラクトではアルゴリズムや中間表現の設計が述べられているが、機械学習や大規模言語モデルの使用は明示されておらず、ML/LLM が手法の中核ではないため除外と判断した。"}], "reasoning": "本稿は PHP バイトコードからソースコードを復元する手法を提案しているが、機械学習や大規模言語モデルの利用についての記述がなく、ルールベース／アルゴリズム中心のアプローチと考えられる。したがって、Decompilation Survey の採択基準である LLM/ML の使用を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3219, "latency_ms": 116572}}
{"key": "8406593", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a tool that decompiles real firewall configurations ... and uses the Z3 solver to synthesize the abstract specification", "explanation": "要約では機械学習や大規模言語モデルの利用が全く言及されておらず、Z3ソルバーによる手法のみが説明されているため、ML/LLM が中心手法でないと判断した。"}], "reasoning": "本研究はファイアウォール設定を低レベル言語から抽象仕様へ変換する手法を提案しているが、使用技術はZ3ソルバーであり機械学習やLLMは含まれない。したがって、デコンパイル調査の包括基準（LLM/ML が中核手法）を満たさず、除外基準 ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3164, "latency_ms": 116000}}
{"key": "9850326", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the control-logic obfuscation subverts the engineering software’s decompilation function", "explanation": "本文は decompilation 機能を攻撃対象としており、ML/LLM を利用した手法については言及されていないため除外基準 EC1 に該当します。"}], "reasoning": "この論文は産業制御システムの制御ロジックを難読化し、既存のエンジニアリングソフトウェアのデコンパイル機能を妨害する攻撃手法を提案しています。ML/LLM を用いたデコンパイルや復元手法ではなく、攻撃手法の提示に留まっているため、スクリーニング基準の除外条件 (ML/LLM 未使用) に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3008, "latency_ms": 115635}}
{"key": "8936022", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "The method of decompiled code static analysis has been improved.", "explanation": "要旨は静的解析手法の改良について述べており、機械学習や大規模言語モデルの使用は言及されていないため、EC1 に該当し除外します。"}], "reasoning": "本稿はデコンパイルされたコードの品質測定を対象とした静的解析手法の改善を提案しているが、ML/LLM を用いた手法についての記述がなく、除外基準 EC1（ML/LLM を使用していない）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 2976, "latency_ms": 117951}}
{"key": "9647781", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "In contrast to previous approaches, our method does not require manual work to create the patterns for matching idioms", "explanation": "本文中に機械学習や大規模言語モデルの利用が示されておらず、ルールベース・パターンマイニング手法と記述されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文はバイナリ中のコンパイライディオムをパターンマッチングで検出・注釈付けし、元の高水準表現に戻す手法を提案しているが、機械学習や大規模言語モデルを用いた旨の記述がなく、完全にルールベースのアプローチであるため、当サーベイのインクルード基準を満たさない。", "model": "openai/gpt-oss-120b", "tokens_used": 3144, "latency_ms": 117737}}
{"key": "8210757", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Applying to the source code techniques of reverse engineering, we will try to perform an analysis", "explanation": "要旨では機械学習／LLM の使用について言及がなく、従来のリバースエンジニアリング手法のみであると解釈できるため、IC0 の条件を満たさず除外する。"}], "reasoning": "本稿は Android アプリのセキュリティ監査を目的に、従来手法でデコンパイルを行うが、LLM や機械学習を中心手法として利用している記述がなく、デコンパイルの LLM/ML コア利用が前提のサーベイ対象外である。したがって除外 (ex_no_ml) と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3277, "latency_ms": 120542}}
{"key": "10320193", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_variable_naming", "evidence": "Building a model to reassign descriptive names for binary functions ...", "explanation": "バイナリ関数に対して名前を再割り当てすることが主目的であり、これは変数/関数名復元に該当するため"}, {"code": "ex_no_ml", "evidence": "leverages a decompiler to obtain a specific representation and applies the corresponding serialization strategy on it. NER then uses an alternative neural network to make predictions.", "explanation": "本文中でニューラルネットワーク（ML）を用いて名前予測を行っていることが明示されているため、ML使用の要件を満たす"}], "reasoning": "本稿はバイナリコード（アセンブリ・IR・疑似コード）を入力とし、ニューラルモデルで関数名を予測することを目的としている。入力は低水準表現であり、ML手法が中心に使われ、出力は関数名という高レベル属性であるため、decompilation の周辺領域（Peripheral）に該当し、`in_variable_naming` として採択すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3427, "latency_ms": 127417}}
{"key": "10043270", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "code obfuscation techniques are applied to smart contracts", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が記載されておらず、単なるオブfuscation手法の提案であるため、ML/LLM が中心手法でないと判断しました。"}], "reasoning": "本稿はスマートコントラクトのバイトコードを難読化する手法を提案しており、デコンパイルを実施・改善する目的やML/LLM の利用は示されていません。そのため、デコンパイル調査の対象外であり、除外基準 ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2918, "latency_ms": 115109}}
{"key": "10197775", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The purpose of this research is to investigate ... the SootDiff analysis tool, a bytecode comparison tool", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用について言及されておらず、単にバイトコード比較ツールによる手法のみが説明されているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本論文はバイトコード比較ツールによるコード改ざん検出を扱っており、機械学習や大規模言語モデルを使用した手法が記載されていない。したがって、Decompilation Survey の採択基準で要求される LLM/ML の中核的利用が欠如しているため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3079, "latency_ms": 118253}}
{"key": "11052248", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "Addressing the detection blind spots in existing source code analysis techniques...", "explanation": "要旨に機械学習や大規模言語モデルの使用について言及がなく、従来の暗号・ブロックチェーン技術のみが説明されているため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "privacy leakage risks caused by decompilation techniques and integrity verification deficiencies in reverse engineering", "explanation": "入力はソースコード解析やコンポーネントの検出に関するもので、バイナリやアセンブリ等の低水準表現が明示されていないため、低水準入力が欠如していると判断した。"}], "reasoning": "本稿はブロックチェーンとゼロ知識証明を用いた信頼性検出フレームワークを提案しており、デコンパイル自体の生成や復元を目的とした手法は示さず、機械学習／LLM の使用も記載されていない。したがって、デコンパイル調査の採択基準を満たさないため除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3419, "latency_ms": 124807}}
{"key": "9445905", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The SM4 encryption algorithm and look-up table are creatively used", "explanation": "抽象からML/LLMが使用されている旨の記述がなく、純粋に暗号アルゴリズムとテーブルを用いた保護手法であるため、EC1に該当し除外する。"}], "reasoning": "本論文はELFファイルの保護手法を提案しており、暗号化やコード難読化を中心とした技術であり、機械学習や大規模言語モデルを利用したデコンパイル手法は示されていない。したがって、デコンパイルにML/LLMが中核手法として用いられる本サーベイの採択基準を満たさず、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3132, "latency_ms": 120233}}
{"key": "11081372", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "uses Ghidra's improved, advanced capabilities of decompilation and scripts", "explanation": "要旨では機械学習や大規模言語モデルの利用が記載されておらず、Ghidra のスクリプトだけで実装されているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "identifying malicious code ... to extract features, ... detection ... 89% success rate of malware detection", "explanation": "本研究の主目的はマルウェアの検出・分類であり、コードの復元や高水準表現の生成ではなく、特徴抽出と判定に焦点を当てているため、コード生成／復元の意図がないと判断した。"}], "reasoning": "本稿は Ghidra を用いてバイナリをデコンパイルし特徴抽出を行い、マルウェア検出を目的とした静的解析フレームワークを提案している。機械学習や LLM の手法は使用されておらず、また生成されたコードの可読化や再構築が目的ではなく分類が中心であるため、デコンパイルを中心とした LLM/ML 研究の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3397, "latency_ms": 128220}}
{"key": "9259834", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "machine learning models were created by using the n-gram features of the smali files ... their performances are reported", "explanation": "要旨は smali（低レベルバイナリ表現）から特徴を抽出しマルウェア分類モデルを構築することであり、コードの復元や高レベル表現の生成は目的としていないため、コード生成/再構成意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文は機械学習を用いて Android の smali からマルウェア検出モデルを構築する分類タスクであり、デコンパイルによるコード復元や高レベル表現生成を目的としていません。したがって、コード生成・再構成意図がないことから除外基準に該当し、exclude と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3076, "latency_ms": 121048}}
{"key": "9331988", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This research proposed a methodology to protect the application assets from piracy using the cryptographic algorithm.", "explanation": "要旨からは機械学習・大規模言語モデルの使用が全く示されておらず、従ってルールの EC1（ML/LLM 未使用）に該当すると判断した。"}], "reasoning": "本稿は暗号化による資産保護手法を提案しており、デコンパイルやコード復元を目的としていない。また、機械学習や LLM を手法の中心に用いている記述がなく、除外基準 EC1（ML/LLM を使用していない）に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 2913, "latency_ms": 114131}}
{"key": "8299877", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "A code obfuscation technique has been proposed to complicate the process of reverse engineering.", "explanation": "要旨に機械学習や大規模言語モデルの利用について言及がなく、従ってML/LLMを用いた手法ではないため除外と判断しました。"}], "reasoning": "本稿は逆コンパイルを防止するためのコード難読化手法を提案しており、ML/LLM を用いたデコンパイルや復元を目的とした研究ではありません。したがって、除外基準 EC1 (No ML/LLM) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3124, "latency_ms": 120350}}
{"key": "9948365", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The experimental results show that the accuracy of vulnerability detection on SARD data set is 96.92%", "explanation": "アブストラクトはバイナリをpcodeにデコンパイルし特徴ベクトルを抽出して脆弱性検出（分類）を行うことを目的としており、コード生成・復元が主目的ではないため除外基準EC3に該当します。"}], "reasoning": "本稿はニューラルネットワークを用いたバイナリ脆弱性検出手法を提案しており、デコンパイルは特徴抽出の前処理として利用されているだけで、復元・可読化を目的としたコード生成は行っていません。したがって、デコンパイルを核心とした研究ではなく、除外基準EC3（コード生成・復元意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3071, "latency_ms": 120883}}
{"key": "9718856", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "measure the similarity of smart contract bytecode", "explanation": "要旨はバイトコードの類似度測定が目的であり、コードの復元や高水準表現の生成は行わないため、コード生成/復元の意図が欠如しています。"}], "reasoning": "本稿はスマートコントラクトのバイトコードを CFG へ変換し類似度を測定する手法を提案していますが、低水準入力から高水準コードを生成することやデコンパイル結果の改善を目的としていません。また、ML/LLM の使用も明示されていないため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3142, "latency_ms": 123497}}
{"key": "9421647", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect whether the target area has stack overflow vulnerabilities", "explanation": "本文はバイナリの脆弱性を検出することを目的としており、復元・高水準コード生成や構造化が主目的ではなく、分類タスクに該当するため除外基準 EC3 に該当します。"}, {"code": "ex_out_of_scope", "evidence": "binary vulnerability detection method based on the attention mechanism", "explanation": "研究の焦点は脆弱性検出であり、デコンパイル（低水準から高水準コードの復元）とは異なる領域であるため、サーベイのスコープ外です。"}], "reasoning": "本論文はバイナリのスタックオーバーフロー脆弱性を検出することを目的とした分類手法を提案しており、コード生成や高水準表現の復元を行わないため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3047, "latency_ms": 121645}}
{"key": "10123584", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose an LLVM-based code virtualization tool, namely xVMP ...", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用は一切記載されていないため、ML/LLM が手法の中核であるという条件を満たさない。"}, {"code": "ex_out_of_scope", "evidence": "code virtualization ... prevents code from being decompiled.", "explanation": "本研究の目的はコードを難読化し逆コンパイルを防ぐことであり、デコンパイルや高水準表現の復元を行うことが主目的ではないため、調査対象外（アウト・オブ・スコープ）に該当する。"}], "reasoning": "本稿は LLVM ベースのコード仮想化による難読化手法を提案しており、デコンパイルやコード復元を目的とした研究ではない。また、機械学習・LLM を用いた手法も記載されていないため、インクルード基準を満たさない。", "model": "openai/gpt-oss-120b", "tokens_used": 3198, "latency_ms": 120364}}
{"key": "9141591", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "research decompiles the VBE system, builds a test platform, sorts out its weak links", "explanation": "要旨では VBE システムをデコンパイルしてテストプラットフォームを構築するとあるが、機械学習や大規模言語モデルの使用については一切言及されていないため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本文は VBE システムのデコンパイルと運用・保守技術の改善に焦点を当てているが、手法として機械学習や大規模言語モデルが用いられているという記述がなく、除外基準 EC1（ML/LLM 未使用）に該当する。したがって本論文は本サーベイの対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 2997, "latency_ms": 120943}}
{"key": "9631860", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "the de-compilation is done using the MobSF tool", "explanation": "抽象では機械学習や大型言語モデルの使用が述べられておらず、従来のツールのみで実施しているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "to find out whether or not WhatsApp Plus has been inserted with malware, spyware, or other malicious code", "explanation": "研究の目的はマルウェアの有無を判断することであり、コードの復元・生成が主目的ではなく分類・検出が中心であるため除外基準に該当する。"}], "reasoning": "本稿は静的解析ツールによるデコンパイル後のコード比較を通じてマルウェア有無を判定する研究であり、機械学習/LLM を用いた手法は示されていない上、目的もコード復元ではなく悪意判定である。従って、Decompilation Survey の対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3440, "latency_ms": 129788}}
{"key": "8109245", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a method to insert an additional security policy code ... decompiling the target app", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く言及されておらず、従来の手法のみで実装されているため、ML/LLM が中核手法ではないと判断しました。"}], "reasoning": "本論文はバイナリアプリのデコンパイル後にセキュリティポリシーコードを挿入する手法を提案しているが、機械学習や LLM を利用した手法についての記述がなく、サーベイの採択基準である「LLM/ML が中核手法として用いられる」条件を満たさないため除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3196, "latency_ms": 122452}}
{"key": "10857519", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "methods that require decompilation, static and dynamic analysis of test samples are difficult to run on IoT devices", "explanation": "本文はバイト n‑gram と機械学習によるマルウェア検出・分類が目的であり、コードの復元や生成を行わないため、コード生成・再構成の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本研究は IoT デバイス上で動作可能なマルウェア分類手法を提案しており、目的はバイト n‑gram と SVM による検出で、デコンパイルや高水準コードの復元は行わない。したがって、デコンパイルを中心とした LLM/ML 手法を用いた研究という本調査の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3158, "latency_ms": 123241}}
{"key": "9115191", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "While analyzing the risks faced by mobile applications, this article also enumerates and analyzes the necessary measures for risk resolution.", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、単なるリスク分析と対策の列挙であり、ML/LLM を用いたデコンパイル手法が提示されていないため除外します。"}], "reasoning": "本稿はモバイルアプリの情報セキュリティリスクと対策を論じるレビュー的内容であり、デコンパイルそのものや ML/LLM を用いた高水準コード生成・改善に関する研究ではありません。したがって、除外基準 EC1 (= ex_no_ml) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3060, "latency_ms": 120502}}
{"key": "10077138", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Replacing these instructions with another more complex order ... which will make the decompilation work more difficult, thus realizing a code obfuscation system", "explanation": "要旨には機械学習や大規模言語モデルの使用が一切言及されておらず、単なるコード難読化手法の提案なので、EC1 に該当し除外されます。"}], "reasoning": "本稿は LLVM を用いたコード難読化手法を提案しており、ML/LLM を利用したデコンパイル支援や復元は行っていません。入力は低水準表現でもなく、目的も復元や可読化ではなく難読化そのものです。そのため、除外基準 EC1（ML/LLM 未使用）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2981, "latency_ms": 120603}}
{"key": "9117398", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "PILDroid adopts tainted analysis based on static method.", "explanation": "要旨には機械学習や大規模言語モデルの利用が記載されておらず、従来の静的解析手法のみが使用されているため、ML/LLM が使用されていないと判断しました。"}], "reasoning": "本稿は JNI のバイナリを LLVM IR にデコンパイルしてプライバシ情報漏洩を検出する静的解析システムを提案していますが、手法として機械学習・LLM を用いていないため、除外基準 EC1（ex_no_ml）に該当します。デコンパイル自体は補助的な前処理であり、研究の中心は taint analysis である点も除外の根拠です。", "model": "openai/gpt-oss-120b", "tokens_used": 3210, "latency_ms": 126120}}
{"key": "7889345", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper investigates what is the possibility of retrieving the information about compiler name and version based on the content of the binary code, without decompiling the binary code.", "explanation": "要旨に機械学習や大規模言語モデルの利用について記述がなく、従来の手法でコンパイラ情報を抽出することを目的としているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "the information can be found in most of the binary files. This paper investigates what is the possibility of retrieving the information about compiler name and version...", "explanation": "目的はコンパイル情報の取得・判別であり、ソースコードや擬似コードなどの高水準表現を生成することはなく、コード生成・復元が主目的ではないため除外基準に該当する。"}], "reasoning": "本研究はバイナリからコンパイラ名・バージョンを抽出する手法を提案しており、ML/LLM の使用が示されていない上に、コードの復元や高水準表現の生成を目的としていない。したがって、デコンパイル調査の対象外（exclude）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3138, "latency_ms": 124852}}
{"key": "9638928", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "decompile the APK file to obtain the opcode features", "explanation": "要約ではデコンパイルはopcode特徴抽出のために使用されており、コードの復元や可読化が目的ではなく、マルウェア検出という分類タスクが主目的であるため、コード生成・再構成の意図がないと判断した。"}], "reasoning": "本論文はデコンパイルを特徴抽出の前処理として利用し、最終的な目的はマルウェア検出という分類である。復元・可読化・高水準コード生成を目的としたLLM/MLを用いたデコンパイル研究ではないため、除外基準 EC3（コード生成・再構成意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3018, "latency_ms": 121069}}
{"key": "8859456", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach is based on code analysis to systematically test the targeted code of the Android apps.", "explanation": "アブストラクトからは機械学習や大規模言語モデルを用いた旨の記述がなく、従来のコード解析手法だけが述べられているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "It analyzes the decompiled code that identifies the code related to Android SDK version", "explanation": "入力は既にデコンパイルされたコード（高水準表現）であり、バイナリやアセンブリといった低水準入力が前提とされていないため、除外基準の \"No Low-level Input\" に該当する。"}], "reasoning": "本稿は Android アプリのテスト用ランタイム環境を生成する手法を提案しているが、使用技術はコード解析のみで機械学習や LLM が中心手法として記述されていない。また、対象はデコンパイル済みコードであり、低水準バイナリ入力を前提としていないため、デコンパイルに関する ML/LLM 研究の検索基準から外れる。", "model": "openai/gpt-oss-120b", "tokens_used": 3204, "latency_ms": 126641}}
{"key": "11205440", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "evaluates ... LLMs ... in detecting malware from decompiled.c code", "explanation": "目的はマルウェアの検出（分類）であり、コード生成や復元は行っていないため除外基準 EC3 に該当する。"}, {"code": "ex_no_lowlevel_input", "evidence": "decompiled.c code derived from Portable Executable (PE) files", "explanation": "入力は既にデコンパイルされた C コードであり、低水準表現（バイナリ/アセンブリ等）ではないため除外基準 EC2 に該当する。"}], "reasoning": "本稿は LLM を用いたマルウェア検出を目的としており、コード生成や復元といったデコンパイルの核心的目的がない上、入力が低水準のバイナリやアセンブリではなくデコンパイル済みの C ソースであるため、デコンパイル調査の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3350, "latency_ms": 130316}}
{"key": "8572021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "by decompiling and recompiling the program", "explanation": "本文はデコンパイルとリコンパイルによる攻撃手法を議論していますが、機械学習や大規模言語モデルの利用について言及しておらず、EC1 に該当するため除外します。"}], "reasoning": "本論文は低レベル制御フロー操作の攻撃パターンを提示しており、ML/LLM を用いたデコンパイル手法の研究ではありません。したがって、Include Criteria を満たさず Exclude Criteria の「No ML/LLM (ex_no_ml)」に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2850, "latency_ms": 119119}}
{"key": "8005920", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the scheme adopts the JNI for calling the encryption and decryption's codes implemented by C/C ++", "explanation": "本文では機械学習や大規模言語モデルの利用が全く言及されておらず、ML/LLM を用いた手法ではないため除外します。"}, {"code": "ex_no_lowlevel_input", "evidence": "protect the Java source code", "explanation": "対象は Java ソースコードであり、バイナリやアセンブリといった低水準入力が前提ではないため除外基準に該当します。"}], "reasoning": "この論文は Java ソースコードを暗号化して保護する手法を提案しており、機械学習・LLM の利用や低水準バイナリから高水準コードへの復元は行っていません。そのため、デコンパイルを対象とした本サーベイの範囲外であり、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2991, "latency_ms": 122450}}
{"key": "10965404", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the model first decompiles ... then filters out suspected counterfeit applications ... finally calculates the icon similarity ... to determine whether the application is counterfeit.", "explanation": "要旨は偽アプリの検出であり、コードや高水準表現の生成・復元を目的としていないため、コード生成／復元の意図がなく除外基準 EC3 に該当する。"}, {"code": "ex_out_of_scope", "evidence": "the results show that the ViT‑based twin network architecture ... can effectively identify counterfeit applications.", "explanation": "研究の主目的は偽アプリの識別であり、デコンパイルによるソース復元や意味回復ではなく、逆解析支援の範囲外と判断できる。"}], "reasoning": "本稿はデコンパイルを前処理としてメタデータを取得し、Siamese ネットワークで偽アプリを分類する手法を提案している。復元・高水準コード生成が目的ではなく、検出タスクであるため、decompilation survey の対象外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3333, "latency_ms": 128740}}
{"key": "11139736", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "multi-staged hybrid framework for malware detection", "explanation": "抽象ではコード生成や復元ではなく、マルウェア検出が主目的であるため、デコンパイルによる高水準コード生成の意図が示されていません。"}, {"code": "ex_no_ml", "evidence": "machine learning classification", "explanation": "MLは検出用分類に使用されており、デコンパイル（低水準から高水準コード生成）に中心的に用いられている記述がありません。"}], "reasoning": "本稿はマルウェア検出の精度向上を目的としたハイブリッドフレームワークを提案しており、デコンパイルによるコード生成や復元は主要な研究対象ではない。したがって、デコンパイルに関するICを満たさず、EC3（コード生成目的ではない）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3165, "latency_ms": 125963}}
{"key": "10858047", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We also present a Genetic algorithm (GA) for the global search approach to locate near optimal solutions for large CFGs.", "explanation": "本文は遺伝的アルゴリズムを用いているが、機械学習や大規模言語モデルは使用していないため、ML/LLM が手法の中核でないと判断した。"}], "reasoning": "本稿は組み込みバイナリの制御構造回復を目的とし、遺伝的アルゴリズムによる探索手法を提案しているが、機械学習や大規模言語モデルは使用していない。したがって、Decompilation Survey のインクルード基準で求められる「LLM/ML が中核手法」である条件を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3052, "latency_ms": 124021}}
{"key": "9410081", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "Through obfuscation, the compiled program is strengthened at the three levels of grammar, control flow, and data flow.", "explanation": "抽象中に機械学習や大規模言語モデルの使用が示されていないため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "the source code of mobile application reinforced by this method is obtained through decompilation, the internal logic ... cannot be known", "explanation": "研究の目的は逆にデコンパイルを困難にするためのコード難読化であり、デコンパイル自体や復元を目的とした手法ではないため範囲外とした。"}], "reasoning": "本稿はモバイルアプリケーションの難読化手法を提案しており、デコンパイルや高水準コードの復元を目的としていない。さらに、機械学習や大規模言語モデルを用いた手法の記述が全くなく、除外基準 EC1（ML/LLM 不使用）および EC5（デコンパイル範囲外）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3291, "latency_ms": 129263}}
{"key": "8965960", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the classification is achieved through an integrated learning framework", "explanation": "要旨は特徴抽出後に分類を行う検知アルゴリズムであり、コードの生成・復元が目的ではないため除外基準EC3に該当します。"}], "reasoning": "本論文はAPKをデコンパイルして特徴を抽出し、機械学習によるマルウェア検知を行うことが主目的です。デコンパイルは前処理として用いられますが、低水準コードから高水準コードやAST等を再構成することはなく、コード生成・再構築が目的ではありません。したがって、デコンパイルの復元・可読化を目的とした研究ではなく、除外基準EC3（コード生成・復元意図がない）に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3007, "latency_ms": 125248}}
{"key": "11241815", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "classify Android applications as benign or malicious", "explanation": "アブストラクトはマルウェア検出のための分類を目的としており、コードやソースの復元・生成は行っていないため、コード生成/復元の意図がないと判断した。"}], "reasoning": "本稿はDeeplearning を用いたマルウェア検出（分類）を目的としており、低水準バイトコードから高水準コードや擬似コードを生成するデコンパイルの目的が示されていない。そのため、除外基準 EC3（コード生成・復元が主目的でない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3079, "latency_ms": 122742}}
{"key": "10937558", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "It utilizes novel simplification methods that take ideas from compiler construction and simplification performed on parse trees.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されておらず、従って本サーベイの除外基準 EC1 に該当します。"}], "reasoning": "本論文は MBA オブfuscation の簡略化手法を提案するもので、Binary Ninja のプラグインとして実装されていますが、機械学習や LLM を中心手法として使用している記述はありません。そのため、除外基準 EC1（ML/LLM 不使用）に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3046, "latency_ms": 124425}}
{"key": "10625666", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "The whole process adopts the method of JNI call, ... which can effectively prevent decompilation.", "explanation": "要旨に機械学習や大規模言語モデルの使用は記載されておらず、従来の JNI 呼び出しによる保護策のみが述べられているため、EC1 に該当し除外します。"}, {"code": "ex_out_of_scope", "evidence": "Research on Security Protection Mechanism of Android APP ... can effectively prevent decompilation.", "explanation": "研究目的は Android アプリの改ざん防止とインストール制御であり、デコンパイルそのものの復元・可読化を目的としていないため、デコンパイル調査の範囲外（EC5）です。"}], "reasoning": "本稿は Android アプリの保護機構を提案するもので、機械学習や大規模言語モデルを用いたデコンパイル手法の研究ではありません。また、目的がコードの復元や可読化ではなく改ざん防止であるため、デコンパイルサーベイの対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3292, "latency_ms": 128217}}
{"key": "8327566", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "analyzing contract state using decompilation techniques driven by the contract structure definition", "explanation": "アブストラクトには機械学習や大規模言語モデルの使用が言及されておらず、手法はルールベースのデコンパイルと記述されているため、EC1 に該当します。"}], "reasoning": "本論文はスマートコントラクトの状態をデコンパイル技術で可視化する手法を提案していますが、機械学習やLLMを中心手法として用いている記述がなく、ルールベース／構造定義に基づくアプローチに留まっています。そのため、Decompilation Survey Screening Rules の除外基準 EC1（ML/LLM未使用）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3021, "latency_ms": 124206}}
{"key": "8728471", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Usual methods like disassembly, decompiling, de-obfuscation or execution of the binary need not be done in this proposed method.", "explanation": "本文はマルウェアの分類を目的としており、逆コンパイルやコード生成・復元は行わないと明言しているため、コード生成や再構成が目的ではないと判断した。"}], "reasoning": "本論文はディープラーニングを用いたマルウェア分類手法を提案しており、低水準バイナリから高水準コードを復元することが目的ではない。したがって、デコンパイルやコード生成を伴わないため除外基準 EC3（コード生成・復元が目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3137, "latency_ms": 124548}}
{"key": "9519451", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a novel probabilistic technique for variable and structure recovery.", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用が言及されておらず、手法は確率的解析に基づくため、ML/LLM が中核手法でないと判断した。"}], "reasoning": "本論文はストリップドバイナリから変数やデータ構造を復元する確率的手法を提案しているが、機械学習や大規模言語モデルの利用は示されていない。したがって、Decompilation Survey の包括基準にある「LLM/ML を中核手法として用いる」要件を満たさず、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3234, "latency_ms": 127936}}
{"key": "9921221", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "classified with multi-layer perceptron", "explanation": "本文はCFG表現を用いたマルウェア検出・分類を目的としており、コードの復元や高水準表現の生成は行わないため、コード生成/再構築の目的がなく除外基準EC3に該当します。"}], "reasoning": "本論文はPEファイルの制御フローグラフを特徴ベクトル化し、MLモデルでマルウェアを分類することに焦点を当てており、デコンパイルやソースコードの復元といった目的は示されていません。したがって、デコンパイル研究の範囲外となり除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3223, "latency_ms": 125598}}
{"key": "10186242", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Existing malware detection solutions are usually invasive as they obtain classification features by performing reverse engineering, decompilation, or disassembly ... our approach also differs ... by being non‑invasive", "explanation": "要旨からはコードや高水準表現の生成・復元が目的ではなく、マルウェア検知のための特徴抽出と分類であることが分かるため、復元・可読化を伴うコード生成が行われていないと判断した。"}], "reasoning": "本稿は低水準バイナリから高水準コードを復元することを目的とせず、逆にデコンパイルを行わない特徴取得と機械学習によるマルウェア検知手法を提案している。デコンパイルやコード生成が主目的でないため、除外基準 EC3（コード生成・復元が主目的でない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3192, "latency_ms": 125792}}
{"key": "8600052", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the malicious program can be detected more accurately", "explanation": "アブストラクトは、Opcode シーケンスからマルウェアを検出することが目的であり、コードの復元・生成や可読化を行う目的ではないため、復元・生成意図が欠如しています。"}], "reasoning": "本稿はデコンパイルによるコード復元を目的とせず、Opcode シーケンスを用いたマルウェア検出（分類）を行うことが主目的です。したがって、Code Generation/ Reconstruction が目的でない点が Exclude Criteria EC3 に該当し、除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3056, "latency_ms": 124267}}
{"key": "8029506", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Static analysis is to decompile the applications to generate intermediate code and then analyze the usage of permissions.", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、従来の静的解析手法のみが使用されているため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿は Android アプリの権限過剰請求検出を目的とした静的解析と意味解析を行うもので、デコンパイルは中間コード生成の手段に過ぎない。機械学習や LLM が中心手法として用いられていないため、Decompilation Survey の採択基準を満たさない。", "model": "openai/gpt-oss-120b", "tokens_used": 3124, "latency_ms": 122232}}
{"key": "9724320", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "present a framework that learns the semantic relationships among binary functions ... to carry out function matching", "explanation": "要旨はバイナリ関数とソース関数のマッチングであり、ソースコードや擬似コードの生成・復元を目的としていないため、コード生成・復元の意図がなく除外基準EC3に該当する。"}], "reasoning": "本稿はバイナリ関数と元ソース関数の対応付け（マッチング）を行う手法を提案しており、低水準入力とMLは使用されているものの、出力はコードそのものではなくマッピング情報です。デコンパイルの目的である「高水準コードの復元・生成」ではないため、除外基準EC3（コード生成・復元が主目的でない）により除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3122, "latency_ms": 126121}}
{"key": "10596484", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we propose ... learns the similarity between binary and source codes", "explanation": "本文はバイナリとソースコード間の類似度を学習しマッチングを行うことが目的であり、コードの復元や生成を行うことは記述されていないため、コード生成/再構成の目的がなく除外基準EC3に該当します。"}], "reasoning": "この論文はバイナリとソースコードの類似性を学習してマッチングを行う手法を提案しており、MLは使用されているものの、出力は類似度スコアでありコードの復元や可読化を目的としていません。したがって、デコンパイルの目的（高水準コード生成）を満たさないため除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3227, "latency_ms": 128030}}
{"key": "10050059", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we designed a GNN-based model for vulnerability detection", "explanation": "この引用は本研究の主目的が脆弱性検出という分類タスクであり、コードの生成や復元を目的としていないことを示すため、除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイトコードをデコンパイルしてオペコードを取得し、その CFG を GNN で解析して脆弱性を検出することが主目的です。コードの復元や高水準表現の生成を目指すものではなく、分類タスクに焦点を当てているため、デコンパイル研究のインクルード基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3405, "latency_ms": 131193}}
{"key": "10925357", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "utilizing an ensemble of Convolutional Neural Networks (CNNs) for enhanced classification accuracy", "explanation": "要旨から、研究の主目的はCNNによるマルウェアの分類・検出であり、コードの生成や復元は行っていないため除外基準EC3に該当する"}], "reasoning": "本稿はAndroidアプリのバイトコードを画像化しCNNでマルウェアを分類する手法を提案している。デコンパイルは前処理として言及されるだけで、低水準入力から高水準コードを復元することやデコンパイラの改善が目的ではない。したがって、デコンパイル研究のインクルード基準を満たさず、除外基準 ex_no_code_generation に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3306, "latency_ms": 128822}}
{"key": "9719255", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "proposes an APT attack detection scheme based on DenseNet convolutional neural network", "explanation": "要旨はマルウェアの検出・分類が目的であり、LLM/MLはコード生成や復元ではなく分類モデルとして使用されているため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿はAPTマルウェアの検出を目的とした分類手法を提案しており、デコンパイルは前処理として言及されるだけで、LLM/ML がデコンパイルや高水準コード生成に中心的に使われているわけではない。したがって、デコンパイル研究のインクルード基準を満たさず、除外基準（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3289, "latency_ms": 130314}}
{"key": "10195953", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose BiAn, a source code level smart contract obfuscation method", "explanation": "抄録に機械学習・LLMの利用が記載されておらず、従来の手法であることからML/LLMを用いていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "source code level smart contract obfuscation method", "explanation": "入力はソースコードレベルであり、バイナリやアセンブリといった低水準表現が使用されていないため除外基準に該当する。"}], "reasoning": "本稿はスマートコントラクトのソースコードを対象にした難読化手法を提案しており、低水準表現から高水準表現への復元（デコンパイル）を目的としていない。また、機械学習や大規模言語モデルの利用が示されていないため、サーベイの採択基準を満たさないと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3117, "latency_ms": 127833}}
{"key": "9869841", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "SSA-MDS and other soft technologies are used to analyze the key characteristics of transformer faults", "explanation": "本文はSSAやMDSといったアルゴリズムを用いた故障診断であり、LLM・機械学習を中心手法として用いている記述がなく、デコンパイルとは無関係です"}, {"code": "ex_no_lowlevel_input", "evidence": "The DGA data is first mapped to a high-dimensional space", "explanation": "入力は変圧器のDGAデータであり、バイナリやアセンブリ等の低水準表現が含まれていないため除外基準に該当します"}], "reasoning": "本論文は電力変圧器の故障診断手法を提案しており、低水準コードから高水準コードへの復元を目的としたデコンパイル研究ではありません。また、LLMや機械学習を主要手法として用いている記述もなく、対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3333, "latency_ms": 130374}}
{"key": "10183629", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we provide an overview of the main tools used in Android reverse engineering", "explanation": "アブストラクトがツールの概要を示す系統的調査であり、実験的手法や新規研究ではないため除外対象です。"}], "reasoning": "本稿はAndroidリバースエンジニアリングツールの系統的調査を行うサーベイ論文であり、ML/LLM を用いたデコンパイル手法の提示や新規生成は含まれていません。そのため、除外基準 EC4 の Survey/Review に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2913, "latency_ms": 122738}}
{"key": "9474328", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "our approach does not require model re‑training or any prior knowledge of the training data", "explanation": "本文はモデル保護を目的としており、デコンパイルや高水準コード生成のために機械学習／LLM を使用している記述がなく、ML/LLM が手法の中核でないため除外基準 EC1 に該当します"}], "reasoning": "本稿は Android アプリ内の深層学習モデルを保護するフレームワークを提案しており、デコンパイル自体を行う技術や LLM/ML による高水準表現生成は扱っていません。そのため、デコンパイル調査の対象範囲外であり、ML/LLM を用いていない点から除外 (ex_no_ml) と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3382, "latency_ms": 132419}}
{"key": "8076511", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose three core technologies: simulation execution, DEX reassembling, and DEX restoration", "explanation": "要旨からは機械学習や大規模言語モデルの使用は言及されておらず、従来のシミュレーション実行や再構築手法のみが説明されているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は Android アプリのパック解除・DEX 抽出手法を提案しており、シミュレーション実行や再構築といった伝統的手法を用いている。要旨に機械学習・LLM の利用が示されていないため、本サーベイのインクルード基準（ML/LLM が中核手法）を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3115, "latency_ms": 123565}}
{"key": "10334519", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "first leverage a decompiling tool to extract multiple features", "explanation": "アブストラクトはデコンパイルをコード生成や復元の目的ではなく、特徴抽出のためにのみ使用しており、復元・可読化が主目的ではないため除外基準 EC3 に該当する。"}], "reasoning": "本論文はデコンパイルを低水準バイナリからコードを復元する手段としてではなく、マルウェアの特徴抽出に利用しています。目的はマルウェアファミリーのクラスタリングであり、コード生成や高水準表現の再構築は行われません。そのため、デコンパイル研究のスコープ外と判断し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3359, "latency_ms": 130547}}
{"key": "10545392", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "standard IDS features ... are not resilient for detecting (control logic) binary programs, such as entropy, n-gram, and decompilation", "explanation": "本文は IDS の検出手法として decompilation を言及しているだけで、LLM/ML を用いたデコンパイル手法は示されておらず、ML の使用がないため除外基準 EC1 に該当します。"}], "reasoning": "本稿は PLC 制御ロジックへの攻撃手法と IDS の脆弱性を示すセキュリティ研究であり、デコンパイルを LLM/ML で実施することを目的としていません。したがって、ML/LLM を用いない点で除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3205, "latency_ms": 125596}}
{"key": "8945606", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We propose a novel method of android malware classification using Object-Oriented Software Metrics and machine learning algorithms.", "explanation": "要旨はマルウェアの分類であり、コードの復元や生成が目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は Android アプリを逆コンパイルしてメトリクスを取得し、機械学習でマルウェアか否かを分類する研究です。デコンパイルは手段に過ぎず、出力はソースや擬似コードなどの高水準表現ではなく、分類用の特徴量です。従って、復元・可読化を目的としたデコンパイル研究とはみなされず、除外基準 EC3（コード生成・復元目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3048, "latency_ms": 127414}}
{"key": "10776359", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect and anticipate malware on Android devices, using algorithms such as Support Vector Machine (SVM), Random Forest (RF), and K-nearest neighbors (KNN).", "explanation": "本文はマルウェア検出・分類が目的であり、デコンパイル後のコード生成や復元は行っていないため、コード生成・再構築の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "この研究は Android アプリのマルウェア検出を機械学習分類器で実施することが主目的で、デコンパイルは特徴抽出の前処理としてのみ利用されており、LLM を用いた高水準コードの生成や復元は行っていません。そのため、デコンパイルにおけるコード生成・再構成が目的ではない点で除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3323, "latency_ms": 130485}}
{"key": "9315052", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The apps were decompiled in order to extract their manifest files ... and performed a series of experiments using a machine learning (ML) model;", "explanation": "要旨ではデコンパイルはマニフェスト抽出のためだけに行われ、最終目的は権限情報によるマルウェア分類であり、コードの生成・復元は行われていないため除外基準 EC3 に該当する。"}], "reasoning": "本稿はデコンパイルをデータ収集手段として利用し、取得した権限情報を用いたマルウェア検出モデルの構築を目的としている。復元・可読化といった高水準コード生成は行わず、ML は分類に使用されているだけであるため、デコンパイル調査の対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3467, "latency_ms": 135564}}
{"key": "10195624", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_variable_naming", "evidence": "binary function naming ... stripped binaries", "explanation": "抽象から、対象はバイナリ（低水準入力）であり、関数名を復元することが主目的であるため、変数/関数命名（in_variable_naming）に該当すると判断した。"}, {"code": "in_decompiler_enhancement", "evidence": "align pseudocode and basic blocks based on disassembly and decompilation", "explanation": "擬似コードと基本ブロックを整合させる工程が、既存デコンパイラ出力を利用して情報を付加している点で、デコンパイラ出力の強化に該当する。"}, {"code": "in_core", "evidence": "seq2seq neural network translation model with attention mechanism", "explanation": "ニューラルネットワークを用いて低水準情報から高水準の関数ラベルを直接生成しているため、コアなデコンパイル要素も含む。"}], "reasoning": "本稿はストリップされたバイナリを入力とし、ニューラルネットワークベースのマルチラベル学習で関数名（高水準属性）を予測する手法を提案している。入力が低水準であること、ML/LLM が中心手法であること、目的が逆解析支援のための名前復元であることから、decompilation survey の採択基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3684, "latency_ms": 137255}}
{"key": "11052915", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "Future enhance automation; explore machine learning enhancements for improved zero-day threat detection.", "explanation": "要旨では機械学習は将来の拡張として言及されており、現在の手法としては使用されていないため、ML/LLM が中心手法であるという条件を満たさない。"}, {"code": "ex_no_code_generation", "evidence": "Apktool enables low-level decompilation of smali code, while Quark focuses on malware behavior detection through API call analysis.", "explanation": "逆コンパイルは解析のための前処理として用いられ、コードの復元・可読化・高水準表現生成が目的ではないため、コード生成/復元の意図がないと判断した。"}], "reasoning": "本論文はモバイルアプリのセキュリティ評価フレームワークを提案しており、デコンパイルは解析手段の一部に過ぎない。機械学習・LLM が主要手法として用いられておらず、コードの復元や高水準表現生成を目的としていないため、除外基準（EC1, EC3）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3394, "latency_ms": 133458}}
{"key": "10410676", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "Using a decompiler, models can be updated (retrained) and sent to other nodes", "explanation": "要旨ではデコンパイラはモデル更新の手段として言及されているだけで、デコンパイル自体に機械学習／大規模言語モデルを用いる記述がなく、ML/LLM が中心手法ではないため除外基準 EC1 に該当する。"}], "reasoning": "本稿は IoT 向け仮想化 VM（REXA VM）の提案が主目的であり、デコンパイルは補助的に言及されるに過ぎない。デコンパイル工程に LLM／ML を利用したことが示されていないため、デコンパイル調査の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3130, "latency_ms": 130561}}
{"key": "10491696", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "…binary function decompilation, we identify the key statement that causes the vulnerability, analyze the cross-function data dependency…", "explanation": "要旨では、逆コンパイルは脆弱性検出の前処理として用いられており、最終目的は脆弱性の類似性評価・検出であり、コード生成や復元は目的に含まれないため、コード生成/復元意図がないと判断した。"}], "reasoning": "本稿はバイナリ関数のデコンパイルを脆弱性検出のための特徴抽出に利用しているが、デコンパイル自体が目的ではなく、復元・可読化・高水準表現生成が主目的ではない。したがって、除外基準 EC3（コード生成・復元意図がない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3139, "latency_ms": 129377}}
{"key": "10500201", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "code does not need to be compiled and thus would not need to be run through a decompiler", "explanation": "本文はコンパイル不要の Python を用いたスマートコントラクトフレームワークを提案しており、ML/LLM の使用は記載されていないため、除外基準 EC1 に該当します"}], "reasoning": "本稿は低水準バイナリから高水準コードへの復元を目的としたデコンパイルや、ML/LLM を用いた手法を扱っていません。入力は高水準の Python ソースであり、機械学習技術の言及もないため、除外基準 (ex_no_ml) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3178, "latency_ms": 131488}}
{"key": "10188657", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present the first framework for static and dynamic analysis of Intel microcode", "explanation": "要旨に機械学習や大規模言語モデルの利用について言及がなく、従来の静的・動的解析手法のみが述べられているため、ML/LLM が使用されていないと判断し、EC1 に該当します。"}], "reasoning": "本稿はマイクロコードの逆解析とカスタマイズを対象としていますが、手法は Ghidra プラグインや UEFI アプリケーションなど従来の解析技術に限られ、機械学習や大規模言語モデルは使用されていません。そのため、Decompilation Survey の除外基準 EC1 (No ML/LLM) に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3209, "latency_ms": 129007}}
{"key": "10589897", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify inline functions in the binary code ... getting rid of the constraints ...", "explanation": "本文はバイナリ中のインライン関数を検出する手法を提案しており、コード生成や復元を行う目的ではなく、識別・分類が主目的であるため除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリコードからインライン関数を検出することに焦点を当てており、LLM/ML を用いた高水準コードの生成や復元・可読化を目的としていません。そのため、デコンパイルの生成・再構成に関するインクルード基準を満たさず、除外基準 EC3（コード生成・復元が目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3268, "latency_ms": 133561}}
{"key": "11166547", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "introduces a high-accuracy detection framework ... to identify Android ransomware", "explanation": "要旨はランサムウェア検出であり、コードの復元や可読化を目的としていないため、コード生成/再構成の意図がなく除外基準EC3に該当する"}], "reasoning": "本稿はSMALIコードから特徴抽出し機械学習でランサムウェアを分類する検出手法を提案しており、デコンパイルによる高水準コード生成や復元を目的としていない。したがって、復元・可読化を目的としたLLM/MLを中心とした研究ではなく、除外基準EC3（コード生成意図なし）に該当するため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2986, "latency_ms": 128212}}
{"key": "11086752", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "binary code similarity detection ...", "explanation": "アブストラクトはバイナリコードの類似性を検出することが目的であり、ソースコードや擬似コードの生成・復元を行う記述がないため、コード生成・復元を目的としたデコンパイル研究には該当しません。"}, {"code": "ex_no_code_generation", "evidence": "decompile the binary code using ... IDA pro to extract the abstract syntax tree as the feature source of the neural network", "explanation": "AST を特徴抽出に利用しているものの、最終的な出力は類似性スコアであり、復元された高水準コードは生成されていないため、コード生成・復元の目的が無いと判断します。"}], "reasoning": "本稿はバイナリコードの類似性検出を目的とした手法であり、LLM/ML を用いても低水準バイナリから高水準コードを生成することは行っていません。したがって、デコンパイル（コード復元）を主目的とする本サーベイのインクルード基準を満たさず、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3374, "latency_ms": 133126}}
{"key": "8284326", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "perform reverse engineering of iOS applications by disassembling, decompiling and debugging application's code using Disassembler", "explanation": "概要では従来の Disassembler を用いた手法しか述べられており、ML/LLM の利用が示されていないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿は iOS アプリの逆アセンブル・デコンパイル手法を従来型のツールで紹介しており、機械学習や大規模言語モデルを用いた手法が存在しないため、デコンパイル調査の対象範囲外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2962, "latency_ms": 127954}}
{"key": "11098869", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This survey provides an extensive evaluation of recent AI-based reverse engineering techniques...", "explanation": "本文は調査・レビュー論文であり、オリジナルのデコンパイル手法を提示していないため、除外基準 EC4 に該当します。"}], "reasoning": "本稿は AI を用いたリバースエンジニアリング全般の調査論文であり、実装されたデコンパイル手法や LLM/ML を中心とした研究成果を新規に提示していません。したがって、サーベイ/レビューという除外基準に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2926, "latency_ms": 128005}}
{"key": "11307212", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "proposes ... Vision Transformer ... classification ... of benign and malicious patterns", "explanation": "要旨はバイトコード画像を用いたマルウェア/正常アプリの分類であり、コードの復元・生成を目的としていないため、コード生成/再構成の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文は Android アプリのバイトコードを画像化し、Vision Transformer でマルウェアか否かを分類する手法を提案しています。デコンパイル（低水準から高水準コードへの復元）やコードの可読化を目的としておらず、主目的はマルウェア検出です。そのため、デコンパイル調査の対象外と判断し、除外 (ex_no_code_generation) としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3163, "latency_ms": 129673}}
{"key": "11023499", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_type_recovery", "evidence": "LLM-assisted double-elimination framework to select the best-fit type declaration", "explanation": "LLM を利用してストリップドバイナリから合成した型候補から最適な型を選択することは、型回復を主目的とした研究であるため"}, {"code": "in_decompiler_enhancement", "evidence": "assessing the readability of the decompiled code", "explanation": "LLM が既存のデコンパイル結果の可読性向上に寄与している点が、デコンパイラ出力の改善に該当するため"}], "reasoning": "本稿はストリップドバイナリという低水準入力から、合成された複合型情報をLLMで選別し、デコンパイルコードの可読性向上を図る手法で、型回復（L4 属性）を主目的としている。LLM が中心手法として用いられ、目的も復元・可読化であるため、Decompilation Survey の対象に該当し、in_type_recovery（主体）と in_decompiler_enhancement（補助）として採択する。", "model": "openai/gpt-oss-120b", "tokens_used": 3448, "latency_ms": 134786}}
{"key": "11242121", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify and classify cryptographic functions in source code and decompiled firmware", "explanation": "要旨は暗号関数の検出・分類と脆弱性検出であり、コードの復元や擬似コード生成などのコード生成・再構成を目的としていないため、除外基準EC3に該当します。"}], "reasoning": "本稿は低水準のファームウェアを入力として暗号関数の検出・分類と脆弱性検出を行う手法を提案していますが、目的はコードの復元や高水準表現の生成ではなく、分類・検出です。したがって、デコンパイルの主目的であるコード生成・再構成を行わない点で除外基準EC3に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3179, "latency_ms": 131393}}
{"key": "10679822", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "code virtualization, also known as virtualization obfuscation, is a technique that protects software ... preventing the code from being decompiled.", "explanation": "アブストラクトには機械学習や大規模言語モデルの使用が一切記載されておらず、純粋に仮想化オブフスケーション手法だけが述べられているため、ML/LLM が中心手法であるという条件を満たさないと判断した。"}], "reasoning": "本稿はバイナリ保護のためのコード仮想化手法を提案しており、機械学習や大規模言語モデルを用いたデコンパイルや復元の研究ではない。したがって、本サーベイの対象である「LLM/ML を中核にしたデコンパイル」には該当せず、除外基準 EC1 に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3199, "latency_ms": 129675}}
{"key": "10743227", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "combines decompilation and diversification compilation techniques", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、従来の手法のみであると判断できるため、EC1 に該当します。"}], "reasoning": "アブストラクトからは、ML/LLM を活用した手法の記述が全くなく、従来のデコンパイル技術とコンパイル技術を組み合わせた保護手法と説明されているため、除外基準 EC1（ML/LLM が使用されていない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3240, "latency_ms": 133352}}
{"key": "11267408", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.91, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "generating precise malware reports", "explanation": "アブストラクトはLLMがマルウェア分析レポートを生成することを目的としていると述べており、コードやソースの復元・生成ではなく自然言語レポートの作成であるため、デコンパイルのコード生成目的を満たさないと判断した。"}], "reasoning": "本稿はデコンパイルされたコードを入力としてレポートを生成することに焦点を当てており、低水準コードから高水準コードやASTなどを再構築することが目的ではない。したがって、デコンパイルの出力レベル（L1-L4）に該当せず、コード生成・復元が主目的でないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3189, "latency_ms": 131370}}
{"key": "7921975", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "the unprecedented ones were captured and decompiled to acquire new app's name", "explanation": "要旨ではアプリをデコンパイルして名前を取得すると述べられているが、機械学習や大規模言語モデルの使用については言及されておらず、ML/LLM を用いていないため除外基準 EC1 に該当する。"}], "reasoning": "本論文はネットワークトラフィックからアプリパッケージを特定する手法を提案しており、デコンパイルは名前取得のための補助的手段として登場するが、ML/LLM が中心手法として使用されていない。したがって、Decompilation Survey の対象外（ex_no_ml）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3144, "latency_ms": 131460}}
{"key": "10590654", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "decompiling them into Smali code, and then trans-forming them into C++ code", "explanation": "抄録では機械学習や大規模言語モデルの利用が全く言及されておらず、単なる変換手法のみが説明されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は Android アプリを Smali から C++ へ変換する強化手法を提案しているが、手法の中心に機械学習・LLM が置かれている記述がない。したがって、Decompilation Survey の対象となる「ML/LLM を用いたデコンパイル」には該当せず、除外基準 EC1 (ex_no_ml) に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3187, "latency_ms": 131099}}
{"key": "10711263", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we can fingerprint reused functions across processor architectures", "explanation": "アブストラクトは関数の指紋付け（検出・識別）を目的としており、コードの復元や高水準表現の生成を行うことは示されていないため、コード生成・再構成が主目的ではなく除外基準 EC3 に該当します。"}], "reasoning": "本論文はバイナリ関数の指紋付けを目的とした機械学習手法であり、LLM/ML を用いて高水準コードや擬似コードを生成することはありません。デコンパイルの復元・可読化を目的とした研究ではないため、除外基準 EC3（コード生成・再構成意図の欠如）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2938, "latency_ms": 131121}}
{"key": "11118682", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "decompilation using Ghidra, and artificial intelligence analysis", "explanation": "要旨ではデコンパイルは Ghidra（従来のルールベースツール）で行われ、AI は別途分析に用いられており、デコンパイル自体に機械学習／LLM が中心手法として使われている記述がないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿はマルウェア解析支援ツールを紹介し、デコンパイルは Ghidra に委ねているため、デコンパイル工程に機械学習や大規模言語モデルが核心的に使用されていません。したがって、Decompilation Survey のインクルード基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3158, "latency_ms": 133464}}
{"key": "11028410", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "Obtaining higher-level representations is possible by reverse engineering ... genetic decompilation", "explanation": "要約から、機械コードという低水準入力から遺伝的アルゴリズムを用いて高水準表現（ソースや構造）を生成する手法（genetic decompilation）を提案しているため、Core Decompilation に該当します。"}], "reasoning": "本文は低水準の機械コードを入力とし、遺伝的アルゴリズムという機械学習手法で高水準のプログラム表現を復元することを目的としているため、LLM/ML を中核にしたデコンパイル研究 (in_core) と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3152, "latency_ms": 132081}}
{"key": "11264981", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Our technique proposes ... for malware detection ... decompiles Dalvik bytecode to extract CFG representations", "explanation": "要旨はマルウェア検出という分類タスクであり、逆コンパイルによるコード復元や可読化が目的ではないため、コード生成・復元の意図がなく除外基準EC3に該当します。"}], "reasoning": "本研究は Dalvik バイトコードをデコンパイルして CFG を取得し、マルウェア検出のためのディープラーニングモデルに入力しています。デコンパイルはデータ前処理に過ぎず、復元・可読化といったデコンパイルの主目的は示されていません。そのため、目的が分類であることから除外基準EC3（コード生成・復元意図なし）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3198, "latency_ms": 132420}}
{"key": "arXiv:2306.14168", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "obtain feature representation vector of binary code", "explanation": "要旨はバイナリコードの類似度検出のための特徴ベクトル取得であり、コードの復元や高水準表現の生成を目的としていないため、コード生成/再構成の意図がないと判断した。"}], "reasoning": "本論文はバイナリコードの類似性検出を目的としており、低水準入力から高水準コードを生成することを目指すデコンパイル研究とは目的が異なる。したがって、コード生成・復元を伴わないため除外基準 EC3（ex_no_code_generation）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3112, "latency_ms": 131254}}
{"key": "arXiv:2201.07420", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "by jointly learning the embeddings of binary code and source code in a common vector space", "explanation": "要旨はバイナリとソースコードの埋め込みを学習しマッチングを行うことが目的で、コードの復元・生成は行っていないため、コード生成・復元意図が無いと判断した。"}], "reasoning": "本稿はバイナリとソースコードの類似検索（マッチング）を目的とした埋め込み学習手法を提案しており、デコンパイルや高水準コードの生成を行うものではない。したがって、除外基準 EC3（コード生成・復元が目的でない）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3096, "latency_ms": 130873}}
{"key": "arXiv:2405.19581", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.88, "reason_codes": [{"code": "in_variable_naming", "evidence": "binary function name recovery", "explanation": "要旨でバイナリから関数名を復元することを主要目的としているため、変数/関数名復元（IC4）に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "probe-and-recover framework ... black-box LLMs to enhance recovery accuracy", "explanation": "既存のバイナリ解析結果に対し LLM を用いて復元精度を向上させている点が、デコンパイラ出力の改善に該当します。"}], "reasoning": "本研究はバイナリという低水準入力を対象とし、LLM/ML を中心手法として関数名の復元やバイナリ要約を行うことで、逆コンパイル（デコンパイル）支援を目的としているため、スクリーニング基準の Include 条件を満たします。", "model": "openai/gpt-oss-120b", "tokens_used": 3497, "latency_ms": 136862}}
