@article{10.1145/3306204,
  abstract = {We present a new approach for predicting program properties from large codebases (aka "Big Code"). Our approach learns a probabilistic model from "Big Code" and uses this model to predict properties of new, unseen programs.The key idea of our work is to transform the program into a representation that allows us to formulate the problem of inferring program properties as structured prediction in machine learning. This enables us to leverage powerful probabilistic models such as Conditional Random Fields (CRFs) and perform joint prediction of program properties.As an example of our approach, we built a scalable prediction engine called JSNICE for solving two kinds of tasks in the context of JavaScript: predicting (syntactic) names of identifiers and predicting (semantic) type annotations of variables. Experimentally, JSNICE predicts correct names for 63% of name identifiers and its type annotation predictions are correct in 81% of cases. Since its public release at http://jsnice.org, JSNice has become a popular system with hundreds of thousands of uses.By formulating the problem of inferring program properties as structured prediction, our work opens up the possibility for a range of new "Big Code" applications such as de-obfuscators, decompilers, invariant generators, and others.},
  address = {New York, NY, USA},
  author = {Raychev, Veselin and Vechev, Martin and Krause, Andreas},
  doi = {10.1145/3306204},
  issn = {0001-0782},
  issue_date = {March 2019},
  journal = {Commun. ACM},
  month = {February},
  number = {3},
  numpages = {9},
  pages = {99–107},
  publisher = {Association for Computing Machinery},
  title = {Predicting program properties from 'big code'},
  url = {https://doi.org/10.1145/3306204},
  volume = {62},
  year = {2019}
}

@article{10.1145/3416262,
  abstract = {Ethereum is a distributed blockchain platform, serving as an ecosystem for smart contracts: full-fledged intercommunicating programs that capture the transaction logic of an account. A gas limit caps the execution of an Ethereum smart contract: instructions, when executed, consume gas, and the execution proceeds as long as gas is available.Gas-focused vulnerabilities permit an attacker to force key contract functionality to run out of gas---effectively performing a permanent denial-of-service attack on the contract. Such vulnerabilities are among the hardest for programmers to protect against, as out-of-gas behavior may be uncommon in nonattack scenarios and reasoning about these vulnerabilities is nontrivial.In this paper, we identify gas-focused vulnerabilities and present MadMax: a static program analysis technique that automatically detects gas-focused vulnerabilities with very high confidence. MadMax combines a smart contract decompiler and semantic queries in Datalog. Our approach captures high-level program modeling concepts (such as "dynamic data structure storage" and "safely resumable loops") and delivers high precision and scalability. MadMax analyzes the entirety of smart contracts in the Ethereum blockchain in just 10 hours and flags vulnerabilities in contracts with a monetary value in billions of dollars. Manual inspection of a sample of flagged contracts shows that 81% of the sampled warnings do indeed lead to vulnerabilities.},
  address = {New York, NY, USA},
  author = {Grech, Neville and Kong, Michael and Jurisevic, Anton and Brent, Lexi and Scholz, Bernhard and Smaragdakis, Yannis},
  doi = {10.1145/3416262},
  issn = {0001-0782},
  issue_date = {October 2020},
  journal = {Commun. ACM},
  month = {September},
  number = {10},
  numpages = {9},
  pages = {87–95},
  publisher = {Association for Computing Machinery},
  title = {MadMax: analyzing the out-of-gas world of smart contracts},
  url = {https://doi.org/10.1145/3416262},
  volume = {63},
  year = {2020}
}

@article{10.1145/3418206,
  abstract = {Software piracy is an act of illegal stealing and distributing commercial software either for revenue or identify theft. Pirated applications on Android app stores are harming developers and their users by clone scammers. The scammers usually generate pirated versions of the same applications and publish them in different open-source app stores. There is no centralized system between these app stores to prevent scammers from publishing pirated applications. As most of the app stores are hosted on cloud storage, therefore a cloud-based interaction system can prevent scammers from publishing pirated applications. In this paper, we proposed IoT-based cloud architecture for clone detection using program dependency analysis. First, the newly submitted APK and possible original files are selected from app stores. The APK Extractor and JDEX decompiler extract APK and DEX files for Java source code analysis. The dependency graphs of Java files are generated to extract a set of weighted features. The Stacked-Long Short-Term Memory (S-LSTM) deep learning model is designed to predict possible clones.Experimental results have shown that the proposed approach can achieve an average accuracy of 95.48% among clones from different application stores.},
  address = {New York, NY, USA},
  articleno = {40},
  author = {Ullah, Farhan and Naeem, Muhammad Rashid and Bajahzar, Abdullah S. and Al-Turjman, Fadi},
  doi = {10.1145/3418206},
  issn = {1533-5399},
  issue_date = {May 2022},
  journal = {ACM Trans. Internet Technol.},
  keywords = {Internet of Things, cloud services, program dependency graph, deep learning, Clone detection},
  month = {October},
  number = {2},
  numpages = {17},
  publisher = {Association for Computing Machinery},
  title = {IoT-based Cloud Service for Secured Android Markets using PDG-based Deep Learning Classification},
  url = {https://doi.org/10.1145/3418206},
  volume = {22},
  year = {2021}
}

@article{10.1145/3428277,
  abstract = {Callbacks are an effective programming discipline for implementing event-driven programming, especially in environments like Ethereum which forbid shared global state and concurrency. Callbacks allow a callee to delegate the execution back to the caller. Though effective, they can lead to subtle mistakes principally in open environments where callbacks can be added in a new code. Indeed, several high profile bugs in smart contracts exploit callbacks. We present the first static technique ensuring modularity in the presence of callbacks and apply it to verify prominent smart contracts. Modularity ensures that external calls to other contracts cannot affect the behavior of the contract. Importantly, modularity is guaranteed without restricting programming. In general, checking modularity is undecidable—even for programs without loops. This paper describes an effective technique for soundly ensuring modularity harnessing SMT solvers. The main idea is to define a constructive version of modularity using commutativity and projection operations on program segments. We believe that this approach is also accessible to programmers, since counterexamples to modularity can be generated automatically by the SMT solvers, allowing programmers to understand and fix the error. We implemented our approach in order to demonstrate the precision of the modularity analysis and applied it to real smart contracts, including a subset of the 150 most active contracts in Ethereum. Our implementation decompiles bytecode programs into an intermediate representation and then implements the modularity checking using SMT queries. Overall, we argue that our experimental results indicate that the method can be applied to many realistic contracts, and that it is able to prove modularity where other methods fail.},
  address = {New York, NY, USA},
  articleno = {209},
  author = {Albert, Elvira and Grossman, Shelly and Rinetzky, Noam and Rodr\'{\i}guez-N\'{u}\~{n}ez, Clara and Rubio, Albert and Sagiv, Mooly},
  doi = {10.1145/3428277},
  issue_date = {November 2020},
  journal = {Proc. ACM Program. Lang.},
  keywords = {smart contracts, program verification, program analysis, logic and verification, invariants, blockchain},
  month = {November},
  number = {OOPSLA},
  numpages = {30},
  publisher = {Association for Computing Machinery},
  title = {Taming callbacks for smart contract modularity},
  url = {https://doi.org/10.1145/3428277},
  volume = {4},
  year = {2020}
}

@article{10.1145/3486860,
  abstract = {Binary code fingerprinting is crucial in many security applications. Examples include malware detection, software infringement, vulnerability analysis, and digital forensics. It is also useful for security researchers and reverse engineers since it enables high fidelity reasoning about the binary code such as revealing the functionality, authorship, libraries used, and vulnerabilities. Numerous studies have investigated binary code with the goal of extracting fingerprints that can illuminate the semantics of a target application. However, extracting fingerprints is a challenging task since a substantial amount of significant information will be lost during compilation, notably, variable and function naming, the original data and control flow structures, comments, semantic information, and the code layout. This article provides the first systematic review of existing binary code fingerprinting approaches and the contexts in which they are used. In addition, it discusses the applications that rely on binary code fingerprints, the information that can be captured during the fingerprinting process, and the approaches used and their implementations. It also addresses limitations and open questions related to the fingerprinting process and proposes future directions.},
  address = {New York, NY, USA},
  articleno = {19},
  author = {Alrabaee, Saed and Debbabi, Mourad and Wang, Lingyu},
  doi = {10.1145/3486860},
  issn = {0360-0300},
  issue_date = {January 2023},
  journal = {ACM Comput. Surv.},
  keywords = {software security, reverse engineering, Binary code analysis},
  month = {January},
  number = {1},
  numpages = {41},
  publisher = {Association for Computing Machinery},
  title = {A Survey of Binary Code Fingerprinting Approaches: Taxonomy, Methodologies, and Features},
  url = {https://doi.org/10.1145/3486860},
  volume = {55},
  year = {2022}
}

@inproceedings{10.1145/3519939.3523702,
  abstract = {Lifting binaries to a higher-level representation is an essential step for decompilation, binary verification, patching and security analysis. In this paper, we present the first approach to provably overapproximative x86-64 binary lifting. A stripped binary is verified for certain sanity properties such as return address integrity and calling convention adherence. Establishing these properties allows the binary to be lifted to a representation that contains an overapproximation of all possible execution paths of the binary. The lifted representation contains disassembled instructions, reconstructed control flow, invariants and proof obligations that are sufficient to prove the sanity properties as well as correctness of the lifted representation. We apply this approach to Linux Foundation and Intel’s Xen Hypervisor covering about 400K instructions. This demonstrates our approach is the first approach to provably overapproximative binary lifting scalable to commercial off-the-shelf systems. The lifted representation is exportable to the Isabelle/HOL theorem prover, allowing formal verification of its correctness. If our technique succeeds and the proofs obligations are proven true, then – under the generated assumptions – the lifted representation is correct.},
  address = {New York, NY, USA},
  author = {Verbeek, Freek and Bockenek, Joshua and Fu, Zhoulai and Ravindran, Binoy},
  booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  doi = {10.1145/3519939.3523702},
  isbn = {9781450392655},
  keywords = {Formal Verification, Disassembly, Binary Analysis},
  location = {San Diego, CA, USA},
  numpages = {16},
  pages = {934–949},
  publisher = {Association for Computing Machinery},
  series = {PLDI 2022},
  title = {Formally verified lifting of C-compiled x86-64 binaries},
  url = {https://doi.org/10.1145/3519939.3523702},
  year = {2022}
}

@article{10.1145/3527321,
  abstract = {Smart contracts on the Ethereum blockchain greatly benefit from cutting-edge analysis techniques and pose significant challenges. A primary challenge is the extremely low-level representation of deployed contracts. We present Elipmoc, a decompiler for the next generation of smart contract analyses. Elipmoc is an evolution of Gigahorse, the top research decompiler, dramatically improving over it and over other state-of-the-art tools, by employing several high-precision techniques and making them scalable. Among these techniques are a new kind of context sensitivity (termed “transactional sensitivity”) that provides a more effective static abstraction of distinct dynamic executions; a path-sensitive (yet scalable, through path merging) algorithm for inference of function arguments and returns; and a fully context sensitive private function reconstruction process. As a result, smart contract security analyses and reverse-engineering tools built on top of Elipmoc achieve high scalability, precision and completeness. Elipmoc improves over all notable past decompilers, including its predecessor, Gigahorse, and the state-of-the-art industrial tool, Panoramix, integrated into the primary Ethereum blockchain explorer, Etherscan. Elipmoc produces decompiled contracts with fully resolved operands at a rate of 99.5% (compared to 62.8% for Gigahorse), and achieves much higher completeness in code decompilation than Panoramix—e.g., up to 67% more coverage of external call statements—while being over 5x faster. Elipmoc has been the enabler for recent (independent) discoveries of several exploitable vulnerabilities on popular protocols, over funds in the many millions of dollars.},
  address = {New York, NY, USA},
  articleno = {77},
  author = {Grech, Neville and Lagouvardos, Sifis and Tsatiris, Ilias and Smaragdakis, Yannis},
  doi = {10.1145/3527321},
  issue_date = {April 2022},
  journal = {Proc. ACM Program. Lang.},
  keywords = {Smart Contracts, Security, Program Analysis, Ethereum, Decompilation, Datalog, Blockchain},
  month = {April},
  number = {OOPSLA1},
  numpages = {27},
  publisher = {Association for Computing Machinery},
  title = {Elipmoc: advanced decompilation of Ethereum smart contracts},
  url = {https://doi.org/10.1145/3527321},
  volume = {6},
  year = {2022}
}

@article{10.1145/3546946,
  abstract = {The decompiler is one of the most common tools for examining executable binaries without the corresponding source code. It transforms binaries into high-level code, reversing the compilation process. Unfortunately, decompiler output is far from readable because the decompilation process is often incomplete. State-of-the-art techniques use machine learning to predict missing information like variable names. While these approaches are often able to suggest good variable names in context, no existing work examines how the selection of training data influences these machine learning models. We investigate how data provenance and the quality of training data affect performance, and how well, if at all, trained models generalize across software domains. We focus on the variable renaming problem using one such machine learning model, DIRE. We first describe DIRE in detail and the accompanying technique used to generate training data from raw code. We also evaluate DIRE’s overall performance without respect to data quality. Next, we show how training on more popular, possibly higher quality code (measured using GitHub stars) leads to a more generalizable model because popular code tends to have more diverse variable names. Finally, we evaluate how well DIRE predicts domain-specific identifiers, propose a modification to incorporate domain information, and show that it can predict identifiers in domain-specific scenarios 23% more frequently than the original DIRE model.},
  address = {New York, NY, USA},
  articleno = {39},
  author = {Dramko, Luke and Lacomis, Jeremy and Yin, Pengcheng and Schwartz, Ed and Allamanis, Miltiadis and Neubig, Graham and Vasilescu, Bogdan and Le Goues, Claire},
  doi = {10.1145/3546946},
  issn = {1049-331X},
  issue_date = {March 2023},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  keywords = {data provenance, decompilation, Machine learning},
  month = {March},
  number = {2},
  numpages = {34},
  publisher = {Association for Computing Machinery},
  title = {DIRE and its Data: Neural Decompiled Variable Renamings with Respect to Software Class},
  url = {https://doi.org/10.1145/3546946},
  volume = {32},
  year = {2023}
}

@article{10.1145/3591237,
  abstract = {We introduce the new problem of hardware decompilation. Analogous to software decompilation, hardware decompilation is about analyzing a low-level artifact—in this case a netlist, i.e., a graph of wires and logical gates representing a digital circuit—in order to recover higher-level programming abstractions, and using those abstractions to generate code written in a hardware description language (HDL). The overall problem of hardware decompilation requires a number of pieces. In this paper we focus on one specific piece of the puzzle: a technique we call hardware loop rerolling. Hardware loop rerolling leverages clone detection and program synthesis techniques to identify repeated logic in netlists (such as would be synthesized from loops in the original HDL code) and reroll them into syntactic loops in the recovered HDL code. We evaluate hardware loop rerolling for hardware decompilation over a set of hardware design benchmarks written in the PyRTL HDL and industry standard SystemVerilog. Our implementation identifies and rerolls loops in 52 out of 53 of the netlists in our benchmark suite, and we show three examples of how hardware decompilation can provide concrete benefits: transpilation between HDLs, faster simulation times over netlists (with mean speedup of 6x), and artifact compaction (39% smaller on average).},
  address = {New York, NY, USA},
  articleno = {123},
  author = {Sisco, Zachary D. and Balkind, Jonathan and Sherwood, Timothy and Hardekopf, Ben},
  doi = {10.1145/3591237},
  issue_date = {June 2023},
  journal = {Proc. ACM Program. Lang.},
  keywords = {program synthesis, loop rerolling, hardware decompilation},
  month = {June},
  number = {PLDI},
  numpages = {23},
  publisher = {Association for Computing Machinery},
  title = {Loop Rerolling for Hardware Decompilation},
  url = {https://doi.org/10.1145/3591237},
  volume = {7},
  year = {2023}
}

@article{10.1145/3631971,
  abstract = {Java bytecode is a quite high-level language and, as such, it is fairly easy to analyze and decompile with malicious intents, e.g., to tamper with code and skip license checks. Code obfuscation was a first attempt to mitigate malicious reverse-engineering based on static analysis. However, obfuscated code can still be dynamically analyzed with standard debuggers to perform step-wise execution and to inspect (or change) memory content at important execution points, e.g., to alter the verdict of license validity checks. Although some approaches have been proposed to mitigate debugger-based attacks, they are only applicable to binary compiled code and none address the challenge of protecting Java bytecode.In this article, we propose a novel approach to protect Java bytecode from malicious debugging. Our approach is based on automated program transformation to manipulate Java bytecode and split it into two binary processes that debug each other (i.e., a self-debugging solution). In fact, when the debugging interface is already engaged, an additional malicious debugger cannot attach. To be resilient against typical attacks, our approach adopts a series of technical solutions, e.g., an encoded channel is shared by the two processes to avoid leaking information, an authentication protocol is established to avoid Man-in-the-middle attacks, and the computation is spread between the two processes to prevent the attacker to replace or terminate either of them.We test our solution on 18 real-world Java applications, showing that our approach can effectively block the most common debugging tasks (either with the Java debugger or the GNU debugger) while preserving the functional correctness of the protected programs. While the final decision on when to activate this protection is still up to the developers, the observed performance overhead was acceptable for common desktop application domains.},
  address = {New York, NY, USA},
  articleno = {107},
  author = {Pizzolotto, Davide and Berlato, Stefano and Ceccato, Mariano},
  doi = {10.1145/3631971},
  issn = {1049-331X},
  issue_date = {May 2024},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  keywords = {Anti-debugging, maliciuos reverse engineering, tampering attacks, man at the end attacks},
  month = {April},
  number = {4},
  numpages = {38},
  publisher = {Association for Computing Machinery},
  title = {Mitigating Debugger-based Attacks to Java Applications with Self-debugging},
  url = {https://doi.org/10.1145/3631971},
  volume = {33},
  year = {2024}
}

@article{10.1145/3649860,
  abstract = {Java decompilers are programs that perform the reverse process of Java compilers, i.e., they translate Java bytecode to Java source code. They are essential for reverse engineering purposes and have become more sophisticated and reliable over the years. However, it remains challenging for modern Java decompilers to reliably perform correct decompilation on real-world programs. To shed light on the key challenges of Java decompilation, this paper provides the first systematic study on the characteristics and causes of bugs in mature, widely-used Java decompilers. We conduct the study by investigating 333 unique bugs from three popular Java decompilers. Our key findings and observations include: (1) Although most of the reported bugs were found when decompiling large, real-world code, 40.2% of them have small test cases for bug reproduction; (2) Over 80% of the bugs manifest as exceptions, syntactic errors, or semantic errors, and bugs with source code artifacts are very likely semantic errors; (3) 57.7%,39.0%, and 41.1% of the bugs respectively are attributed to three stages of decompilers—loading structure entities from bytecode, optimizing these entities, and generating source code from these entities; (4) Bugs in decompilers’ type inference are the most complex to fix; and (5) Region restoration for structures like loop, sugaring for special structures like switch, and type inference of variables of generic types or indistinguishable types are the three most significant challenges in Java decompilation, which to some extent explains our findings in (3) and (4).Based on these findings, we present JD-Tester, a differential testing framework for Java decompilers, and our experience of using it in testing the three popular Java decompilers. JD-Tester utilizes different Java program generators to construct executable Java tests and finds exceptions, syntactic, and semantic inconsistencies (i.e. bugs) between a generated test and its compiled-decompiled version (through compilation and execution). In total, we have found 62 bugs in the three decompilers, demonstrating both the effectiveness of JD-Tester, and the importance of testing and validating Java decompilers.},
  address = {New York, NY, USA},
  articleno = {143},
  author = {Lu, Yifei and Hou, Weidong and Pan, Minxue and Li, Xuandong and Su, Zhendong},
  doi = {10.1145/3649860},
  issue_date = {April 2024},
  journal = {Proc. ACM Program. Lang.},
  keywords = {Reverse Engineering, Decompiler, Differential Testing},
  month = {April},
  number = {OOPSLA1},
  numpages = {27},
  publisher = {Association for Computing Machinery},
  title = {Understanding and Finding Java Decompiler Bugs},
  url = {https://doi.org/10.1145/3649860},
  volume = {8},
  year = {2024}
}

@article{10.1145/3689711,
  abstract = {Since funds or tokens in smart contracts are maintained through specific state variables, contract audit, an effective means for security assurance, particularly focuses on these variables and their related operations. However, the absence of publicly accessible source code for numerous contracts, with only bytecode exposed, hinders audit efforts. Recovering variables and their types from Solidity bytecode is thus a critical task in smart contract analysis and audit, yet this is a challenging task because the bytecode loses variable and type information, only with low-level data operated by stack manipulations and untyped memory/storage accesses. The state-of-the-art smart contract decompilers miss identifying many variables and incorrectly infer the types for many identified variables. To this end, we propose VarLifter, a lifter dedicated to the precise and efficient recovery of typed variables. VarLifter interprets every read or written field of a data region as at least one potential variable, and after discarding falsely identified variables, it progressively refines the variable types based on the variable behaviors in the form of operation sequences. We evaluate VarLifter on 34,832 real-world Solidity smart contracts. VarLifter attains a precision of 97.48% and a recall of 91.84% for typed variable recovery. Moreover, VarLifter finishes analyzing 77% of smart contracts in around 10 seconds per contract. If VarLifter is used to replace the variable recovery modules of the two state-of-the-art Solidity bytecode decompilers, 52.4%, and 74.6% more typed variables will be correctly recovered, respectively. The applications of VarLifter to contract decompilation, contract audit, and contract bytecode fuzzing illustrate that the recovered variable information improves many contract analysis tasks.},
  address = {New York, NY, USA},
  articleno = {271},
  author = {Li, Yichuan and Song, Wei and Huang, Jeff},
  doi = {10.1145/3689711},
  issue_date = {October 2024},
  journal = {Proc. ACM Program. Lang.},
  keywords = {Blockchain, EVM, Solidity bytecode, smart contract, variable recovery},
  month = {October},
  number = {OOPSLA2},
  numpages = {29},
  publisher = {Association for Computing Machinery},
  title = {VarLifter: Recovering Variables and Types from Bytecode of Solidity Smart Contracts},
  url = {https://doi.org/10.1145/3689711},
  volume = {8},
  year = {2024}
}

@article{10.1145/3699674,
  abstract = {Cybersecurity attacks on embedded devices for industrial control systems and cyber-physical systems may cause catastrophic physical damage as well as economic loss. This could be achieved by infecting device binaries with malware that modifies the physical characteristics of the system operation. Mitigating such attacks benefits from reverse engineering tools that recover sufficient semantic knowledge in terms of mathematical equations of the implemented algorithm. Conventional reverse engineering tools can decompile binaries to low-level code, but offer little semantic insight. This article proposes the REMaQE automated framework for reverse engineering of math equations from binary executables. Improving over state-of-the-art, REMaQE handles equation parameters accessed via registers, the stack, global memory, or pointers, and can reverse engineer equations from object-oriented implementations such as C++ classes. Using REMaQE, we discovered a bug in the Linux kernel thermal monitoring tool “tmon.” To evaluate REMaQE, we generate a dataset of 25,096 binaries with math equations implemented in C and Simulink. REMaQE successfully recovers a semantically matching equation for all 25,096 binaries. REMaQE executes in 0.48 seconds on average and in up to 2 seconds for complex equations. Real-time execution enables integration in an interactive math-oriented reverse engineering workflow.},
  address = {New York, NY, USA},
  articleno = {43},
  author = {Udeshi, Meet and Krishnamurthy, Prashanth and Pearce, Hammond and Karri, Ramesh and Khorrami, Farshad},
  doi = {10.1145/3699674},
  issn = {2378-962X},
  issue_date = {October 2024},
  journal = {ACM Trans. Cyber-Phys. Syst.},
  keywords = {binary reverse engineering, embedded systems, symbolic execution, mathematical equations},
  month = {November},
  number = {4},
  numpages = {25},
  publisher = {Association for Computing Machinery},
  title = {REMaQE: Reverse Engineering Math Equations from Executables},
  url = {https://doi.org/10.1145/3699674},
  volume = {8},
  year = {2024}
}

@article{10.1145/3704857,
  abstract = {Guarded Kleene Algebra with Tests (GKAT) provides a sound and complete framework to reason about trace equivalence between simple imperative programs. However, there are still several notable limitations. First, GKAT is completely agnostic with respect to the meaning of primitives, to keep equivalence decidable. Second, GKAT excludes non-local control flow such as goto, break, and return. To overcome these limitations, we introduce Control-Flow GKAT (CF-GKAT), a system that allows reasoning about programs that include non-local control flow as well as hardcoded values. CF-GKAT is able to soundly and completely verify trace equivalence of a larger class of programs, while preserving the nearly-linear efficiency of GKAT. This makes CF-GKAT suitable for the verification of control-flow manipulating procedures, such as decompilation and goto-elimination. To demonstrate CF-GKAT’s abilities, we validated the output of several highly non-trivial program transformations, such as Erosa and Hendren’s goto-elimination procedure and the output of Ghidra decompiler. CF-GKAT opens up the application of Kleene Algebra to a wider set of challenges, and provides an important verification tool that can be applied to the field of decompilation and control-flow transformation.},
  address = {New York, NY, USA},
  articleno = {21},
  author = {Zhang, Cheng and Kapp\'{e}, Tobias and Narv\'{a}ez, David E. and Naus, Nico},
  doi = {10.1145/3704857},
  issue_date = {January 2025},
  journal = {Proc. ACM Program. Lang.},
  keywords = {Kleene algebra, Program equivalence, control flow recovery},
  month = {January},
  number = {POPL},
  numpages = {27},
  publisher = {Association for Computing Machinery},
  title = {CF-GKAT: Efficient Validation of Control-Flow Transformations},
  url = {https://doi.org/10.1145/3704857},
  volume = {9},
  year = {2025}
}

@inproceedings{10.1145/3713081.3731728,
  abstract = {Binary Code Similarity Detection (BCSD) is not only essential for security tasks such as vulnerability identification but also for code copying detection, yet it remains challenging due to binary stripping and diverse compilation environments. Existing methods tend to adopt increasingly complex neural networks for better accuracy performance. The computation time increases with the complexity. Even with powerful GPUs, the treatment of large-scale software becomes time-consuming. To address these issues, we present a framework called ReGraph to efficiently compare binary code functions across architectures and optimization levels. Our evaluation with public datasets highlights that ReGraph exhibits a significant speed advantage, performing 700 times faster than Natural Language Processing (NLP)-based methods while maintaining comparable accuracy results with respect to the state-of-the-art models.},
  address = {New York, NY, USA},
  author = {Zhou, Li and Dacier, Marc and Konstantinou, Charalambos},
  booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  doi = {10.1145/3713081.3731728},
  isbn = {9798400714740},
  keywords = {binary code similarity detection, code property graph, graph neural network, code lifting, binary code re-optimization},
  location = {Clarion Hotel Trondheim, Trondheim, Norway},
  numpages = {5},
  pages = {6–10},
  publisher = {Association for Computing Machinery},
  series = {ISSTA Companion '25},
  title = {ReGraph: A Tool for Binary Similarity Identification},
  url = {https://doi.org/10.1145/3713081.3731728},
  year = {2025}
}

@article{10.1145/3765521,
  abstract = {The complexities introduced by compiler optimization have long stood as a significant obstacle in binary analysis and reverse engineering. Function inlining, in particular, complicates function recognition by replacing function calls with the entire body of the callee, mixing code from multiple functions. State-of-the-art approaches can identify inlined functions at basic block granularity, but cannot determine which instructions belong to each function and precisely deduce inlined boundaries. Without this information, further analyses such as decompilation cannot be performed effectively. This article presents Highliner, a novel approach that improves state-of-the-art approaches by identifying inline instances at instruction-level granularity. Highliner operates downstream of block-level detectors: given basic blocks reported by state-of-the-art approaches as belonging to a specific inlined function, it labels each instruction as Inlined or Not inlined and recovers the inlined-function boundaries. We treat the problem as a sequence tagging task typical of NLP and implement a learning-based technique involving instruction embedding and recurrent neural networks. We compile a dataset of open-source projects with different optimizations and use the DWARF debug information standard to construct labeled sequences of inline instructions. We use this dataset to train, validate, and test a sequence labeling architecture in which instructions are encoded via the pre-trained assembly language transformer PalmTree and then processed by an RNN-based classifier to produce binary predictions. When evaluated as a binary classifier, Highliner achieves an F1-score of 0.94 overall. In addition, when specifically tested on recognizing function boundaries, Highliner achieves an Accuracy of 0.82 on initial boundaries and 0.83 on final boundaries.},
  address = {New York, NY, USA},
  articleno = {51},
  author = {Dall'Aglio, Lorenzo and Binosi, Lorenzo and Carminati, Michele and Zanero, Stefano and Polino, Mario},
  doi = {10.1145/3765521},
  issn = {2471-2566},
  issue_date = {November 2025},
  journal = {ACM Trans. Priv. Secur.},
  keywords = {Binary analysis, reverse engineering, function inlining, inline function recognition, natural language processing (NLP)},
  month = {October},
  number = {4},
  numpages = {22},
  publisher = {Association for Computing Machinery},
  title = {Highliner: Enhancing Binary Analysis through NLP-Based Instruction-Level Detection of C++ Inline Functions},
  url = {https://doi.org/10.1145/3765521},
  volume = {28},
  year = {2025}
}

@article{10035436,
  abstract = {JNI programs are widely used thanks to the combined benefits of C and Java programs. However, because understanding the interaction behaviors between two different programming languages is challenging, JNI program development is difficult to get right and vulnerable to security attacks. Thus, researchers have proposed static analysis of JNI program source code to detect bugs and security vulnerabilities in JNI programs. Unfortunately, such source code analysis is not applicable to compiled JNI programs that are not open-sourced or open-source JNI programs containing third-party binary libraries. While JN-SAF, the state-of-the-art analyzer for compiled JNI programs, can analyze binary code, it has several limitations due to its symbolic execution and summary-based bottom-up analysis. In this paper, we propose a novel approach to statically analyze compiled JNI programs without their source code using binary decompilation. Unlike JN-SAF that analyzes binaries directly, our approach decompiles binaries and analyzes JNI programs with the decompiled binaries using an existing JNI program analyzer for source code. To decompile binaries to compilable C source code with precise JNI-interoperation-related types, we improve an existing decompilation tool by leveraging the characteristics of JNI programs. Our evaluation shows that the approach is precise as almost the same as the state-of-the-art JNI program analyzer for source code, and more precise than JN-SAF.},
  author = {Park, Jihee and Lee, Sungho and Hong, Jaemin and Ryu, Sukyoung},
  doi = {10.1109/TSE.2023.3241639},
  issn = {1939-3520},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {Java;Codes;Source coding;Static analysis;Libraries;Computer architecture;Security;Java native interface;binary decompilation;static analysis},
  month = {May},
  number = {5},
  pages = {3089-3105},
  title = {Static Analysis of JNI Programs via Binary Decompilation},
  volume = {49},
  year = {2023}
}

@article{10186242,
  abstract = {Android has been a constant target of cybercriminals that try to attack one of the most used operating systems, commonly using malicious applications (denominated malware) that, once installed on a device, can harm users in several ways. Existing malware detection solutions are usually invasive as they obtain classification features by performing reverse engineering, decompilation, or disassembly of the analyzed application, which infringes licenses and terms of use of applications. In addition, these solutions often employ a single machine learning (ML) model to detect various types of malware, resulting in several false alarms. In this context, we propose an approach to detect Android malware consisting of a set of specific-type detectors in which each one performs a multi-stage analysis, based on rules and ML techniques, in different phases of the application cycle (before and after its installation). Our approach also differs from state-of-the-art solutions by being non-invasive, since it leverages a process to obtain application’s features that does not infringe licenses and terms of use of applications. In addition, according to experiments performed on a real Android smartphone, our proposal presents the following additional advantages over state-of-the-art solutions: a more efficient process to classify applications that is three times faster and requires ten times less CPU usage in some cases (saving device energy); and a better detection performance, with higher balanced accuracy, nine times less false positive cases, and ten times less false negative cases.},
  author = {Costa, Leonardo da and Moia, Vitor},
  doi = {10.1109/ACCESS.2023.3296606},
  issn = {2169-3536},
  journal = {IEEE Access},
  keywords = {Malware;Feature extraction;Smart phones;Operating systems;Proposals;Detectors;Behavioral sciences;Androids;Noninvasive treatment;Android;machine learning;malware detection;multi-stage analysis;non-invasive feature extraction},
  month = {},
  number = {},
  pages = {73127-73144},
  title = {A Lightweight and Multi-Stage Approach for Android Malware Detection Using Non-Invasive Machine Learning Techniques},
  volume = {11},
  year = {2023}
}

@article{10195953,
  abstract = {With the rising prominence of smart contracts, security attacks targeting them have increased, posing severe threats to their security and intellectual property rights. Existing simplistic datasets hinder effective vulnerability detection, raising security concerns. To address these challenges, we propose BiAn, a source code level smart contract obfuscation method that generates complex vulnerability test datasets. BiAn protects contracts by obfuscating data flows, control flows, and code layouts, increasing complexity and making it harder for attackers to discover vulnerabilities. Our experiments with buggy contracts showed an average complexity enhancement of approximately 174% after obfuscation. Decompilers Vandal and Gigahorse had total failure rate increments of 38.8% and 40.5% respectively. Obfuscated contracts also decreased vulnerability detection rates in more than 50% of cases for ten widely-used static analysis detection tools.},
  author = {Zhang, Pengcheng and Yu, Qifan and Xiao, Yan and Dong, Hai and Luo, Xiapu and Wang, Xiao and Zhang, Meng},
  doi = {10.1109/TSE.2023.3298609},
  issn = {1939-3520},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {Smart contracts;Codes;Source coding;Security;Complexity theory;Intellectual property;Layout;Blockchain;Ethereum;smart contract;source code;obfuscation},
  month = {Sep.},
  number = {9},
  pages = {4456-4476},
  title = {BiAn: Smart Contract Source Code Obfuscation},
  volume = {49},
  year = {2023}
}

@inproceedings{10298504,
  abstract = {Decompilation is a widely used process for reverse engineers to significantly enhance code readability by lifting assembly code to a higher-level C-like language, pseudo-code. Nevertheless, the process of compilation and stripping irreversibly discards high-level semantic information that is crucial to code comprehension, such as comments, identifier names, and types. Existing approaches typically recover only one type of information, making them suboptimal for semantic inference. In this paper, we treat pseudo-code as a special programming language, then present a unified pre-trained model, HexT5, that is trained on vast amounts of natural language comments, source identifiers, and pseudo-code using novel pseudo-code-based pre-training objectives. We fine-tune HexT5 on various downstream tasks, including code summarization, variable name recovery, function name recovery, and similarity detection. Comprehensive experiments show that HexT5 achieves state-of-the-art performance on four downstream tasks, and it demonstrates the robust effectiveness and generalizability of HexT5 for binary-related tasks.},
  author = {Xiong, Jiaqi and Chen, Guoqiang and Chen, Kejiang and Gao, Han and Cheng, Shaoyin and Zhang, Weiming},
  booktitle = {2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  doi = {10.1109/ASE56229.2023.00099},
  issn = {2643-1572},
  keywords = {Computer languages;Semantics;Natural languages;Binary codes;Object recognition;Data mining;Task analysis;Reverse Engineering;Deep Learning;Binary Diffing;Information Inference;Programming Language Model},
  month = {Sep.},
  number = {},
  pages = {774-786},
  title = {HexT5: Unified Pre-Training for Stripped Binary Code Information Inference},
  volume = {},
  year = {2023}
}

@article{10299644,
  abstract = {Most of the time, cybercriminals look for new ways to bypass security controls by improving their attacks. In the 1980s, attackers developed malware to kidnap user data by requesting payments. Malware is called a ransomware. Recently, they have demanded payment in Bitcoin or any other cryptocurrency. Ransomware is one of the most dangerous threats on the Internet, and this type of malware could affect almost all devices. Malware cipher device data, making them inaccessible to users. In this study, a new method for Android ransomware classification was proposed. This method implements a Convolutional Neural Network (CNN) for malware classification based on images. This paper presents a novel method for transforming an Android Application Package (APK) into a grayscale image. The image creation relies on using Natural Language Processing (NLP) techniques for text cleaning and Fuzzy Hashing to represent the decompiled code from the APK in a set of hashes after preprocessing using NLP techniques. The image is composed of  $n$  fuzzy hashes that represent the APK. The method was tested using a dataset of 7,765 Android ransomware samples obtained from external researchers and public sources. The accuracy of the proposed method was higher than that of other methods in the literature.},
  author = {Rodriguez-Bazan, Horacio and Sidorov, Grigori and Escamilla-Ambrosio, Ponciano Jorge},
  doi = {10.1109/ACCESS.2023.3328314},
  issn = {2169-3536},
  journal = {IEEE Access},
  keywords = {Operating systems;Ransomware;Natural language processing;Classification algorithms;XML;Metadata;Matched filters;Androids;Convolutional neural networks;Deep learning;Fuzzy systems;Android ransomware;convolutional neural network;deep learning;fuzzy hashing;malware classification;ransomware},
  month = {},
  number = {},
  pages = {121724-121738},
  title = {Android Ransomware Analysis Using Convolutional Neural Network and Fuzzy Hashing Features},
  volume = {11},
  year = {2023}
}

@article{10334519,
  abstract = {Familiar analysis for malware plays an important role in comprehending the diversity of malicious behaviors and identifying the emerging security threats. Existing studies mainly focus on classifying malware into known families by supervised learning. However, these methods face two main challenges, 1) the lack of a large amount of labeled data and 2) the poor effectiveness in identifying unknown families of malware. To overcome these challenges, we propose a new method called multiple features (MulFC) based on unsupervised learning. In the method, we first leverage a decompiling tool to extract multiple features, including manifest features, application programming interface (API) features, and opcode features. Then, the opcode features are preprocessed to filter out the redundant ones to reduce the calculation cost. After that, we adopt the Jaccard index to calculate the similarities between malware and construct a malware network. Finally, InfoMap is applied to perform the clustering on the basis of the malware network. Overall, MulFC does not require the use of labeled data and can identify unknown families of malware. Experiments are conducted on two datasets for the performance evaluation of MulFC. The experimental results show that MulFC achieves 0.810 in terms of normalized mutual information, 0.576 in terms of adjusted rand index, 0.620 in terms of the Fowlkes–Mallows index, and 0.805 in terms of V-measure on average, and outperforms the state-of-the-art baseline method by 0.060, 0.054, 0.038, and 0.065, respectively.},
  author = {Chen, Xin and Yu, Dongjin and Cai, Xinxin and Jiang, He and Yu, Haihua},
  doi = {10.1109/TR.2023.3332090},
  issn = {1558-1721},
  journal = {IEEE Transactions on Reliability},
  keywords = {Malware;Feature extraction;Operating systems;Indexes;Costs;Data mining;Androids;Unsupervised learning;Android malware;InfoMap;malware family clustering;multiple features;unsupervised learning},
  month = {June},
  number = {2},
  pages = {1202-1215},
  title = {Android Malware Family Clustering Based on Multiple Features},
  volume = {73},
  year = {2024}
}

@inproceedings{10444788,
  abstract = {Decompilation is a well-studied area with numerous high-quality tools available. These are frequently used for security tasks and to port legacy code. However, they regularly generate difficult-to-read programs and require a large amount of engineering effort to support new programming languages and ISAs. Recent interest in neural approaches has produced portable tools that generate readable code. Nevertheless, to-date such techniques are usually restricted to synthetic programs without optimization, and no models have evaluated their portability. Furthermore, while the code generated may be more readable, it is usually incorrect. This paper presents SLaDe, a Small Language model Decompiler based on a sequence-to-sequence Transformer trained over real-world code and augmented with a type inference engine. We utilize a novel tokenizer, dropout-free regularization, and type inference to generate programs that are more readable and accurate than standard analytic and recent neural approaches. Unlike standard approaches, SLaDe can infer out-of-context types and unlike neural approaches, it generates correct code. We evaluate SLaDe on over 4,000 ExeBench functions on two ISAs and at two optimization levels. SLaDe is up to 6× more accurate than Ghidra, a state-of-the-art, industrial-strength decompiler and up to 4× more accurate than the large language model ChatGPT and generates significantly more readable code than both.},
  author = {Armengol-Estapé, Jordi and Woodruff, Jackson and Cummins, Chris and O'Boyle, Michael F.P.},
  booktitle = {2024 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  doi = {10.1109/CGO57630.2024.10444788},
  issn = {2643-2838},
  keywords = {Codes;Transformers;Security;Task analysis;Optimization;Standards;Engines;decompilation;neural decompilation;Transformer;language models;type inference},
  month = {March},
  number = {},
  pages = {67-80},
  title = {SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly},
  volume = {},
  year = {2024}
}

@article{10531777,
  abstract = {Industrial Control System (ICS) depends on the underlying Programmable Logical Controllers (PLCs) to run. As such, the security of the internal control logic of the PLCs is the top concern of ICS. Reversing analysis and forensic work against PLC require extracting control logic from the control application running inside PLC, which is still an unresolved problem. To address the challenge, we propose a PLC decompile framework named CLEVER, which can analyze the control application and extract the control logic. First, we propose a simulation execution based code extraction method, which is utilized to filter the control logic related data. Then, to normalize the control application decompile process, an intermediate representation (IR) is designed, which can simplify the analysis process and enhance the extensibility of CLEVER. Finally, a heuristic data flow analysis algorithm is proposed to find variable dependency, and a sequential parsing method is utilized to reconstruct the source code from the control application. To evaluate our work, real world PLC hardware and programming software are used for the experiment. We use 22 real-world, 58 hand-written, and 150 auto-generated control applications to demonstrate the usability, correctness, and operational efficiency of CLEVER.},
  author = {Sang, Chao and Wu, Jun and Li, Jianhua and Guizani, Mohsen},
  doi = {10.1109/TIFS.2024.3402117},
  issn = {1556-6021},
  journal = {IEEE Transactions on Information Forensics and Security},
  keywords = {Codes;Software;Registers;Data mining;Assembly;Process control;Feature extraction;Reverse engineering;program analysis;network forensics;industrial control system;PLC},
  month = {},
  number = {},
  pages = {8685-8700},
  title = {From Control Application to Control Logic: PLC Decompile Framework for Industrial Control System},
  volume = {19},
  year = {2024}
}

@article{10711263,
  abstract = {By combining the SLEIGH decompiler in Ghidra with an machine learning-based technique we can fingerprint reused functions across processor architectures with high accuracy. This opens the door for reverse engineers and antivirus tools to more effectively identify vulnerable and malware code.},
  author = {Hartman, Corey M. and Rimal, Bhaskar P. and de Leon, Daniel Conte and Budhathoki, Nirmal},
  doi = {10.1109/MSEC.2024.3468153},
  issn = {1558-4046},
  journal = {IEEE Security & Privacy},
  keywords = {Codes;Object recognition;Malware;Internet of Things;Fingerprint recognition;Libraries;Systems architecture;Accuracy;Optimization;Source coding;Machine learning},
  month = {March},
  number = {2},
  pages = {71-80},
  title = {Cross-Architecture Binary Function Fingerprinting},
  volume = {23},
  year = {2025}
}

@article{10740475,
  abstract = {Vulnerabilities are challenging to locate and repair, especially when source code is unavailable and binary patching is required. Manual methods are time-consuming, require significant expertise, and do not scale to the rate at which new vulnerabilities are discovered. Automated methods are an attractive alternative, and we propose Partially Recompilable Decompilation (PRD) to help automate the process. PRD lifts suspect binary functions to source, available for analysis, revision, or review, and creates a patched binary using source- and binary-level techniques. Although decompilation and recompilation do not typically succeed on an entire binary, our approach does because it is limited to a few functions, such as those identified by our binary fault localization. We evaluate the assumptions underlying our approach and find that, without any grammar or compilation restrictions, up to 79% of individual functions are successfully decompiled and recompiled. In comparison, only 1.7% of the full C-binaries succeed. When recompilation succeeds, PRD produces test-equivalent binaries 93.0% of the time. We evaluate PRD in two contexts: a fully automated process incorporating source-level Automated Program Repair (APR) methods; and human-edited source-level repairs. When evaluated on DARPA Cyber Grand Challenge (CGC) binaries, we find that PRD-enabled APR tools, operating only on binaries, perform as well as, and sometimes better than full-source tools, collectively mitigating 85 of the 148 scenarios, a success rate consistent with the same tools operating with access to the entire source code. PRD achieves similar success rates as the winning CGC entries, sometimes finding higher-quality mitigations than those produced by top CGC teams. For generality, the evaluation includes two independently developed APR tools and C++, Rode0day, and real-world binaries.},
  author = {Reiter, Pemma and Tay, Hui Jun and Weimer, Westley and Doupé, Adam and Wang, Ruoyu and Forrest, Stephanie},
  doi = {10.1109/TDSC.2024.3482413},
  issn = {1941-0018},
  journal = {IEEE Transactions on Dependable and Secure Computing},
  keywords = {Maintenance engineering;Source coding;Codes;Location awareness;Software;Computer bugs;Prototypes;Measurement;Grammar;C++ languages;Software engineering;software maintenance},
  month = {May},
  number = {3},
  pages = {2270-2282},
  title = {Automatically Mitigating Vulnerabilities in Binary Programs via Partially Recompilable Decompilation},
  volume = {22},
  year = {2025}
}

@article{10858047,
  abstract = {Existing decompilers use rule-based algorithms to transform unstructured Control flow graph (CFG) into equivalent high-level programming language constructs with “goto” statements. One problem of such approaches is that they generate a large number of “goto”s in the output code, which reduce the readability and hinder the understanding of input binaries. A global search algorithm is proposed based on structural analysis. This algorithm restructures a CFG and generates fewer number of “goto” statements than the rule-based algorithm does. We also present a Genetic algorithm (GA) for the global search approach to locate near optimal solutions for large CFGs. Evaluation results on a set of real CFGs show that the genetic algorithm-based heuristic for global search is capable of finding high-quality solutions.},
  author = {Ji, Weixing and Huo, Yuanhong and Wang, Yizhuo and Gao, Yujin and Shi, Feng},
  doi = {10.1049/cje.2017.09.003},
  issn = {2075-5597},
  journal = {Chinese Journal of Electronics},
  keywords = {Computer languages;Codes;Transforms;Flow graphs;Genetic algorithms;Decompiling;Control flow graph restructuring;Structural analysis;Genetic algorithm (GA)},
  month = {November},
  number = {6},
  pages = {1118-1124},
  title = {Control Structure Analysis and Recovery of Embedded Binaries},
  volume = {26},
  year = {2017}
}

@article{10925357,
  abstract = {The exponential growth of Android applications has resulted in a surge of malware threats, posing severe risks to user privacy and data security. To address these challenges, this study introduces a novel malware detection approach utilizing an ensemble of Convolutional Neural Networks (CNNs) for enhanced classification accuracy. The methodology incorporates a multi-phase process, starting with the extraction and preprocessing of APK (Android app) files. The preprocessing phase involves decompressing, decompiling, and transforming the APK files into bytecode and Dex files. The extracted byte data is converted into 1D vectors and reshaped into 2D grayscale images, enabling efficient feature learning through CNNs. The proposed ensemble of CNN-based models undergoes comprehensive training, validation, and evaluation, demonstrating superior performance compared to existing approaches. We used two popular Android datasets to evaluate the performance of our proposed model. Specifically, the model achieves an accuracy of 98.65%, F1-score of 96.43% on the Drebin dataset and attains 97.91% accuracy, 96.73% of F1-score on the AMD dataset. These results confirm the mode’s ability to effectively identify Android malware with high precision and reliability, outperforming traditional techniques. This research not only underscores the potential of our proposed approach in malware detection but also sets a foundation for future advancements. Future efforts will focus on real-time malware detection, integration with mobile security frameworks, and evaluation across diverse datasets to ensure adaptability to emerging malware threats.},
  author = {Nethala, Sainag and Chopra, Pronoy and Kamaluddin, Khaja and Alam, Shahid and Alharbi, Soltan and Alsaffar, Mohammad},
  doi = {10.1109/ACCESS.2025.3551152},
  issn = {2169-3536},
  journal = {IEEE Access},
  keywords = {Malware;Accuracy;Feature extraction;Machine learning;Deep learning;Static analysis;Real-time systems;Random forests;Computational modeling;Support vector machines;Android malware detection;convolutional neural networks;malware classification;machine learning;ensemble learning;attention mechanism;Meta-CNN;deep learning},
  month = {},
  number = {},
  pages = {46673-46696},
  title = {A Deep Learning-Based Ensemble Framework for Robust Android Malware Detection},
  volume = {13},
  year = {2025}
}

@inproceedings{11029887,
  abstract = {Binary-level pointer analysis can be of use in symbolic execution, testing, verification, and decompilation of software binaries. In various such contexts, it is crucial that the result is trustworthy, i.e., it can be formally established that the pointer designations are overapproximative. This paper presents an approach to formally proven correct binary-level pointer analysis. A salient property of our approach is that it first generically considers what proof obligations a generic abstract domain for pointer analysis must satisfy. This allows easy instantiation of different domains, varying in precision, while preserving the correctness of the analysis. In the trade-off between scalability and precision, such customization allows “meaningful” precision (sufficiently precise to ensure basic sanity properties, such as that relevant parts of the stack frame are not overwritten during function execution) while also allowing coarse analysis when pointer computations have become too obfuscated during compilation for sound and accurate bounds analysis. We experiment with three different abstract domains with high, medium, and low precision. Evaluation shows that our approach is able to derive designations for memory writes soundly in COTS binaries, in a context-sensitive interprocedural fashion.},
  author = {Verbeek, Freek and Shokri, Ali and Engel, Daniel and Ravindran, Binoy},
  booktitle = {2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE)},
  doi = {10.1109/ICSE55347.2025.00231},
  issn = {1558-1225},
  keywords = {Accuracy;Scalability;Software;Testing;Software engineering;binary analysis;pointer analysis;formal methods},
  month = {April},
  number = {},
  pages = {42-53},
  title = {Formally Verified Binary-Level Pointer Analysis},
  volume = {},
  year = {2025}
}

@article{11052248,
  abstract = {The cybersecurity threats targeting industrial control systems (ICSs) are evolving with increasing sophistication. Addressing the detection blind spots in existing source code analysis techniques, this study reveals a dual security paradox arising from code sensitivity: privacy leakage risks caused by decompilation techniques and integrity verification deficiencies in reverse engineering. This article investigates three critical challenges: 1) what are the component flow process and detection elements of ICS component source code? 2) how can high-performance and reliable tracing and traceability be provided for ICS component source code exceptions and routine detection? and 3) how can privacy enhancement and trusted detection of ICS component source code with high sensitivity be achieved? This article proposes a blockchain-integrated trusted detection framework for ICS (BCTD-ICS), delivering groundbreaking solutions: 1) establishing a lifecycle circulation model that systematically maps component types, stakeholders, and detection parameters; 2) developing a tripartite collaborative architecture [blockchain- identification resolution zero-knowledge proofs (ZKPs)], featuring a traceability mechanism with trusted identification codes (resolution efficiency: 40 ms/105 queries) to eliminate decompilation-induced privacy risks; and 3) creating an industrial-oriented privacy enhancement system utilizing DBSCAN clustering for intelligent sampling (26% compression rate on BCN3D Moveo) and optimizing ZK-SNARK protocols through Shamir’s secret sharing, establishing a backdoor-resistant distributed parameter generation system (time delay increment < 100 ms). Experimentally verified, our solution enables ICS component code detection supply-chain-wise without sensitive data leakage in real-world industries. This work establishes a novel trusted detection paradigm for ICS, advancing detection efficiency and credibility under strict privacy preservation requirements, meeting Industry 4.0 security demands.},
  author = {Peng, Xiangzhen and Ma, Tianyu and Zheng, Chengliang and Shen, Zhidong and Cui, Xiaohui},
  doi = {10.1109/JIOT.2025.3583304},
  issn = {2327-4662},
  journal = {IEEE Internet of Things Journal},
  keywords = {Blockchains;Source coding;Security;Codes;Privacy;Supply chains;Protocols;Object recognition;Telecommunication traffic;Internet of Things;Artificial intelligence technology;blockchain;identification resolution technology;industrial control systems (ICSs);source code detection;zero-knowledge proofs (ZKPs)},
  month = {Sep.},
  number = {18},
  pages = {37552-37570},
  title = {BCTD-ICS: A Blockchain-Aided Framework for Trusted Detection of Industrial Control System Components},
  volume = {12},
  year = {2025}
}

@article{11098869,
  abstract = {Reverse engineering process serves essential functions in software analysis and security auditing and malware detection but requires significant time and effort. Researchers and practitioners now investigate how Artificial Intelligence (AI) technology can automate and improve different reverse engineering procedures. This survey provides an extensive evaluation of recent AI-based reverse engineering techniques which focus on software decompilation and function identification as well as control flow recovery and vulnerability analysis. The paper presents a classification system for existing methods while comparing them through an analysis of their development from traditional rule-based systems to contemporary deep learning frameworks. The research examines fundamental datasets together with field tools and evaluation metrics. This paper establishes a fundamental understanding of AI integration in reverse engineering for software security while discussing future development directions.},
  author = {Ghimire, Ashutosh and Lingala, Sahasra Rao and Zhang, Junjie and Alsulami, Faris and Amsaad, Fathi},
  doi = {10.1109/ACCESS.2025.3593456},
  issn = {2169-3536},
  journal = {IEEE Access},
  keywords = {Reverse engineering;Software;Codes;Security;Malware;Artificial intelligence;Surveys;Source coding;Static analysis;Logic;Reverse engineering;software security;malware detection;anomalies;threat analysis},
  month = {},
  number = {},
  pages = {152903-152913},
  title = {A Survey on Application of AI on Reverse Engineering for Software Analysis and Security},
  volume = {13},
  year = {2025}
}

@article{11207559,
  abstract = {Decompiler is a specialized type of reverse engineering tool extensively employed in program analysis tasks, particularly in program comprehension and vulnerability detection. However, current Solidity smart contract decompilers face significant limitations in reconstructing the original source code. In particular, the bottleneck of SOTA decompilers lies in inaccurate function identification, incorrect variable type recovery, and missing contract attributes. These deficiencies hinder downstream tasks and understanding of the program logic. To address these challenges, we propose SmartHalo, a new framework that enhances decompiler output by combining static analysis (SA) and large language models (LLM). SmartHalo leverages the complementary strengths of SA’s accuracy in control and data flow analysis and LLM’s capability in semantic prediction. More specifically, SmartHalo constructs a new data structure - Dependency Graph (DG), to extract semantic dependencies via static analysis. Then, it takes DG to create prompts for LLM optimization. Finally, the correctness of LLM outputs is validated through symbolic execution and formal verification. Evaluation on a dataset consisting of 465 randomly selected smart contract functions shows that SmartHalo significantly improves the quality of the decompiled code, compared to SOTA decompilers (e.g., Gigahorse). Notably, integrating GPT-4o mini with SmartHalo further enhances its performance, achieving a precision of 91.32% and a recall of 87.38% for function boundaries, a precision of 90.40% and a recall of 88.82% for variable types, and a precision of 80.66% and a recall of 91.78% for contract attributes.},
  author = {Liao, Zeqin and Nan, Yuhong and Gao, Zixu and Liang, Henglong and Hao, Sicheng and Ren, Peifan and Zheng, Zibin},
  doi = {10.1109/TSE.2025.3623325},
  issn = {1939-3520},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {Smart contracts;Codes;Optimization;Source coding;Static analysis;Large language models;Accuracy;Training;Semantics;Annotations;Smart contract;decompilation;static analysis;large language model},
  month = {Dec},
  number = {12},
  pages = {3574-3590},
  title = {Augmenting Smart Contract Decompiler Output Through Fine-Grained Dependency Analysis and LLM-Facilitated Semantic Recovery},
  volume = {51},
  year = {2025}
}

@article{11242121,
  abstract = {Cryptographic techniques are widely used to safeguard software against privacy breaches. Efficiently detecting encryption algorithms in software to determine whether they meet security requirements is a critical task. However, traditional static and dynamic detection methods often suffer from high false alarm rates or low efficiency, as they cannot fully capture the structural and semantic features of cryptographic algorithms. In this article, we propose FirmCCF, a vulnerability detection tool for custom cryptographic functions in Internet of Things (IoT) devices. FirmCCF leverages an improved deep learning encoder–decoder classification model, CodeT5-cate, to identify and classify cryptographic functions in source code and decompiled firmware. It then outputs highly structured meta-level attributes of cryptographic functions via a large language model (LLM) and detects vulnerabilities through a query-driven approach. FirmCCF achieves 99.97% accuracy, 99.72% recall, and 99.86%  $F1$ -score in detecting cryptographic functions from binary files. We further define seven security rules, encode them as queries, and use them to uncover seven categories of vulnerabilities. An evaluation of 40902 function codes revealed 46 vulnerabilities, including eight previously unknown issues. Our work highlights the urgent need for systematic assessment solutions to detect and mitigate vulnerabilities in custom cryptographic functions.},
  author = {Huang, Jing and Wang, Min and Hu, Yupeng},
  doi = {10.1109/JIOT.2025.3631834},
  issn = {2327-4662},
  journal = {IEEE Internet of Things Journal},
  keywords = {Cryptography;Encryption;Codes;Salt;Software algorithms;Software;Heuristic algorithms;Feature extraction;Internet of Things;Threat modeling;CodeT5-cate;custom cryptographic function;query-driven},
  month = {Jan},
  number = {2},
  pages = {2988-2999},
  title = {FirmCCF: Detecting Custom Cryptographic Function Vulnerabilities Through Query-Driven Approaches},
  volume = {13},
  year = {2026}
}

@article{11267408,
  abstract = {The Android operating system continues to face escalating security challenges, primarily due to its open-source nature and the rapid proliferation of applications from untrusted sources. Traditional static analysis tools lack the flexibility to capture evolving malware behaviors, limiting their interpretability and scalability. Large Language Models (LLMs) are now applied in cybersecurity for malware detection, phishing classification, and cyber threat intelligence. However, their use has not been extended to producing detailed and interpretable Android malware analysis reports. This study integrates LLMs into Android malware analysis by creating a dataset for instruction tuning and fine-tuning the Qwen-7B model using the LoRA method. The model MalQwen is developed by fine-tuning Qwen 2.5-7B with 429 malware samples containing decompiled code and expert labeled security reports. MalQwen outperforms models like Gemini and LLaMA, achieving a BERTscore of 0.84 for SMS malware and a Perplexity score of 3.30 for Scareware. These findings confirm MalQwen’s superior performance in generating precise malware reports, validating LLMs as a powerful new method for Android malware analysis.},
  author = {Priambodo, Tegar Ganang Satrio and Prabowo, Angela Oryza and Puspitarini, Annisa Dwi and Winarso, Raihan Adam Handoyo and Aisyah, Nur and Pratama, Mohammad Yoga and Purwitasari, Diana and Pratomo, Baskoro Adi},
  doi = {10.1109/ACCESS.2025.3637047},
  issn = {2169-3536},
  journal = {IEEE Access},
  keywords = {Malware;Codes;Operating systems;Feature extraction;Static analysis;Security;Cyber threat intelligence;Training;Data mining;Adaptation models;Android malware analysis;large language model;LoRA fine-tuning;static analysis;report generation},
  month = {},
  number = {},
  pages = {208483-208497},
  title = {MalQwen: Fine Tuned LLM for Static Android Malware Analysis Report},
  volume = {13},
  year = {2025}
}

@article{8443103,
  abstract = {This paper investigates the security and privacy of Internet-connected children's smart toys through case studies of three commercially available products. We conduct network and application vulnerability analyses of each toy using static and dynamic analysis techniques, including application binary decompilation and network monitoring. We discover several publicly undisclosed vulnerabilities that violate the Children's Online Privacy Protection Rule as well as the toys' individual privacy policies. These vulnerabilities, especially security flaws in network communications with first-party servers, are indicative of a disconnect between many Internet of Things toy developers and security and privacy best practices despite increased attention to Internet-connected toy hacking risks.},
  author = {Chu, Gordon and Apthorpe, Noah and Feamster, Nick},
  doi = {10.1109/JIOT.2018.2866423},
  issn = {2327-4662},
  journal = {IEEE Internet of Things Journal},
  keywords = {Toy manufacturing industry;Privacy;Servers;Mobile applications;Internet of Things;Authentication;Data security;Internet of Things (IoT);privacy},
  month = {Feb},
  number = {1},
  pages = {978-985},
  title = {Security and Privacy Analyses of Internet of Things Children’s Toys},
  volume = {6},
  year = {2019}
}

@inproceedings{8811905,
  abstract = {The rise of smart contracts - autonomous applications running on blockchains - has led to a growing number of threats, necessitating sophisticated program analysis. However, smart contracts, which transact valuable tokens and cryptocurrencies, are compiled to very low-level bytecode. This bytecode is the ultimate semantics and means of enforcement of the contract. We present the Gigahorse toolchain. At its core is a reverse compiler (i.e., a decompiler) that decompiles smart contracts from Ethereum Virtual Machine (EVM) bytecode into a highlevel 3-address code representation. The new intermediate representation of smart contracts makes implicit data- and control-flow dependencies of the EVM bytecode explicit. Decompilation obviates the need for a contract's source and allows the analysis of both new and deployed contracts. Gigahorse advances the state of the art on several fronts. It gives the highest analysis precision and completeness among decompilers for Ethereum smart contracts - e.g., Gigahorse can decompile over 99.98% of deployed contracts, compared to 88% for the recently-published Vandal decompiler and under 50% for the state-of-the-practice Porosity decompiler. Importantly, Gigahorse offers a full-featured toolchain for further analyses (and a “batteries included” approach, with multiple clients already implemented), together with the highest performance and scalability. Key to these improvements is Gigahorse's use of a declarative, logic-based specification, which allows high-level insights to inform low-level decompilation.},
  author = {Grech, Neville and Brent, Lexi and Scholz, Bernhard and Smaragdakis, Yannis},
  booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
  doi = {10.1109/ICSE.2019.00120},
  issn = {1558-1225},
  keywords = {Smart contracts;Blockchain;Virtual machining;Task analysis;Java;Security;Ethereum;Blockchain;Decompilation;Program Analysis;Security},
  month = {May},
  number = {},
  pages = {1176-1186},
  title = {Gigahorse: Thorough, Declarative Decompilation of Smart Contracts},
  volume = {},
  year = {2019}
}

@inproceedings{8952404,
  abstract = {The decompiler is one of the most common tools for examining binaries without corresponding source code. It transforms binaries into high-level code, reversing the compilation process. Decompilers can reconstruct much of the information that is lost during the compilation process (e.g., structure and type information). Unfortunately, they do not reconstruct semantically meaningful variable names, which are known to increase code understandability. We propose the Decompiled Identifier Renaming Engine (DIRE), a novel probabilistic technique for variable name recovery that uses both lexical and structural information recovered by the decompiler. We also present a technique for generating corpora suitable for training and evaluating models of decompiled code renaming, which we use to create a corpus of 164,632 unique x86-64 binaries generated from C projects mined from GitHub. Our results show that on this corpus DIRE can predict variable names identical to the names in the original source code up to 74.3% of the time.},
  author = {Lacomis, Jeremy and Yin, Pengcheng and Schwartz, Edward and Allamanis, Miltiadis and Le Goues, Claire and Neubig, Graham and Vasilescu, Bogdan},
  booktitle = {2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  doi = {10.1109/ASE.2019.00064},
  issn = {2643-1572},
  keywords = {Tools;Recurrent neural networks;Reverse engineering;Training;Software;Analytical models;Decompilation;Deep learning},
  month = {Nov},
  number = {},
  pages = {628-639},
  title = {DIRE: A Neural Approach to Decompiled Identifier Naming},
  volume = {},
  year = {2019}
}

@inproceedings{9073578,
  abstract = {Mobile phones have become nowadays a commodity to the majority of people. Using them, people are able to access the world of Internet and connect with their friends, their colleagues at work or even unknown people with common interests. This proliferation of the mobile devices has also been seen as an opportunity for the cyber criminals to deceive smartphone users and steel their money directly or indirectly, respectively, by accessing their bank accounts through the smartphones or by blackmailing them or selling their private data such as photos, credit card data, etc. to third parties. This is usually achieved by installing malware to smartphones masking their malevolent payload as a legitimate application and advertise it to the users with the hope that mobile users will install it in their devices. Thus, any existing application can easily be modified by integrating a malware and then presented it as a legitimate one. In response to this, scientists have proposed a number of malware detection and classification methods using a variety of techniques. Even though, several of them achieve relatively high precision in malware classification, there is still space for improvement. In this paper, we propose a text mining all repeated pattern detection method which uses the decompiled files of an application in order to classify a suspicious application into one of the known malware families. Based on the experimental results using a real malware dataset, the methodology tries to correctly classify (without any misclassification) all randomly selected malware applications of 3 categories with 3 different families each.},
  author = {Xylogiannopoulos, Konstantinos F. and Karampelas, Panagiotis and Alhajj, Reda},
  booktitle = {2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  doi = {10.1145/3341161.3350841},
  issn = {2473-991X},
  keywords = {Malware;Androids;Humanoid robots;Mobile handsets;Social network services;Text mining;Payloads;Android malware detection;malware family classification;text mining;ARPaD;LERP-RSA},
  month = {Aug},
  number = {},
  pages = {887-894},
  title = {Text Mining for Malware Classification Using Multivariate All Repeated Patterns Detection},
  volume = {},
  year = {2019}
}

@article{9514711,
  abstract = {Control flow-based feature extraction method has the ability to detect malicious code with higher accuracy than traditional text-based methods. Unfortunately, this method has been encountered with the NP-hard problem, which is infeasible for the large-sized and high-complexity programs. To tackle this, we propose a control flow-based feature extraction dynamic programming algorithm for fast extraction of control flow-based features with polynomial time O($N^{2}$), where N is the number of basic blocks in decompiled executable codes. From the experimental results, it is demonstrated that the proposed algorithm is more efficient and effective in detecting malware than the existing ones. Applying our algorithm to an Internet of Things dataset gives better results on three measures: Accuracy = 99.05%, False Positive Rate = 1.31% and False Negative Rate = 0.66%.},
  author = {Nghi Phu, Tran and Dai Tho, Nguyen and Huy Hoang, Le and Ngoc Toan, Nguyen and Ngoc Binh, Nguyen},
  doi = {10.1093/comjnl/bxaa087},
  issn = {1460-2067},
  journal = {The Computer Journal},
  keywords = {IoT malware detection;control flow-based features;dynamic programming;CFD;embedded malware},
  month = {Nov},
  number = {1},
  pages = {599-609},
  title = {An Efficient Algorithm to Extract Control Flow-Based Features for IoT Malware Detection},
  volume = {64},
  year = {2019}
}

@article{9520296,
  abstract = {Much software, whether beneficent or malevolent, is distributed only as binaries, sans source code. Absent source code, understanding binaries’ behavior can be quite challenging, especially when compiled under higher levels of compiler optimization. These optimizations can transform comprehensible, “natural” source constructions into something entirely unrecognizable. Reverse engineering binaries, especially those suspected of being malevolent or guilty of intellectual property theft, are important and time-consuming tasks. There is a great deal of interest in tools to “decompile” binaries back into more natural source code to aid reverse engineering. Decompilation involves several desirable steps, including recreating source-language constructions, variable names, and perhaps even comments. One central step in creating binaries is optimizing function calls, using steps such as inlining. Recovering these (possibly inlined) function calls from optimized binaries is an essential task that most state-of-the-art decompiler tools try to do but do not perform very well. In this paper, we evaluate a supervised learning approach to the problem of recovering optimized function calls. We leverage open-source software and develop an automated labeling scheme to generate a reasonably large dataset of binaries labeled with actual function usages. We augment this large but limited labeled dataset with a pre-training step, which learns the decompiled code statistics from a much larger unlabeled dataset. Thus augmented, our learned labeling model can be combined with an existing decompilation tool, Ghidra, to achieve substantially improved performance in function call recovery, especially at higher levels of optimization.},
  author = {Ahmed, Toufique and Devanbu, Premkumar and Sawant, Anand Ashok},
  doi = {10.1109/TSE.2021.3106572},
  issn = {1939-3520},
  journal = {IEEE Transactions on Software Engineering},
  keywords = {Libraries;Tools;Optimization;Databases;Reverse engineering;Training;Malware;Reverse engineering;software modeling;deep learning},
  month = {Oct},
  number = {10},
  pages = {3862-3876},
  title = {Learning to Find Usages of Library Functions in Optimized Binaries},
  volume = {48},
  year = {2022}
}

@article{9869841,
  abstract = {Aiming at the problems of coupling between transformer input characteristics and low accuracy of transformer fault diagnosis, SSA-MDS and other soft technologies are used to analyze the key characteristics of transformer faults, so as to improve the accuracy of transformer fault diagnosis. The SSA algorithm cascade MDS algorithm to process the DGA data is proposed. Subsequently, the TSSA-RF model is introduced to classify the DGA data. The DGA data is first mapped to a high-dimensional space. Next, the optimal feature subset is encoded using the SSA algorithm to reduce irrelevant and redundant features. In this study, the correlation between the optimal feature dimension and the transformer fault diagnosis accuracy is investigated. the expression of the optimal feature subset is obtained by decompiling the SSA operator. The pre-processed data are classified using the RF model, and the TSSA -RF model for classifying the DGA data is found with the highest accuracy through the comparison of different optimization algorithms. After the RF model is optimized using the TSSA algorithm, its accuracy increases by 7.89%, and the accuracy of the TSSA -RF model is obtained as 92.11%. The example results show that compared with the original data, the proposed data processing algorithm improves the diagnostic accuracy of transformer by 11.97 % in the RF model. Compared with multiple preprocessing methods, SSA-MDS has the highest accuracy. Compared with the original data, the accuracy of TSSA-RF model increases by 11.64 %.},
  author = {Zhang, Mei and Chen, Wanli},
  doi = {10.1109/ACCESS.2022.3202982},
  issn = {2169-3536},
  journal = {IEEE Access},
  keywords = {Oil insulation;Fault diagnosis;Optimization;Data models;Power transformer insulation;Classification algorithms;Classification tree analysis;Power transformer;fault diagnosis;RF~model;TSSA algorithm;feature extraction},
  month = {},
  number = {},
  pages = {92505-92515},
  title = {Fault Diagnosis of Power Transformer Based on SSA—MDS Pretreatment},
  volume = {10},
  year = {2022}
}

@article{9921221,
  abstract = {With society’s increasing reliance on computer systems and network technology, the threat of malicious software grows more and more serious. In the field of information security, malware detection has been a key problem that academia and industry are committed to solving. Machine learning is an effective method for processing large-scale data, such as the Gradient Boosting Decision Tree (GBDT) and deep neural network technology. Although these types of detection methods can deal with cyber threats, most feature extraction methods are based on the statistical information features of portable executable (PE) files and thus lack the decompiled code and execution flow structure of the PE samples. Therefore, we propose a Control-Flow Graph (CFG)- and Graph Isomorphism Network (GIN)-based malware classification system. The feature vectors of CFG basic blocks are generated using the large-scale pre-trained language model MiniLM, which is beneficial for the GIN to further learn and compress the CFG-based representation, and classified with multi-layer perceptron. In addition, we evaluated the effectiveness of the representation under different dimensions and classifiers. To evaluate our method, we set up a CFG-based malware detection graph dataset from a PE file of the Blue Hexagon Open Dataset for Malware Analysis (BODMAS), which we call the Malware Geometric Binary Dataset (MGD-BINARY) and collected the experimental results of CFG representation in different dimensions and classifier settings. The evaluation results show that our proposal has proved an Accuracy metric of 0.99160 and achieved 0.99148 Area Under the Curve (AUC) results.},
  author = {Gao, Yun and Hasegawa, Hirokazu and Yamaguchi, Yukiko and Shimada, Hajime},
  doi = {10.1109/ACCESS.2022.3215267},
  issn = {2169-3536},
  journal = {IEEE Access},
  keywords = {Malware;Feature extraction;Codes;Data mining;Analytical models;Machine learning;Natural language processing;Graphics;Malware detection;machine learning;static analysis;graph classification},
  month = {},
  number = {},
  pages = {111830-111841},
  title = {Malware Detection by Control-Flow Graph Level Representation Learning With Graph Isomorphism Network},
  volume = {10},
  year = {2022}
}
