{"key": "10.1109/ASE.2019.00064", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_variable_naming", "evidence": "novel probabilistic technique for variable name recovery", "explanation": "抽象から変数名復元を主目的としていることが分かり、出力は元コードの変数名を付与した高水準コードになるため、IC4 に該当する。"}, {"code": "in_decompiler_enhancement", "evidence": "uses both lexical and structural information recovered by the decompiler", "explanation": "入力としてデコンパイラが生成したコード（低水準出力）を利用し、LLM/ML により識別子を付与してコードの可読性を向上させているため、IC2 の条件も満たす。"}], "reasoning": "本論文はバイナリから得られたデコンパイル結果を入力とし、LLM/ML を用いて変数名を自動復元する手法を提案している。出力は識別子が付与された擬似コード（L1‑L3）であり、デコンパイルの可読化・意味回復という目的に合致するため、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3579, "latency_ms": 40954}}
{"key": "10.1109/ASE56229.2023.00099", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "lifting assembly code to a higher-level C-like language, pseudo-code", "explanation": "アブストラクトがアセンブリ（低水準）から擬似コード（L2）を直接生成することを目的としているため、Core Decompilation に該当します。"}, {"code": "in_variable_naming", "evidence": "variable name recovery, function name recovery", "explanation": "変数・関数名の復元タスクを下流タスクとして扱っている点で、識別子復元も目的に含まれます。"}], "reasoning": "本論文はアセンブリコードという低水準入力から、LLM（HexT5）を用いてC風の擬似コード（L2）を生成することを中心に研究しており、デコンパイルのコアタスクに該当します。また、変数名や関数名の復元も評価タスクとして含まれるため、Decompilation の主要目的を満たしています。", "model": "openai/gpt-oss-120b", "tokens_used": 3487, "latency_ms": 37401}}
{"key": "10.1109/CGO57630.2024.10444788", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "SLaDe, a Small Language model Decompiler ... generate programs that are more readable and accurate", "explanation": "LLM（Transformer）を用いて低水準の最適化アセンブリから直接ソースコードを生成しているため、Core Decompilation に該当します。"}, {"code": "in_type_recovery", "evidence": "augmented with a type inference engine ... can infer out-of-context types", "explanation": "タイプ推論エンジンを組み込み、型情報の復元を行っていることから Type Recovery でも該当します。"}], "reasoning": "本論文は最適化されたアセンブリという低水準入力を対象に、Transformer ベースの小型言語モデルを用いてソースコード（L1/L2）を生成する手法を提案している。LLM/ML が中心手法であり、生成されたコードは可読性と正確性の向上を目的としているため、Decompilation Survey の採択基準（IC）を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3520, "latency_ms": 35606}}
{"key": "10.1109/ICSE.2019.00120", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Key to these improvements is Gigahorse's use of a declarative, logic-based specification", "explanation": "アブストラクトではML/LLMの使用は言及されず、むしろ宣言的ロジックベースの手法と記述されているため、ML/LLM が中核手法でないと判断した。"}], "reasoning": "本論文はEVMバイトコードから高レベルの3アドレスコードへ逆コンパイルするツールを提示していますが、手法は宣言的ロジック仕様であり機械学習や大規模言語モデルの利用は示されていません。したがって、ML/LLM が中核であるというインクルード基準を満たさないため除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3221, "latency_ms": 21546}}
{"key": "10.1109/ICSE55347.2025.00231", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an approach to formally proven correct binary-level pointer analysis.", "explanation": "抽象からは機械学習や大規模言語モデルの使用が言及されておらず、従来の形式検証手法のみであるため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿はバイナリレベルのポインタ解析を形式的に検証する手法を提示しており、ML/LLM を用いたデコンパイル手法とは無関係です。入力は低水準バイナリでも、出力はコード生成や可読化ではなく解析結果であり、L1‑L3 のデコンパイル対象外です。そのため除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3225, "latency_ms": 25896}}
{"key": "10.1145/3019612.3019926", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "In order to protect applications from piracy or illegal theft, it is necessary to detect theft by measuring application similarity.", "explanation": "抽象からは機械学習・LLM の使用が全く言及されておらず、類似度測定は従来手法で行われていると判断したため、ML/LLM 不使用として除外しました。"}, {"code": "ex_no_code_generation", "evidence": "application similarity is measured 1) using the source codes decompiled from the executables, or 2) using the characteristics extracted from the executables (i.e., birthmark).", "explanation": "目的はコードの復元・可読化ではなく、類似度測定・盗用検出であり、コード生成・再構成が主目的ではないため除外基準に該当します。"}], "reasoning": "本稿は Android アプリの類似性測定による盗用検出を目的としており、ML/LLM を用いたデコンパイルや高水準コード生成は行わない。入力はバイナリだが、出力はコードではなく類似度スコアであり、デコンパイルの復元目的を満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3406, "latency_ms": 31544}}
{"key": "10.1145/3098954.3103152", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "using the open source decompiler Dagger", "explanation": "本文は従来のデコンパイラ Dagger を用いており、機械学習や LLM の利用は示されていないため ML/LLM 不使用と判断した。"}, {"code": "ex_out_of_scope", "evidence": "LLVM Intermediate Representation (IR)", "explanation": "出力は LLVM IR という低水準中間表現であり、L1–L3 の高水準コード（ソース、擬似コード、AST 等）には該当しないため L4‑only とみなして除外した。"}], "reasoning": "本稿は機械学習・LLM を用いない従来のデコンパイラに依存し、出力も LLVM IR という低レベルの中間表現であるため、デコンパイルサーベイの対象（ML/LLM を中心に L1–L3 出力を生成する研究）から外れます。", "model": "openai/gpt-oss-120b", "tokens_used": 3303, "latency_ms": 29827}}
{"key": "10.1145/3106237.3121274", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "We used statistical machine translation to suggest variable names that are natural given the context.", "explanation": "本稿は変数名の提案という属性（識別子）だけを出力しており、L1–L3 のコード全体や擬似コードの生成を行わないため、L4‑only に該当し除外します。"}], "reasoning": "本論文は decompiled code の変数名を統計的機械翻訳で付与する手法を提案していますが、出力は変数名という属性情報のみであり、コンパイル可能なソースや擬似コードといった L1–L3 レベルの高水準表現を生成しません。そのため、本バージョンの対象範囲（L1–L3）外（L4‑only）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 4047, "latency_ms": 67662}}
{"key": "10.1145/3176258.3176319", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We have developed the first decompiler for ladder logic programs.", "explanation": "要旨ではデコンパイラの開発について述べられていますが、機械学習や大規模言語モデルの利用は言及されておらず、ML/LLM が手法の中核でないため除外基準 EC1 に該当します。"}], "reasoning": "本稿は ladder logic のデコンパイル手法を提示していますが、機械学習・LLM の使用が示されていません。サーベイの採択基準では ML/LLM が必須であるため、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3286, "latency_ms": 26457}}
{"key": "10.1145/3191737", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "software decompiling, and both static and dynamic embedded code analysis", "explanation": "要旨ではデコンパイルや静的・動的解析を用いると記載されていますが、機械学習や大規模言語モデルの利用については言及されていないため、ML/LLM を使用していないと判断し、除外基準 EC1 に該当します。"}], "reasoning": "本論文は Fitbit のファームウェアやアプリの脆弱性を解析するセキュリティ研究であり、デコンパイルは手法の一つとして言及されていますが、ML/LLM を中心とした手法は使用されていません。したがって、除外基準 ex_no_ml に該当し、除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3150, "latency_ms": 19420}}
{"key": "10.1145/3196321.3196330", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "We consider decompiler output to be a noisy distortion of the original source code", "explanation": "入力として使用しているのは既存デコンパイラの出力であり、バイナリやアセンブリなどの低水準表現ではないため、低水準入力が無いと判断した。"}], "reasoning": "本論文はデコンパイラが生成した擬似コードを入力とし、変数名の自然さを改善する手法を提案している。入力が低水準（バイナリ/アセンブリ/バイトコード）でないため、IC0 の条件を満たさず除外対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3301, "latency_ms": 27203}}
{"key": "10.1145/3212480.3212487", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a way to decompile 64-bit ARM binaries to their LLVM intermediate representation (IR).", "explanation": "アブストラクトに機械学習・LLMの使用が記載されておらず、従来の静的解析手法だけで実装されているため、EC1（ML/LLM未使用）に該当し除外します。"}], "reasoning": "本論文はバイナリをLLVM IRへデコンパイルし、静的解析で暗号使用の誤用を検出する手法を提案していますが、機械学習や大規模言語モデルを利用していないことが明示されています。そのためインクルード基準のIC0（ML/LLM が中核手法）を満たさず、除外基準 EC1 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3222, "latency_ms": 23466}}
{"key": "10.1145/3236794", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "All our prototypes have been implemented in OCaml", "explanation": "要旨に機械学習や大規模言語モデルの使用は記載されておらず、実装は OCaml で行われているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本論文は CAD 用関数型言語の設計と、メッシュから CAD 言語への逆コンパイル手法を提示していますが、機械学習や LLM を手法の中核として利用している記述がなく、実装は OCaml による従来のコンパイラ技術です。そのため、Decompilation Survey の ML/LLM を必須とする基準を満たさず、除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3287, "latency_ms": 26167}}
{"key": "10.1145/3276486", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to automatically detect gas-focused vulnerabilities with very high confidence", "explanation": "目的が脆弱性検出であり、復元・可読化・コード生成が主目的ではないため除外"}], "reasoning": "本論文は低水準バイトコードをデコンパイルして解析に利用していますが、主たる目的はガス関連脆弱性の検出であり、復元や高水準コードの生成を目指していません。そのため、復元・可読化を目的としたデコンパイル研究の基準（IC）を満たさず、除外基準 ex_no_code_generation に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3302, "latency_ms": 24410}}
{"key": "10.1145/3293880.3294102", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "generating formally proven equivalence theorems between decompiled x86-64 machine code and big step semantics", "explanation": "低水準のバイナリ/アセンブリから高水準のビッグステップ意味論（L3）を生成しており、LLM/ML が中心手法として用いられているため、Core Decompilation に該当する。"}, {"code": "ex_no_code_generation", "evidence": "The methodology minimizes the trusted code base by leveraging machine‑learned semantics to build a formal machine model", "explanation": "本手法はコード生成（ソースコードや擬似コード）そのものを目的としていないが、生成対象は高水準意味表現であり、復元・意味回復が主目的であるため除外基準には該当しないことを示す。"}], "reasoning": "本論文は低水準の x86‑64 バイナリを入力とし、機械学習を利用して高水準のビッグステップ意味論へ変換する手法を提案している。出力は L3 に相当する高水準表現であり、目的は復元・意味回復であるため、Decompilation Survey のコアデコンパイル（in_core）に該当し、採択対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3445, "latency_ms": 36425}}
{"key": "10.1145/3319535.3363255", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "automatically stitches the results from multiple decompilers together", "explanation": "要旨では既存のデコンパイラを組み合わせるシステムと述べられており、ML/LLM の利用は言及されていないため、ML/LLM を用いない点で除外基準 EC1 に該当します。"}], "reasoning": "本稿は複数の従来型デコンパイラの出力を統合する実践的システムを提案していますが、機械学習や大規模言語モデルを手法の中核として用いている記述がありません。したがって、除外基準『No ML/LLM』に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3078, "latency_ms": 21877}}
{"key": "10.1145/3320269.3384766", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The algorithm is designed from the ground up with the goal of producing C code...", "explanation": "要旨に機械学習や大規模言語モデルの利用が言及されていないため、ML/LLMを使用していないと判断し、除外基準 EC1 に該当します。"}], "reasoning": "本論文はバイナリから高品質な C ソースコードを生成するデコンパイラ手法を提案していますが、要旨に機械学習や大規模言語モデルの使用が記載されていません。したがって、Decompilation Survey の対象である「LLM/ML を中核手法としたデコンパイル」には該当せず、除外基準 ex_no_ml により除外されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3151, "latency_ms": 24240}}
{"key": "10.1145/3321705.3329833", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we implemented a prototype of DeClassifier using Binary Analysis Platform (BAP)", "explanation": "要旨に機械学習や大規模言語モデルの利用が記載されておらず、従来の静的解析ツール（BAP）だけが使用されているため、ML/LLM が使われていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "Recovering class inheritance from C++ binaries has several security benefits including in solving problems such as decompilation", "explanation": "出力はクラス継承関係という属性情報のみで、ソースコードや擬似コード（L1‑L3）を生成しないため、L4‑only に該当し本バージョンの対象外とする。"}], "reasoning": "本論文はバイナリからクラス継承情報を推測する手法を提案しており、機械学習やLLMは用いられていない。さらに出力は継承関係という高水準属性（L4）に留まり、コードや擬似コード（L1‑L3）の生成を伴わないため、デコンパイル調査の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3487, "latency_ms": 36260}}
{"key": "10.1145/3324884.3418905", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "we enhance the results of taint analysis with call graph concatenation", "explanation": "本文では機械学習や大規模言語モデルの使用は言及されておらず、従来の静的解析手法だけが使われているため、ML/LLM が中核手法であるという条件を満たさない。"}], "reasoning": "本稿は Android のクリップボードアクセスを動的検知し、静的データフロー解析でプライバシー漏洩を検出する手法を提案しているが、デコンパイルやコード生成を目的としておらず、ML/LLM を使用していない。したがって、Decompilation Survey の対象外であり除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3094, "latency_ms": 22081}}
{"key": "10.1145/3338503.3357725", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "In this tutorial, the Ghidra software reverse engineering framework will be presented...", "explanation": "概要は Ghidra の使い方や機能紹介であり、機械学習／大規模言語モデルの利用について言及されていないため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿は Ghidra のチュートリアルであり、デコンパイル手法そのものや ML/LLM の適用についての研究内容が示されていない。したがって、Decompilation Survey の対象である LLM/ML を中核としたデコンパイル研究ではないと判断し、除外 (ex_no_ml) とした。", "model": "openai/gpt-oss-120b", "tokens_used": 2977, "latency_ms": 18249}}
{"key": "10.1145/3338906.3338956", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a general strategy for reducing such graphs. We combine this with a novel algorithm for reduction called Binary Reduction in a tool called J-Reduce for Java bytecode.", "explanation": "アブストラクトに機械学習・LLM の使用について言及がなく、従来のアルゴリズムによる入力削減手法のみが述べられているため、EC1 に該当し除外する。"}], "reasoning": "本論文は Java バイトコードの依存関係グラフを削減する手法（Delta debugging の高速化）を提案しており、ML/LLM を利用したデコンパイルや高水準コード生成を目的としない。入力は低水準だが出力も低水準であり、L1–L3 の高水準表現を生成しない上に、ML 手法が全く使用されていないため除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3224, "latency_ms": 28768}}
{"key": "10.1145/3340422.3343639", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "features extracted from intermediate code representations obtained using decompilation of APK file ... to develop the models for predicting android malware applications.", "explanation": "要旨ではデコンパイルした中間表現を特徴量として機械学習モデルを訓練し、マルウェアの分類・予測を行うことが目的であり、復元・高水準コード生成は目的に含まれないため除外と判断した。"}], "reasoning": "本論文はデコンパイルされたコードを特徴量として利用し、マルウェア検出のための分類モデルを構築している。デコンパイル自体は手段に過ぎず、出力はコード（L1‑L3）ではなくマルウェアか否かのラベルであるため、再構成・復元を目的としたデコンパイル研究の範囲外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3297, "latency_ms": 28696}}
{"key": "10.1145/3341161.3350841", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a text mining all repeated pattern detection method", "explanation": "本文はテキストマイニング手法を用いると述べており、機械学習やLLMの利用は示されていないため、ML/LLM未使用と判断した。"}, {"code": "ex_no_code_generation", "evidence": "classify a suspicious application into one of the known malware families", "explanation": "目的はマルウェアの分類であり、低水準コードから高水準コードを生成する復元・可読化ではないため、コード生成・復元意図がないと判断した。"}], "reasoning": "本論文はデコンパイルされたファイルを入力としてテキストマイニングによりマルウェアを分類する手法を提案しているが、機械学習・LLMの使用がなく、主目的も復元や可読化ではなく分類である。したがって、Decompilation Survey の対象から外れると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3462, "latency_ms": 33299}}
{"key": "10.1145/3342195.3387550", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present BinRec, a new approach to heuristic‑free binary recompilation which lifts dynamic traces of a binary to a compiler‑level intermediate representation (IR)", "explanation": "アブストラクトに機械学習／LLMの利用が記載されておらず、従来の手法（ヒューリスティックフリーな動的リフティング）だけが述べられているため、ML/LLM を用いていないと判断し、EC1 に該当する"}], "reasoning": "本稿はバイナリの動的リフトと再コンパイルを提案しているが、機械学習や大規模言語モデルを手法の中心に据えている記述がなく、ML を用いたデコンパイルとは無関係である。したがって、Include 基準を満たさず、EC1 の 'ex_no_ml' に該当し除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3437, "latency_ms": 32382}}
{"key": "10.1145/3371307.3371312", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach is based on a series of periodic checks on the execution environment (i.e., Android components) and on the app itself.", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用は記載されておらず、従来のチェック手法のみなので、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は Android アプリに対する悪意あるリバースエンジニアリングの検出を目的とした手法を提案しており、低水準バイナリやアセンブリを高水準コードへ変換するデコンパイルとは無関係です。また、機械学習・LLM の利用が示されていないため、除外基準 EC1（ex_no_ml）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3137, "latency_ms": 24507}}
{"key": "10.1145/3372297.3417251", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an efficient technique to detect virtual inheritance in C++ binaries...", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が言及されていないため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "recover virtual inheritance from COTS binaries... recover a maximum of 95% ... of virtual and intermediate bases", "explanation": "出力はクラス継承関係という属性情報のみで、L1‑L3 のコードや擬似コードの生成が示されていないため L4‑only とみなし除外する。"}], "reasoning": "本稿はバイナリから仮想継承関係を復元する手法を提示しているが、機械学習手法は使用していない。また、提供される出力はクラス階層という属性情報であり、ソースコードや擬似コードといった L1‑L3 レベルの表現が含まれないため、本サーベイの対象外（L4‑only）となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3551, "latency_ms": 35860}}
{"key": "10.1145/3375894.3375895", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a new approach that leverages the human analyst expertise to overcome decompilation challenges.", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、手法は人間アナリストとGDB拡張によるものであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文はデバッグ指向のマルウェアデコンパイル手法を提案しており、入力はバイナリで高位コードを生成する点はデコンパイルに該当するが、手法の中心が機械学習やLLMではなく人間の専門知識とGDB拡張に基づくため、Include Criteria の「LLM/ML が中核手法」の条件を満たさない。したがって除外 (ex_no_ml) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3198, "latency_ms": 20832}}
{"key": "10.1145/3385412.3386012", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present Szalinski, a tool that uses Equality Saturation with semantics-preserving CAD rewrites...", "explanation": "本文は ML／LLM を用いず、Equality Saturation と CAD rewrite に基づく手法のみを述べているため、EC1 に該当し除外します。"}], "reasoning": "本稿は低レベルのメッシュから高レベルの CSG 表現へのデコンパイルを提案していますが、手法は機械学習や大規模言語モデルを利用していません。デコンパイル研究の対象ではあるものの、ML/LLM が中核でないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3136, "latency_ms": 22962}}
{"key": "10.1145/3395363.3397370", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "A C decompiler converts an executable (the output from a C compiler) into source code.", "explanation": "アブストラクトではML/LLMの利用について言及せず、従来のCデコンパイラの動作や評価のみを述べているため、ML/LLMを用いていないと判断した。"}], "reasoning": "本論文はCデコンパイラの正確性を実証的に評価する研究であり、機械学習や大規模言語モデルを手法の中核として使用していない。したがって、Include Criteriaを満たさず、Exclude Criteriaの「No ML/LLM」に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3268, "latency_ms": 19415}}
{"key": "10.1145/3395363.3404365", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose EShield, an automated security enhancement tool for protecting smart contracts against reverse engineering.", "explanation": "要旨に機械学習や大規模言語モデルの利用が全く記載されておらず、従って EC1 (ML/LLM 未使用) に該当します。"}], "reasoning": "本稿はスマートコントラクトのリバースエンジニアリング防止手法を提案しており、ML/LLM を用いたデコンパイル手法ではないため、除外基準 EC1 に該当し、採択対象外です。", "model": "openai/gpt-oss-120b", "tokens_used": 3147, "latency_ms": 25561}}
{"key": "10.1145/3405962.3405980", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "we developed a classification dataset from collected anti-malware data", "explanation": "アブストラクトでは低水準バイナリやアセンブリなどの入力ではなく、アンチマルウェアデータの分類データセットを作成したと述べており、デコンパイルの低水準入力が存在しないため除外と判断した。"}, {"code": "ex_no_code_generation", "evidence": "applied various machine learning algorithms ... provides high accuracy", "explanation": "目的はマルウェア検出の分類であり、コードの復元や生成は行わないため除外基準（復元・生成が主目的でない）に該当する。"}], "reasoning": "本論文は低水準コードを入力としたデコンパイルを目的としておらず、アンチマルウェアデータの分類と機械学習による検出精度向上を扱っている。したがって、低水準入力の欠如とコード生成目的の不在により除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3227, "latency_ms": 29307}}
{"key": "10.1145/3411764.3445249", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Falx, a synthesis-powered visualization tool that allows users to specify visualizations ... without needing to worry about data layout.", "explanation": "本稿はデコンパイルではなく、可視化仕様の合成とデータ変換を扱うため、L1–L3 のデコンパイル対象外である。"}, {"code": "ex_no_lowlevel_input", "evidence": "When the input data layout conforms to the visualization design, users can easily specify visualizations ...", "explanation": "入力はデータレイアウトや列であり、バイナリや機械語などの低水準表現ではない。"}, {"code": "ex_no_ml", "evidence": "a synthesis-powered visualization tool", "explanation": "本研究はプログラム合成を用いており、機械学習・LLM が中心手法として明示されていない。"}], "reasoning": "論文はデコンパイルに関する研究ではなく、データ可視化のための合成支援ツールを提案している。入力は低水準コードではなくデータレイアウトであり、ML/LLM が使用されていないため、スクリーニング基準の対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3314, "latency_ms": 31837}}
{"key": "10.1145/3411764.3445535", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose IGScript... we design ... a compiler ... and then develop a code generator (decompiler)", "explanation": "本文ではコンパイラとデコンパイラを紹介していますが、機械学習や大規模言語モデルの利用は言及されておらず、ML/LLM が使用されていないため除外します。"}, {"code": "ex_no_lowlevel_input", "evidence": "translate the interactive data exploration animations back into script codes", "explanation": "デコンパイルの入力はアニメーションという高レベル表現であり、バイナリやアセンブリといった低水準入力ではないと判断できるため除外基準に該当します。"}], "reasoning": "本稿は科学データ可視化用の対話型文法ツールを提案し、アニメーションからスクリプトへの逆変換（デコンパイル）機能を示していますが、低水準バイナリ等を入力としたものではなく、また機械学習・LLM を用いた手法も記載されていません。したがって、Decompilation Survey Screening Rules の除外基準（ML未使用、低水準入力なし）に該当し、除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3279, "latency_ms": 28050}}
{"key": "10.1145/3422337.3450321", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose OBFUS, a web-based tool that can easily apply obfuscation techniques...", "explanation": "アブストラクトに機械学習・LLM の利用についての記述がなく、単なるツール実装とみなせるため、ML/LLM が使用されていないと判断しました。"}], "reasoning": "本稿はバイナリをLLVM IRにデコンパイルし再コンパイルするオブfuscation ツールを提案していますが、手法は機械学習や大規模言語モデルを用いたものではなく、単なるルールベース／コンパイラ技術です。目的も可読化やコード復元ではなく、難読化であり、LLM/ML が中心手法でないため除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3163, "latency_ms": 28054}}
{"key": "10.1145/3428151", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "efficient and self-learning autonomous hybrid ... multi-vector Android malware threat detection framework", "explanation": "要旨はマルウェア検出フレームワークの提案であり、復元・コード生成が目的ではなく分類・検知が主目的であるため除外と判断した。"}], "reasoning": "本論文は Android マルウェアの検出を目的としたハイブリッド深層学習手法を提案しており、低水準バイナリから高水準コードを生成するデコンパイルの目的・手法が記載されていない。したがって復元・可読化を目指すデコンパイル研究には該当せず、EC3（コード生成・復元意図がない）に該当するため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3218, "latency_ms": 22962}}
{"key": "10.1145/3441296", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Relevant topics range from ... decompilation, program generation, and abstract interpretation.", "explanation": "要旨はワークショップ全体の紹介であり、ML／LLM を用いた手法については一切言及されていないため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は PEPM 2021 の開催記録であり、個別の研究内容や手法の記述がない。要旨からは低水準入力や LLM/ML の利用が確認できず、デコンパイルに関する研究でもなく、従って除外基準の「ML/LLM を使用していない (ex_no_ml)」に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3192, "latency_ms": 24509}}
{"key": "10.1145/3442381.3450138", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We study the security properties, source languages, and use cases of the binaries...", "explanation": "要旨からは機械学習・LLM を用いた手法に関する記述がなく、単なる実証調査であるため除外基準 EC1 に該当します。"}], "reasoning": "本稿は WebAssembly バイナリの実態調査を行う経験的研究であり、デコンパイル手法や LLM/ML の利用について述べていません。そのため、ML/LLM を使用していないという除外基準 ex_no_ml に該当し、L1–L3 のデコンパイル研究として採択できません。", "model": "openai/gpt-oss-120b", "tokens_used": 3135, "latency_ms": 18251}}
{"key": "10.1145/3453483.3454033", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "decompiler from proof terms to suggested tactic scripts", "explanation": "要旨では機械学習や大規模言語モデルの利用が示されておらず、単なる変換/デコンパイラ手法とみなされるため、ML/LLM を中核にしていないと判断した。"}], "reasoning": "本稿は Coq の証明項からタクティックスクリプトへの変換を行うデコンパイラを提案しているが、機械学習や大規模言語モデルの使用が明記されていない。したがって、Decompilation Survey の「ML/LLM が中核手法」という採択基準を満たさないため除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3164, "latency_ms": 26286}}
{"key": "10.1145/3453483.3454091", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our tool J-Reduce efficiently reduces Java bytecode ...", "explanation": "要旨に機械学習や大規模言語モデルの使用は記載されておらず、従来のアルゴリズムによるバイトコード削減であるため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "We can reduce Java bytecode to 4.6 percent of its original size ...", "explanation": "出力は依然として Java バイトコード（低水準表現）であり、L1‑L3 の高水準コードや擬似コード等への復元ではなく、L4‑only（属性でもない）に該当するため除外する。"}], "reasoning": "本論文はバイトコードのサイズ削減手法を提案しているが、機械学習・LLM を使用していない上、出力も低水準のバイトコードであり、デコンパイル（L1‑L3 の高水準コード生成）には該当しない。そのため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3291, "latency_ms": 28521}}
{"key": "10.1145/3461666", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Successful software authorship de-anonymization ... The results of our work show high accuracy ... identifying ... programmers of software binaries.", "explanation": "本文はバイナリやソースから著者を分類・特定することが目的であり、コードの復元や高水準表現の生成は行っていないため、復元・生成が主目的でない（EC3）と判断した。"}], "reasoning": "本論文はバイナリやソースコードを入力として著者属性を推定し、プログラマを識別することを目的とした著者帰属研究であり、デコンパイルやコード生成（L1–L3）の目的を持たない。ML は使用されているが、出力は作者ラベルでありコードの復元・可読化ではないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3409, "latency_ms": 23030}}
{"key": "10.1145/3465481.3470040", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "We defined views as different components of the app, such as permissions, APIs, sensor usage, etc.", "explanation": "入力として低水準バイナリ・アセンブリ等ではなく、アプリの権限や API などの高レベル特徴を用いているため、低水準入力がなく除外すべきです。"}, {"code": "ex_no_code_generation", "evidence": "The model was trained end-to-end to jointly learn appropriate features and to perform the classification.", "explanation": "目的はマルウェアの検出であり、コードの復元や生成が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本論文はマルウェア検出のためのマルチビュー学習を提案しており、入力はアプリの高レベル特徴で低水準コードではなく、出力も分類ラベルです。デコンパイル（低水準から高水準コード生成）やその改善を目的としていないため、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3366, "latency_ms": 30932}}
{"key": "10.1145/3465481.3470077", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Ste\\ae{}lErgon, a framework aimed to inject a malicious payload in two or more different Android applications.", "explanation": "要旨はマルウェアペイロード注入フレームワークの提案であり、機械学習やLLMの使用が言及されていないため、ML/LLM不使用として除外します。"}], "reasoning": "本論文はAndroidアプリへの協調型マルウェアペイロード注入手法を示すもので、デコンパイルや機械学習・LLMを用いた手法の記述が全くない。したがって、Decompilation Survey Screening Rulesの除外基準 EC1（ML/LLM未使用）に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3252, "latency_ms": 23154}}
{"key": "10.1145/3468264.3468607", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "we present ... a new neural architecture that is adept at accurate and robust type inference.", "explanation": "抽象からはコードや擬似コードの生成ではなく型情報のみを復元することが示されており、出力は L4（属性のみ）に該当するため除外"}], "reasoning": "本論文はバイナリから型情報を推論することを目的としており、LLM/ML を用いた点は評価できるが、出力は型属性のみで L1–L3 のコード生成や再構成には至らない。したがって L4‑only とみなされ、本バージョンの対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3411, "latency_ms": 28698}}
{"key": "10.1145/3474369.3486865", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "recover stack frame information ... predict ... stack size from its function body", "explanation": "アブストラクトはバイナリ関数のスタックフレームサイズを数値で予測することのみを目的としており、コードや擬似コードといった L1‑L3 の高水準表現を生成しないため、L4‑only と判断し除外します。"}], "reasoning": "本論文はバイナリ関数からスタックフレームサイズという属性情報を予測する手法であり、ソースコードや擬似コード、AST などのコード表現を生成しません。出力が L4‑only（属性のみ）であるため、今回のスクリーニング基準（L1‑L3 のみ採択対象）では除外対象となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3293, "latency_ms": 25756}}
{"key": "10.1145/3479394.3479399", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a novel reduction theory for Moggi’s computational λ-calculus extended with shift0 and a control delimiter dollar...", "explanation": "抄録には機械学習・LLMの使用や言及が全くなく、純粋に形式的理論とCPS変換を扱っているため、ML/LLM を用いたデコンパイル手法ではないと判断した。"}], "reasoning": "本論文は低水準コードから高水準表現への変換や復元を目的としたデコンパイル研究ではなく、制御演算子とそのCPS/直接スタイル変換に関する形式的理論を提示している。機械学習や大規模言語モデルの利用が示唆されていないため、除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3171, "latency_ms": 22480}}
{"key": "10.1145/3486860", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This article provides the first systematic review of existing binary code fingerprinting approaches", "explanation": "アブストラクトが既存手法の体系的レビューであり、オリジナルのデコンパイル研究ではないため除外します。"}, {"code": "ex_no_ml", "evidence": "Numerous studies have investigated binary code with the goal of extracting fingerprints", "explanation": "本文では機械学習・LLM の利用について言及せず、従来手法の調査に留まっているため除外します。"}], "reasoning": "本稿はバイナリコード指紋付けの手法を体系的にまとめたサーベイ論文であり、ML/LLM を用いたデコンパイル（L1–L3 出力）に関する研究ではありません。また、低水準入力から高水準コードを生成する目的も示されていないため、除外基準 (ex_survey_or_meta) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3090, "latency_ms": 20829}}
{"key": "10.1145/3488932.3497764", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "Decompilers are tools designed to recover a high-level language representation (typically in C code) from program binaries.", "explanation": "要旨ではデコンパイラそのものや評価について述べられているが、機械学習／LLM の使用は言及されておらず、ML 手法が中心でないことが判断できるため除外基準 EC1 に該当する。"}], "reasoning": "本稿は既存デコンパイラの性能評価と脆弱性検出への応用を議論しており、ML/LLM を用いた手法の提案がなく、Decompilation に関する調査・実験が中心である。したがって、ML が使用されていないという点で除外基準 ex_no_ml に該当し、採択対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3290, "latency_ms": 26128}}
{"key": "10.1145/3490725.3490733", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "designed the weighting mechanism to set the malicious score to every code node, and filtered out the nodes with the highest malicious score to locate the malicious code fragments", "explanation": "概要はスコア付けとノード選択によるマルウェア検出・コード位置特定であり、コードの生成や復元を目的としていないため除外基準 EC3 に該当します"}], "reasoning": "本稿はグラフニューラルネットワークを用いたマルウェア検出とコード位置特定手法を提案しており、出力はスコア付きノードでありコードや擬似コードの再構成を行わない。したがって、復元・可読化を目的とするデコンパイル研究ではなく、除外基準 EC3（code generation が目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3189, "latency_ms": 24081}}
{"key": "10.1145/3494110.3528244", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "we conduct a critical review of existing adversarial attacks against malware detection", "explanation": "本稿はマルウェア検知に対する敵対的サンプル生成を扱っており、デコンパイルや低水準コードから高水準コードへの復元を目的としていないため、デコンパイル調査の範囲外（L1‑L3）であると判断した。"}], "reasoning": "抽象からは低水準バイナリやアセンブリを入力として高水準コードを生成することが示唆されておらず、目的もコード復元ではなくマルウェアの回避手法の提案である。したがってデコンパイル調査の対象外とし、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3382, "latency_ms": 34020}}
{"key": "10.1145/3498361.3538938", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "using symbolic execution and data flow analysis", "explanation": "要旨にML/LLMの使用は記載されておらず、シンボリック実行とデータフロー解析のみで実装されているため、ML/LLMが用いられていないと判断した。"}], "reasoning": "本稿はバイナリから制御関数や変数を復元する逆コンパイル手法を提案しているが、手法はシンボリック実行とデータフロー解析に基づくものであり、LLMや機械学習技術は使用していない。したがって、Decompilation Survey Screening RulesのInclude Criteriaを満たさず、Exclude Criteriaの EC1 (No ML/LLM) に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3269, "latency_ms": 21456}}
{"key": "10.1145/3502718.3524744", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "students develop tools that automatically detect and exploit program vulnerabilities", "explanation": "要旨にML/LLMの使用について言及がなく、ツールは検出と exploit に焦点を当てているため、ML/LLM が用いられていないと判断した"}, {"code": "ex_no_code_generation", "evidence": "students develop tools that automatically detect and exploit program vulnerabilities", "explanation": "目的は脆弱性の検出・利用であり、ソースコードや擬似コードの生成（復元）を行わないため、コード生成（デコンパイル）意図がないと判断した"}], "reasoning": "本稿は学部向けバイナリリバースエンジニアリングコースと自動 exploit 生成コンペの設計・運用について述べており、ML/LLM を用いたデコンパイルや高水準コードの復元は対象外である。したがって除外基準 EC1 と EC3 に該当し、exclude とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3361, "latency_ms": 36929}}
{"key": "10.1145/3507657.3528555", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we design a novel automated tool, PITracker, to detect the PendingIntent vulnerabilities", "explanation": "要旨では機械学習・LLMの使用について言及されておらず、従来のフロー解析手法のみが述べられているため、ML/LLM を用いていないと判断した。"}], "reasoning": "本論文は Android アプリの Intent フロー解析による脆弱性検出を目的としており、低水準バイナリから高水準コードを生成するデコンパイルや機械学習手法の利用は示されていない。したがって、Decompilation Survey の対象外であり、除外 (ex_no_ml) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 2961, "latency_ms": 17045}}
{"key": "10.1145/3510454.3516854", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "ACID utilizes API differences and static analysis of Android apps to detect both API invocation compatibility issues and API callback compatibility issues.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、従来の静的解析手法のみが記述されているため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "static analysis of Android apps", "explanation": "入力は Android アプリのバイナリやソースコードの高レベル情報であり、低水準表現（バイナリ/アセンブリ/バイトコード）からの入力ではないため除外基準に該当する。"}], "reasoning": "本論文は API 互換性問題の検出を目的とした静的解析ツールであり、機械学習・LLM を用いた手法や低水準コードから高水準コードへの変換（デコンパイル）とは無関係です。そのため、ML/LLM 未使用かつ低水準入力がない点で除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3162, "latency_ms": 26592}}
{"key": "10.1145/3519939.3523449", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "recovering precise, high-level parameter and return types for WebAssembly functions", "explanation": "アブストラクトは型情報のみを出力することを述べており、コードや擬似コード等の L1‑L3 出力ではなく L4（属性のみ）に該当するため除外とする"}], "reasoning": "本論文は WebAssembly バイナリから型情報を予測する学習手法を提案しているが、出力は関数のパラメータ/戻り値型という属性情報に留まり、コンパイル可能なコードや擬似コード・AST など L1‑L3 の高水準表現は生成しない。したがって、本バージョンの対象である L1‑L3 の出力を伴うデコンパイル研究ではなく L4‑only に該当し、除外基準 ex_out_of_scope に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3519, "latency_ms": 36200}}
{"key": "10.1145/3519939.3523702", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present the first approach to provably overapproximative x86-64 binary lifting", "explanation": "要旨に機械学習や大規模言語モデルの使用について言及がなく、純粋に形式的手法でのリフティングを述べているため、ML/LLM を使用していないと判断した。"}], "reasoning": "本稿はバイナリの形式的リフティングと検証手法を提案しており、機械学習や大規模言語モデルを用いた手法は示されていない。したがって、ML/LLM が中心手法であるというインクルード基準を満たさず、除外基準 ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3062, "latency_ms": 18993}}
{"key": "10.1145/3519939.3523719", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose Lasagne, an end-to-end static binary translator with precise translation rules", "explanation": "本文はルールベースの静的バイナリ翻訳手法を述べており、LLM/ML の利用は記載されていないため、ML 未使用として除外する"}], "reasoning": "本稿は低水準バイナリを別アーキテクチャ向けバイナリに変換する静的バイナリ翻訳ツールを提案しているが、機械学習や大規模言語モデルを手法の中心に用いている記述がなく、LLM/ML が使用されていないことから除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3343, "latency_ms": 29308}}
{"key": "10.1145/3520084.3520103", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper proposed the de-obfuscation method against for DNR (dynamic name resolution) obfuscation method.", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が言及されておらず、従来の静的・動的解析手法のみが述べられているため、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿は動的名前解決の難読化手法に対する逆難読化手法を提案しており、機械学習やLLM を利用した手法の記述がない。したがって、Decompilation Survey の対象であるML/LLM を中核としたデコンパイル研究には該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 3034, "latency_ms": 22111}}
{"key": "10.1145/3520312.3534867", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "pairs real-world C code taken from GitHub with IO examples", "explanation": "入力がバイナリやアセンブリなどの低水準表現ではなく、ソースコード（C 関数）であるため、低水準入力が存在しません。"}, {"code": "ex_out_of_scope", "evidence": "introduce a new dataset … to enable machine‑learning‑based programming tasks", "explanation": "本論文はデコンパイル手法の研究ではなく、実行可能な C 関数データセットの提供であり、デコンパイル（低水準→高水準変換）の範囲外です。"}], "reasoning": "論文は低水準コードから高水準コードを生成するデコンパイル手法を提示しておらず、入力もバイナリやアセンブリではなくソースコードです。そのため、Decompilation Survey の対象外（L1–L3 のデコンパイル）となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3214, "latency_ms": 25255}}
{"key": "10.1145/3524452", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "adopts LLVM, extends CRIU, and integrates with Docker", "explanation": "抽象だけではML/LLMの使用が一切言及されておらず、従来のコンパイラ・チェックポイント技術を用いているため、本サーベイのML/LLMを中核としたデコンパイル研究から外れます。"}], "reasoning": "本論文は異種ISA間でコンテナ化されたバイナリをマイグレーションするシステムを提案しており、MLやLLMを用いたデコンパイル手法についての記述がありません。したがって、Exclude Criteria の EC1（No ML/LLM）に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3331, "latency_ms": 25633}}
{"key": "10.1145/3533767.3534222", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "static analysis at the bytecode level", "explanation": "アブストラクトに機械学習・LLMの利用が言及されておらず、従来の静的解析手法のみであるため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "detecting cross-contract vulnerability", "explanation": "目的は脆弱性検出であり、コードの復元・可読化・生成は主目的ではないため、復元・生成意図が欠如している。"}], "reasoning": "本稿はバイトコードレベルの静的解析による脆弱性検出手法を提案しており、機械学習や大規模言語モデルを用いたデコンパイルとは無関係である。出力は高水準コードや擬似コードではなく、脆弱性の有無の判定に留まるため、L1‑L3 のデコンパイル対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3332, "latency_ms": 28531}}
{"key": "10.1145/3544902.3546240", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect supply chain vulnerabilities ... based on pseudo-code and Graph Matching Network", "explanation": "本文は擬似コードとグラフマッチングネットワークを用いた脆弱性検出（分類）を目的としており、コードの復元・生成は行わないため除外と判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "based on pseudo-code ...", "explanation": "入力として低水準バイナリやアセンブリではなく、すでに擬似コードが用いられているため、低水準入力がないと判断した。"}], "reasoning": "本稿はLLM/ML を用いたコード復元や可読化ではなく、擬似コードを入力とした脆弱性検出（分類）手法を提示している。入力が低水準表現でなく、出力もコード生成ではないため、デコンパイル調査の対象（L1–L3）から外れる。", "model": "openai/gpt-oss-120b", "tokens_used": 3440, "latency_ms": 31170}}
{"key": "10.1145/3548636.3548651", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Neural network is used to classify the fused features.", "explanation": "アブストラクトはニューラルネットワークで特徴を分類しマルウェア検出を行うことを目的としており、コードの復元・可読化といったデコンパイル目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本論文は Android アプリの N‑gram 特徴を用いたマルウェア検出モデルを提案しており、目的は分類・検知です。低水準バイナリから高水準コードを生成する（復元・可読化）ことは行っていないため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3146, "latency_ms": 24493}}
{"key": "10.1145/3550355.3552396", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose the OSATE Declarative-Instance Mapping Tool (OSATE-DIM1), an Eclipse plugin for deinstantiation of AADL models", "explanation": "概要から機械学習や大規模言語モデルを使用している記述がなく、従来のツール実装だけが述べられているためML/LLM不使用として除外"}, {"code": "ex_no_lowlevel_input", "evidence": "instance model is a simple object tree ... no automated backward transformation (deinstantiation) from instance to declarative models", "explanation": "入力はAADLの高水準モデルであり、バイナリやアセンブリ等の低水準表現ではないため除外基準に該当"}], "reasoning": "本論文はAADLモデルのビュー更新問題を解決するツールについて述べており、機械学習・LLMの利用や低水準コードからの復元を目的としていない。したがってデコンパイル（L1–L3）に該当せず、除外基準（ML未使用、低水準入力なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3167, "latency_ms": 21688}}
{"key": "10.1145/3551349.3559505", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "We introduce a reusable automated model-based GUI testing technique for Android apps", "explanation": "要旨は Android アプリの GUI テスト手法の提案であり、デコンパイルやコード生成とは無関係であるため、本サーベイの対象外（L1–L3 のデコンパイル出力が無い）と判断した。"}], "reasoning": "本論文は低水準バイナリから高水準コードを生成することを目的とした研究ではなく、Android アプリの GUI テストを強化する手法を紹介している。入力も低水準コードやバイナリではなく、イベント遷移情報であり、ML/LLM がコード復元に使われている記述もないため、デコンパイル領域の範囲外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3122, "latency_ms": 20086}}
{"key": "10.1145/3551349.3561339", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The approach is based on clone detection and implemented in our prototype APK-Simplifier.", "explanation": "アブストラクトではML/LLMの使用について言及がなく、手法はクローン検出のみと記載されているため、MLを用いていないと判断しex_no_mlで除外します。"}], "reasoning": "本文はMLやLLMを利用したデコンパイル手法ではなく、クローン検出によるライブラリコード除去を提案しているため、デコンパイルのコア要件を満たさず除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3119, "latency_ms": 22954}}
{"key": "10.1145/3556223.3556257", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "malware family classification based on the static features of Android applications", "explanation": "要旨はマルウェアの分類・検出であり、コードの復元や生成を目的としていないため、コード生成・復元の意図がなく除外基準 EC3 に該当する"}], "reasoning": "この論文はAndroidアプリの静的特徴を用いたマルウェア検出・分類を目的としており、低水準コードから高水準コードを生成するデコンパイルやLLMを用いた復元とは無関係です。したがって、復元・生成が目的でないことから除外基準 ex_no_code_generation に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3317, "latency_ms": 30469}}
{"key": "10.1145/3571786.3573015", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We aim to develop a reflection for algebraic effects and handlers.", "explanation": "要旨にML/LLMの利用についての記述がなく、機械学習手法が使用されていないため。"}, {"code": "ex_no_lowlevel_input", "evidence": "A reflection is a relationship between compiling and decompiling functions.", "explanation": "入力が低水準表現（バイナリやアセンブリ）であることが示されておらず、抽象的にコンパイル/デコンパイルの関係を論じているだけなので除外。"}, {"code": "ex_no_code_generation", "evidence": "We show that, if we use the simplest CPS translation as the compiling function, we can prove most but not all theorems required of a reflection.", "explanation": "復元・コード生成が目的ではなく、コンパイラの正当性証明が主目的であるため、デコンパイルによるコード生成は意図されていない。"}], "reasoning": "本稿はコンパイラの正当性を保証するための「reflection」概念を理論的に研究しており、低水準バイナリから高水準コードを生成することや、ML/LLM を用いたデコンパイル手法とは無関係である。したがって、Decompilation Survey の対象外（ML 不使用・低水準入力なし・コード生成目的なし）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3278, "latency_ms": 32893}}
{"key": "10.1145/3582016.3582058", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "LLVM-IR to C/OpenMP decompiler", "explanation": "要旨では LLVM‑IR から C/OpenMP へのデコンパイル手法のみが述べられ、機械学習や大規模言語モデルの使用は言及されていないため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は LLVM‑IR を入力とし C/OpenMP ソースコードを出力するデコンパイラを提案しているが、機械学習や大規模言語モデルを手法の中心に据えている記述がなく、ルールベースまたはコンパイラ技術に基づく従来型のアプローチとみなせる。したがって、ML/LLM 未使用という除外基準 (ex_no_ml) に該当し、採択対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3266, "latency_ms": 25386}}
{"key": "10.1145/3597503.3639100", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "BinaryAI … detects the reused TPLs based on the ratio of matched source functions.", "explanation": "対象はバイナリ関数とソース関数のマッチングであり、コードの復元や生成を目的としていないため、復元意図がなく除外する。"}], "reasoning": "本稿はバイナリとソースコード間のマッチングによるライブラリ検出を目的としており、低水準入力から高水準コードを生成する（L1–L3）デコンパイルではない。ML 手法は使用されているが、出力はマッチング結果でありコード生成・可読化が主目的ではないため、除外基準 EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3332, "latency_ms": 23458}}
{"key": "10.1145/3597503.3639140", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose PrettySmart, a bytecode-level Permission re-delegation vulnerability detector", "explanation": "アブストラクトに機械学習・LLM の利用が記載されておらず、従来の分析手法のみであると判断したため"}, {"code": "ex_no_code_generation", "evidence": "detect whether adversaries could manipulate the privileged token management functionalities", "explanation": "目的は脆弱性検出であり、コードや高水準表現の生成・復元ではないため"}], "reasoning": "本論文はバイトコードレベルでの脆弱性検出手法を提案しており、ML/LLM を用いたデコンパイルやコード生成を目的としていない。入力は低水準バイトコードだが、出力は脆弱性の有無という検出結果であり、L1–L3 の高水準コード生成や再構成に該当しないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3369, "latency_ms": 30468}}
{"key": "10.1145/3597503.3639153", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "implement BlockWatchdog using cross-contract static dataflow techniques", "explanation": "抽象ではML/LLMを用いた手法について言及されず、静的データフロー技術のみと記載されているため、ML/LLMが使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "detecting reentrancy vulnerabilities by identifying attacker contracts", "explanation": "目的は脆弱性検出であり、コードの復元・生成（L1‑L3の出力）ではないため、復元・生成意図が欠如していると判断した。"}], "reasoning": "本論文はスマートコントラクトのバイトコードを入力とし、静的データフロー解析のみで再入可能性脆弱性を検出するツールを提案している。ML/LLM を用いた手法は示されておらず、コード生成や高水準表現の復元を目的としていないため、デコンパイル調査の対象外（L1‑L3 の出力を伴わない）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3287, "latency_ms": 25829}}
{"key": "10.1145/3597926.3598068", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "present DITWO, a differential testing framework to uncover missed optimizations", "explanation": "要旨からは機械学習・LLM の使用が全く言及されていないため、ML/LLM が手法の中核である本サーベイの対象外と判断した。"}], "reasoning": "本論文は WebAssembly の最適化漏れを検出するための差分テストフレームワークを提案しており、機械学習や大規模言語モデルを用いたデコンパイル手法とは無関係である。入力は C ソースから生成された wasm バイナリで、目的はコード生成や可読化ではなく最適化評価であるため、除外基準 EC1（ML/LLM 未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3190, "latency_ms": 20823}}
{"key": "10.1145/3597926.3598124", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "DeFiTainter, an inter-contract taint analysis framework", "explanation": "本文では機械学習・大規模言語モデルの利用が言及されておらず、純粋に静的/動的解析手法のみであるため、ML/LLM が使われていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "construct a call graph for inter-contract taint analysis by restoring call information", "explanation": "入力はスマートコントラクトのコードやストレージ情報であり、バイナリ・アセンブリ等の低水準表現ではないため、低水準入力が存在しないと判断した。"}], "reasoning": "本稿は DeFi スマートコントラクトの脆弱性検出を目的とした taint 解析フレームワークであり、機械学習・LLM の利用やバイナリ等の低レベル入力からのコード生成は行っていない。したがって、デコンパイル調査の対象外（ML 非使用・低水準入力非該当）として除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 23309}}
{"key": "10.1145/3603273.3635055", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we use soft attention to fuse two modalities features to finish classification.", "explanation": "要旨ではマルウェア検出のための分類が目的であり、コードの復元・生成は行っていないため除外基準EC3に該当します。"}], "reasoning": "本稿は低水準バイトコードを特徴抽出しマルウェア検出モデルを構築する分類タスクを行っているだけで、デコンパイルや高水準コードの復元を目的としていない。したがって、復元・生成意図がなく除外基準EC3（ex_no_code_generation）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3063, "latency_ms": 18993}}
{"key": "10.1145/3605762.3624428", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "JSLibD introduces a heuristic prediction approach, comprising two integral components: a whitelist matching method ... and a heuristic prediction method to extract the unknown libraries using function call relationships.", "explanation": "本文では機械学習/LLMは使用されず、ヒューリスティック手法のみが述べられているため、ML/LLM不使用として除外します。"}, {"code": "ex_no_code_generation", "evidence": "We propose JSLibD, an automated extraction method for third‑party libraries in miniapps.", "explanation": "目的はライブラリの検出・抽出であり、コードの復元・生成を行わないためコード生成目的ではなく除外対象です。"}], "reasoning": "本論文はミニアプリのサードパーティライブラリ検出手法を提案しており、機械学習や大規模言語モデルを用いたデコンパイルとは無関係です。また、低水準バイナリから高水準コードを再構成することも目的としていないため、デコンパイル調査の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3342, "latency_ms": 32891}}
{"key": "10.1145/3605762.3624432", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we design a novel analysis framework for the security risk assessment of miniapps", "explanation": "抽象からは機械学習やLLMの使用が示されておらず、ML手法が用いられていないと判断したため"}, {"code": "ex_no_lowlevel_input", "evidence": "miniapps ... security of miniapps can directly impact compromising the integrity of sensitive data", "explanation": "対象はミニアプリのウェブインタフェースであり、バイナリやアセンブリなどの低水準入力が存在しないため"}], "reasoning": "本論文はミニアプリのセキュリティ評価に関する調査・分析であり、デコンパイルや低水準コードの復元を目的としていない。ML/LLM を用いた手法の記載もなく、低水準入力も存在しないため、L1–L3 のデコンパイル研究の範囲外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3403, "latency_ms": 34012}}
{"key": "10.1145/3611643.3616343", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "recover function signatures and returns", "explanation": "抽象だけ見ると出力は関数シグネチャや戻り値という属性情報のみで、L1‑L3 のソースコードや擬似コードには至らないため L4‑only と判断し除外する"}], "reasoning": "本稿はバイトコードを入力とし、深層学習で関数シグネチャや型情報を推定するものです。出力はコードそのものではなく属性情報（シグネチャ・型）に留まるため、本バージョンで対象とする L1‑L3 の復元出力には該当しません。したがって L4‑only とみなして除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3373, "latency_ms": 30466}}
{"key": "10.1145/3611643.3617852", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "utilizes a Java dynamic analysis tool to record calls to core Java libraries", "explanation": "アブストラクトは入力としてバイナリやアセンブリなどの低水準表現ではなく、Java ライブラリ呼び出しの動的トレースを用いると述べており、低水準入力がないため除外基準 EC2 に該当します。"}], "reasoning": "本稿は BERT を用いたコード検索手法を提案していますが、入力はバイナリ・アセンブリ等の低水準表現ではなく動的トレースです。Decompilation の定義に必要な低水準入力が欠如しているため、包括基準を満たさず除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3153, "latency_ms": 27772}}
{"key": "10.1145/3617184.3630160", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "Based on this method, this paper has implemented an encrypted traffic identification system", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が記載されておらず、従来手法のみであるため除外しました。"}], "reasoning": "本論文は暗号化されたWebシェルのトラフィック検知と復号に関する手法を提案しており、低水準バイナリやアセンブリを入力としたデコンパイルやML/LLMの活用は示されていません。したがって、Decompilation Survey Screening Rulesの除外基準 EC1（ML/LLM未使用）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3030, "latency_ms": 21462}}
{"key": "10.1145/3617686", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a compilation tool to automatically migrate legacy programs ... based on the low-level virtual machine (LLVM) compiler infrastructure", "explanation": "本文ではLLVMコンパイラ基盤を用いたコンパイルツールを提案しており、機械学習・LLMの利用は記述されていないため、ML/LLM が使用されていないことが明らかです。"}], "reasoning": "本稿は低レベルのLLVM IR を利用したコンパイル・オフローディングツールを紹介しており、デコンパイル（低水準から高水準コードへの復元）やML/LLM を中心とした手法を示していません。そのため、除外基準 EC1（No ML/LLM）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3242, "latency_ms": 24368}}
{"key": "10.1145/3623759.3624544", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We introduce Pancake, a new language for verifiable, low-level systems programming", "explanation": "アブストラクトではML／LLMの利用について一切言及されておらず、言語設計と検証コンパイラが主題なので、ML/LLMが用いられていないと判断した。"}], "reasoning": "本稿は新しいシステムプログラミング言語とその検証コンパイラの提案・評価が中心であり、デコンパイルやML/LLMを利用したコード復元に関する記述が全くないため、除外基準EC1（ML/LLM不使用）に該当し、L1–L3 のデコンパイル研究ではない。", "model": "openai/gpt-oss-120b", "tokens_used": 3124, "latency_ms": 25018}}
{"key": "10.1145/3643744", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.89, "reason_codes": [{"code": "ex_no_ml", "evidence": "In this work first introduces R2I, a specialized metric tailored to evaluate decompiled code...", "explanation": "要旨に機械学習・LLMの利用について言及がなく、純粋にメトリックを提案しているため、ML/LLM が使用されていないと判断しました。"}, {"code": "ex_no_code_generation", "evidence": "Our empirical experiments demonstrate that R2I is a versatile metric capable of representing the relative quality of decompiled code...", "explanation": "本稿の目的はコードの可読性を測定する指標の提案であり、コード生成や復元は行わないため、復元/生成目的がないと判断しました。"}], "reasoning": "本論文はデコンパイルされたコードの可読性評価指標を提案するのみで、低水準コードから高水準コードを生成する機械学習／LLM 手法を用いていません。そのため、ML/LLM が核心手法であるという条件を満たさず、復元・生成目的も無いことから除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3516, "latency_ms": 34017}}
{"key": "10.1145/3646547.3688433", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "we characterize the potential information leakage from IoT platforms during their setup phase", "explanation": "アブストラクトはIoTデバイスのセットアップ時の情報漏洩を調査するもので、デコンパイルや低水準バイナリからの高水準コード生成とは無関係であり、範囲外と判断したため"}], "reasoning": "本文はIoTデバイスのセットアップ時のセキュリティ分析を扱っており、低水準バイナリやアセンブリを入力としたコード復元・可読化を目的としていない。LLM/ML の使用記述もなく、デコンパイルに該当しないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3212, "latency_ms": 26487}}
{"key": "10.1145/3650212.3652133", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The generator uses static analysis techniques to deduce the correct calling sequences and parameters of the native API", "explanation": "抽象からは機械学習や大規模言語モデルの使用が言及されておらず、従って EC1（ML/LLM を用いていない）に該当するため除外です。"}], "reasoning": "本稿は Android のクローズドソースネイティブライブラリ向けの自動ハーネス生成とファジングフレームワークを提案しており、ML/LLM を用いたデコンパイル手法は含まれません。入力は低水準バイナリでもなく、出力はコード生成でもなくハーネスであるため、デコンパイル調査の対象外です。", "model": "openai/gpt-oss-120b", "tokens_used": 3191, "latency_ms": 20826}}
{"key": "10.1145/3650212.3652144", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we systematically evaluate current mainstream decompilers’ semantic consistency and readability.", "explanation": "要旨は既存デコンパイラの評価のみで、ML/LLM を用いた手法について言及していないため、EC1 に該当し除外する。"}], "reasoning": "本稿は既存のデコンパイラを評価し改善点を議論する調査研究であり、ML/LLM を利用したデコンパイル手法を提示していない。したがって、除外基準 EC1（ML/LLM 未使用）に該当し、L1–L3 の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3123, "latency_ms": 20126}}
{"key": "10.1145/3650212.3680301", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "While lack of soundness may be acceptable for applications such as decompilation, it can cause unpredictable runtime failures...", "explanation": "要旨はジャンプテーブルの解析手法を提示しており、コード生成や高水準表現の復元を目的としていないため除外基準 EC3 に該当する。"}, {"code": "ex_no_ml", "evidence": "Our analysis uses a novel abstract domain to systematically track the \"structure\" of computed code pointers...", "explanation": "手法は抽象ドメインによる解析であり、機械学習や大規模言語モデルの使用が記載されていないため除外基準 EC1 に該当する。"}], "reasoning": "本論文はバイナリ中のジャンプテーブルを解析し制御フローグラフを構築する手法を提案しているが、ML/LLM を用いたコード生成やソース・擬似コードの復元を目的としていない。また、手法は抽象解釈ベースであり機械学習は使用されていないため、デコンパイル（L1‑L3）に該当する研究ではない。", "model": "openai/gpt-oss-120b", "tokens_used": 3418, "latency_ms": 34043}}
{"key": "10.1145/3650215.3650347", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "establish a mapping between the AST and the binary function names to realize the prediction function", "explanation": "出力が関数名（識別子）のみであり、L1–L3 のコードや擬似コードは生成していないため L4‑only と判断し除外"}], "reasoning": "本研究はバイナリから関数名を予測することが目的で、最終成果は識別子（関数名）であり高水準コード（L1–L3）の復元や生成が行われていない。デコンパイルは途中で利用されているが、出力が属性のみなので本バージョンの対象外（L4‑only）となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3407, "latency_ms": 32884}}
{"key": "10.1145/3652588.3663324", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Loop analysis is a key component of static analysis tools.", "explanation": "本文・要旨からは機械学習・LLM が使用されている旨が全く示されておらず、ML/LLM を用いたデコンパイル手法ではないため"}, {"code": "ex_no_lowlevel_input", "evidence": "Loop analysis is a key component of static analysis tools.", "explanation": "要旨は C 言語のソースコード上のループ解析を扱っており、バイナリやアセンブリなどの低水準表現が入力と説明されていないため"}], "reasoning": "本稿は C 言語のループ解析に関する事例や課題を紹介するだけで、デコンパイルや機械学習・LLM を用いた高水準コード生成に関する研究ではありません。そのため、ML/LLM を使用していないことと低水準入力が存在しないことが明確であり、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3038, "latency_ms": 24718}}
{"key": "10.1145/3652628.3652786", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We present a novel Android app repackaging classification method...", "explanation": "要旨は再パッケージされたアプリを分類することが目的であり、コードやソースの復元・生成を行わないため、復元・生成インテントがなく除外基準 EC3 に該当します。"}], "reasoning": "本稿は低水準の smali ファイルを入力に機械学習で特徴を抽出し、アプリが再パッケージかどうかを判別する分類手法を提案しています。デコンパイルとして高水準コード（L1‑L3）を生成する目的がなく、ML を用いたのは分類であるため、Include 基準を満たさず Exclude 基準 ex_no_code_generation に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3147, "latency_ms": 23452}}
{"key": "10.1145/3658644.3670340", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "recover both names and types for local variables and user-defined data structures", "explanation": "抽象からはソースコードや擬似コードの生成ではなく、変数名や型といった属性情報のみを出力することが読み取れ、L1–L3 のコードレベル出力がなく L4‑only と判断したため除外します。"}], "reasoning": "本稿は LLM を用いてバイナリから変数名や型情報を回復することに焦点を当てており、出力は属性（名前・型）のみでコードや擬似コード等の L1–L3 出力を提供していない。したがって本バージョンの対象外（L4‑only）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3726, "latency_ms": 45997}}
{"key": "10.1145/3658644.3690244", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an approach to lift position-independent x86-64 binaries to symbolized NASM.", "explanation": "要旨には機械学習・LLM の使用が記載されておらず、従来の形式手法によるリフトであるため、ML/LLM 不使用の除外基準に該当します。"}], "reasoning": "本論文はバイナリをシンボライズされたアセンブリへ変換する手法を提案していますが、機械学習や大規模言語モデルを利用している記述がなく、ML/LLM を中心手法とする本サーベイのインクルード条件を満たさないため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3141, "latency_ms": 22479}}
{"key": "10.1145/3658644.3691386", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_core", "evidence": "lifting from assembly to the IR P-Code", "explanation": "アセンブリ（低水準入力）から P-Code（高水準IR）への変換を行っており、機械学習を用いたセマンティクスが中心手法として使用されているため、コアデコンパイルに該当します。"}, {"code": "in_type_recovery", "evidence": "machine-learned x86-64 semantics, to stay as close as possible to actual CPU behavior", "explanation": "機械学習で取得した命令セマンティクスを利用し、アセンブリと P-Code の意味的等価性を証明することで、型・意味の回復を目的としていると解釈できるため、型/意味回復のカテゴリにも該当します。"}], "reasoning": "本稿は低水準のアセンブリを入力とし、機械学習で得た命令セマンティクスを活用して P-Code（高水準IR）へ変換する手法を提案している。出力は L3 相当の高水準IR であり、ML が手法の中心に位置するため、Decompilation Survey の採択基準（L1‑L3、ML 中核）を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 4011, "latency_ms": 57565}}
{"key": "10.1145/3659211.3659272", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose an improvement scheme for OLLVM obfuscation", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、従来のオブフュスケーション手法のみであると判断したため、ML/LLM未使用として除外"}, {"code": "ex_out_of_scope", "evidence": "improves the difficulty of reverse engineering of software and device source code", "explanation": "研究はコードオブフュスケーションの強化が主目的であり、デコンパイル（低水準から高水準コード生成）や L1–L3 の出力を提供しないため、スコープ外として除外"}], "reasoning": "本稿は OLLVM のオブフュスケーション手法を提案しており、機械学習・LLM の使用や低水準バイナリからの高水準コード復元を目的としていない。したがって、ML/LLM 未使用かつデコンパイル対象外であり、除外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3317, "latency_ms": 30931}}
{"key": "10.1145/3663530.3665020", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "our pilot study reviews prevalent data challenges across various SE tasks", "explanation": "アブストラクトがデータ課題の調査・レビューであり、実験的なデコンパイル手法の提案ではないため、サーベイ論文として除外します。"}, {"code": "ex_out_of_scope", "evidence": "introduce practical LLM solutions from the SE community to mitigate these challenges", "explanation": "対象がSEタスク全般のデータ課題であり、低水準バイナリからのコード復元（デコンパイル）とは無関係でL4‑onlyでもないため、スコープ外として除外します。"}], "reasoning": "本稿は自動ソフトウェア工学タスクにおけるデータ課題の調査を目的としたパイロットサーベイであり、デコンパイルやLLM/MLを用いた低水準コードから高水準コードへの変換研究ではない。したがって除外基準（EC4: Survey/Review）に該当し、さらにデコンパイルの範囲外でもあるため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3139, "latency_ms": 27798}}
{"key": "10.1145/3664476.3664486", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "large-scale analysis of TEE utilization in Android applications", "explanation": "アブストラクトはTEE機能の調査であり、デコンパイルや低水準コードから高水準表現への変換を扱っていないため、対象外（L4‑only除外）と判断した。"}], "reasoning": "本論文はAndroidアプリにおけるTEE機能の利用実態を調査するもので、入力も目的もデコンパイルとは無関係です。ML/LLM を用いたコード復元や高水準表現の生成も示されていないため、除外基準 (ex_out_of_scope) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2963, "latency_ms": 16330}}
{"key": "10.1145/3672608.3707995", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "without resorting to any disassembly or decompilation", "explanation": "要旨にML/LLMの利用が記載されておらず、逆に従来の逆コンパイルを使わない手法と述べているため、ML/LLMを用いたデコンパイル研究ではないと判断した。"}], "reasoning": "本稿はELFバイナリを共有ライブラリ化し、具体的実行により関数パラメータや戻り値を回復する手法を提案しているが、ML/LLM を使用したデコンパイル手法ではない。したがって Include Criteria を満たさず、Exclude Criteria の EC1（ML/LLM 未使用）に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3184, "latency_ms": 26127}}
{"key": "10.1145/3677999.3678276", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Using rewrite rules and specialisation to partition our Haskell programs", "explanation": "アブストラクトはプログラムの分割（partitioning）手法を扱っており、デコンパイルや低水準コードからの復元とは無関係であるため、L1–L3 のデコンパイル対象外と判断した。"}], "reasoning": "本稿は Haskell プログラムの自動分割手法を提案しており、低水準バイナリやアセンブリから高水準コードを生成することを目的としていない。ML/LLM の使用も言及されておらず、デコンパイルの範囲外（L4 すら該当しない）であるため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3022, "latency_ms": 19244}}
{"key": "10.1145/3678232.3678233", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Elpi offers an encoding of Coq terms that is suitable for meta programming", "explanation": "アブストラクトは Coq の高階項やメタ言語のエンコーディングを扱っており、バイナリやアセンブリなどの低水準入力は示されていないため除外基準 EC2 に該当します。"}, {"code": "ex_no_ml", "evidence": "we translate unification problems ... to an alternative encoding", "explanation": "手法は高階統一やロジックプログラミングであり、機械学習／LLM の使用は示されていないため除外基準 EC1 も満たします。"}], "reasoning": "本稿はメタ言語 Elpi を用いた高階統一・証明検索手法の提案であり、低水準バイナリや機械語を入力としたデコンパイルを目的としていません。また、機械学習や大規模言語モデルの利用も言及されていないため、デコンパイル調査の対象外 (L1–L3) と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3889, "latency_ms": 29812}}
{"key": "10.1145/3678890.3678892", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we surveyed 21 professional malware analysts ...", "explanation": "アブストラクトで調査（survey）を実施している旨が記載されているため、サーベイ論文に該当し除外"}], "reasoning": "本稿はマルウェア分析者へのアンケート調査を報告するサーベイ論文であり、デコンパイルやML/LLMを用いたコード復元の研究とは無関係です。そのため除外基準 EC4（Survey/Review）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3032, "latency_ms": 17150}}
{"key": "10.1145/3686215.3690147", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LLMs correctly identify methods of bypassing evasive techniques in real‑world malware", "explanation": "抽象からはLLMがコード生成や復元ではなく、回避手法の特定・説明に使われているため、復元・可読化目的ではなく除外基準EC3に該当する"}], "reasoning": "本稿はLLMを用いてマルウェアの回避技術を特定・説明することに焦点を当てており、低水準バイナリから高水準コード（L1‑L3）を生成するデコンパイルの目的や手法が示されていない。そのため、復元・コード生成を目的としないため除外基準EC3（ex_no_code_generation）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3431, "latency_ms": 31528}}
{"key": "10.1145/3691620.3695012", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "determine the presence of a patch ... match the features to determine the presence of a patch", "explanation": "アブストラクトはパッチ有無の判定（yes/no）を目的としており、コードやソースの生成・復元は行わないため、復元・生成が主目的でない（ex_no_code_generation）と判断した。"}, {"code": "ex_no_ml", "evidence": "We propose React, the first patch presence test approach on IR-level. ... we first extract four types of feature ... then we match the features ... with an SMT solver", "explanation": "論文は特徴抽出とSMTソルバによるマッチングを用いており、ML/LLM の利用は記述されていないため、ML未使用（ex_no_ml）でもある。"}], "reasoning": "本稿はバイナリのパッチ有無を判定する手法であり、コードやソースの生成・復元を目的としていない（ex_no_code_generation）。さらに、手法に機械学習や大規模言語モデルは使用されていない（ex_no_ml）。したがって、デコンパイル（L1–L3 出力）に該当せず除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3431, "latency_ms": 45346}}
{"key": "10.1145/3691620.3695020", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "first use of a fine-tuned LLM to interpret and decompile Wasm binary code into a higher-level, more comprehensible source code representation", "explanation": "LLM が低水準の Wasm バイナリを直接入力として、コンパイル可能なソースコード（L1）を生成しているため、Core Decompilation に該当する。"}, {"code": "in_core", "evidence": "maintains a recompilability rate of 52.11%, a re‑execution rate of 43.55%", "explanation": "出力がコンパイル・実行可能であることを示す指標が示されており、出力レベルが L1（コンパイル可能なソース）であることが確認できる。"}], "reasoning": "本論文は WebAssembly バイナリ（低水準入力）を対象に、ファインチューニングされた大規模言語モデルを中心手法として利用し、コンパイル可能な高水準ソースコードを直接生成している。復元・可読化が主要目的であり、出力は L1 に該当するため、Include 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3393, "latency_ms": 41799}}
{"key": "10.1145/3691620.3695271", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect and classify malicious code poisoning attacks", "explanation": "要旨はコードの検出・分類であり、復元・高水準コード生成が主目的ではないため除外基準 EC3 に該当する"}, {"code": "ex_no_ml", "evidence": "combines dataset loading script extraction, model deserialization, in-depth taint analysis, and heuristic pattern matching", "explanation": "手法はヒューリスティックパターンマッチング中心で、ML/LLM が中核手法として明示されていないため除外基準 EC1 にも該当する"}], "reasoning": "本論文は事前学習モデルハブに対する悪意あるコード汚染攻撃の検出・分類を対象としており、低水準バイナリから高水準コードを生成するデコンパイル目的とは無関係です。さらに、ML/LLM が主要手法として示されておらず、復元やコード生成の意図もないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3378, "latency_ms": 42616}}
{"key": "10.1145/3691620.3695502", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "type recovery in stripped binaries ... TypeFSL ... predicts uncommon and complicated types", "explanation": "抽象的にバイナリから型予測のみを行い、ソースコードや擬似コードといった L1‑L3 の高水準表現を生成しないため L4‑only と判断し除外します。"}], "reasoning": "本稿はバイナリから型情報を予測することに焦点を当てており、出力は型属性のみでコードや擬似コードの生成は行われません。L4‑only のため、本バージョンの対象 (L1‑L3) から外れます。", "model": "openai/gpt-oss-120b", "tokens_used": 3304, "latency_ms": 45171}}
{"key": "10.1145/3696410.3714790", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "LLM-powered web application that decompiles smart contract bytecodes on Sui into ... re-compilable source code", "explanation": "LLM が低水準のバイトコードを直接入力とし、コンパイル可能なソースコード（L1）を生成しているため、Core Decompilation に該当します。"}], "reasoning": "本論文はバイトコードという低水準入力から、LLM を中核手法として人間が読める再コンパイル可能なソースコード（L1）を生成しています。目的はコードの可読化・再利用・監査支援であり、デコンパイルそのものを行う研究なので、Include 基準を満たします。", "model": "openai/gpt-oss-120b", "tokens_used": 3291, "latency_ms": 38003}}
{"key": "10.1145/3696630.3728508", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LLM-driven method for identifying compliance issues", "explanation": "本文はLLMを用いてプライバシー規制違反を検出することが目的であり、コードを復元・生成することは主目的ではなく、分類・検出タスクに該当するため除外します。"}], "reasoning": "本論文はAndroidアプリのSmaliコードを入力として、GDPR遵守違反を検出することを目的としており、コードの復元や高水準表現（L1–L3）の生成を行わない。従って、復元・生成意図がなく、分類・検出タスクに該当するため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3123, "latency_ms": 38719}}
{"key": "10.1145/3696630.3731468", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.5, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "technical requirements are challenging to understand from legal texts", "explanation": "アブストラクトは法的テキストを対象にしており、バイナリやアセンブリといった低水準入力は全く言及されていないため除外"}, {"code": "ex_no_ml", "evidence": "This thesis aims to reconcile both parties.", "explanation": "本文中に機械学習や大規模言語モデルの使用が示唆されていないため、ML/LLM が用いられていないと判断し除外"}], "reasoning": "本稿はサイバーフィジカルシステムのソフトウェア適合性評価を自動化することに焦点を当てており、低水準コードやバイナリからのデコンパイルやML/LLM を用いたコード生成とは無関係です。そのため、Decompilation Survey の対象外（L1–L3 のデコンパイル出力を伴わない）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3371, "latency_ms": 48212}}
{"key": "10.1145/3698062.3698068", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "constructs a formidable framework for Android malware detection", "explanation": "アブストラクトは LSTM を用いたマルウェア検出（分類）を目的としており、コードの復元・可読化などの生成は行わないため、復元志向でない（ex_no_code_generation）と判断した。"}], "reasoning": "本稿はネイティブコードのオペコードを特徴量として LSTM によりマルウェアか否かを分類する手法を提案しており、低水準コードから高水準コードを生成するデコンパイル目的ではない。したがって、復元・可読化を目的とした LLM/ML を用いたデコンパイル研究の対象外であり、除外 (ex_no_code_generation) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3096, "latency_ms": 39469}}
{"key": "10.1145/3700058.3700123", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This study provides a comprehensive review of the types of smart contract security vulnerabilities and the development of detection techniques.", "explanation": "アブストラクトがサーベイであることを示す記述なので、除外基準 EC4 に該当します。"}, {"code": "ex_no_ml", "evidence": "including static and dynamic analysis", "explanation": "本文中に機械学習・LLM の使用が言及されておらず、従来の静的・動的解析のみであるため除外基準 EC1 に該当します。"}], "reasoning": "本稿はスマートコントラクトの脆弱性検出手法を包括的にレビューしたサーベイであり、機械学習や大規模言語モデルを用いたデコンパイル手法の記述はありません。したがって、除外基準（サーベイ・ML未使用）に該当し、L1‑L3 のデコンパイル研究としては採択対象外です。", "model": "openai/gpt-oss-120b", "tokens_used": 3148, "latency_ms": 45462}}
{"key": "10.1145/3702977", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose ReuNify to improve Soot-based static analysis coverage... ReuNify converts Hermes bytecode to Soot’s intermediate representation.", "explanation": "要旨に機械学習／LLMの使用が言及されていないため、ML/LLM が手法の中核でないと判断し、除外基準 EC1 に該当します。"}], "reasoning": "本稿は Hermes バイトコードを Soot の IR へ変換する手法を提案していますが、機械学習や大規模言語モデルの利用は記載されていません。したがって、ML/LLM が中核であるというインクルード基準を満たさず、除外基準 ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3270, "latency_ms": 43941}}
{"key": "10.1145/3708821.3733877", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we perform the first comprehensive empirical study on state-of-the-art C decompilers", "explanation": "アブストラクトは既存デコンパイラの評価を述べており、ML/LLM の利用について言及がないため、ML を用いていないと判断した。"}], "reasoning": "本論文は C デコンパイラの性能評価とエラータクソノミーの構築を目的とした実証研究であり、手法に機械学習や大規模言語モデルは使用されていない。したがって、除外基準 EC1（No ML/LLM）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3095, "latency_ms": 39712}}
{"key": "10.1145/3713081.3731728", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Binary Code Similarity Detection (BCSD) is ... essential for security tasks ...", "explanation": "アブストラクトはバイナリ類似性の検出が目的であり、コードの復元・生成を主目的としていないため、復元意図がなく除外基準EC3に該当します。"}], "reasoning": "本稿はバイナリ類似性の検出手法を提案しており、復元や高水準コード生成を目的としていないため、Decompilation Survey の対象外です。MLは使用されていますが、目的がコード生成でないため除外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3062, "latency_ms": 41143}}
{"key": "10.1145/3713081.3731745", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "malicious function identification and malware purpose summarization", "explanation": "要旨はデコンパイルされたコードから関数の識別や目的の要約を行うことが目的であり、コードそのものを再構成・生成することはなく、分類・検知が主目的なので除外基準 EC3 に該当します。"}], "reasoning": "本論文は低水準のデコンパイルコードを入力とし、LLM を用いてマルウェア解析タスク（関数識別や要約）を実施していますが、コードの復元・生成（L1‑L3 の出力）を目的としていません。したがって、復元・コード生成が主目的でないという除外基準に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3252, "latency_ms": 45990}}
{"key": "10.1145/3714393.3726486", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "we introduced a dataset of 272 real-world violations of Google's Android Security Best Practices... from Android Java classes and Manifest files", "explanation": "アブストラクトはJavaソースコードとXMLマニフェストを対象としており、低水準バイナリやアセンブリといった入力がなく、デコンパイルの対象外であるため"}], "reasoning": "本稿はAndroidアプリのソースコードとマニフェストを用いた脆弱性修復データセットの提供と、LLMによる自動プログラム修復の評価を目的としている。入力は高水準のJava/XMLであり、低水準バイナリからの復元を伴うデコンパイル研究ではない。したがって、低水準入力がないことから除外基準EC2に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 41521}}
{"key": "10.1145/3715780", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "intent-aware summary generator ... produce customized summaries", "explanation": "アブストラクトはバイナリコードから自然言語のサマリーを生成することを目的としており、コード（L1‑L3）を復元することは目的に含まれていないため、コード生成が主目的ではないと判断した。"}], "reasoning": "本論文はバイナリコードの要約（自然言語生成）を目的としており、デコンパイルの定義で求められる低水準入力から高水準コード（L1‑L3）の生成・復元を行っていない。したがって、復元・可読化を主目的とするデコンパイル研究には該当せず、除外基準 ex_no_code_generation に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3352, "latency_ms": 47117}}
{"key": "10.1145/3719027.3760714", "action": "keep", "reason": "uns_unclear_method", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_method", "evidence": "Relying on our hypothesis, HarvETHter sources knowledge of the Ethereum blockchain and leverages it to decompile smart contracts to Solidity source code.", "explanation": "抄録ではデコンパイルは行う旨が記載されているが、手法としてML/LLMが使用されているか明示されていないため、手法の不明確さに該当する。"}], "reasoning": "本稿はEVMバイトコードからSolidityソースへのデコンパイルを行うことを示しており、入力は低水準、出力はL1に該当する。しかし、LLM/MLが中心手法として用いられている記述が抽象からは読み取れないため、採択可否を判定できず不確実（uncertain）とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3233, "latency_ms": 51829}}
{"key": "10.1145/3719027.3762169", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present JaDX-ACVTool, a plugin that bridges this gap by integrating code coverage information from ACVTool directly into JaDX-GUI.", "explanation": "要旨に機械学習・LLM の使用は言及されておらず、従来のツール連携のみであるため、ML/LLM を用いていないと判断し、除外基準 EC1 に該当します。"}], "reasoning": "本論文は Android アプリの逆コンパイル結果にコードカバレッジ情報を統合するプラグインを紹介しており、機械学習や大規模言語モデルを利用したデコンパイル手法は示されていません。したがって、除外基準 EC1（ML/LLM 未使用）に該当し、L1–L3 のデコンパイル研究としては除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3036, "latency_ms": 43429}}
{"key": "10.1145/3719027.3765040", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We investigate how reverse engineers respond to inaccurate decompilation and identify factors influencing their efforts to achieve accurate decompilation.", "explanation": "要旨に機械学習や大規模言語モデルの利用について言及がなく、完全に人間の作業と観察に焦点を当てているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は Python バイトコードのデコンパイル結果の人間による修正プロセスを大規模に調査する実証研究であり、機械学習や大規模言語モデルを手法の中心に用いた研究ではない。したがって、Decompilation Survey の採択基準（LLM/ML が必須）を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3435, "latency_ms": 51060}}
{"key": "10.1145/3719027.3765089", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "recover function signatures ... parameter type recovery", "explanation": "出力が関数シグネチャや型情報のみで、L1‑L3 のソースや擬似コードではなく属性だけ（L4）であるため除外"}, {"code": "ex_no_ml", "evidence": "learning-based approaches ... resource‑intensive and inaccurate. In this paper, we present CDA, a novel decompilation‑based method", "explanation": "論文は ML/LLM を中心手法として使用しておらず、従来の確率的制約と推論規則に基づく手法であるため除外"}], "reasoning": "本稿はバイナリから関数シグネチャや型情報を復元することを目的としており、出力は属性情報（L4）のみでコード生成（L1‑L3）を行わない。さらに手法は機械学習や大規模言語モデルを用いていないため、Decompilation Survey の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3855, "latency_ms": 71181}}
{"key": "10.1145/3719027.3765144", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose new obfuscation schemes tailored for DNN binaries", "explanation": "要旨に機械学習／LLM を用いた手法の記述がなく、単にオブファスケーション手法を提案しているので、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は DNN バイナリのリバースエンジニアリングに対抗するためのオブファスケーション手法を提案しており、LLM/ML を用いたデコンパイル手法ではない。入力は低水準バイナリだが、復元やコード生成を目的とした ML 手法が存在しないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3262, "latency_ms": 43432}}
{"key": "10.1145/3720524", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.91, "reason_codes": [{"code": "ex_no_ml", "evidence": "Binary lifting is a key component in binary analysis tools... we propose a new interpretation of the correctness of real‑world binary lifting.", "explanation": "要旨中に機械学習・LLM の使用について言及がなく、従来の形式手法のみが述べられているため、ML/LLM を用いていないと判断しました。"}], "reasoning": "本論文は形式的手法によるバイナリリフティングの正当性評価を扱っており、機械学習や大規模言語モデルを用いたデコンパイル手法が提示されていません。したがって、Decompilation Survey Screening Rules の除外基準 EC1（No ML/LLM）に該当し、除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3068, "latency_ms": 38755}}
{"key": "10.1145/3722041.3723097", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "predict vulnerabilities in binary code ... leveraging ... neural decompilation and predicting vulnerabilities through deep learning on the decompiled source code", "explanation": "要旨から、本研究の主目的はバイナリコード上の脆弱性予測という分類タスクであり、デコンパイルはその手段に過ぎないため、復元・生成が主目的ではないと判断した。"}], "reasoning": "本論文はバイナリコードから脆弱性を予測することを主目的とした分類研究であり、デコンパイルはその前処理として用いられている。目的が復元・可読化ではなく分類であるため、除外基準 EC3（No Reconstruction Intent）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3404, "latency_ms": 57570}}
{"key": "10.1145/3722572.3727926", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we integrate an energy-aware networking stack with reverse-engineered Wi‑Fi drivers", "explanation": "アブストラクトではML/LLMの使用について言及がなく、従来のリバースエンジニアリング手法のみが述べられているため、ML/LLMが用いられていないと判断した。"}], "reasoning": "本稿は閉源ドライバを手動または従来手法でリバースエンジニアリングし、静的最悪ケース解析に利用する研究であり、LLM/ML を中核手法として用いていない。したがって、除外基準 EC1 (ex_no_ml) に該当し、除外と判断する。", "model": "openai/gpt-oss-120b", "tokens_used": 3149, "latency_ms": 40255}}
{"key": "10.1145/3723498.3723739", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "examines the emergence and rise of speculative game design communities on itch.io", "explanation": "抽象的にゲームデザインやファンタジーコンソールについて述べており、デコンパイルやML/LLMの使用とは無関係であるため、L1‑L3 のデコンパイル対象外（アウト・オブ・スコープ）として除外する。"}, {"code": "ex_no_ml", "evidence": "the paper examines ... speculative games ... fantasy consoles", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く言及されていないため、ML/LLM を用いた研究ではない。"}], "reasoning": "本稿はゲームデザインとファンタジーコンソールの社会的・文化的側面を分析したもので、低水準バイナリから高水準コードを生成するデコンパイル研究とは無関係です。そのため、デコンパイルのスコープ（L1‑L3）および ML/LLM 手法の要件を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3367, "latency_ms": 48179}}
{"key": "10.1145/3726101.3726103", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Numerous security researchers have employed various machine learning algorithms to detect these new Android and other types of malware.", "explanation": "ML がマルウェアの検出（分類）に用いられており、コードの復元・可読化といった生成目的が示されていないため、復元意図が不存在として除外します。"}], "reasoning": "本論文は Android アプリのマルウェア検出を目的とした ML 手法を提案しており、低水準コードから高水準コードや擬似コードを生成するデコンパイルの目的がなく、分類タスクに限られています。そのため Include Criteria を満たさず、Exclusion Criteria の「復元・生成意図がない（ex_no_code_generation）」で除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3142, "latency_ms": 41592}}
{"key": "10.1145/3728911", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "hashes binaries into program-level representations ... for large-scale binary code similarity analysis", "explanation": "要旨はバイナリを埋め込みに変換し類似性評価を行うことで、コードの復元・可読化を目的としていないため除外です"}, {"code": "ex_out_of_scope", "evidence": "LLM-generated function embeddings", "explanation": "LLMは埋め込み生成に使われており、デコンパイル（L1‑L3 のコード生成）とは範囲外です"}], "reasoning": "本論文はバイナリを埋め込みに変換して類似性評価を行う手法を提案しており、復元・可読化といったコード生成を目的としていない。したがってデコンパイルのコアタスク（L1‑L3 の高水準コード出力）に該当せず、除外基準 EC3（コード生成なし）およびスコープ外（L4 以上）に該当するため、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3541, "latency_ms": 56536}}
{"key": "10.1145/3728935", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "Shrnkr, a static-analysis-based decompiler succeeding the state-of-the-art Elipmoc decompiler.", "explanation": "本文は静的解析手法のみでデコンパイルを行うと述べており、ML/LLM を用いていないため除外基準 EC1 に該当します。"}], "reasoning": "本論文は低水準バイナリからのデコンパイルを静的解析中心で実装しており、機械学習や大規模言語モデルを手法の中核にしていないため、インクルード基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3162, "latency_ms": 41016}}
{"key": "10.1145/3728958", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "automatically correcting decompiler outputs into compilable versions", "explanation": "LLM が扱う入力は既存デコンパイラの出力（擬似コード）であり、バイナリやアセンブリといった低水準表現が示されていないため、低水準入力がないと判断した。"}], "reasoning": "アブストラクトでは、LLM が入力として利用するのは既存デコンパイラの出力（pseudocode）であり、バイナリやアセンブリといった低水準表現が明示されていない。従って、Include 基準の IC0（低水準入力の存在）を満たさず、Exclude 基準 EC2（低水準入力がない）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3965, "latency_ms": 71186}}
{"key": "10.1145/3729373", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "first LLMs-based EVM decompilation pipeline... lift it into smart contract code", "explanation": "LLM を中心手法として低水準の EVM バイトコードからコンパイル可能な Solidity ソースコード（L1）を直接生成しているため、Core Decompilation に該当します。"}, {"code": "in_type_recovery", "evidence": "type-aware graph model to infer stripped variables during compilation", "explanation": "型情報の復元を目的とした手法が組み込まれており、型回復要素が含まれるため Type Recovery としても分類できます。"}], "reasoning": "本稿は低水準の EVM バイトコードを入力とし、LLM を核にして Solidity ソースコード（コンパイル可能）を生成することを目的としている。入力が低水準であり、出力は L1 に相当するため Include 基準を満たす。さらに型情報の推論機構を含むため、Type Recovery の側面も持ち合わせている。", "model": "openai/gpt-oss-120b", "tokens_used": 3274, "latency_ms": 48175}}
{"key": "10.1145/3732365.3732428", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "combining static analysis with fuzzing techniques", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、従来の静的解析・ファジングのみであるためML/LLM不使用と判断した。"}, {"code": "ex_no_code_generation", "evidence": "guide the seed file mutation technique, hence improving the accuracy and efficiency of fuzzing", "explanation": "目的はファジングの効果向上であり、コードの復元・生成は主目的でないため復元意図がなく除外基準に該当する。"}], "reasoning": "本稿は静的解析とファジングを組み合わせた手法を提案しており、機械学習やLLMを用いたデコンパイルは行っていない。また、コード生成や可読化といった復元目的も示さず、ファジング支援が主目的であるため、Decompilation Survey の対象（ML/LLM を用いた L1–L3 出力の生成）から外れると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3266, "latency_ms": 49266}}
{"key": "10.1145/3732771.3742714", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "TranspileJS leverages a multi-stage architecture that converts JS to TypeScript, which is compiled into Wasm using the AssemblyScript compiler.", "explanation": "要旨に機械学習や大規模言語モデルの使用は記載されておらず、純粋にルールベースのパイプラインであるため。"}, {"code": "ex_no_lowlevel_input", "evidence": "converts JS to TypeScript, which is compiled into Wasm", "explanation": "入力は JavaScript（高水準言語）であり、低水準バイナリやアセンブリが入力として示されていないため。"}], "reasoning": "本稿は JavaScript を TypeScript 経由で WebAssembly に変換するトランスパイラであり、低水準コードから高水準コードへの復元を目的としたデコンパイルではない。また、機械学習や LLM を手法の中心に用いていないため、除外基準に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3426, "latency_ms": 54288}}
{"key": "10.1145/3732771.3742724", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our work introduces Alpakka, a source-to-source compiler for Android's Smali syntax.", "explanation": "抽象では機械学習・LLM の利用が言及されておらず、従来のコンパイラ手法のみが示されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は Smali からソースへ変換するコンパイラを提案し、リソースリークの検出と自動修正を行うが、機械学習や大規模言語モデルを使用していない。したがって、Decompilation Survey の Include Criteria（LLM/ML が中核手法）を満たさず、除外基準 ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3162, "latency_ms": 47626}}
{"key": "10.1145/3733817.3762702", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an empirical evaluation of the Tigress obfuscator, focusing on its ability to degrade the precision of static analyses performed by two state-of-the-art tools...", "explanation": "要旨に機械学習や大規模言語モデルの利用は言及されておらず、従来の静的解析・逆コンパイラ評価のみであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はオブファスケーション手法が静的解析やバイナリ逆コンパイラ（BinaryNinja）の精度に与える影響を実証的に評価するもので、デコンパイルをML/LLMで実施する研究ではない。従って、ML/LLM を用いたデコンパイルという本サーベイの対象外であり、除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3029, "latency_ms": 42987}}
{"key": "10.1145/3733822.3764668", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "using GPT-4o and GPT-4.1-mini as test subjects", "explanation": "本文ではGPT-4系を評価に用いているだけで、フレームワーク自体がML/LLMを中心手法として利用している記述がなく、ML/LLMが非中心的であるため除外基準EC1に該当します。"}], "reasoning": "本論文はルールベースのフレームワークで、バイナリ入力からのデコンパイル結果を改善することが主旨です。LLMは評価目的でのみ使用されており、手法の中核として使用されていないため、除外基準「No ML/LLM」に該当し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3231, "latency_ms": 52874}}
{"key": "10.1145/3733822.3764672", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a method for constructing understanding-questions and evaluating answers at scale", "explanation": "抽象では機械学習や大規模言語モデルの利用が言及されておらず、ML/LLM が使用されていないと判断したため"}, {"code": "ex_no_code_generation", "evidence": "compare Ghidra’s default auto analysis with an analysis that supports binary constructs", "explanation": "目的はソフトウェア理解の評価であり、コードの復元・生成が主目的ではないため"}], "reasoning": "本稿はデコンパイル手法やML/LLM を用いたコード復元を扱っておらず、逆向き工学の評価手法の提案に留まる。入力が低水準バイナリであっても、ML 活用やコード生成が目的に含まれないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3195, "latency_ms": 51829}}
{"key": "10.1145/3733822.3764673", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "infer semantic properties of structure members", "explanation": "抽象的に構造体メンバの型や役割といった属性のみを推測しており、L1–L3 のコードや擬似コードの生成は示されていないため L4‑only と判断し除外します。"}], "reasoning": "本論文はバイナリから構造体メンバの型や役割などの属性を推測することに焦点を当てており、ソースコードや擬似コード、AST といった L1–L3 の高水準表現を生成することは示されていません。したがって、本バージョンの対象である L1–L3 出力を伴うデコンパイル研究には該当せず、L4‑only とみなして除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3421, "latency_ms": 53875}}
{"key": "10.1145/3733822.3764675", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper presents a benchmark study of five decompilers...", "explanation": "要旨からは機械学習や大規模言語モデルを用いた手法の記述がなく、従来のデコンパイラを比較評価しているだけなので、ML/LLM が使用されていないと判断した。"}], "reasoning": "本文は既存デコンパイラの型推論性能をベンチマークする研究であり、LLM/ML を中心手法として用いていない。デコンパイル自体は対象だが、ML 手法が不可欠な本サーベイの採択基準を満たさないため除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3048, "latency_ms": 40652}}
{"key": "10.1145/3735971", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we decompile bytecodes into higher-order representations to analyze control flows and state variable dependencies", "explanation": "デコンパイルは検出のための特徴抽出に用いられており、復元・可読化が主目的ではなく分類（Ponzi 契約検出）が目的なので除外基準 ex_no_code_generation に該当する"}], "reasoning": "本稿はバイトコードを高次表現に変換して Ponzi 契約の検出を行うことが主目的であり、コードの復元や可読化を目的としたデコンパイルではない。したがって、復元・生成を目的としない点で除外基準 EC3（ex_no_code_generation）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3429, "latency_ms": 51320}}
{"key": "10.1145/3746252.3761266", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "ORCAS takes binary functions ... and scores their semantic similarity more robustly.", "explanation": "本論文はバイナリ関数間の類似度をスコアリングすることが目的であり、コードの復元・可読化を行う出力は示されていないため、復元意図がなく除外対象となります。"}], "reasoning": "本稿はバイナリコード類似性解析を目的とした手法であり、低水準入力から高水準コードを生成するデコンパイルや再構成を行う記述がない。目的が類似度評価（分類/検出）であるため、Decompilation Survey の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3164, "latency_ms": 42611}}
{"key": "10.1145/3749988", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "neural decompilation framework to reverse engineer math equations from binaries", "explanation": "抽象的にバイナリ（低水準入力）から数式コード（高水準表現）をTransformerベースのMLで直接生成しているため、Core decompilation に該当する。"}], "reasoning": "本論文はバイナリ実行ファイルを入力とし、Transformer エンコーダ‑デコーダを用いたニューラルデコンパイラで数式形態の高水準コードを生成している。ML 手法が中心であり、出力は L1‑L3 に相当するソースコード／擬似コードであることが示唆されるため、インクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3357, "latency_ms": 48611}}
{"key": "10.1145/3755881.3755883", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "function identification in Ethereum smart contract bytecode", "explanation": "アブストラクトはバイトコードから関数を識別することを目的としており、コードの復元や高水準表現の生成ではなく分類タスクであるため、復元・可読化目的ではないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "improves the effectiveness of function identification", "explanation": "出力は関数の有無や位置といった属性情報であり、L1〜L3 のソースコード・擬似コード・AST などの高水準表現を提供しないため、L4‑only とみなして除外する。"}], "reasoning": "本論文はバイトコードを入力として関数境界を検出する手法を提案しており、ML（GNN）を用いている点は基準を満たすが、出力はコード生成ではなく属性情報であり、復元・可読化を目的としたデコンパイル（L1–L3 の高水準表現）の範囲外である。そのため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3386, "latency_ms": 57945}}
{"key": "10.1145/3756681.3756954", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "code completion focuses on integrating new lines or blocks of code into an existing codebase", "explanation": "アブストラクトからは低水準バイナリやアセンブリが入力であることが示されず、既存のソースコードへの補完であるため低水準入力が無いと判断した。"}], "reasoning": "本稿はコード補完を対象としており、低水準（バイナリ・アセンブリ等）から高水準コードへの復元を目的としていない。デコンパイルの定義に合致しないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3130, "latency_ms": 44183}}
{"key": "10.1145/3757735", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This article presents a taxonomy categorizing and describing the main techniques used to secure Android applications.", "explanation": "アブストラクトが手法の調査・分類（taxonomy）を中心に述べており、デコンパイル研究ではなくサーベイ的な内容であるため除外と判断した。"}, {"code": "ex_out_of_scope", "evidence": "Software protection refers to a range of methods used to protect applications against reverse engineering.", "explanation": "研究対象が逆コンパイルやコード復元ではなく、保護手法全般でありデコンパイルのスコープ外なので除外とした。"}], "reasoning": "本稿はAndroidアプリの保護技術に関する分類・調査を目的としており、低水準バイナリ入力からLLM/MLを用いてコードを復元するデコンパイル研究とは無関係である。したがって除外基準 (survey/meta および scope外) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3234, "latency_ms": 50400}}
{"key": "10.1145/3759425.3763387", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "assigning meaningful function names", "explanation": "本稿は関数名の付与（識別子復元）だけを目的としており、出力は名前という高水準属性のみであり L1‑L3 のコード生成が示されていないため L4‑only と判断し除外します。"}], "reasoning": "本文はデコンパイルされたコードに対して関数名を付与することに焦点を当てており、出力は名前という属性に留まります。L1‑L3 の高水準コード（ソース・擬似コード・AST 等）を生成する記述がないため、本バージョンの対象外（L4‑only）となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3505, "latency_ms": 62820}}
{"key": "10.1145/3759425.3763397", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Statically detecting vulnerabilities at the binary level ... recent efforts that leverage Large Language Models (LLMs) for vulnerability detection", "explanation": "要旨ではLLMを用いた脆弱性検出が主目的であり、コードの復元・可読化・高水準表現生成は示されていないため、復元意図がなく除外する"}], "reasoning": "本稿はバイナリレベルでの脆弱性検出を目的としており、LLMは検出支援に使用されているがコード生成やデコンパイルは行わない。Decompilation Survey の対象は復元・可読化を目的とした L1–L3 出力の生成であるため、除外基準 EC3（復元意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3140, "latency_ms": 47775}}
{"key": "10.1145/3772368", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "existing techniques for evaluating neural decompilation models are generally inadequate... we introduce codealign, a novel instruction-level code equivalence technique designed for neural decompilers.", "explanation": "論文はニューラルデコンパイラの評価手法を提案しており、コード生成や復元が目的ではなく評価・類似性測定が主目的なので除外基準 EC3 に該当する"}], "reasoning": "本稿は低水準バイナリから高水準コードを生成すること自体を目的とした研究ではなく、ニューラルデコンパイラの出力を評価する手法を提案している。復元・可読化が目的ではなく評価指標の改善であるため、包含基準を満たさず除外基準 EC3（復元意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3208, "latency_ms": 51022}}
{"key": "10.5555/3507788.3507824", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Modern obfuscation techniques aim to prevent reverse engineering", "explanation": "本文では機械学習や大規模言語モデルを用いた手法について言及しておらず、ML/LLM が使用されていないため除外します。"}, {"code": "ex_out_of_scope", "evidence": "we propose a method of control flow obfuscation using the InvokeDynamic instruction", "explanation": "対象はデコンパイルではなく制御フロー難読化であり、L1–L3 のコード復元を目的としないため本サーベイの範囲外です。"}], "reasoning": "この論文は JVM バイトコードの制御フロー難読化手法を提案しており、機械学習や LLM を利用したデコンパイルとは無関係です。入力は低水準表現だが、目的は復元・可読化ではなく保護であり、出力も高水準コード生成を行わないため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3080, "latency_ms": 45995}}
{"key": "10.5555/3615924.3615947", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "deep learning-based approach for code similarity detection in binaries", "explanation": "抽象からは、最終目的がバイナリの類似性・脆弱性検出であり、コードの復元や高水準コード生成ではないため、復元・生成が主目的ではないと判断した。"}], "reasoning": "本稿はバイナリの類似性を測り脆弱性検出を行うことが目的であり、デコンパイルは中間的な前処理として用いられているだけです。コード生成や復元（L1-L3 の出力）を主目的としていないため、除外基準 EC3 に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3186, "latency_ms": 48456}}
{"key": "10043270", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a novel bytecode obfuscation approach called BOSC", "explanation": "要旨に機械学習や大規模言語モデルの利用が記載されておらず、純粋にオブフュスケーション手法を提案しているためML/LLMが使用されていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "the failure rate of decompilation tools is over 99%", "explanation": "本研究はデコンパイルを困難にするためのオブフュスケーション手法を提案しており、L1–L3 のコード生成や復元が目的ではないため、対象外（L4‑only除外）と判断した。"}], "reasoning": "本稿はバイトコードの難読化手法を提案するもので、機械学習・LLM の使用がなく、デコンパイルから高水準コードを生成することを目的としていないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3118, "latency_ms": 49271}}
{"key": "10050059", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "graph neural network (GNN) based vulnerability detection for smart contracts", "explanation": "目的が脆弱性検出であり、コードの復元・可読化・生成ではなく分類が主目的であるため、コード生成意図がなく除外されます。"}], "reasoning": "本論文はバイトコードをデコンパイルしてOpcodeを取得し、CFGを構築した上でGNNを用いて脆弱性を検出する手法を提案しています。ML/LLM は脆弱性検出に使用されており、デコンパイルは前処理に過ぎません。復元・可読化などのコード生成が目的でないため、除外基準 EC3（No Reconstruction Intent）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3294, "latency_ms": 49947}}
{"key": "10077138", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "it will transform the code into a kind of intermediate code, and then generate the target code after Control Flow Flattening and string encryption obfuscation", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く記載されていないため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "which will make the decompilation work more difficult, thus realizing a code obfuscation system", "explanation": "研究の目的はコード難読化であり、デコンパイル自体の復元や生成を対象としていないため、スコープ外（L4 も含む）と判断した。"}], "reasoning": "本稿は LLVM を用いたコード難読化手法の提案であり、機械学習・LLM を用いたデコンパイル手法の研究ではない。低水準入力から高水準コードを生成する目的や手法が示されておらず、除外基準 EC1 (ML未使用) および EC5 (デコンパイル範囲外) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3278, "latency_ms": 56026}}
{"key": "10123452", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "automated summarisation of decompiled code can help reverse engineers", "explanation": "要旨はデコンパイルされたバイナリ関数を要約（自然言語）することが目的であり、コード生成や復元を行わないため、復元・可読化目的のデコンパイルとはみなされず除外されます。"}], "reasoning": "本論文はデコンパイルされたバイナリ関数を入力として、自然言語の要約を生成することを目的としており、コード（L1–L3）の再構成や復元を行わないため、デコンパイルの定義に合致しません。したがって除外基準 EC3（No Reconstruction Intent）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3434, "latency_ms": 53882}}
{"key": "10123564", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "we conduct... the first and most comprehensive large-scale empirical study of smart contract decompilers", "explanation": "アブストラクトは既存デコンパイラの評価を行う実証研究であり、ML/LLM を用いた手法について言及していないため、ML/LLM 不使用として除外と判断した。"}], "reasoning": "本稿はスマートコントラクトデコンパイラの信頼性や性能を実証的に評価する調査論文であり、LLM/ML を中心としたデコンパイル手法の提案や実装が含まれていない。したがって、ML/LLM 不使用という除外基準 (ex_no_ml) に該当し、採択対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3251, "latency_ms": 47121}}
{"key": "10123584", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose an LLVM-based code virtualization tool, namely xVMP", "explanation": "要旨に機械学習や大規模言語モデルの使用は言及されておらず、従ってML/LLMを用いていないと判断したため"}, {"code": "ex_no_code_generation", "evidence": "code virtualization ... hides both the control flow and the data flow of the code, thereby preventing code from being decompiled", "explanation": "目的はコードを隠蔽しデコンパイルを防止することであり、復元・可読化・コード生成が主目的ではないため"}], "reasoning": "本論文はコード仮想化を用いた難読化手法を提案しており、ML/LLM を利用したデコンパイルやコード生成を行う目的ではない。低水準入力から高水準コードを生成する研究ではなく、逆にデコンパイルを阻害することが主たる目的であるため、除外基準（EC1, EC3）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3431, "latency_ms": 53883}}
{"key": "10174218", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_type_recovery", "evidence": "Transformer-based Encoder-Decoder architecture capable of augmenting decompiled code with variable names and types", "explanation": "ML（Transformer）を用いて、デコンパイル済みコードに変数型（および名前）を付与することで型回復を目的としているため、L1–L3 の出力を伴う Type Recovery と判断した。"}], "reasoning": "本論文は機械学習（Transformer）を中心手法とし、デコンパイラ出力を入力として変数型と識別子名を付与することでコードの可読化を行う。出力は型情報が付与された擬似コードであり、L1–L3 の高水準表現に該当する。したがって Include 基準を満たし、in_type_recovery カテゴリに含める。", "model": "openai/gpt-oss-120b", "tokens_used": 4050, "latency_ms": 84783}}
{"key": "10179314", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a precise and scalable symbolic analysis called fearless symbolic analysis that uses intuitive queries for binary code and implement this in QueryX.", "explanation": "抽象では機械学習や大規模言語モデルの使用について言及されておらず、シンボリック解析・クエリ機構が中心であるため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本論文はバイナリをデコンパイルしたコード上でのシンボリッククエリ分析手法を提案しており、機械学習や大規模言語モデルを中核技術として用いている記述がない。したがって、Exclude Criteria の EC1 (No ML/LLM) に該当し、除外と判断する。", "model": "openai/gpt-oss-120b", "tokens_used": 3606, "latency_ms": 60020}}
{"key": "10179370", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a novel solution that transforms a decompilation error-inducing Python binary into a decompilable binary.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が言及されておらず、従来の変換手法のみであるため、ML/LLM を用いていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "Our approach ... transforms error-inducing code blocks in the input binary into another form.", "explanation": "出力は変換されたバイナリ（低水準表現）であり、L1–L3 の高水準コードや擬似コードは生成しないため、対象外（L4‑only もしくは低レベル出力）とみなした。"}], "reasoning": "本稿は Python バイナリを変換して既存デコンパイラの成功率を上げる手法を提案しているが、機械学習・LLM を利用していない上に生成物が高水準コード（L1–L3）ではなく変換バイナリであるため、デコンパイル調査の対象基準を満たさず除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3640, "latency_ms": 66282}}
{"key": "10183629", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we provide an overview of the main tools used in Android reverse engineering", "explanation": "本論文はツールの概要をまとめたサーベイであり、実装や評価を行う研究ではないため除外基準に該当します"}, {"code": "ex_no_ml", "evidence": "The study's finding shows App Cloner and Mt manager tools have the highest precision", "explanation": "要旨に機械学習・LLM の使用が記載されておらず、従来のツール比較のみであるため除外基準に該当します"}], "reasoning": "本稿は Android リバースエンジニアリングツールの系統的サーベイであり、機械学習や大規模言語モデルを用いたデコンパイル手法の提案・評価がない。したがって、本スクリーニングの対象（LLM/ML を中心とした L1–L3 デコンパイル研究）から外れます。", "model": "openai/gpt-oss-120b", "tokens_used": 3093, "latency_ms": 48606}}
{"key": "10188657", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we implement a Ghidra processor module for decompilation and analysis of decrypted microcode", "explanation": "抽象からは機械学習・大規模言語モデルの使用が全く示されておらず、従来の静的解析とGhidra拡張のみであるため、ML/LLM が使われていないと判断した。"}], "reasoning": "本論文は Intel マイクロコードの逆解析とカスタマイズに焦点を当て、Ghidra を用いた静的・動的解析フレームワークを提示しているが、機械学習や大規模言語モデルを手法の中核として用いている記述がない。したがって、Decompilation Survey の Inclusion Criteria を満たさず、EC1（ML/LLM 未使用）に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3248, "latency_ms": 47621}}
{"key": "10195624", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "This model automatically generates relevant labels for binary function naming", "explanation": "アブストラクトから、出力は関数名ラベルのみであり、ソースコードや擬似コードといった L1‑L3 の高水準表現は生成していないため L4‑only と判断し除外します。"}], "reasoning": "本稿はストリップされたバイナリから関数名（ラベル）を生成することを目的としており、入力は低水準バイナリでML手法も用いられていますが、出力は関数名という属性情報のみで、コンパイル可能なコードや擬似コードなど L1‑L3 に該当する高水準表現を提供していません。そのため、本バージョンの対象外（L4‑only）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3935, "latency_ms": 76035}}
{"key": "10197775", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The purpose of this research is to investigate ... SootDiff analysis tool, a bytecode comparison tool...", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、従来の静的解析ツールのみが言及されているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "to determine if an application has been tampered with by comparing a known good version with a version that is unknown", "explanation": "目的はコード改ざんの検出であり、復元・可読化や高水準コード生成ではなく、分類・検知が主であるため除外基準に該当する。"}], "reasoning": "本稿はバイトコード比較ツールによる改ざん検出を目的としており、機械学習・LLM を用いた手法は示されていない。また、コード生成や高水準表現への復元を目指すものではなく、検知が主目的であるため、デコンパイル調査の対象（L1–L3 の出力を伴う ML/LLM 手法）から外れる。", "model": "openai/gpt-oss-120b", "tokens_used": 3356, "latency_ms": 57571}}
{"key": "10320193", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "reassign descriptive names for binary functions ... NER-pc ... improvements against the state-of-the-art methods.", "explanation": "アブストラクトは関数名（識別子）の付与のみを目的としており、出力は L4 の属性（名前）に限られるため、L1–L3 のコード生成がなく、スコープ外（L4-only）として除外します。"}], "reasoning": "本論文はバイナリ関数の名前付与（識別子復元）に焦点を当てており、生成物は関数名という L4 の属性のみです。デコンパイルの目的は L1–L3 の高水準コード生成である必要がありますが、本稿はそれを満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3495, "latency_ms": 61355}}
{"key": "10410676", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "Using a decompiler, models can be updated (retrained) and sent to other nodes (mobile models).", "explanation": "要旨からはデコンパイルに機械学習や大規模言語モデルが用いられている記述がなく、従来のデコンパイラを利用していると解釈できるため、ML/LLM未使用として除外します。"}], "reasoning": "本稿はIoT/エッジ向け仮想化VMの提案と、モデル更新のために従来型デコンパイラを使用することを述べているが、デコンパイル手法としてML/LLMを中心に据えていない。したがって、Decompilation Survey の包括基準（ML/LLM の使用）が満たされず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3164, "latency_ms": 51826}}
{"key": "10491696", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Based on binary function decompilation, we identify the key statement that causes the vulnerability", "explanation": "要旨はデコンパイルしたコードから脆弱性キー文を抽出して検出を行うことであり、復元・高水準コード生成が主目的ではないため除外"}], "reasoning": "本稿はバイナリ関数のデコンパイルを脆弱性検出の前処理として使用し、鍵文の抽出と類似性評価で脆弱性検出を行うことが主目的です。LLM/ML は検出モデルに用いられますが、コード復元や高水準表現生成は目的としていません。そのため、decompilation の再構成（L1‑L3）を目指す基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3379, "latency_ms": 57905}}
{"key": "10500201", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "code does not need to be compiled and thus would not need to be run through a decompiler", "explanation": "抽象的に低水準バイナリからの復元・デコンパイルが目的でなく、コンパイル不要なインタプリタ言語を使用しているため、デコンパイル研究の対象外（L1‑L3の出力もなく、ML/LLMも使用していない）と判断した。"}], "reasoning": "本稿はブロックチェーン上のスマートコントラクトを Python で記述し、IPFS で保存するフレームワークを提案しているだけで、バイナリ等の低水準入力から高水準コードを生成するデコンパイルや ML/LLM の利用は一切示されていない。したがってデコンパイルサーベイの適用範囲外であり除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3194, "latency_ms": 52854}}
{"key": "10515515", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "use of artificial intelligence ... genetic algorithms to restore the source code ... from machine code", "explanation": "遺伝的アルゴリズムを中心手法とした AI/ML が、機械コードという低水準入力からソースコード（L1）を直接生成しているため、Core Decompilation に該当する。"}], "reasoning": "本稿は機械コードを入力とし、遺伝的アルゴリズムという AI 手法でソースコードを復元することを目的としている。出力はコンパイル可能なソースコード（L1）であり、Decompilation のコアタスクを満たす。したがって L1–L3 の範囲でインクルードと判定する。", "model": "openai/gpt-oss-120b", "tokens_used": 3604, "latency_ms": 65482}}
{"key": "10545392", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose three unique attack methods (GizmoSplit, BuffWarp, and EnigmaFlow)...", "explanation": "本文は攻撃手法の提案だけであり、機械学習や大規模言語モデルの利用が記述されていないため、ML/LLM 不使用として除外します。"}, {"code": "ex_out_of_scope", "evidence": "decompilation... is not resilient for detecting (control logic) binary programs", "explanation": "デコンパイルは検知評価の対象として言及されるのみで、低水準入力から高水準コードを生成する研究ではなく、デコンパイル自体が本サーベイの対象外（L1–L3 の復元）であるため除外します。"}], "reasoning": "この論文はPLC制御ロジックへの攻撃手法を提案しており、デコンパイル技術やML/LLMの利用は主題に含まれません。したがって、ML未使用かつデコンパイル範囲外という除外基準に該当し、採択候補外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3566, "latency_ms": 60740}}
{"key": "10581196", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "Through a combination of automated processes and user-friendly features", "explanation": "アブストラクトではML／LLMの利用が言及されておらず、従来の自動化プロセスのみが述べられているため、ML/LLM非使用と判断した。"}], "reasoning": "本論文はAPKの解析・デコンパイルを支援するツールを紹介しているが、手法として機械学習や大規模言語モデルの使用が明示されていない。したがって、ML/LLM を中核としたデコンパイル研究の条件を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3221, "latency_ms": 51102}}
{"key": "10589897", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify these recurring inline functions (RIFs)", "explanation": "抑制はバイナリ中のインライン関数を検出・識別することが目的であり、ソースコードや擬似コード等の高水準表現を生成していないため、コード生成（復元）を目的としたデコンパイルではないと判断した。"}], "reasoning": "本論文はバイナリコード中のインライン関数を検出する手法を提案しており、ML を用いているものの出力は関数の存在判定という属性情報であり、L1–L3 の高水準コード生成を目的としていない。したがってデコンパイルの再構成目的に該当せず、除外基準 EC3 に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3115, "latency_ms": 50396}}
{"key": "10590654", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The paper presents a novel Android application reinforcement method... It uses less computational power and storage while meeting the high safety standards of 5G technology.", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されていないため、ML/LLM を用いていないと判断し、除外基準 EC1 に該当します。"}], "reasoning": "本稿は Android アプリを Smali から C++ へ変換しハードニングする手法を提案しているが、機械学習・LLM の利用が明示されていない。デコンパイル自体は行われているものの、ML/LLM が中心手法でないため、除外基準 ex_no_ml に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3184, "latency_ms": 48783}}
{"key": "10594168", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "the decompiling component is used to get the source of the procedure to be tested", "explanation": "要旨ではデコンパイルは単なる前処理として言及されており、LLM/ML がデコンパイルに使用されている記述がないため、ML/LLM 不使用として除外する"}, {"code": "ex_no_code_generation", "evidence": "the detection mechanism ... is improved, and the malicious applications or software detection mechanism ...", "explanation": "本研究の主目的はマルウェア検出であり、復元・可読化が主目的ではなく分類・検出が中心であるため除外基準に該当する"}], "reasoning": "本稿はマルウェア検出を目的とした特徴融合手法を提案しており、デコンパイルは検出パイプラインの前段階として言及されるのみで、LLM/ML を用いたデコンパイル手法は示されていない。したがって、ML/LLM がデコンパイルの核心でないことと、復元が主目的でないことから除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3346, "latency_ms": 57619}}
{"key": "10596484", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "learns the similarity between binary and source codes", "explanation": "要旨はバイナリとソースコード間の類似性を学習しマッチングを行うことに焦点を当てており、コードの復元や高水準表現の生成を目的としていないため、再構成意図がなく除外基準 EC3 に該当する。"}], "reasoning": "本文はバイナリとソースコードのクロスランゲージマッチングを GNN で学習し、類似度評価を行う手法を提案している。出力はマッチング結果（類似スコア）であり、デコンパイルによるコード生成や高水準表現の復元は行わない。したがって、復元・可読化を目的とした LLM/ML 手法ではなく、分類/検索タスクに該当するため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3332, "latency_ms": 58143}}
{"key": "10625666", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the whole process adopts the method of JNI call, the application core code is placed in the Java layer, the digital signature mechanism and integrity verification are placed in the Native layer", "explanation": "要旨からは機械学習や大規模言語モデルの使用が一切言及されておらず、従来の JNI・デジタル署名による保護手法のみが説明されているため、ML/LLM が使われていないと判断した。"}], "reasoning": "本論文はAndroidアプリの保護機構を提案しており、デジタル署名やJNIを用いた実装方法が中心である。デコンパイルそのものやML/LLM を利用したコード復元・可読化に関する記述がなく、ML技術が使用されていないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3107, "latency_ms": 48327}}
{"key": "10646727", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_variable_naming", "evidence": "predict meaningful variable names in decompilation output", "explanation": "LLM（BERT）を用いて、デコンパイル結果の変数名を予測し、L1–L3 のコード表現を改善しているため"}, {"code": "in_decompiler_enhancement", "evidence": "modern decompilers attempt to generate C‑style source code from a binary, they cannot recover lost variable names", "explanation": "既存デコンパイラの出力（変数名の無い疑似コード）を入力とし、MLで可読性（変数名）を向上させているため"}], "reasoning": "本稿はバイナリから生成されたデコンパイル出力を対象に、LLM（BERT）で変数・関数名を予測し、ソースコードレベル（L1/L2）の可読化を行う研究である。ML を中核手法とし、復元目的で L1–L3 の出力を提供しているため、IC4 に該当し採択対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 4502, "latency_ms": 99787}}
{"key": "10649756", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Decompilation is crucial to transforming an application from machine code to something that can be read and understood by humans.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されていないため、ML/LLM を用いた手法ではなく除外基準 EC1 に該当します。"}, {"code": "ex_survey_or_meta", "evidence": "This chapter explores the steps necessary to get started reverse engineering an application.", "explanation": "章（chapter）形式で逆向き工学の概要を解説しているだけで、特定の研究手法や実装を報告していないため、サーベイ/レビューの範囲に入り除外基準 EC4 に該当します。"}], "reasoning": "本稿は decompilation の概念と逆向き工学全般を解説する章であり、低水準入力から高水準コードを生成するために ML/LLM を利用した手法の記述がありません。また、実装や実験の報告もなく、調査的な内容に留まるため、除外基準（ML 未使用、サーベイ）に該当し除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3121, "latency_ms": 53130}}
{"key": "10649762", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This chapter describes at a high level some advanced techniques and tools on the cutting edge of reverse engineering.", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、従来の手法や概念的説明に留まっているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "アブストラクトからは機械学習やLLMを用いたデコンパイル手法の記述がなく、単なる逆アセンブルや構造化の概念紹介にとどまっている。したがって、ML/LLM 不使用のため除外基準 EC1 に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3094, "latency_ms": 51284}}
{"key": "10679822", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "uses polymorphic and modular encryption mechanisms to secure binary code", "explanation": "要旨では機械学習・大規模言語モデルの使用が全く言及されておらず、暗号化手法だけが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はコード仮想化によるバイナリ保護手法を提案しており、復元や可読化を目的としたデコンパイル研究ではない。また、手法に機械学習や大規模言語モデルは使われていないため、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3412, "latency_ms": 56826}}
{"key": "10743227", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "combines decompilation and diversification compilation techniques", "explanation": "アブストラクトに機械学習やLLMの利用が記述されておらず、ML/LLM を手法の中核として用いていないため、EC1 に該当し除外します。"}], "reasoning": "本稿はバイナリ保護のための多様化手法を提案しており、デコンパイルは手段の一部ですが機械学習や大規模言語モデルは使用していません。したがって、Decompilation Survey の Include Criteria（LLM/ML を中核とする）を満たさず、ex_no_ml に基づき除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3187, "latency_ms": 54284}}
{"key": "10773695", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present IRENE, a decompiler that produces recompilable decompilation for patching.", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、従来のデコンパイラ手法のみであると判断したため、ML/LLMが使用されていないとみなします。"}], "reasoning": "本文はバイナリからのデコンパイルとパッチ生成に焦点を当てていますが、機械学習や大規模言語モデルを用いた手法についての記述がありません。そのため、ML/LLM を中核手法とする本サーベイの採択基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3195, "latency_ms": 52850}}
{"key": "10776359", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "develop a hybrid machine learning model to detect and anticipate malware on Android devices", "explanation": "目的がマルウェアの検出・予測であり、コードの復元や高水準表現の生成ではないため、復元・生成意図がなく除外対象となります。"}], "reasoning": "本稿は Android マルウェア検出のためのハイブリッド機械学習モデルを提案しており、デコンパイルは前処理の一部に過ぎません。復元・可読化といったコード生成が主目的でないため、Decompilation Survey の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3236, "latency_ms": 50838}}
{"key": "10795101", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We compare Erase with state-of-the-art decompilers Ghidra and Hex-Rays", "explanation": "本文は既存デコンパイラと比較する手法を提示しており、ML/LLM の使用は言及されていないため、ML が用いられていないと判断した。"}], "reasoning": "本稿は自己再帰インライン化の逆変換手法を提案し、デコンパイラ出力を最適化するだけで、機械学習や大規模言語モデルを中心手法として利用していない。したがって、ML/LLM 不使用という除外基準（ex_no_ml）に該当し、採択対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3444, "latency_ms": 61887}}
{"key": "10857519", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Malware detection using byte n-grams and machine learning", "explanation": "アブストラクトはバイト n‑gram と機械学習によるマルウェア検出（分類）を目的としており、コードの復元・可読化といった生成目的が示されていないため、復元・生成が主目的でない（ex_no_code_generation）と判断した。"}], "reasoning": "本論文はバイナリのバイト n‑gram を用いたマルウェア分類手法を提案しており、目的は検出・分類でありデコンパイルによるコード復元や高水準表現の生成は行っていない。したがって、復元・生成意図が無いことから除外基準 EC3（ex_no_code_generation）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3197, "latency_ms": 55667}}
{"key": "10911787", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "CNN-BiLSTM fusion model ... enhancing classification performance.", "explanation": "目的がマルウェアの分類・検出であり、コード生成や復元を行うことが主目的ではないため"}], "reasoning": "本稿はバイナリをデコンパイルして opcode などの特徴を抽出し、CNN‑BiLSTM によるマルウェア検出モデルを構築することに焦点を当てている。復元・可読化といったデコンパイルの目的はなく、最終出力は分類ラベルであるため、除外基準 EC3（復元・生成が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3201, "latency_ms": 53172}}
{"key": "10937558", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "It utilizes novel simplification methods that take ideas from compiler construction and simplification performed on parse trees.", "explanation": "要旨に機械学習・LLMの利用は言及されておらず、従来のコンパイラ技術だけを用いているため、ML/LLM 未使用として除外します。"}, {"code": "ex_no_lowlevel_input", "evidence": "MBASED ... performs MBA deobfuscation on C programs.", "explanation": "入力は C ソースコードであり、低水準のバイナリやアセンブリではないため除外基準に該当します。"}], "reasoning": "本稿は低水準バイナリを対象としたデコンパイルではなく、C ソースコード上の混合ブール‑算術オブフュスケーションを簡略化するツールを紹介しています。さらに機械学習や大規模言語モデルは使用していないため、Decompilation Survey の対象 (LLM/ML を用いた L1–L3 のコード生成) から外れます。", "model": "openai/gpt-oss-120b", "tokens_used": 3136, "latency_ms": 56695}}
{"key": "10965404", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the model first decompiles and extracts the name, package name, icon, and signature information of the APP", "explanation": "デコンパイルは低水準バイナリから属性情報を取得するだけで、ML/LLM は使用されていないため除外基準 EC1 に該当する"}, {"code": "ex_out_of_scope", "evidence": "extracts the name, package name, icon, and signature information of the APP", "explanation": "出力は名前やシグネチャといった L4 の属性のみで、L1–L3 のコードや擬似コードは生成しないため除外基準 EC5（L4‑only）に該当する"}], "reasoning": "本稿はデコンパイルを前処理として利用し、抽出した属性情報を用いて Siamese Network による偽アプリ判定を行うもので、ML/LLM がデコンパイルに用いられていない上に、出力もコードや擬似コードではなく属性情報のみです。そのため、Decompilation Survey の対象（L1–L3 のコード生成）から外れ、除外と判定します。", "model": "openai/gpt-oss-120b", "tokens_used": 3462, "latency_ms": 66210}}
{"key": "10967090", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Finally, KNN is used to classify the proposed feature.", "explanation": "抽象からはMLが用いられているが、出力はバイトコードの特徴分類であり、ソースコードや疑似コード等の L1‑L3 の高水準表現を生成することは示されていないため、復元・生成が主目的ではなく分類が目的と判断した。"}], "reasoning": "本論文は Java バイトコードから特徴を抽出し、KNN により制御フローを分類してデコンパイラの性能向上を目指すが、実際に高水準コード（L1‑L3）を生成する手法は示されていない。したがって、デコンパイルの復元目的（コード生成）を満たさず、除外基準 EC3（コード生成なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3260, "latency_ms": 58893}}
{"key": "10986108", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper examines the development of a methodology for embedding a digital watermark in class files by replacing bytecode opcodes and adding certain Java programming language constructs that hinder decompilation.", "explanation": "要旨に機械学習・LLM の使用についての記述がなく、従来のバイトコード改変手法のみが述べられているため、ML/LLM を使用していないと判断し、除外基準 EC1 に該当します。"}], "reasoning": "本稿はデジタルウォーターマークをバイトコードに埋め込み、逆コンパイル（デコンパイル）を困難にする手法を提案しており、ML/LLM を用いたコード復元や高水準表現生成を目的としていません。したがって、ML/LLM 不使用という除外基準 (ex_no_ml) に該当し、L1‑L3 のデコンパイル研究としては除外されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3119, "latency_ms": 53881}}
{"key": "11023256", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "PyLINGUAL plugs in data-driven NLP components ... to automatically absorb superficial bytecode and compiler changes", "explanation": "データ駆動のNLP（ML）コンポーネントがバイナリ（bytecode）入力から直接高水準のPythonソースコードを生成することから、コアデコンパイルに該当します。"}], "reasoning": "本論文はPythonバイトコードを入力とし、データ駆動のNLP/ML手法を用いてソースコード（L1）を生成するデコンパイラを提案している。目的は復元・可読化であり、出力はコンパイル可能なコードであるため、Include基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3357, "latency_ms": 58585}}
{"key": "11023499", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_type_recovery", "evidence": "LLM-assisted double-elimination framework to select the best-fit type declaration from the candidates", "explanation": "LLM が型宣言の選択に用いられ、型回復が主目的であるため in_type_recovery に該当する。"}, {"code": "in_core", "evidence": "synthesizing possible composite type declarations from the stripped binaries", "explanation": "低水準のストリップドバイナリを入力として、直接高水準の型宣言 (ソースレベル) を生成しているので core decompilation とみなす。"}], "reasoning": "本論文はストリップドバイナリという低水準入力から、LLM を活用して最適な合成型宣言を生成・選択し、型情報の復元を行っている。出力はコンパイル可能な構造体等の型宣言であり、L1-L3 に該当するため採択対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 4031, "latency_ms": 86948}}
{"key": "11028410", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.82, "reason_codes": [{"code": "in_core", "evidence": "difficult-to-analyze machine code ... genetic decompilation", "explanation": "低水準の機械コードを入力とし、遺伝的アルゴリズムという機械学習手法で高水準表現（デコンパイル）を生成しているため、Core Decompilation に該当する"}], "reasoning": "本論文は機械コードという低水準入力を対象に、遺伝的アルゴリズム（ML 手法）を用いて高水準表現を生成する「遺伝的デコンパイル」を提案している。復元・可読化を目的としており、出力はコード様の高水準表現と考えられる（L1‑L3）。したがって、Include 基準を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3295, "latency_ms": 62512}}
{"key": "11050729", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "integration of the Ghidra framework with the Heros IFDS solver", "explanation": "アブストラクトでは機械学習／LLM の利用が記載されておらず、従来の静的解析・プラグイン実装のみが言及されているため、ML 手法が使用されていないと判断した。"}], "reasoning": "本論文は Objective‑C バイナリに対する静的汚染解析を中心に、Ghidra と Heros の統合プラグインを提示しているが、ML/LLM を手法の中核として用いていない。したがって Include Criteria を満たさず、Exclude Criteria の ex_no_ml に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3264, "latency_ms": 64933}}
{"key": "11052915", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Future enhance automation; explore machine learning enhancements for improved zero-day threat detection.", "explanation": "本文では将来的に機械学習を検討すると述べているが、実際のデコンパイル手法としてML/LLMは使用していないため、ML/LLMが中核でないと判断した。"}], "reasoning": "本稿はモバイルアプリのセキュリティ評価フレームワークを提案しており、逆コンパイルはApktool等の従来ツールを用いるだけで、ML/LLM を用いたデコンパイルは行っていない。したがって、Decompilation Survey の採択基準 (ML/LLM が中核) を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3160, "latency_ms": 54935}}
{"key": "11068876", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "machine-generated variable and type names", "explanation": "出力が変数名や型といった属性のみで、コードそのもの（L1‑L3）の再構成には至っていないため L4‑only と判断し除外"}, {"code": "ex_no_lowlevel_input", "evidence": "decompilers attempt to reconstruct high-level code from binaries", "explanation": "本文では AI が扱う入力としてバイナリではなくデコンパイラ出力が示されており、低水準入力が明示されていないため除外基準に該当"}], "reasoning": "本論文は AI による変数名・型名の自動付与という属性回復に焦点を当てており、生成物はコード全体ではなく L4 レベルの情報に留まる。低水準入力も明示されていないため、L1‑L3 のデコンパイル成果を提供しない点で除外対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 4094, "latency_ms": 94022}}
{"key": "11081372", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "using Ghidra. The proposed malware analysis framework decompiles malware samples automatically", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が記載されておらず、従来の静的解析ツールだけが言及されているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "to identify malicious code, using Ghidra... to extract features, while reviewing control flow, scanning opcodes, or extracting embedded strings", "explanation": "目的はマルウェア検出・分類であり、コードの復元・可読化が主目的ではなく、コード生成（L1‑L3 の出力）を行わないため除外した。"}], "reasoning": "本稿は Ghidra を用いた静的マルウェア解析フレームワークであり、機械学習や大規模言語モデルを用いた手法が記載されていない上、デコンパイルの目的は検出・分類でありコード生成や可読化ではない。したがって、Decompilation Survey のL1‑L3 対象のML/LLM を用いたデコンパイル研究には該当しないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3382, "latency_ms": 67192}}
{"key": "11086752", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "binary code similarity detection approach", "explanation": "アブストラクトはバイナリの類似性検出が目的であり、コードの復元・生成を行うことが主目的ではないため、復元意図がなく除外します。"}], "reasoning": "本論文はバイナリコードの類似性を判定する手法を提案しており、LLM/ML は類似度推定に用いられていますが、低水準入力から高水準コードを生成すること（復元・可読化）が目的ではありません。したがって、Decompilation Survey の採択基準（IC）を満たさず、除外基準 EC3（No Reconstruction Intent）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3290, "latency_ms": 59301}}
{"key": "11118682", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "comprehensive report generation and an interactive user interface", "explanation": "アブストラクトはコード生成（L1‑L3）ではなくレポート作成を主目的としているため、出力はL4‑onlyであり本バージョンの対象外です。"}], "reasoning": "本稿はマルウェア解析支援ツールであり、Ghidraによる従来型デコンパイルを利用しつつAIで解析レポートを生成する点は示されているが、LLM/ML がデコンパイル（低水準から高水準コード）の中心手法ではない。また、最終成果はコードそのものではなくレポートであり、L1‑L3 のコード出力に該当しないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3380, "latency_ms": 71189}}
{"key": "11129273", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we review existing methods, comparing them, while highlighting both their advantages and limitations", "explanation": "要旨は既存手法の体系化と評価であり、調査・レビュー論文であるため除外と判定した"}], "reasoning": "本稿はデコンパイル手法の系統的整理と課題のレビューを行うSoKであり、ML/LLM を用いた新手法の提案や実装が示されていない。したがって、除外基準 EC4（Survey/Review）に該当し、L1‑L3 のコアデコンパイル研究としては採択対象外である。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 57569}}
{"key": "11139736", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a multi-staged hybrid framework for malware detection that combines static analysis, machine learning, and rule-based approaches", "explanation": "要旨はマルウェア検出が目的であり、LLM/ML は分類やスコアリングに使われていて、コードの復元・生成は主目的ではないため除外します。"}], "reasoning": "本稿はマルウェア検出精度向上を目的としたハイブリッドフレームワークを提案しており、デコンパイルは検出プロセスの一部として言及されるだけで、LLM/ML を用いたコード復元や高水準表現の生成は行っていません。したがって、復元・生成意図がなく L1–L3 の出力が示されていないため、除外基準 EC3（コード生成・復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3233, "latency_ms": 64940}}
{"key": "11166547", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to identify Android ransomware ... applies various machine learning classifiers to distinguish ransomware from benign applications", "explanation": "抽象ではコード生成や復元を目的にしておらず、SMALI から特徴を抽出して機械学習でマルウェアを分類することが主目的なので、復元・可読化を目的としたデコンパイルではないため除外と判断した。"}], "reasoning": "本稿は SMALI コードから特徴を抽出し、機械学習でランサムウェアを検出する分類手法を提案している。デコンパイルによるコードの復元や高水準表現の生成を目的としていないため、除外基準 EC3（復元・生成が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3124, "latency_ms": 60740}}
{"key": "11185876", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a new technique for identifying abstract syntax tree components", "explanation": "抽象語法木を用いた手法は記述されているが、機械学習や大規模言語モデルの利用は言及されておらず、ML/LLM が使われていないと判断したため"}], "reasoning": "本稿はバイナリ解析におけるスイッチ構造の復元手法を提案しているが、手法は規則ベースの AST 解析であり機械学習や LLM を用いていない。したがって Include Criteria の IC0（ML/LLM が中核手法）を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3317, "latency_ms": 64939}}
{"key": "11205440", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "evaluates the effectiveness of three LLMs... for detecting malware from decompiled.c code", "explanation": "目的がマルウェア検出（分類）であり、コードの復元・可読化は主目的ではないため除外基準EC3に該当する"}, {"code": "ex_no_lowlevel_input", "evidence": "detecting malware from decompiled.c code derived from Portable Executable (PE) files", "explanation": "入力は既にデコンパイルされたCコードであり、低水準バイナリやアセンブリではないため除外基準EC2に該当する"}], "reasoning": "本論文はLLMを用いたマルウェア検出（分類）を目的としており、コード生成や復元を目指すものではない。また、入力はPEファイルから生成されたデコンパイル済みのCコードで、低水準バイナリやアセンブリといったデコンパイル対象の入力ではない。したがって、Decompilation Surveyの包括基準を満たさず、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3307, "latency_ms": 68842}}
{"key": "11208400", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a validation framework for iOS sandbox profile decompilers, specifically targeting the SandBlaster tool.", "explanation": "本文・要旨からは機械学習や大規模言語モデルの利用が言及されておらず、従来の手法（依存関係グラフやアルゴリズム最適化）に基づくため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は iOS サンドボックスプロファイルのバイナリをデコンパイルする既存ツールの検証・最適化を扱っていますが、機械学習や大規模言語モデルを手法の中核として用いている記述がありません。そのため、Include Criteria の「LLM/ML が中核手法として使われている」条件を満たさず、除外基準 ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3181, "latency_ms": 61966}}
{"key": "11241815", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "ensemble deep learning model designed to classify Android applications as benign or malicious", "explanation": "目的がマルウェアの分類であり、復元・高水準コード生成が主目的ではないため除外"}], "reasoning": "本稿はAPKをデコンパイルして得たバイトコードから画像を生成し、深層学習でマルウェアか否かを分類することが主目的である。デコンパイルは前処理として使用されているが、出力はコード（L1‑L3）ではなく分類ラベルであり、復元・可読化を目的とした研究ではないため、除外基準 EC3 (ex_no_code_generation) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3202, "latency_ms": 64114}}
{"key": "11264981", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Our DeepWalk-DeepGraphCNNs and TCN model demonstrated superior performance ... for malware detection.", "explanation": "本文はマルウェア検出（分類）を目的としており、コードやASTの生成・復元が主目的ではないため除外基準EC3に該当します。"}], "reasoning": "本稿はDalvikバイトコードを逆コンパイルしてCFGを抽出し、深層学習でマルウェアを分類する手法を提案しています。デコンパイルは特徴抽出の前処理として利用されているものの、出力は検出結果であり、L1–L3 の高水準コード生成を目的としていないため、除外基準 (ex_no_code_generation) により除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3166, "latency_ms": 61351}}
{"key": "11307212", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "…Vision Transformer (ViT) on bytecode images… for accurate classification.", "explanation": "抽象からは、LLM/ML はバイトコード画像を用いたマルウェア分類（検出）に使われており、コードの復元・可読化といった生成目的が示されていないため、復元意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文は Android APK をデコンパイルして得たバイトコードを画像化し、ViT でマルウェアか否かを分類する手法を提案しています。目的はコードの復元や高水準表現の生成ではなく、マルウェア検出という分類タスクであるため、デコンパイルのコア目的を満たさず除外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3263, "latency_ms": 62572}}
{"key": "11334294", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "LLMs hold promise for PTX-to-CUDA de-compilation to improve code intelligibility", "explanation": "LLM が低水準 PTX から高水準 CUDA ソースコード（L1）を直接生成することが目的であるため、コアデコンパイルに該当します。"}], "reasoning": "本論文は PTX という低水準表現を入力とし、LLM を中心手法として CUDA ソースコードを生成することを目的としているため、IC0 をすべて満たし L1 出力を提供します。したがって、L1‑L3 の範囲内で採択対象となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3297, "latency_ms": 62086}}
{"key": "11334528", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a novel file format-based anti-decompilation strategy...", "explanation": "本文は逆コンパイル防止手法を提案しており、機械学習や大規模言語モデルの利用について言及していないため、ML/LLM が使用されていないと判断した。"}], "reasoning": "この論文は Android アプリ向けのアンチデコンパイル技術を紹介しており、ML/LLM を用いたデコンパイル手法とは無関係です。入力も低水準バイナリではなく、保護手法の提案であるため、除外基準の「No ML/LLM」に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3133, "latency_ms": 55137}}
{"key": "11334626", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.85, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "PseudoFix employs ... large language models (LLMs) ... to efficiently refactor distorted pseudocode.", "explanation": "LLM が中心手法として用いられ、既存の逆コンパイル結果（distorted pseudocode）を入力にして可読性向上のために出力をリファクタリングしているため、デコンパイラ出力の改善（Decompiler Enhancement）に該当します。"}, {"code": "in_core", "evidence": "Decompilation can convert binary programs into clear C-style pseudocode", "explanation": "論文はバイナリから生成された C スタイルの疑似コードを対象としており、低水準入力に由来する高水準表現（L2）を扱っていることを示しています。"}], "reasoning": "本論文は LLM を用いて既存の逆コンパイラが生成した歪んだ疑似コードをリファクタリングし、可読性の高い C スタイル疑似コード（L2）を生成する手法を提案している。低水準バイナリから派生した疑似コードを入力とし、構造改善という復元目的を持つため、Decompilation Survey の採択基準（L1–L3）に合致し、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 4015, "latency_ms": 95283}}
{"key": "11352404", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we introduce a structural analysis algorithm specifically for PHP syntax", "explanation": "本文でML/LLMの使用は言及されておらず、アルゴリズム的な構造解析に基づく手法であるため、ML/LLMが中核手法でないと判断しました。"}], "reasoning": "本論文はPHPバイトコードからソースコードを復元するフレームワークを提案していますが、手法は構造解析アルゴリズムに依存しており、ML・LLMの利用が示されていません。そのため、Decompilation Survey Screening RulesのInclude Criteriaを満たさず、Exclude Criteriaの「No ML/LLM」に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3373, "latency_ms": 66714}}
{"key": "11367734", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "DECodeT5 builds upon the CodeT5 code generation model by integrating a pre-trained assembly encoder ... mapping assembly-to-source code.", "explanation": "アブストラクトは、アセンブリ（低水準）を入力とし、C言語のソースコード（高水準・L1）を生成することを目的としており、LLM/ML が中心手法であることが示されているため、Core Decompilation に該当します。"}], "reasoning": "本稿はアセンブリコードから直接C言語ソースコードを生成するニューラルデコンパイラを提案しており、入力が低水準、出力が L1（コンパイル可能なソース）、手法が大規模言語モデルを用いたニューラルネットワークであるため、Decompilation Survey の採択基準（IC0・IC1）を満たすと判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3165, "latency_ms": 60735}}
{"key": "7880502", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We study effects of compilation and decompilation to code clone detection in Java.", "explanation": "要旨に機械学習や大規模言語モデルの使用は言及されておらず、ML/LLM が用いられていないと判断できるため。"}, {"code": "ex_no_code_generation", "evidence": "decompilation ... can be used as source code normalisation ... to achieve higher recall without losing precision.", "explanation": "デコンパイルはコードクローン検出の正規化手段として利用されており、復元・高水準コード生成が主目的ではなく分類・検知が目的なので除外基準に該当する。"}], "reasoning": "本稿はデコンパイラをクローン検出の前処理として使用しており、ML/LLM を用いた手法でもなく、復元や可読化が主目的ではないため、除外基準 (ex_no_ml, ex_no_code_generation) に該当し除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3294, "latency_ms": 69270}}
{"key": "7889345", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the information can be found in most of the binary files. This paper investigates what is the possibility of retrieving the information about compiler name and version based on the content of the binary code, without decompiling the binary code.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が言及されておらず、単純にバイナリからコンパイラ情報を抽出する手法であるため、EC1の「ML/LLM を使用していない」基準に該当し除外する。"}], "reasoning": "本論文はバイナリからコンパイラ名・バージョン情報を取得する手法を検討しており、機械学習やLLMを用いたデコンパイル手法とは無関係である。したがって、ML/LLM 不使用という除外基準 (ex_no_ml) に該当し、L1–L3 のデコンパイル研究としては除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3001, "latency_ms": 60204}}
{"key": "7921975", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we proposed AppTwins, an efficient, robust and automatical approach", "explanation": "本文・要旨に機械学習や大規模言語モデルの使用が言及されておらず、ML/LLM が手法の中核でないため除外します。"}, {"code": "ex_out_of_scope", "evidence": "decompiled to acquire new app's name, a fingerprint was also calculated", "explanation": "出力はアプリ名（属性情報）だけで、コードや擬似コード等の L1–L3 出力がなく L4‑only であるため本バージョンの対象外です。"}], "reasoning": "本論文はネットワークトラフィックからアプリパッケージ名を特定する手法を提案しており、ML/LLM を用いたデコンパイル手法ではありません。また、出力はアプリ名という属性情報（L4）に留まり、コード生成や高水準表現（L1–L3）を提供しないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3382, "latency_ms": 73945}}
{"key": "8005920", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the encryption and decryption's codes adopt an improved AES encryption algorithm", "explanation": "本文に機械学習・LLM の利用が記載されていないため、EC1 に該当し除外と判断した。"}], "reasoning": "本稿は JNI と AES を用いた Java ソースコード保護手法を提案しており、デコンパイルやコード復元を目的としていない。また、ML/LLM を使用した手法の記述がなく、デコンパイル調査の対象外であるため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3057, "latency_ms": 64938}}
{"key": "8029506", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Static analysis is to decompile the applications to generate intermediate code and then analyze the usage of permissions.", "explanation": "抽象では機械学習や大規模言語モデルの利用が言及されておらず、純粋に静的解析のみであるため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "Our method can efficiently detect the above three kinds of permission over claim problems", "explanation": "目的は権限過大要求の検出であり、復元・コード生成が主目的ではなく分類・検知であるため除外基準に該当する。"}], "reasoning": "本論文は Android アプリの権限過大要求を検出するための静的解析と意味的類似度計算を行うもので、ML/LLM を用いたデコンパイルや高水準コード生成は行っていない。したがって、Decompilation Survey の対象外（exclude）となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3467, "latency_ms": 73946}}
{"key": "8054016", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "By introducing the instruction template and operand template, we propose a decompiling framework", "explanation": "要旨では機械学習や大規模言語モデルの使用は言及されておらず、テンプレートベースの手法のみが説明されているため、ML/LLM が使われていないと判断した。"}], "reasoning": "本論文はPLCのバイトコードを対象に、指示テンプレートとオペランドテンプレートを用いたルールベースのデコンパイル手法を提案している。要旨に機械学習や大規模言語モデルの利用が示されていないため、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3041, "latency_ms": 63405}}
{"key": "8076511", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose three core technologies: simulation execution, DEX reassembling, and DEX restoration", "explanation": "アブストラクトには機械学習や大規模言語モデルの利用が記述されておらず、従来のシミュレーションとリアセンブル手法のみが述べられているため、ML/LLM を使用していないと判断した。"}], "reasoning": "本論文は Android アプリのパック解除を目的とし、シミュレーション実行や DEX 再構築といった手法で元の DEX バイトコードを抽出するものです。機械学習・LLM を中核手法として用いていないため、Decompilation Survey の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3305, "latency_ms": 68210}}
{"key": "8080433", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "we use genre‑related corpora (including fantasy books and decompiled games)", "explanation": "アブストラクトは低水準バイナリやアセンブリではなく、デコンパイル済みのゲームテキストや小説を入力としているため、低水準入力がなく除外基準 EC2 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "our agent ... plays on a level comparable to the winner of the last year Text‑Based Adventure AI Competition", "explanation": "目的はゲームエージェントのプレイであり、コードや高水準プログラム表現の生成・復元は行わないため、復元・生成が主目的でない EC3 に該当します。"}], "reasoning": "本論文はテキストゲームエージェントの構築を目的としており、入力はデコンパイル済みテキストや小説といった高水準データで、バイナリ等の低水準入力からのデコンパイル手法やコード生成は行っていません。したがって、Decompilation Survey の包括基準 (低水準入力＋MLによるコード復元) を満たさないため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3257, "latency_ms": 73434}}
{"key": "8109245", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a method to insert an additional security policy code at a certain interval position in the intermediate code of a binary app", "explanation": "アブストラクトに機械学習やLLMの使用が言及されておらず、従来の手法のみで実装されているため、ML/LLMを用いていないと判断した。"}], "reasoning": "本論文はバイナリアプリの中間コードにセキュリティポリシーを挿入する手法を提案しており、機械学習技術は使用されていない。Decompilationは目的の一部であるが、ML/LLMが中心手法ではないため、除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3285, "latency_ms": 69849}}
{"key": "8109451", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We evaluate current Java bytecode decompilers.", "explanation": "アブストラクトにML/LLMを用いた手法の記述がなく、単なる既存デコンパイラの評価であるため、ML/LLM不使用として除外します。"}], "reasoning": "本稿は既存のJavaバイトコードデコンパイラの出力を評価する調査研究であり、ML或はLLMを用いたデコンパイル手法を提示していません。したがって、EC1（No ML/LLM）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3070, "latency_ms": 65997}}
{"key": "8210757", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The methodology consists in attempting to decompile the application HeartKeeper. Applying to the source code techniques of reverse engineering...", "explanation": "要旨からは機械学習や大規模言語モデルを用いた手法の記述がなく、単なるリバースエンジニアリング手法だけが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は Android アプリのセキュリティ監査のために手動または従来のリバースエンジニアリング手法でデコンパイルを行っているが、機械学習や大規模言語モデルを中心手法として用いている記述がない。したがって、Decompilation Survey Screening Rules の Exclude Criteria (EC1) に該当し、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3239, "latency_ms": 65992}}
{"key": "8284326", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "disassembling, decompiling and debugging application's code using Disassembler", "explanation": "摘要ではML/LLMの使用が言及されておらず、従来のディスアセンブラによる手法のみが説明されているため、ML/LLMが使われていないと判断しました。"}], "reasoning": "本稿はiOSアプリの逆コンパイルやパッチ適用を手動のディスアセンブラ手法で説明しており、機械学習や大規模言語モデルを用いた手法が示されていないため、除外基準EC1（ML/LLM未使用）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3014, "latency_ms": 63442}}
{"key": "8299877", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "A code obfuscation technique has been proposed to complicate the process of reverse engineering.", "explanation": "本文に機械学習や大規模言語モデルの使用は記載されておらず、単なる難読化手法であるためML/LLMを用いていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "The basic idea is to conceal the proprietary code section by using preventive design obfuscation and insertion of self-modifying code at the binary level.", "explanation": "目的が逆コンパイルやコード復元ではなく、難読化による逆コンパイル防止であり、L1–L3 のデコンパイル出力を生成しないため本サーベイの対象外とした。"}], "reasoning": "この論文は機械学習やLLMを利用したデコンパイル手法を提案しておらず、コード難読化による逆コンパイル防止を目的としているため、除外基準 (ex_no_ml, ex_out_of_scope) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3450, "latency_ms": 79961}}
{"key": "8327566", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "decompilation techniques driven by the contract structure definition", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、従来のルールベース手法のみであるため"}, {"code": "ex_no_code_generation", "evidence": "allows contract developers to better visualize and understand the contract stored state", "explanation": "出力は状態の可視化であり、ソースコードや擬似コードなどの L1–L3 の高水準コード生成を目的としていないため"}], "reasoning": "本文はスマートコントラクトの状態可視化を目的としたデコンパイル手法を紹介しているが、機械学習・LLM を用いた手法が示されていない。さらに、出力はコード生成ではなく属性の可視化であり、L1–L3 のコード復元を目的としないため、除外基準 (ex_no_ml, ex_no_code_generation) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3046, "latency_ms": 67665}}
{"key": "8330222", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "decompiling binary code snippets using a model based on Recurrent Neural Networks", "explanation": "RNN（ML）を用いてバイナリ（低水準）から直接ソースコード等の高水準表現を生成しているため、Core Decompilation に該当する。"}, {"code": "in_variable_naming", "evidence": "recovering ... variable or function names", "explanation": "変数や関数名の復元を目的としており、LLM/ML が識別子を生成している点で Variable Naming カテゴリに該当する。"}, {"code": "in_control_structure", "evidence": "recovering control flow constructs", "explanation": "制御構造の復元を目的にしているため、Control Structure Recovery の要素も含んでいる。"}], "reasoning": "本論文はバイナリを入力とし、RNN を中核手法として直接ソースコードを生成する decompilation 手法を提示している。出力はコンパイル可能なコードもしくは擬似コードであり、変数名や制御構造の復元も対象としているため、L1‑L3 の範囲に該当し、Include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3703, "latency_ms": 88324}}
{"key": "8406593", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "uses the Z3 solver to synthesize the abstract specification", "explanation": "本文では Z3 ソルバを用いた合成手法のみが記述され、機械学習や LLM の利用は示されていないため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はファイアウォール設定を抽象仕様へデコンパイルする手法を提案しているが、使用技術は Z3 ソルバによる合成であり機械学習・LLM が中心手法として記載されていない。したがって Exclude Criteria の EC1 (No ML/LLM) に該当し、除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3249, "latency_ms": 68711}}
{"key": "8572021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "by decompiling and recompiling the program", "explanation": "本文はデコンパイルや再コンパイルについて述べているが、機械学習や大規模言語モデルの利用は言及されておらず、EC1に該当するため除外とする"}, {"code": "ex_no_code_generation", "evidence": "present a strictly limited set of low-level attack patterns", "explanation": "目的は攻撃パターンの提示であり、コードの復元や生成ではなく分類・説明に留まるため、EC3に該当し除外となる"}], "reasoning": "本稿は低レベル制御フロー操作の攻撃手法を提示するもので、機械学習を用いたデコンパイルや高水準コード生成を目的としていない。そのため、ML未使用およびコード生成非目的という除外基準に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3335, "latency_ms": 82955}}
{"key": "8600052", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the malicious program can be detected more accurately", "explanation": "アブストラクトはマルウェア検出（分類）を目的としており、コードの復元や可読化を行う記述がないため、復元・生成が主目的ではないと判断した。"}], "reasoning": "本論文は Android 悪意プログラムの検出を目的としたディープラーニング手法を提案しており、低水準の opcode シーケンスを入力に機械学習で分類を行うだけで、バイナリからソースコードや擬似コードを生成するデコンパイルの目的や出力は示されていない。したがって、復元・可読化を主目的とする本サーベイの Include 基準を満たさず、EC3（コード生成/復元目的でない）に該当するため除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3111, "latency_ms": 69053}}
{"key": "8668959", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Based on the static analysis method, we propose a method for automatically collecting forensic artifact.", "explanation": "本文からは機械学習や大規模言語モデルの利用が言及されておらず、従来の静的解析のみであるため、EC1の「ML/LLMを使用していない」に該当します。"}], "reasoning": "本稿はAndroidアプリを静的解析でデコンパイルし、法的証拠となるアーティファクトを抽出する手法を提案していますが、機械学習やLLMを手法の中核として用いている記述がなく、除外基準EC1に該当するため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2954, "latency_ms": 65494}}
{"key": "8728471", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Usual methods like disassembly, decompiling, de-obfuscation or execution of the binary need not be done in this proposed method.", "explanation": "論文はマルウェアの分類が目的であり、コードの復元や生成は行わないため除外します。"}, {"code": "ex_no_lowlevel_input", "evidence": "The architecture used in this work is a hybrid cost-sensitive network of one-dimensional Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) network...", "explanation": "入力は画像データセット (Malimg) 等の高レベル表現であり、低水準バイナリやアセンブリは利用していません。"}], "reasoning": "本稿はディープラーニングを用いたマルウェア分類手法を提案しており、デコンパイルやコード生成を目的としていない。また、入力は低水準コードではなく画像データセットであるため、デコンパイル調査の対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3279, "latency_ms": 73951}}
{"key": "8859456", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "It analyzes the decompiled code that identifies the code related to Android SDK version", "explanation": "抽象からは機械学習・LLM の使用が言及されておらず、単なるコード解析手法であるため、ML/LLM 不使用の基準に該当します。"}], "reasoning": "本論文は Android アプリのテスト手法を提案しており、低水準バイナリからの復元や高水準コード生成を目的としていません。また、手法はコード解析に基づくもので、機械学習や大規模言語モデルの利用が示されていないため、除外基準 ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3078, "latency_ms": 68246}}
{"key": "8930870", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We study the effectiveness of eight Java decompilers with respect to three quality indicators", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及されておらず、従来のデコンパイラを評価しているだけなので、ML/LLM を用いていないと判断した。"}], "reasoning": "本稿は Java バイトコード向け既存デコンパイラ8種の品質を評価する実証研究であり、ML/LLM を手法の中核として用いていない。したがって Exclude Criteria の EC1（No ML/LLM）に該当し、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3060, "latency_ms": 65131}}
{"key": "8936022", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "The method of decompiled code static analysis has been improved.", "explanation": "本文では機械学習や大規模言語モデルの利用が言及されておらず、従来の静的解析手法の改善のみを述べているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文はオブフュスケーション後のコード品質測定手法を提案しており、ML/LLM を用いたデコンパイル手法ではない。入力が低水準表現かどうかも明示されず、コード生成・復元が目的ではないため、除外基準 ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2959, "latency_ms": 67187}}
{"key": "8945606", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We propose a novel method of android malware classification using Object-Oriented Software Metrics and machine learning algorithms.", "explanation": "要旨はマルウェアの分類が目的であり、コードの復元・生成は行っていないため除外基準EC3に該当します。"}], "reasoning": "本稿は Android アプリをデコンパイルして得たメトリクスを用いたマルウェア分類手法を提案しており、LLM/ML は分類モデル構築に使用されています。デコンパイルは前処理に過ぎず、復元・可読化といったコード生成目的がありません。そのため、Decompilation Survey の対象外（コード生成なし）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3151, "latency_ms": 72104}}
{"key": "8965960", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "By decompiling and processing APK files, ... the classification is achieved through an integrated learning framework", "explanation": "要旨はデコンパイル後の特徴抽出で分類を行うことが目的であり、コードの復元や可読化は主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はデコンパイルを前処理として用い、Android アプリのマルウェア検出という分類タスクを行うものです。復元・可読化といった高水準コード生成を目的としていないため、Decompilation Survey の対象外（ex_no_code_generation）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3079, "latency_ms": 73438}}
{"key": "8987703", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We classify .NET files as either benign or malicious by examining directed graphs...", "explanation": "目的がマルウェア分類であり、コードの復元・可読化ではなく分類のみであるため除外と判断した。"}, {"code": "ex_out_of_scope", "evidence": "Files are subsequently vectorized by aggregating the set of vectors ... from decompiled .NET", "explanation": "デコンパイルは前処理として利用され、出力はベクトル表現と分類結果であり、L1‑L3 の高水準コード生成が行われないため除外。"}], "reasoning": "本論文は .NET バイナリをデコンパイルし、関数グラフをベクトル化してマルウェア分類器を訓練することが主目的であり、LLM/ML を用いたコード復元や高水準コード生成は行っていない。したがって、復元・可読化を目的としたデコンパイル研究（L1‑L3）には該当せず、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3566, "latency_ms": 86099}}
{"key": "9115191", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "reverse decompilation of installation package, malicious code injection", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が記載されておらず、従来の手法の議論のみなのでEC1に該当し除外する"}], "reasoning": "本稿はモバイルアプリの情報セキュリティに関する課題と対策を論じたもので、デコンパイル自体は言及されるものの、ML/LLM を用いたコード復元手法の提示はなく、IC を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3110, "latency_ms": 69233}}
{"key": "9117398", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "adopts tainted analysis based on static method", "explanation": "要旨に機械学習や大規模言語モデルの利用が記載されておらず、従来の静的解析手法のみであるため、ML/LLMが使用されていないと判断した。"}], "reasoning": "本稿はJNIのプライバシ情報漏洩検出を目的とした静的汚染解析システムを提案しており、デコンパイルはLLVM IRへの変換に留まります。機械学習・LLM を中核手法として用いていないため、除外基準 EC1 (ex_no_ml) に該当し、対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3246, "latency_ms": 76812}}
{"key": "9141591", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "research decompiles the VBE system, builds a test platform", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、ML/LLM を用いた手法が無いと判断したため。"}, {"code": "ex_out_of_scope", "evidence": "research decompiles the VBE system, builds a test platform, sorts out its weak links", "explanation": "出力はテストプラットフォームや弱点整理であり、L1–L3 のコード生成や高水準表現が示されていないため、L4‑only（属性のみ）に該当し除外する。"}], "reasoning": "要旨では VBE システムのデコンパイルとテストプラットフォーム構築が中心で、機械学習や大規模言語モデルの利用は示されていない。また、成果物はコード生成や高水準表現ではなくシステム評価・改善に留まるため、デコンパイル調査の対象（L1–L3）外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3297, "latency_ms": 81765}}
{"key": "9259834", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "machine learning models were created by using the n-gram features of the smali files, which are the decompiled Android packages", "explanation": "本文は ML を用いたマルウェア分類が目的であり、低水準コードから高水準コードを生成する復元・可読化の意図が示されていないため、コード生成（復元）目的ではないと判断した。"}], "reasoning": "本稿は Android パッケージのデコンパイル済み smali を特徴量として利用し、マルウェア検出のための機械学習モデルを構築することが主目的である。デコンパイル自体や高水準コードの生成・復元を行う研究ではなく、分類タスクに限定されているため、除外基準 EC3（No Reconstruction Intent）に該当し、`ex_no_code_generation` として除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3105, "latency_ms": 72108}}
{"key": "9282282", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "generate descriptions for the bytecodes of smart contracts ... generate four categories of descriptions", "explanation": "抽象からはコード（L1‑L3）ではなく自然言語の説明文しか生成していないため、L4‑only と判断し除外します"}], "reasoning": "本論文はバイトコードから自然言語による説明を生成することを目的としており、出力はコードや構造化された高水準表現ではなくテキスト記述です。したがって、L1‑L3 の出力要件を満たさず、L4‑only に該当するため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3110, "latency_ms": 71203}}
{"key": "9282790", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a combination of existing and new tools", "explanation": "要旨にML/LLMの使用は言及されておらず、従来のツール（remill など）を組み合わせているだけなので、ML/LLM が中心手法ではないと判断した。"}], "reasoning": "本論文は機械語から LLVM IR へのデコンパイルとその後の形式的検証を扱うが、手法に機械学習や大規模言語モデルは用いられていない。Decompilation Survey の基準ではML/LLM がコア手法であることが必須であるため、除外 (ex_no_ml) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3177, "latency_ms": 75044}}
{"key": "9315052", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "the apps were decompiled in order to extract their manifest files and construct a dataset", "explanation": "デコンパイルはマニフェスト抽出という属性情報取得のみで行われ、出力はL4（型・シグネチャ等の属性）であり、L1–L3 のコード復元や可読化を目的としていないため除外"}], "reasoning": "本論文はマルウェア検出のためにAPKをデコンパイルしてマニフェスト情報を取得し、権限ベースの特徴で機械学習分類を行うものです。デコンパイルの目的は属性抽出であり、コードや擬似コードの生成（L1–L3）は含まれません。したがって本サーベイの対象外（L4‑only）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3204, "latency_ms": 74651}}
{"key": "9331988", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This research proposed a methodology to protect the application assets from piracy using the cryptographic algorithm.", "explanation": "要旨に機械学習・LLMの利用は言及されておらず、暗号化手法のみが扱われているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "The assets are encrypted during the compile-time using the Gradle build system...", "explanation": "研究対象は資産の暗号化保護であり、デコンパイル（低水準から高水準コード生成）やその改善とは無関係であるため、スコープ外（L4‑only でもなく）と判断した。"}], "reasoning": "本論文は Android アプリの資産保護を暗号化手法で実現することに焦点を当てており、機械学習や大規模言語モデルを用いたデコンパイル手法は含まれない。したがって、除外基準 EC1（ML/LLM 未使用）およびスコープ外であることから除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3188, "latency_ms": 75685}}
{"key": "9410081", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "this paper proposes a mobile application reinforcement method based on control flow and data flow confusion", "explanation": "要旨にML/LLMの使用が言及されておらず、単なる制御・データフロー混乱による難読化手法であるため、MLを用いたデコンパイル研究ではないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "Through obfuscation, the compiled program is strengthened at the three levels of grammar, control flow, and data flow", "explanation": "目的は難読化であり、復元・コード生成（L1–L3）を目指すデコンパイルではなく、L4‑only の属性強化に該当するため除外する。"}], "reasoning": "この論文はモバイルアプリの難読化手法を提案しており、ML/LLM を用いたデコンパイルや高水準コード生成を目的としていない。入力は低水準コードかもしれないが、出力は難読化されたバイナリであり、L1–L3 のコード復元を行わないため、除外基準 (ex_no_ml, ex_out_of_scope) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3293, "latency_ms": 79583}}
{"key": "9421647", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect whether the target area has stack overflow vulnerabilities", "explanation": "アブストラクトは脆弱性の検出・分類が目的であり、コードの復元や高水準表現の生成を行うことは示されていないため、復元・生成目的ではないとして除外します。"}], "reasoning": "本論文はバイナリの脆弱性検出を目的とした分類タスクであり、デコンパイル後のコードを用いた検出モデルを提案していますが、復元・可読化・高水準コード生成といった目的が存在しないため、除外基準 EC3（復元・生成が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3037, "latency_ms": 71417}}
{"key": "9425937", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Decompilers are indispensable tools... While a large proportion of methods in an app can typically be decompiled successfully...", "explanation": "本文では既存のデコンパイラを評価しており、ML/LLM を用いた手法について言及していないため、EC1 に該当し除外します。"}], "reasoning": "本稿は Android アプリのデコンパイル失敗率を実証的に調査した研究であり、ML/LLM を用いた新規デコンパイル手法の提案や評価を行っていません。したがって、除外基準 EC1（ML/LLM 未使用）に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3248, "latency_ms": 69466}}
{"key": "9445905", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "code obfuscation or ELF shell (special in Android) were provided and then applied widely.", "explanation": "本文・要旨ではML/LLMを用いた手法の記述がなく、純粋に暗号化・難読化による保護策を述べているため、ML/LLM不使用として除外します。"}], "reasoning": "要旨はELF ファイルの保護・暗号化手法を提案しており、デコンパイル自体の復元や可読化をML/LLMで行う研究ではない。ML/LLM の使用が全く言及されていないため、除外基準 EC1 (ex_no_ml) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 72199}}
{"key": "9453483", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "retrieve the Bytecode from the target and decompile the Bytecode to STL source code", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、従来の手法でバイトコードを逆コンパイルしているため、EC1に該当し除外と判断しました。"}], "reasoning": "本稿はPLCのバイトコードを取得し従来の手法でSTLソースへ逆コンパイルする攻撃手法を示すもので、ML/LLM を中心手法として用いていない。したがって、Decompilation Survey の採択基準（LLM/ML が必須）を満たさず除外対象となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3132, "latency_ms": 70360}}
{"key": "9464996", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "provides comments and observations regarding decompilation of a Pascal compiler", "explanation": "アブストラクトではML/LLMの利用が言及されておらず、単なる観察・コメントであるため、ML/LLMを用いた手法ではないと判断し除外します。"}], "reasoning": "本文の要旨はBESM-6のシミュレータ歴史とPascalコンパイラのデコンパイルに関する観察を述べており、機械学習や大規模言語モデルの使用は示されていません。したがって、ML/LLMが中核手法であるというInclude基準を満たさず、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3073, "latency_ms": 78246}}
{"key": "9474328", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "can be stolen by decompiling the apps directly", "explanation": "論文はアプリのデコンパイルによるモデル盗難を防ぐことが目的であり、デコンパイル自体を行う手法を提案していないため、L1‑L3 のデコンパイル研究の範囲外です。"}], "reasoning": "本稿は Android アプリ内のディープラーニングモデル保護を目的としたフレームワークを提案しており、デコンパイル手法や LLM/ML を用いたコード復元は扱っていません。したがって、本サーベイの対象である L1‑L3 出力のデコンパイル研究から外れます。", "model": "openai/gpt-oss-120b", "tokens_used": 3159, "latency_ms": 73950}}
{"key": "9519451", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Recovering variables and data structure information from stripped binary ... produces the recovery results.", "explanation": "出力は変数や構造の属性情報のみで、L1–L3 のコードや擬似コードではなく L4‑only に該当するため除外します。"}], "reasoning": "本論文はストリップドバイナリから変数とデータ構造情報を確率的手法で復元することを目的としていますが、生成物は属性情報（型・構造）に留まり、コンパイル可能なソースや擬似コード等の L1‑L3 出力ではありません。したがって本バージョンの対象外（L4‑only）となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3420, "latency_ms": 85210}}
{"key": "9589721", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "employs a decompiler to convert the stolen compiled bytecode (low-level) to its decompiled version (high-level)", "explanation": "要旨ではデコンパイルは攻撃手順の一部として言及されていますが、機械学習や大規模言語モデルの利用は示されておらず、ML/LLM が使われていないため除外基準 ex_no_ml に該当します。"}], "reasoning": "本稿はPLCへの攻撃手法を示すもので、デコンパイラはツールとして使用されていますが、LLM/ML を中心手法として用いた研究ではありません。したがって除外基準 ex_no_ml に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3241, "latency_ms": 75517}}
{"key": "9631736", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "The purpose of the article is to develop a methodology that allows you to determine the java-module of the information system", "explanation": "要旨中に機械学習や大規模言語モデルの利用が言及されていないため、ML/LLM が使われていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "It is necessary that the digital watermark is not damaged during the decompilation of the entire system", "explanation": "目的はデジタル透かしの耐性評価であり、復元やソースコード生成は主目的ではないためコード生成が行われていないと判断した。"}], "reasoning": "本稿は Java バイトコードにデジタル透かしを埋め込み、その耐性を評価する手法を提案しているが、機械学習・LLM の使用は示されていない。さらに、デコンパイル後のコード生成や復元を目的としていないため、Decompilation Survey の対象外である。", "model": "openai/gpt-oss-120b", "tokens_used": 3259, "latency_ms": 79924}}
{"key": "9631860", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The exploration used the static analysis method", "explanation": "要旨でML/LLMの利用が言及されておらず、従来の静的解析手法のみで実施しているため、ML/LLMが使用されていないと判断しました。"}, {"code": "ex_no_code_generation", "evidence": "to find out whether or not WhatsApp Plus has been inserted with malware", "explanation": "目的がマルウェア検出という分類・検知であり、復元・可読化が主目的ではないため、コード生成（復元）の意図がないと判断しました。"}], "reasoning": "本論文は静的解析によるマルウェア検出を目的とした調査であり、ML/LLM を用いたデコンパイル手法は採用していません。また、復元や高水準コード生成が主目的ではなく、検出・比較が中心であるため、除外基準（EC1, EC3）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3463, "latency_ms": 86575}}
{"key": "9638928", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "decompile the APK file to obtain the opcode features", "explanation": "要旨ではデコンパイルはマルウェア検知のための特徴抽出にしか使われており、復元・可読化・高水準コード生成が目的ではないため除外と判定した。"}], "reasoning": "本論文は Android マルウェア検出を目的とし、デコンパイルは opcode 特徴抽出の前処理に過ぎない。復元やコード生成を伴う LLM/ML 主導のデコンパイルではないため、除外基準（EC3: No Reconstruction Intent）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3258, "latency_ms": 81333}}
{"key": "9647781", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Modern decompilers address this issue by reverting idioms using static, manually crafted rules.", "explanation": "本文は静的な手動ルールによる手法を述べており、LLM/ML が使用されている記述がなく、EC1 に該当するため除外する。"}], "reasoning": "要旨からは機械学習や大規模言語モデルの利用が示唆されておらず、手動で構築したルールやパターンマッチングに基づく手法と記載されている。従って、IC の条件を満たさないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3261, "latency_ms": 76993}}
{"key": "9718856", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper proposes a method to measure the similarity of smart contract bytecode.", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されていないため、ML/LLM を用いていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "the similarity measurement of smart contract bytecode ... can be used for vulnerability mining, contract upgrading and malicious contract detection.", "explanation": "目的はバイトコードの類似度測定であり、コードの復元・可読化・高水準表現の生成（L1‑L3）を行わないため除外する。"}], "reasoning": "本論文はバイトコードの類似度評価手法を提案しており、ML/LLM を用いたデコンパイルや高水準コード生成を行わない。したがって、Decompilation Survey の対象である L1‑L3 のコード生成を伴う研究ではなく、除外基準 EC1 と EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3389, "latency_ms": 87562}}
{"key": "9719255", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The detection of malicious code ... proposes an APT attack detection scheme ... binary sample ... are preprocessed with ... decompilation ... DenseNet ... trained and tested ... detection of APT attack malicious code", "explanation": "要旨はマルウェアの検出が目的であり、デコンパイルは前処理として用いられるだけで、コード生成や可読化は行わないため「復元・生成」目的ではないと判断し、EC3 に該当するため除外とした。"}], "reasoning": "本論文はマルウェア検出を目的とした分類手法を提案しており、デコンパイルは入力データの前処理に過ぎない。復元・可読化等のコード生成が主目的でないため、Decompilation Survey の採択基準を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3195, "latency_ms": 76958}}
{"key": "9724320", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Mapping a binary function ... to the same function in the original source code has many security applications, such as discovering reused free open source code in malware binaries.", "explanation": "アブストラクトはバイナリ関数とソースコード関数のマッチングを行うことを目的としており、コードの復元・生成ではなく類似性判定であるため、復元・生成が主目的ではないと判断した。"}], "reasoning": "本論文はバイナリ関数とソース関数のマッチングを学習するフレームワークを提案しており、出力はソースコードそのものではなくマッチング結果である。デコンパイルの定義における「復元・可読化・高水準意味回復」の目的を満たさないため、除外基準 EC3（コード生成・復元が主目的でない）に該当し、除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3250, "latency_ms": 80174}}
{"key": "9833799", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This paper conducts an in-depth study of binary lifters ... We summarize our findings", "explanation": "アブストラクトはバイナリリフタの体系的調査・評価を行う SoK であり、研究手法としての新規 ML/LLM アプローチは示されていないため除外とした。"}, {"code": "ex_no_ml", "evidence": "Binary lifters convert executables into an intermediate representation (IR) of a compiler framework.", "explanation": "本文中に機械学習／大規模言語モデルの利用は言及されておらず、従来の静的解析・リフト手法の評価のみであるため除外基準 EC1 に該当する。"}], "reasoning": "本稿はバイナリリフタの機能と下流アプリケーションへの適用を調査する SoK（Survey）であり、ML/LLM を中心としたデコンパイル手法を提示していない。したがって、除外基準 EC4（Survey/Review）および EC1（No ML/LLM）に該当し、L1–L3 のデコンパイル研究としては対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3523, "latency_ms": 83210}}
{"key": "9850326", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the engineering software’s decompilation function", "explanation": "本文は制御ロジックの難読化攻撃を議論しており、ML/LLM を用いた手法について言及していないため、ML 不使用の除外基準に該当します。"}], "reasoning": "本稿は産業制御システムに対する難読化攻撃を提示しており、ML/LLM を利用したデコンパイル手法や復元目的の研究ではありません。そのため、LLM/ML が中心手法であるという条件を満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3074, "latency_ms": 74688}}
{"key": "9948365", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The experimental results show that the accuracy of vulnerability detection on SARD data set is 96.92%", "explanation": "アブストラクトはバイナリの脆弱性検出を目的としており、復元・可読化などのコード生成が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本論文はニューラルネットワークを用いてバイナリをデコンパイルし特徴抽出を行い、脆弱性検出（分類）を目的としています。復元や高水準コード生成を目指すものではなく、分類タスクに焦点を当てているため、デコンパイルの復元目的要件を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 77820}}
{"key": "Achamyeleh2026", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "supplied to a general-purpose LLM, along with raw decompiler output", "explanation": "LLM が既存のデコンパイラ出力を入力として受け取り、よりコンパイル可能なコードへ改善しているため、Decompiler Enhancement に該当します。"}, {"code": "in_core", "evidence": "summarizes a binary's control flow and function calls into a hierarchical text representation", "explanation": "バイナリ（低水準）を要約した表現を LLM に与えてコード生成を行っているので、Core Decompilation の要素も含みます。"}, {"code": "in_core", "evidence": "raises average object file compilability ... from 45.0% to 85.2%", "explanation": "生成されたコードが実際にオブジェクトファイルとしてコンパイル可能であることを示しており、出力は L1（コンパイル可能なソース）に該当します。"}], "reasoning": "本稿はバイナリの制御フロー情報と既存デコンパイラ出力を LLM に入力し、コンパイル可能な高水準コードを生成する手法を提案している。低水準入力、LLM 中核、復元目的、L1 出力という全ての Include 条件を満たすため、採択対象と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3960, "latency_ms": 105484}}
{"key": "Arasteh2025", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "identify modules in stripped binaries and associate them with high-level natural language descriptions", "explanation": "出力が自然言語によるモジュール説明のみで、L1–L3 のコードや擬似コード・AST ではなく L4‑only（属性のみ）であるため除外"}], "reasoning": "本論文はバイナリからモジュールを特定し自然言語で説明することを目的としており、生成物はコードや擬似コードではなくテキスト記述です。出力は L1–L3 の高水準プログラム表現に該当せず、L4‑only とみなされるため本サーベイの対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3437, "latency_ms": 88318}}
{"key": "Armengol-Estapé2022", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "produce x86 assembler from C code", "explanation": "抄録はCコード（高水準ソース）からx86アセンブリ（低水準）を生成すると述べており、入力が低水準表現ではないため除外基準EC2に該当します。"}], "reasoning": "本稿は高水準のCソースを入力とし、低水準のx86アセンブリを出力する「ニューラルコンパイル」を研究対象としているため、デコンパイル（低水準入力→高水準出力）とは逆の方向であり、低水準入力が存在しません。したがって除外基準EC2（ex_no_lowlevel_input）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3298, "latency_ms": 89281}}
{"key": "Arranz-Olmos2025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we build CT-RetDec, a CT analysis tool based on a modified version of the LLVM-based decompiler RetDec", "explanation": "本文はLLVMベースの既存デコンパイラRetDecの改造であり、機械学習やLLMの利用は示されていないため、ML/LLMが手法の中核でないと判断した。"}], "reasoning": "本稿は暗号ライブラリの定時間性検証のためにデコンパイラを前処理として用いるが、機械学習や大規模言語モデルは使用していない。したがって、Decompilation SurveyのML/LLM中心の採択基準を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3493, "latency_ms": 86029}}
{"key": "arXiv:2201.07420", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "binary-source code matching ... learning the embeddings of binary code and source code", "explanation": "要旨はバイナリとソースコードの埋め込みを学習してマッチングを行うことを目的としており、コードの復元や高水準表現の生成は行わないため、復元意図がなく除外されます。"}], "reasoning": "本稿はバイナリとソースコードのマッチング手法を提案しており、LLM/MLは埋め込み学習に用いられていますが、復元・可読化・コード生成といったデコンパイル目的が示されていません。そのため、EC3（復元意図なし）に該当し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3233, "latency_ms": 80951}}
{"key": "arXiv:2306.14168", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to obtain feature representation vector of binary code", "explanation": "アブストラクトはバイナリコードの類似度計測のためにベクトル表現を生成することを目的としており、ソースコードや擬似コード等の復元・生成は行わないため、復元意図がなく除外対象となる。"}], "reasoning": "本論文はバイナリコードの類似性検出を目的とし、低水準入力から高水準コードを生成することはない。復元・可読化を伴うデコンパイルではなく、特徴ベクトル取得のみであるため、除外基準EC3（No Reconstruction Intent）に該当し除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3197, "latency_ms": 79787}}
{"key": "arXiv:2405.19581", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "zero-shot binary summarization and binary function name recovery", "explanation": "要旨では出力がバイナリ要約や関数名の回復に限定されており、コード（L1‑L3）ではなく属性情報（L4）のみであるため、L1‑L3 の出力がなく除外対象となります。"}], "reasoning": "本稿はバイナリから要約テキストや関数名を生成することに焦点を当てており、ソースコードや擬似コードといった L1‑L3 の高水準表現を生成しません。したがって、L4‑only の出力とみなされ本バージョンの採択基準（L1‑L3）から除外されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3597, "latency_ms": 93341}}
{"key": "arXiv:2509.14646", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "fine-tunes an LLM using the reconstructed \\salt to generate decompiled code", "explanation": "LLM を中心手法として、バイナリ（アセンブリ）から直接高水準コードを生成しているため Core Decompilation に該当します。"}, {"code": "in_control_structure", "evidence": "abstract stable logical features ... specific jumps ... to approximate the logic structure of high-level language", "explanation": "バイナリのジャンプ情報を抽象化し、ソースレベルのロジックツリーを構築して制御構造を復元しようとしているため、Control Structure Recovery に該当します。"}], "reasoning": "本論文はバイナリ関数のアセンブリを入力とし、LLM を用いて高水準コード（L1‑L3）を生成する手法を提案している。目的は逆コンパイルによるコードの復元・可読化であり、出力は実際のソースコード形式であることが示唆される。したがって、Decompilation Survey の採択基準（IC0 と L1‑L3 出力）を満たすため include と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3632, "latency_ms": 92871}}
{"key": "Banerjee2021", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "infer variable names in decompiled code", "explanation": "アブストラクトが変数名の推測を主目的として述べているため、変数/関数命名回復に該当する。"}, {"code": "in_decompiler_enhancement", "evidence": "takes raw decompiler output ... as input, and enriches it", "explanation": "既存のデコンパイラ出力を入力として、LLM/ML で可読性・命名を改善している点がデコンパイラ強化に該当する。"}], "reasoning": "本稿はバイナリから生成されたデコンパイラ出力を入力とし、LLM（BERT/Transformer）を用いて変数名を予測・付与することで、コードの可読性を向上させる手法を提案している。入力は低水準バイナリ由来のデコンパイル結果であり、出力は変数名が復元された擬似コード（L2）であるため、L1‑L3 の範囲に該当し、変数命名とデコンパイラ強化の両方のカテゴリに含められる。", "model": "openai/gpt-oss-120b", "tokens_used": 3902, "latency_ms": 108966}}
{"key": "Bielik2020", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we explore this issue by: (i) instantiating adversarial attacks for code ... (iii) combining ... to improve robustness", "explanation": "要旨はコードモデルへの敵対的攻撃とロバスト性向上を扱っており、コード生成や復元は目的ではないため除外と判断しました。"}], "reasoning": "本論文はコードに対する敵対的攻撃とロバスト性の評価・改善に焦点を当てており、デコンパイルや高水準コード生成といった復元目的の手法は提示していません。したがって、ICを満たさずEC3（コード生成なし）に該当するため除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3120, "latency_ms": 82386}}
{"key": "Bu2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.91, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect vulnerabilities directly from bytecode", "explanation": "アブストラクトはバイトコードから脆弱性を検出することを目的としており、コードやソースの生成・復元が主目的ではないため、復元・可読化の意図がなく除外基準 EC3 に該当します"}], "reasoning": "本論文はバイトコードを入力として BERT と CFG を用いて脆弱性を検出する手法を提案しており、出力は脆弱性ラベルでありコードや高水準表現の生成を目的としていません。したがって、デコンパイルの復元・可読化目的ではなく分類・検出目的であるため、除外基準 EC3 に該当し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3199, "latency_ms": 79578}}
{"key": "Butz2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose SPN2BN, an algorithm that decompiles an SPN into a BN", "explanation": "抄録にはMLやLLMが使用されている旨の記述がなく、純粋にアルゴリズム的手法のみが述べられているため、ML/LLM不使用として除外しました。"}, {"code": "ex_no_lowlevel_input", "evidence": "decompiles an SPN into a BN", "explanation": "入力はSPNという高水準の確率的モデルであり、低水準（バイナリ/アセンブリ等）のコード入力ではないため、低水準入力なしとして除外しました。"}], "reasoning": "本論文はSPNからBNへの変換手法を提案しており、ML/LLM を用いた手法でもなく、入力もバイナリやアセンブリといった低水準コードではないため、デコンパイル調査の対象（L1–L3 のコード復元）から外れます。", "model": "openai/gpt-oss-120b", "tokens_used": 3289, "latency_ms": 82172}}
{"key": "Caliskan2017", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "using a novel set of features that include ones obtained by decompiling the executable binary to source code", "explanation": "デコンパイルは特徴抽出のための前処理として利用されており、最終目的はプログラマの著者推定という分類であり、コードの復元・生成が主目的ではないため除外と判断した。"}], "reasoning": "本論文はバイナリからデコンパイルしたソースを特徴として機械学習による作者特定（分類）を行うもので、デコンパイル自体が高水準コード生成や復元を目的としているわけではない。したがって、復元・可読化を目的とした LLM/ML によるデコンパイル（L1–L3）に該当せず、除外基準 EC3（No Reconstruction Intent）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3463, "latency_ms": 88016}}
{"key": "Cao2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "transform a low-level program language (LPL) (eg., binary file) into its functionally-equivalent high-level program language (HPL) (e.g., C/C++)", "explanation": "抽象から低水準バイナリを入力とし、ニューラルネットワークで C/C++ のソースコード（L1）を直接生成することが述べられているため、コアデコンパイルに該当します。"}], "reasoning": "本論文はバイナリを入力とし、グラフニューラルネットワークを用いて高水準のソースコードを生成することを目的としています。LLM/ML が中心手法であり、出力はコンパイル可能なコード（L1）であるため、Include 基準を満たし、Core Decompilation（in_core）として採択します。", "model": "openai/gpt-oss-120b", "tokens_used": 3275, "latency_ms": 81947}}
{"key": "Chakraborty2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "state-of-the-art translation tools do not handle concurrency primitives correctly ... we develop correct and efficient translations ...", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用について言及されておらず、従来の翻訳/マッピング技術を扱っているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はアーキテクチャ間の同時実行性マッピング手法を提案しており、機械学習やLLMの利用は示されていない。Decompilation の範囲外であり、ML/LLM が核心手法でないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3069, "latency_ms": 76817}}
{"key": "Chawla2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "leverages LLMs to perform the classification", "explanation": "LLMはコードの復元や高水準表現の生成ではなく、分類（malware detection）を目的としているため除外基準EC3に該当します。"}], "reasoning": "本稿はLLMを用いてデコンパイルされたCコードを分類しマルウェア検出を行うことが目的であり、復元・可読化といったコード生成・再構成を主目的としていない。したがって、デコンパイルの出力をL1‑L3の形で提供する研究ではなく、分類タスクに利用している点から除外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3090, "latency_ms": 80600}}
{"key": "Chen2021", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "a novel technique for improving the quality of decompiler output that automatically generates meaningful variable names and types", "explanation": "既存のデコンパイラ出力を入力とし、LLM/MLで可読性向上（名前・型付与）を行う手法であるため、Decompiler Enhancement に該当する。"}, {"code": "in_variable_naming", "evidence": "automatically generates meaningful variable names", "explanation": "変数・関数名の復元が主要目的の一つであるため、Variable Naming に該当する。"}, {"code": "in_type_recovery", "evidence": "automatically generates meaningful ... types", "explanation": "型情報の復元・推論を行う点が Type Recovery に該当する。"}], "reasoning": "この論文はデコンパイラの出力（擬似コード）を入力とし、機械学習を用いて変数名と型を付与し、コンパイル可能な高水準ソースコード（L1）を生成する手法を提案している。入力はバイナリから得られたデコンパイラ出力であり、ML が中心手法で、復元・可読化が目的であるため、L1–L3 の対象として採択すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3806, "latency_ms": 109688}}
{"key": "Chukkol2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.85, "reason_codes": [{"code": "in_core", "evidence": "transform raw binary code into pseudocode using CodeT5", "explanation": "抽象から、低水準入力（raw binary）をCodeT5というLLMで直接高水準の擬似コード（L2）に変換していることが分かるため、Core Decompilation に該当する。"}], "reasoning": "本論文は CodeT5（LLM）を用いてバイナリを擬似コードへ変換する Synergy Decompilation Module を提案しており、低水準入力から L1‑L3 の高水準表現を生成する点で Core decompilation に該当する。したがって本サーベイの採択基準を満たすので include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3567, "latency_ms": 100265}}
{"key": "Cristea2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LLM-based code summarization enables highly accurate and explainable malware identification.", "explanation": "要旨からはLLMがコード要約やマルウェア検出・CVE分類に用いられているが、生成されるのは要約や検出結果であり、ソースコード・擬似コード・AST などの L1‑L3 の高水準コード出力ではないため、復元・生成が主目的とはみなせない。"}], "reasoning": "本論文はバイナリマルウェアの検出と CVE 付与を目的とし、LLM はコード要約や分類に使用されているが、低水準入力から L1‑L3 のコードを生成することが主目的ではない。したがって、復元・高水準コード生成を伴うデコンパイル研究の条件を満たさず、除外基準 EC3（コード生成目的なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3410, "latency_ms": 90739}}
{"key": "David2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "leverages Large Language Models (LLMs) to transform Ethereum Virtual Machine (EVM) bytecode into ... Solidity code", "explanation": "LLMを用いてバイトコードから直接コンパイル可能なSolidityソース（L1）を生成しているため、Core decompilation に該当する。"}], "reasoning": "本論文はEVMバイトコード（低水準入力）をLLMで直接Solidityソースコード（L1）に変換する手法を提案しており、復元・可読化が主目的である。出力はコンパイル可能な高水準コードであり、LLM/ML が中心手法として使用されているため、Include 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3467, "latency_ms": 90589}}
{"key": "Enders2022", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We developed a variety of improvements over the previous academic state-of-the-art decompiler and some novel algorithms to enhance readability and comprehension", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用について言及がなく、従来型のアルゴリズム改善のみが述べられているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は既存デコンパイラの改良と新規アルゴリズムによる可読性向上を目的としているが、機械学習や大規模言語モデルを手法の中心に据えている記述がない。そのため、Decompilation Survey の採択基準（ML/LLM の使用）が満たされず除外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3198, "latency_ms": 81250}}
{"key": "Escalada2021", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "predict function return types with a 79.1% F1-measure", "explanation": "本研究は関数の戻り型という属性情報のみを予測しており、L1–L3 のソースコードや擬似コードは生成しないため L4‑only と判断し除外する"}], "reasoning": "本稿はバイナリから関数の戻り型を機械学習で推測し、既存デコンパイラの型情報を改善することを目的としている。出力は型情報という属性のみで、コンパイル可能なソースや擬似コード等の L1–L3 出力を提供しないため、今回のスクリーニング基準（L1–L3 のみ対象）では除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3524, "latency_ms": 98213}}
{"key": "Fang2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "decompile complex WebAssembly code into readable C++ snippets", "explanation": "LLM とプログラム解析を用いて、WebAssembly（低水準）から C++ ソース（L1）を直接生成しているため、コアデコンパイルに該当する。"}], "reasoning": "本論文は WebAssembly という低水準バイナリ表現を入力とし、LLM と静的解析を組み合わせて C++ ソースコードを生成する手法を提案している。目的はコードの可読化・意味回復であり、出力はコンパイル可能なソース（L1）であるため、IC を満たすコアデコンパイル研究として採択すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3062, "latency_ms": 80954}}
{"key": "Feng2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "Decompilation transforms compiled code back into a high-level programming language... Self-Constructed Context Decompilation (sc²dec) method recompiles the LLM's decompilation results to construct pairs for in‑context learning", "explanation": "抽象から、LLM を用いてバイナリ/アセンブリから直接高水準ソースコードを生成しており、低水準入力と L1 出力が明示されているため Core Decompilation に該当する"}], "reasoning": "本論文は低水準のアセンブリコードを入力とし、LLM を中心に高水準のソースコード（L1）を生成する手法を提案している。Decompilation が主目的であり、出力がコンパイル可能なソースコードであるため、Include 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3399, "latency_ms": 92683}}
{"key": "Feng2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "end-to-end decompile method based on large langauge models (LLMs)", "explanation": "LLM が中心手法となって低水準コードから高水準ソースコードを直接生成しているため"}, {"code": "in_type_recovery", "evidence": "Function Call strategy infers variable types and retrieves missing variable information", "explanation": "変数型の推論が主要機能の一つであり、型回復を目的としているため"}], "reasoning": "本稿はアセンブリなどの低水準コードを入力とし、LLM を用いてソースコードを直接生成するエンドツーエンド手法を提案している。出力は高水準言語（L1）であり、型推論も組み込まれているため、Decompilation Survey のコアデコンパイル（in_core）かつ型回復（in_type_recovery）に該当し、採択対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3588, "latency_ms": 101088}}
{"key": "Fu2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "Coda ... end-to-end neural-based framework for code decompilation ... generating an abstract syntax tree (AST)", "explanation": "抽象構文木（AST）はL3に該当し、低水準バイナリを入力としてニューラルネットワークが直接高水準表現を生成しているため、Core Decompilation に該当します。"}], "reasoning": "本論文はバイナリを入力とし、ニューラルエンコーダとツリーデコーダでAST（L3）を生成するエンドツーエンドのデコンパイラを提案している。ML/LLM を中心手法として用い、復元・可読化を目的としている点が包括基準を満たすため、include と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3251, "latency_ms": 82425}}
{"key": "Gao2025", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "We present DecompileBench, the first comprehensive framework that enables effective evaluation of decompilers...", "explanation": "アブストラクトはデコンパイラの評価基盤を提案しているだけで、LLM/ML を用いた復元・コード生成手法を示していないため、L1‑L3 のデコンパイル研究の対象外と判断した。"}], "reasoning": "本稿はデコンパイラのベンチマーク・評価フレームワークの提案であり、低水準入力から高水準コードを生成する LLM/ML 手法を提示していない。したがって本バージョンの対象（L1‑L3 のデコンパイル成果を提供する研究）から外れ、除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3284, "latency_ms": 86609}}
{"key": "Green2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose STRIDE, a lightweight technique that predicts variable names and types by matching sequences of decompiler tokens to those found in training data.", "explanation": "本文は機械学習や大規模言語モデルを用いず、トークンマッチングによる手法を採用しているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "predict variable names and types ... by matching sequences of decompiler tokens", "explanation": "入力はデコンパイラのトークン列であり、低水準のバイナリやアセンブリといった低レベル表現ではないため、低水準入力が存在しないと判断した。"}], "reasoning": "本論文は低水準コードからの直接的なデコンパイルではなく、既存デコンパイラ出力のトークンを用いた型・名称予測手法を提案しており、かつ機械学習や大規模言語モデルを使用していないため、除外基準 (EC1, EC2) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3346, "latency_ms": 92952}}
{"key": "Hosseini2022", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "using techniques from neural machine translation to automate the process in decompilation ... treat the assembly and source languages as plain text", "explanation": "ニューラル機械翻訳（ML手法）でアセンブリ（低水準）を入力とし、C/Go/Fortran/OCaml などのソースコード（L1）を直接生成しているため、コアデコンパイルに該当する"}], "reasoning": "本稿はアセンブリを低水準入力として、ニューラル機械翻訳を中心手法に用い、複数の高水準言語のソースコード（コンパイル可能な形）を生成することを目的としている。入力が低水準、出力が L1‑L3、ML が核となっている点が Include Criteria を満たすため、'in_core' として採択する。", "model": "openai/gpt-oss-120b", "tokens_used": 3205, "latency_ms": 85215}}
{"key": "Hussain2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect vulnerabilities within these binary files ... state-of-the-art performance in binary vulnerability analysis", "explanation": "本文はバイナリから脆弱性を検出することを主目的としており、復元・高水準コード生成が目的ではないため、コード生成（復元）意図がなく除外されます。"}], "reasoning": "本稿はLLMを用いてバイナリの脆弱性検出を行うことに焦点を当てており、出力は検出結果やコメントであり、L1–L3 の高水準コード生成が主目的ではありません。したがって、復元・コード生成意図がないことから除外基準 EC3（ex_no_code_generation）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3375, "latency_ms": 89243}}
{"key": "Jiang2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "assess model performance across four core tasks: control flow graph reconstruction, decompilation, code summarization, and execution reasoning.", "explanation": "LLM を低水準の IR から直接高水準コード（decompilation）へ変換させている点がコアデコンパイルに該当するため"}, {"code": "in_decompiler_enhancement", "evidence": "evaluate model performance across ... decompilation", "explanation": "本研究は LLM が生成したデコンパイル結果を評価しているが、既存デコンパイラ出力の改善ではなく LLM が直接生成しているため、補助的にデコンパイルタスク全体の評価に位置付けられる"}], "reasoning": "本文は中間表現(IR)という低水準入力から LLM が直接コードを生成する decompilation タスクを扱っており、出力は高水準コード（L1/L2）と推測できる。目的は復元・可読化であり、ML 手法が中心であるため、L1‑L3 のコアデコンパイル研究として採択すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3383, "latency_ms": 94630}}
{"key": "Jiang2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "Nova outperforms existing techniques on binary code decompilation by up to 14.84 -- 21.58% ... higher Pass@1 and Pass@10", "explanation": "この記述は、LLM がバイナリ（低水準）を入力として直接高水準コードを生成し、デコンパイル精度を評価していることを示すため、Core Decompilation に該当する"}], "reasoning": "本稿は LLM を中心手法とし、バイナリコードという低水準入力から高水準のコード（L1/L2）を生成してデコンパイル性能を測定している。出力はコンパイル可能なコードまたは擬似コードとみなせ、目的も復元・可読化であるため、Include 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3523, "latency_ms": 101698}}
{"key": "Katz2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "we present a novel approach to decompilation based on neural machine translation...decompile both LLVM IR and x86 assembly to C code", "explanation": "LLM/ML（ニューラル機械翻訳）が低水準入力（LLVM IR・x86 アセンブリ）から直接高水準の C ソースコード（L1）を生成しているため、Core Decompilation に該当します。"}], "reasoning": "本稿は低水準表現（LLVM IR・x86 アセンブリ）を入力とし、ニューラル機械翻訳という機械学習手法を中核に据えて C ソースコードを生成することを目的としている。出力はコンパイル可能なソースコード（L1）であり、復元・可読化が主目的であるため、Include 基準をすべて満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3141, "latency_ms": 85496}}
{"key": "KC2023", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we survey the NMT for code generation literature", "explanation": "アブストラクトが調査・レビューを目的としていることを示しているため、サーベイ論文として除外基準EC4に該当します。"}], "reasoning": "本稿はNMTによるコード生成全般を概観するサーベイであり、オリジナルのデコンパイル手法を提示していません。したがって、除外基準EC4（Survey/Review）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2918, "latency_ms": 78894}}
{"key": "Kim2023", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Malware detection on binary executables provides a high availability to even binaries which are not disassembled or decompiled.", "explanation": "アブストラクトはバイナリのマルウェア判別（分類）を目的としており、コードの復元・生成を行う意図がなく、復元・可読化が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリのレイアウト情報を用いた特徴量設計でマルウェア検出精度向上を目指すもので、LLM/ML はCNNによる分類にしか使われていません。デコンパイル（低水準から高水準コード生成）やその改善を目的としていないため、除外基準 EC3（コード生成・復元目的でない）に該当し、L1–L3 の出力を提供しない点から除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3079, "latency_ms": 88013}}
{"key": "Kumar2018", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we systematically study CFO techniques proposed for Java programs", "explanation": "本文はJavaプログラム向け制御フロー難読化技術の体系的調査であり、デコンパイル手法やML/LLMの利用を目的としていないため、サーベイ論文として除外します。"}], "reasoning": "本稿は制御フロー難読化技術の系統的調査・分類を目的としたサーベイ論文であり、ML/LLMを用いたデコンパイル（L1‑L3出力）に関する研究ではない。そのため除外基準 EC4（Survey/Review）に該当し、除外と判定します。", "model": "openai/gpt-oss-120b", "tokens_used": 3147, "latency_ms": 81797}}
{"key": "Li2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "we view reverse engineering as a statistical machine translation task ... propose a fault-tolerant Java decompiler based on machine translation models. Our model is based on attention-based Neural Machine Translation (NMT) and Transformer architectures.", "explanation": "抽象的に低水準のバイトコード等から直接高水準のJavaソース（L1）を生成することを目的とし、手法の中核にLLM/ML（NMT・Transformer）を用いているため、Core Decompilation に該当する。"}], "reasoning": "本論文は機械翻訳モデル（NMT/Transformer）を用いて低水準のJavaバイトコードから可読なJavaソースコードを生成することを目的としている。入力は低水準で、ML が中心手法であり、出力はコンパイル可能なソース（L1）であるため、Decompilation Survey の採択基準（IC）を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3313, "latency_ms": 92734}}
{"key": "Li2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "NeuroDeX leverages the semantic understanding capabilities of LLMs ... to accurately and efficiently perform ... model reconstruction.", "explanation": "LLM が中心手法として低水準の DNN 実行ファイルから高水準モデルへ直接生成しているので core decompilation に該当する。"}, {"code": "in_type_recovery", "evidence": "perform operator type recognition, operator attribute recovery and model reconstruction.", "explanation": "LLM を用いて演算子タイプや属性を回復し、これが高水準モデル生成の一部となっているため型回復カテゴリでも該当する。"}], "reasoning": "本稿はバイナリレベルの DNN 実行ファイル（低水準入力）を対象とし、LLM を中心手法として高水準のモデル表現（L1–L3）へ復元することを目的としている。出力はコンパイル可能なモデルや構造化された高水準表現であり、Decompilation Survey の採択基準（IC0・IC1）を満たすため include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3668, "latency_ms": 107430}}
{"key": "Li2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect security patches from binary patches", "explanation": "アブストラクトはバイナリパッチからセキュリティパッチを検出することが目的であり、コード生成や復元ではなく分類タスクであるため、復元・可読化の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文はコード LLM を用いたバイナリセキュリティパッチ検出（分類）を扱っており、低水準入力から高水準コードを生成するデコンパイル目的ではないため、除外基準 EC3（No Reconstruction Intent）に該当し除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3280, "latency_ms": 88791}}
{"key": "Liang2021", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "neural decompilation approach to translate low-level PL into accurate and user-friendly high-level PL", "explanation": "LLM/ML を用いてバイナリ等の低水準言語から C/C++ などの高水準ソースコード（L1）を直接生成しているため、Core Decompilation に該当する。"}], "reasoning": "本論文は低水準プログラム言語（バイナリ）を入力とし、ニューラル機械翻訳（ML）を中心手法として高水準言語（C/C++）のソースコードを出力する手法を提案している。出力はコンパイル可能なコード（L1）であり、復元・可読化が目的であるため、Include Criteria を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3175, "latency_ms": 84787}}
{"key": "Liu2021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a new tool DarkSea, the first tool capable of verifying reachability, termination, and LTL of lifted binaries.", "explanation": "概要に機械学習や大規模言語モデルの使用が言及されておらず、Verification ツールの説明のみなので ML/LLM が使われていないと判断したため。"}, {"code": "ex_no_code_generation", "evidence": "verifying reachability, termination, and LTL of lifted binaries", "explanation": "目的はバイナリの検証であり、コードの復元や生成が主目的ではないため除外基準に該当する。"}], "reasoning": "本稿は低水準バイナリを検証対象としたツール DarkSea を提案しており、ML/LLM を用いたデコンパイル手法は示されていない。目的も復元・可読化ではなく形式的検証であり、コード生成は行わないため、除外基準 (ex_no_ml, ex_no_code_generation) に該当し除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3328, "latency_ms": 93171}}
{"key": "Liu2022", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "BTD takes DNN executables and outputs full model specifications... It employs learning-based techniques to infer DNN operators.", "explanation": "抽象から、低水準のバイナリ（DNN executables）を入力とし、ML 手法で高水準のモデル仕様（L1‑L3 に相当）を生成しているため、コアデコンパイルに該当する。"}], "reasoning": "本稿はバイナリ実行ファイルを入力として、学習ベースの手法でニューラルネットワークの構造・パラメータ等の高水準表現を復元するデコンパイラを提案している。出力はコンパイル可能なモデル仕様であり、L1‑L3 の範囲に入るためインクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3627, "latency_ms": 104460}}
{"key": "Liu2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "end-to-end decompilation methods powered by large language models (LLMs) ... generate highly readable source code", "explanation": "LLM を中心手法として低水準のバイナリから可読なソースコード（L1）を直接生成しているため、Core Decompilation に該当します。"}, {"code": "in_control_structure", "evidence": "incorporates control flow graphs (CFG) and explicit data mappings to improve LLM-based decompilation", "explanation": "CFG を用いて制御構造の復元を強化している点が Control Structure Recovery に該当します。"}], "reasoning": "本稿はバイナリを入力とし、LLM を核としたエンドツーエンドのデコンパイル手法を提案している。出力はコンパイル可能なソースコード（L1）であり、制御フロー情報を活用した構造復元も行うため、IC1 の Core Decompilation（in_core）かつ IC5 の Control Structure Recovery（in_control_structure）に該当し、採択対象となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3644, "latency_ms": 102455}}
{"key": "Manuel2024", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "identifying; classifying; describing vulnerabilities; and recovering function names", "explanation": "本稿はデコンパイルされたバイナリ上で脆弱性の検出や関数名復元を行うが、出力はコード（L1‑L3）ではなく属性情報やテキストであり、L4‑only のため除外"}], "reasoning": "本研究は LLM を用いてデコンパイル済みバイナリの脆弱性分類や関数名復元を行うが、生成物はソースコードや擬似コードといった L1‑L3 の高水準表現ではなく、属性情報や説明文に留まる。デコンパイルの本質であるコード再構成を目的としていないため、L4‑only と判断し除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3746, "latency_ms": 106429}}
{"key": "Manuel2025", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "automate the creation and curation of datasets by mapping decompiled functions to their corresponding source functions", "explanation": "目的はデコンパイルされた関数と元のソース関数の対応付けによるデータセット生成であり、L1‑L3 の高水準コード生成や復元ではないためスコープ外（L4‑only）と判断した"}, {"code": "ex_no_ml", "evidence": "integrates with existing decompilers and parsers to streamline dataset generation", "explanation": "手法は既存のデコンパイラやパーサの統合であり、論文要旨からは機械学習／LLM が中心的に使用されていることが読み取れないため除外対象とした"}], "reasoning": "本稿はデコンパイル結果とソースコードを対応付けてデータセットを構築するフレームワークを提示しており、コード自体の復元・生成（L1‑L3）の目的がなく、ML/LLM が中心手法として示されていない。したがって、デコンパイル調査の対象範囲（L1‑L3 の出力）外であり除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3886, "latency_ms": 119391}}
{"key": "Mihajlenko2021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We developed the algorithms for the following operations: preprocessing assembly code, searching data accesses, extracting system values, decompiling arithmetic operations and recovering data types.", "explanation": "抽象からは機械学習・LLM が使用された旨が全く記載されておらず、従来のアルゴリズムベースの手法であると判断できるため、EC1に該当し除外します。"}], "reasoning": "本論文は AMD GPU アセンブリから OpenCL ソースへ変換するデコンパイラをアルゴリズム的に実装しているが、ML/LLM の利用が示されていない。したがって Include Criteria を満たさず、Exclude Criteria の ex_no_ml に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3079, "latency_ms": 86768}}
{"key": "Minn2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "reason about unsatisfied activation conditions ... generates dynamic instrumentation scripts that satisfy activation conditions", "explanation": "目的はGUIテストのカバレッジ向上であり、低水準コードから高水準ソースを復元することではなく、テスト用スクリプト生成であるため、復元・可読化の意図がなく除外する"}], "reasoning": "本稿はAgentic AIを用いてデコンパイルされたSmaliコードを解析し、テストカバレッジ向上のための動的インストルメンテーションスクリプトを生成する手法を提案している。低水準入力はあるものの、ML/LLMの主目的はコード復元や可読化ではなくテスト支援であり、L1‑L3 の高水準コード生成を目指していないため、除外基準 EC3（復元・生成意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3697, "latency_ms": 105826}}
{"key": "Palmarini2024", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "\"decompiling its amortized knowledge to extract relevant program components\"", "explanation": "アブストラクトは低水準のバイナリやアセンブリではなく、ニューラル検索ポリシーという高レベルの知識を対象としており、低水準入力が存在しないため除外基準に該当します。"}], "reasoning": "本稿は DreamCoder のニューラル検索ポリシーからプログラム部品を抽出する手法を提案しており、入力は低水準コードやバイナリではなく高レベルの学習済みポリシーです。したがって、デコンパイル調査の定義で求められる低水準入力がなく、対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3119, "latency_ms": 90432}}
{"key": "Pearce2022", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "identify ... from code, even when the code is produced through decompilation", "explanation": "入力はすでにデコンパイルされたコードであり、低水準（バイナリ・アセンブリ等）ではないため除外基準 EC2 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "identify the purpose, capabilities, and important variable names or values from code", "explanation": "目的はコードの意味や変数情報を抽出することであり、コード自体を再生成・復元することではないため除外基準 EC3 に該当します。"}], "reasoning": "本論文は LLM を用いてデコンパイル済みコードから情報抽出（目的・変数名など）を行うもので、低水準入力からのコード生成や復元を目的としていません。そのため、入力が低水準でない点とコード生成意図がない点の両方で除外基準に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3501, "latency_ms": 105487}}
{"key": "Pochelu2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "This article introduces JaxDecompiler, a tool that transforms any JAX function into an editable Python code", "explanation": "アブストラクトでは機械学習や大規模言語モデルを用いたことが示されておらず、従来の変換手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は Jaxpr という中間表現から Python ソースコードへの変換ツールを提示しているが、手法に機械学習や大規模言語モデルの利用が明記されていない。したがって Exclude Criteria の EC1 (No ML/LLM) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3295, "latency_ms": 100261}}
{"key": "Pordanesh2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "analy... performance in interpreting and explaining human-written and decompiled codes", "explanation": "アブストラクトは LLM がコードを「解釈・説明」することを評価しており、コードを生成・復元することは示していないため、コード生成（復元）が目的ではなく除外基準 ex_no_code_generation に該当する。"}, {"code": "ex_no_lowlevel_input", "evidence": "binary reverse engineering", "explanation": "タイトル・アブストラクトからはバイナリが入力であるかは明示されず、主にデコンパイル済みコードや人書きコードを対象としているように見えるため、低水準入力の有無が不明であり、低水準入力がないと解釈でき除外基準 ex_no_lowlevel_input にも該当する。"}], "reasoning": "本稿は LLM を用いてバイナリリバースエンジニアリングにおけるコードの解釈・説明を評価しているが、実際に低水準バイナリから高水準コードを生成（L1‑L3）するデコンパイル目的ではない。コード生成が目的でないことと、低水準入力の明示がないことから、除外基準に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3616, "latency_ms": 112429}}
{"key": "Qin2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose the first empirical study on the understandability of Java decompiled code", "explanation": "アブストラクトにML/LLMの使用が示されておらず、機械学習を用いた手法が無いと判断したため"}], "reasoning": "本稿はJavaデコンパイルコードの可読性を評価する実証研究であり、ML/LLM を用いたデコンパイル手法の提示や出力生成は行っていない。したがって、ML/LLM が中心手法であるというインクルード基準を満たさず、除外基準の『No ML/LLM』に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3437, "latency_ms": 98808}}
{"key": "Rao2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We devise a method for register aggregation, to identify relationships between the data flip-flops ... resulting in HDL code", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用が言及されておらず、従来のアルゴリズムによる手法であると判断したため"}], "reasoning": "本稿はゲートレベルのネットリストという低水準入力から HDL コードという L1 出力を生成するハードウェア デコンパイル手法を提案していますが、手法は「register aggregation」アルゴリズムであり、機械学習・LLM の利用は記載されていません。したがって、LLM/ML が中核手法であるという Inclusion Criteria を満たさず、Exclude Criteria の EC1 (ex_no_ml) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3444, "latency_ms": 98733}}
{"key": "Reis2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We provide an automated decompiler of Michelson smart contracts to Tezla.", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、従来の自動デコンパイラとみなすため除外します。"}], "reasoning": "本稿は Michelson から Tezla 中間表現へのデコンパイル手法を提示していますが、ML/LLM を用いたことが示されていません。したがって、Decompilation Survey の採択基準（ML/LLM が中核手法）を満たさないため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3072, "latency_ms": 91491}}
{"key": "Saul2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "perform the first serious evaluation of ML binary function similarity models", "explanation": "本文はバイナリ関数の類似性検出を目的としており、コード生成や復元を行わないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリ関数の類似性検出ベンチマークを構築し、ML を用いた類似度評価を行う研究であり、デコンパイルやコード生成・復元を目的としていません。そのため、復元・可読化を主目的とする Inclusion Criteria を満たさず、除外基準 ex_no_code_generation に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3207, "latency_ms": 90430}}
{"key": "Shang2025", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "we introduce BinMetric, a comprehensive benchmark ... evaluating ... decompilation, code summarization, assembly instruction generation", "explanation": "論文はデコンパイル手法を提案せず、LLM のバイナリ解析能力を測定するベンチマークを紹介しているだけで、L1‑L3 の出力を生成する研究ではないため、対象外（L4‑only除外）と判定した。"}], "reasoning": "本稿はデコンパイル手法そのものを提示せず、LLM のバイナリ解析性能を評価するベンチマークの提案に留まっている。入力が低水準であっても、LLM/ML が中心となる復元生成を行う研究ではないため、スクリーニング基準の除外項目（対象外）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3282, "latency_ms": 94061}}
{"key": "Shokri2023", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we perform an evolutionary-based search to find the correct semantic for the created representation", "explanation": "抽象では機械学習・大規模言語モデルの使用が示されておらず、進化的探索は ML/LLM に該当しないため除外とした"}, {"code": "ex_out_of_scope", "evidence": "synthesize a mathematical representation of the control algorithms", "explanation": "出力は制御アルゴリズムの数式表現であり、L1–L3 のコード（ソース/擬似コード/AST）ではないため本バージョンの対象外（L4‑only除外）"}], "reasoning": "本稿は組み込みバイナリから制御アルゴリズムの数式モデルを再構築する手法を提案しているが、ML/LLM を利用したデコンパイル手法ではなく、進化的検索を用いているため除外基準 ex_no_ml に該当する。また出力はコードではなく数式表現であり、L1–L3 のコード生成を伴わないため L4‑only とみなし、ex_out_of_scope として除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3228, "latency_ms": 96705}}
{"key": "Stuglik2023", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "the mapping process is performed which consists of a set of rules", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、ルールベースの手法のみが記述されているため、ML/LLM が使われていないと判断した。"}], "reasoning": "本稿はJVMバイトコードをASTにデコンパイルし、ルールベースで並列化コードを生成するフレームワークを紹介しているが、機械学習やLLM を手法の中心に用いている記述がない。したがって、Decompilation Survey の除外基準 EC1 (No ML/LLM) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3128, "latency_ms": 91150}}
{"key": "Su2026", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "low-level transaction traces ... leveraging the code-generation capabilities of large language models (LLMs)", "explanation": "抽象では低レベルのトランザクショントレースを入力とし、LLM により擬似コードという高レベル表現を直接生成しているため、Core Decompilation に該当する"}, {"code": "in_core", "evidence": "dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode", "explanation": "LLM を中心に、具体的な実行情報を擬似コード（L2）へ変換しており、出力が L1–L3 に該当する"}], "reasoning": "本論文は低レベルのトランザクショントレースを入力とし、LLM を用いて実行ロジックを擬似コード（L2）として復元・生成している。入力・手法・目的・出力すべてが本サーベイの Include Criteria を満たすため、採択候補として include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3832, "latency_ms": 116402}}
{"key": "Szafraniec2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "low-level compiler intermediate representations (IR) ... generating programming source code from IR", "explanation": "抽象的に低水準IRを入力とし、MLモデルでソースコード（L1）を生成しているため、Core Decompilation に該当する"}], "reasoning": "本論文は低水準のコンパイラIRを入力として、ニューラル機械翻訳モデルを用いてソースコードを直接生成している。入力が低水準表現であり、MLが中心手法、出力がコンパイル可能なソースコード（L1）であることから、Decompilation Survey のInclude基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3301, "latency_ms": 97189}}
{"key": "Tan2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "LLM4Decompile-End models to decompile binary directly", "explanation": "LLMを中核手法として用い、バイナリ（低水準入力）から直接高水準ソースコードを生成しているため、Core Decompilation に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "refine the decompiled code from Ghidra and achieve a further 16.2% improvement", "explanation": "既存デコンパイラ（Ghidra）の出力をLLMでさらに可読性・実行性向上させている点が、Decompiler Enhancement に該当します。"}], "reasoning": "本稿はバイナリを入力とし、LLM を中心に高水準ソースコード（L1/L2）を生成する手法を提案しているため、Decompilation の Core 研究に該当し、さらに既存デコンパイラ出力の改善も行っている点で採択基準を満たします。", "model": "openai/gpt-oss-120b", "tokens_used": 3322, "latency_ms": 98217}}
{"key": "Tan2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "Large Language Models (LLMs) have emerged as a promising approach for binary decompilation.", "explanation": "LLMを用いてバイナリ（低水準入力）から高水準のコードを直接生成する研究であるため、Core Decompilationに該当します。"}, {"code": "in_variable_naming", "evidence": "apply an Identifier Naming model to produce meaningful identifiers which reflect actual program semantics", "explanation": "識別子復元を目的としたモデルを組み込んでおり、変数・関数命名回復を行うため、Variable/Function Namingにも該当します。"}], "reasoning": "本論文はバイナリを入力としてLLM/MLベースの二段階アプローチでソースコード（L1レベル）を生成している。構造回復と識別子付与の両方を行うことで、デコンパイルの核心的タスクを満たすため、L1–L3の対象として採択します。", "model": "openai/gpt-oss-120b", "tokens_used": 3358, "latency_ms": 97253}}
{"key": "Tan2025", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "we introduce Decompile-Bench, the first open-source dataset comprising two million binary-source function pairs", "explanation": "アブストラクトはデータセット作成とベンチマークの提供に焦点を当てており、LLM/ML を用いたデコンパイル手法そのものは提示していないため、L1–L3 の高水準コード生成を目指す研究ではなく対象外と判断した。"}], "reasoning": "本稿は大規模なバイナリ‑ソース対応データセットと評価ベンチマークの提供を目的としており、LLM/ML を中心としたデコンパイル手法の提案や実装が示されていない。したがって、Decompilation Survey の採択基準（IC）を満たさず、範囲外（L4‑only ではなく手法不在）として除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3476, "latency_ms": 102245}}
{"key": "Thurnherr2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "generate a large dataset of pairs of transformer weights and corresponding RASP programs... recovering the RASP code from the compiled model", "explanation": "抽象的に「Transformer weights」を低水準入力とし、MLモデルで「RASP code」（高水準ソース）を直接生成しているため、コアデコンパイルに該当する。"}], "reasoning": "本論文はトランスフォーマーの重みという低水準表現から、ニューラルモデルを用いてRASPプログラムという高水準コードを復元する手法を提案している。入力が低水準、MLが中心手法、出力がコンパイル可能なソースコード（L1）であり、デコンパイルの目的・出力レベルを満たすため、include と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3142, "latency_ms": 94015}}
{"key": "Wan2025", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "train a VLM to decompile raster images into programs composed of Bézier curves", "explanation": "アブストラクトでは入力としてラスタ画像（視覚情報）を扱っており、二進数やバイナリ・アセンブリといった本ルールで定義する低水準表現が示されていないため、低水準入力がないと判断した。"}], "reasoning": "本論文は画像を入力とし、ベジエ曲線プログラムを生成するタスクを扱っているが、デコンパイルの定義で求められるバイナリ／アセンブリ等の低水準コード入力が存在しない。したがって除外基準 EC2（低水準入力がない）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3270, "latency_ms": 99032}}
{"key": "Wang2023", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "designed a GNN-based model for vulnerability detection", "explanation": "本文の主目的は脆弱性検出であり、デコンパイルは入力前処理に過ぎず、コード生成や可読化は行っていないため除外と判断した"}], "reasoning": "本稿はバイトコードをデコンパイルして得たOpcodeを用いてグラフニューラルネットワークで脆弱性を検出することを目的としている。デコンパイルは検出モデルの入力生成にすぎず、低水準から高水準コード（L1–L3）を再構築する目的がないため、再構築意図がないと判断し除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3356, "latency_ms": 100551}}
{"key": "Wong2023", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "we investigate the feasibility of using LLMs to augment decompiler outputs, thus delivering recompilable decompilation", "explanation": "LLM が既存のデコンパイラ出力（C コード）を入力とし、再コンパイル可能な高水準コードに改善しているため、Decompiler Enhancement に該当する"}], "reasoning": "本論文はバイナリから生成された C デコンパイラ出力を LLM で加工し、再コンパイル可能なソースコード（L1）を生成する手法を提案している。低水準入力（実行ファイル）の存在と LLM の中核的利用が明示されており、目的もコードの復元・可読化であるため、インクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3825, "latency_ms": 115385}}
{"key": "WOS:000396087900059", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we proposed an approach to mine dynamic noteworthy functions (DNFM) in software execution sequences", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、ML/LLM を用いていないため除外と判断しました。"}, {"code": "ex_no_code_generation", "evidence": "the results show that the DNFM method can mine noteworthy functions in software effectively and precisely", "explanation": "目的は関数の重要度を抽出・順位付けすることであり、コードの復元・生成（L1‑L3 出力）は行わないため除外対象です。"}], "reasoning": "本論文は実行トレースから重要な関数を抽出する手法を提案しており、機械学習やLLM を用いたデコンパイル（低水準から高水準コード生成）とは無関係です。出力は関数の重要度評価であり、コード生成や可読化を目的としないため、L1‑L3 のデコンパイル研究の範囲外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3370, "latency_ms": 102378}}
{"key": "WOS:000397194600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "allows finding patterns not detected with the manual approach", "explanation": "抽象はパターン抽出が主目的であり、コードの復元や高水準表現の生成を目的としていないため、復元意図がないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "automatic extraction of patterns from native code", "explanation": "出力はパターン（属性）であり、L1–L3 のソース/擬似コード/AST ではなく L4‑only に該当するため除外した。"}], "reasoning": "本稿はバイナリからパターンを自動抽出することを目的としており、LLM/ML を用いたコード復元や高水準表現生成は行わない。出力はパターン情報（属性）であり、レビュー対象の L1–L3 のデコンパイル成果に該当しないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3206, "latency_ms": 100323}}
{"key": "WOS:000399815400003", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "a cloud‑based framework, which employs a systematic method", "explanation": "アブストラクトに機械学習やLLMの利用が記載されておらず、ML/LLM が手法の中核でないため"}, {"code": "ex_no_code_generation", "evidence": "examines all permission labels ... and API invocations extracted from its decompiled code", "explanation": "目的は権限やAPIレベルのセキュリティ認証であり、コードの生成・復元は行わないため"}], "reasoning": "本論文は Android アプリの API レベルセキュリティ認証フレームワークを提案しており、デコンパイルされたコードを入力として解析は行うが、機械学習・LLM を用いた手法やコード生成（L1‑L3 の復元）は行っていない。したがって、Decompilation Survey の対象外であり除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3430, "latency_ms": 104808}}
{"key": "WOS:000403121900083", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the DM is then decompiled into frames that are ordered sequentially.", "explanation": "要旨ではフレームへの分割が述べられているが、機械学習や大規模言語モデルの使用は言及されていないため、ML/LLM が用いられていないと判断し除外する。"}], "reasoning": "本稿はデジタル映像をフレームに分割し titration を自動化する手法を紹介しており、低水準バイナリから高水準コードへの復元や LLM/ML を中心としたデコンパイル手法とは無関係である。したがって、ML/LLM が使用されていない点で除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3275, "latency_ms": 91147}}
{"key": "WOS:000412054600026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "focus on extracting ... from the decompiled source codes ... for Android malware detection", "explanation": "本文はデコンパイルしたコードから特徴を抽出しマルウェア検出を行うことが目的で、コードの復元や高水準表現の生成は行わないため除外基準 EC3 に該当する"}], "reasoning": "本稿はデコンパイルされたソースコードを入力として特徴抽出・選択を行い、マルウェア検出という分類タスクに利用しています。デコンパイル自体や高水準コードの生成を目的とした研究ではなく、コード生成や復元が主目的ではないため、除外基準 EC3（復元・生成が主目的でない）に該当し除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3266, "latency_ms": 99514}}
{"key": "WOS:000415662500002", "action": "keep", "reason": "in_control_structure", "details": {"decision": "include", "confidence": 0.82, "reason_codes": [{"code": "in_control_structure", "evidence": "We also present a Genetic algorithm (GA) for the global search approach to locate near optimal solutions for large CFGs.", "explanation": "遺伝的アルゴリズムを用いた全体探索により CFG を再構築し、制御構造（goto の削減）を回復することが目的であり、低水準バイナリから高水準構造化コードを生成するため、IC5（制御構造復元）に該当する。"}], "reasoning": "本論文は組み込みバイナリの低水準表現を入力とし、遺伝的アルゴリズムという機械学習的手法で制御構造の再構成を行い、goto を削減した高水準表現を出力する。出力はコード様式（擬似コード/構造化コード）に該当し、L1‑L3 の範囲内であるため、インクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3434, "latency_ms": 110473}}
{"key": "WOS:000419845600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "most malware detection methods ... rely on expert knowledge for manual feature engineering", "explanation": "アブストラクトはマルウェア検出という分類・検知が主目的であり、コードの復元や高水準表現の生成を目指していないため、復元・コード生成の意図がないと判断した。"}], "reasoning": "本論文は LSTM を用いてデコンパイルされた Android ファイルから抽出した opcode シーケンスを特徴としてマルウェア検出を行う分類手法を提案している。目的は復元・可読化ではなくマルウェアの有無を判定することにあり、コード生成や高水準表現の出力を行わないため、Decompilation Survey の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3152, "latency_ms": 94632}}
{"key": "WOS:000425569100004", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We implement the ``Naive Bayesian Classifier{''} algorithm for the optimized obfuscation of the software complexity and the performance", "explanation": "本稿はオブフュスケーションの最適化を目的としており、ML 手法は分類器として利用されているが、低水準コードから高水準コードを生成する（復元・可読化）目的ではなく、コード生成は行わないため除外基準 EC3 に該当する。"}, {"code": "ex_out_of_scope", "evidence": "its Java bytecode is easier to decompile and to reconstruct the original Java source code. Therefore obfuscation is an essential criterion for the protection of Android applications.", "explanation": "デコンパイルは議論の背景として言及されているだけで、実際の研究対象はオブフュスケーションの性能コストであり、L1–L3 のコード復元を行うデコンパイル研究ではないためスコープ外と判断した。"}], "reasoning": "本稿は Android アプリのオブフュスケーション手法とその性能コストを評価・最適化することが中心であり、ML はオブフュスケーションのパラメータ予測に用いられているが、デコンパイル（低水準入力から高水準コード生成）を目的とした手法は示されていない。したがって、デコンパイル調査の対象外（EC3）となり除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3462, "latency_ms": 106410}}
{"key": "WOS:000428354700001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "takes a stacking ensemble for malware classification", "explanation": "アブストラクトはマルウェア検出・分類が主目的であり、コードの復元や可読化を目指していないため、復元・生成意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文はディープニューラルネットワークを用いたマルウェア検出手法を提案しており、デコンパイルは特徴抽出の一部に過ぎません。目的は分類であり、低水準コードから高水準コードを生成することはありません。したがって、復元・コード生成を目的としたデコンパイル研究ではないため除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3202, "latency_ms": 98216}}
{"key": "WOS:000435804100020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "We evaluate 30 code similarity detection techniques and tools...", "explanation": "本文の要旨では機械学習や大規模言語モデルの利用について言及されておらず、従来の手法のみを評価しているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文はコード類似性解析ツールの比較評価を目的としており、デコンパイルは正規化手段として言及されるだけで、ML/LLM を用いたデコンパイル手法そのものの研究ではない。したがって、ML/LLM 不使用という除外基準 (ex_no_ml) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3389, "latency_ms": 98729}}
{"key": "WOS:000448568500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a classifier is trained for the malware detection and classification tasks", "explanation": "抽象・分類が目的であり、コードやソースの復元・可読化を行わないため、復元・生成意図がなく除外基準 EC3 に該当します"}], "reasoning": "本稿は Dalvik バイトコードを簡略化し機械学習で特徴抽出・分類器を構築し、マルウェアの検出・分類を行うことを目的としている。LLM/ML を使用しているが、低水準入力から高水準コードを生成（L1–L3）するデコンパイル目的ではなく、分類タスクのみであるため除外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3199, "latency_ms": 101090}}
{"key": "WOS:000448653700147", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "This study uses a dynamic analysis method to inspect an executing app", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、従来の動的解析のみを用いているため、ML/LLM が使われていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "It is then determined whether or not the ad lib is from a trusted ad network using comparisons of graph similarities.", "explanation": "目的は広告ライブラリの信頼性判定であり、コードの復元や可読化といった生成・再構築ではなく、分類・判定であるため除外基準に該当する。"}], "reasoning": "本論文は APK の動的解析によるネットワーク振る舞いの類似性比較で広告ライブラリを識別することを目的としており、機械学習や大規模言語モデルを用いたデコンパイルやコード生成は行っていない。したがって、Decompilation Survey の対象外（ML未使用かつコード生成目的なし）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3302, "latency_ms": 101090}}
{"key": "WOS:000450592600010", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Defect prediction ... the model could achieve an AUC ... and it is capable of predicting defects in apks.", "explanation": "本文はバイナリからソースコードを再構成することを目的としておらず、欠陥予測という分類タスクであり、コード生成や復元が主目的ではないため除外と判断した。"}], "reasoning": "本稿はAndroidバイナリから取得したsmali特徴を用いて欠陥予測モデルを構築する研究であり、LLM/MLは予測（分類）に使用されているが、低水準入力から高水準コードを生成する（L1‑L3）目的がない。したがってデコンパイルの再構成目的に該当せず、除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3376, "latency_ms": 104051}}
{"key": "WOS:000459709500083", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "including application binary decompilation", "explanation": "アブストラクトではバイナリデコンパイルは言及されていますが、ML／LLM の使用については記述がなく、機械学習手法が用いられていないと判断したため。"}], "reasoning": "本稿はIoT玩具のセキュリティとプライバシー分析が主目的であり、バイナリデコンパイルは分析手法の一部として言及されているものの、LLM/ML を用いたデコンパイル手法の提案や評価は行っていない。したがって、ML/LLM が使用されていないことから除外基準 EC1 (ex_no_ml) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3145, "latency_ms": 102455}}
{"key": "WOS:000459807600022", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "We present a new approach for predicting program properties from large codebases (aka \"Big Code\").", "explanation": "アブストラクトは大規模コードベース（ソースコード）から性質を予測すると記述しており、入力は低水準バイナリやアセンブリではなくソースコードであるため、低水準入力がないと判断した。"}], "reasoning": "本稿はバイナリやアセンブリといった低水準表現を入力とせず、ソースコード上で名前や型を予測する手法を提案している。デコンパイルの定義に必要な低水準入力が欠如しているため、除外基準 EC2（No Low-level Input）に該当し、L1–L3 の出力でも対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 97192}}
{"key": "WOS:000460845200059", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "using Min Hashing techniques applied to applications' meta-data", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、Min Hashing は従来のハッシュ手法であるため、EC1 に該当し除外します。"}, {"code": "ex_no_code_generation", "evidence": "detect Repackaged versions of Android apps", "explanation": "目的はクローン検出であり、コードの復元・生成ではなく分類・検出であるため、EC3 に該当します。"}], "reasoning": "本稿は Android アプリのメタデータを用いたクローン検出手法を提案しており、ML/LLM を利用したデコンパイルや高水準コード生成を行わない。入力は低水準バイナリでもなく、出力もコードや擬似コードではなく検出結果であるため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3125, "latency_ms": 101089}}
{"key": "WOS:000463843700059", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "target structures immediately decompiled into the constituent building blocks and assembly sequences", "explanation": "「decompiled」は化学構造を部品に分解する比喩的表現であり、低水準コードやML/LLMの使用が示されていないため、デコンパイル調査の対象外（L4‑onlyでもなく）として除外"}], "reasoning": "本稿は化学合成に関する研究であり、低水準バイナリや機械語から高水準コードを生成するデコンパイルとは無関係です。ML/LLM を用いた手法やコード出力も記載されていないため、スクリーニング基準の除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3121, "latency_ms": 101081}}
{"key": "WOS:000495504500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "TensorFlow with Keras deep learning model is designed to predict clones in Android applications.", "explanation": "本文はMLを用いてクローンアプリを分類・検出することが目的であり、低水準入力から高水準コードを生成する復元・可読化が主目的ではないため除外と判断した。"}], "reasoning": "本稿はAPK/DEX から抽出したソースを特徴量化し、ディープラーニングでクローン検出を行う分類システムを提案している。デコンパイルは前処理として使用されるが、LLM/ML がコード生成や再構成に使われているわけではなく、復元・可読化が目的でないため除外（ex_no_code_generation）とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3413, "latency_ms": 108461}}
{"key": "WOS:000497359300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a dynamic method to solve this issue", "explanation": "概要からは機械学習・LLM を用いた手法は記載されておらず、単なる動的解析手法であるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は Android アプリの SSL 脆弱性検出を目的とした動的解析手法を提案しており、デコンパイルやコード生成を行う LLM/ML 手法は含まれていない。入力は低水準バイナリではなくアプリの実行時挙動であり、復元・可読化を目的とした出力も存在しないため、除外基準 EC1（ML/LLM 不使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3325, "latency_ms": 103230}}
{"key": "WOS:000508186400109", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "process to automate the decompilation of all the applications on a user's mobile device", "explanation": "要旨では decompilation の自動化を述べているが、ML/LLM を用いる旨の記述がなく、EC1 に該当するため除外する。"}], "reasoning": "本稿は Android アプリの自動 decompilation と脆弱性評価手法を提案しているが、機械学習や大規模言語モデルを手法の中核としている記述がない。したがって、Include 基準の IC0（ML/LLM 使用）を満たさず、除外基準の ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 101694}}
{"key": "WOS:000536764600007", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach contains two components: pre-compilation and compile-time virtualization.", "explanation": "本文に機械学習や大規模言語モデルの使用が記載されておらず、従来のコンパイラフレームワークでの実装のみであるためML/LLM未使用と判断した。"}], "reasoning": "本稿はAndroidアプリのコード仮想化手法を提案しており、ML/LLM を活用したデコンパイル手法ではない。低水準入力（DEXバイトコード）からの変換は行うが、目的は復元・可読化ではなく保護であり、ML/LLM の利用がないため除外対象とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3332, "latency_ms": 103257}}
{"key": "WOS:000541153400012", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.91, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "use of a decompiled source code for malicious code classification", "explanation": "アブストラクトはデコンパイルしたコードを分類に利用することが主目的であり、コードの復元・可読化・意味回復といった生成目的が示されていないため、EC3に該当し除外します"}], "reasoning": "本論文はデコンパイルしたAPKのソースコードを用いてマルウェア分類を行うことが目的であり、復元や可読化といったコード生成を目指すものではありません。したがって、復元・生成意図がなく除外基準EC3（No Reconstruction Intent）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3239, "latency_ms": 101856}}
{"key": "WOS:000551423500007", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "use ... CNN ... to train a detection model and apply it to classify malware", "explanation": "アブストラクトはバイトコード画像からCNNでマルウェアを分類することが目的であり、コードの復元・生成（デコンパイル）を目指していないため、再構成意図がなく除外対象となります。"}], "reasoning": "本論文はバイトコードを画像化しCNNでマルウェア検出を行う分類手法を提案しており、低水準コードから高水準コードを生成すること（デコンパイル）を目的としていません。したがって、復元・可読化を目的としたML/LLM利用というサーベイの採択基準を満たさず、除外基準 EC3（復元意図なし）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3140, "latency_ms": 102664}}
{"key": "WOS:000557871300009", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we assess the strategies of eight Java decompilers", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用が言及されておらず、従来のルールベース／統計的手法のみでデコンパイル手法を評価しているため、EC1に該当し除外する"}], "reasoning": "本論文は既存のJavaデコンパイラを比較評価し、出力を統合する新しいデコンパイラArlecchinoを提案していますが、ML/LLM を利用した手法の記述が全くなく、機械学習を中心としたデコンパイル研究ではありません。そのため、除外基準EC1（No ML/LLM）に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3333, "latency_ms": 104805}}
{"key": "WOS:000565246000013", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect... malicious program can be detected more accurately", "explanation": "アブストラクトはマルウェア検出（分類）を目的としており、コードの復元や高水準表現の生成は目的に含まれないため、復元志向でないことが示されている。"}], "reasoning": "本稿はCNNを用いたAndroidマルウェア検出システムを提案しており、低水準 opcode シーケンスを入力としてマルウェアの有無を分類することが主目的である。デコンパイルによるコード復元や高水準表現の生成を行わないため、復元/可読化を目的としたICを満たさず、除外基準 EC3（復元・生成が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3158, "latency_ms": 101087}}
{"key": "WOS:000569691600001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "bilingual translation, LaTeX decompilation and audio transcription", "explanation": "本文のアブストラクトでは入力がバイナリやアセンブリといった低水準表現ではなく、翻訳やLaTeXといった高水準テキストであることが示されているため、低水準入力がないと判断した。"}], "reasoning": "本稿はエンコーダ‑デコーダネットワークを用いた汎用テキスト処理タスクの評価であり、対象タスクの一つとして LaTeX decompilation が挙げられるが、入力は低水準コードではなく高水準の LaTeX ソースである。デコンパイルの定義（低水準入力から高水準コード生成）を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3316, "latency_ms": 106409}}
{"key": "WOS:000570595700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a two-phase detection scheme ... the locality-sensitive hashing (LSH) algorithm is used", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、ハッシュや LSH といった手法のみが述べられているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本論文は Android アプリのクローン検出手法を提案しているが、ML/LLM を用いたデコンパイルや高水準コード生成は行っていない。入力は低水準バイナリではなく UI レイアウト情報で、目的も復元・可読化ではなく類似度計算による検出であるため、除外基準 EC1（ML未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3273, "latency_ms": 106405}}
{"key": "WOS:000575515300019", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "MadMax combines a smart contract decompiler and semantic queries in Datalog.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、従ってML/LLMが用いられていないと判断したため。"}, {"code": "ex_no_code_generation", "evidence": "automatically detects gas-focused vulnerabilities with very high confidence.", "explanation": "研究目的は脆弱性検出であり、復元・コード生成が主目的でないため、コード生成目的の除外基準に該当する。"}], "reasoning": "本論文はスマートコントラクトのガス関連脆弱性検出を目的とした静的解析手法を提案しており、ML/LLMは用いられていない。また、出力は脆弱性の検出結果であり、L1–L3 の高水準コード生成や復元を行うものではないため、除外基準（ML不使用、コード生成目的外）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3584, "latency_ms": 116249}}
{"key": "WOS:000582272700012", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Reditus is based on the observation that an engineering software has a built-in decompiler", "explanation": "要旨では既存のエンジニアリングソフトの組み込みデコンパイラを利用すると述べており、機械学習・LLM の使用は言及されていないため、ML/LLM 不使用と判断した。"}], "reasoning": "本論文はネットワークトラフィックから制御ロジックを復元するために、既存の組み込みデコンパイラを利用する手法を提案しているが、機械学習や大規模言語モデルを中核手法として使用していない。したがって、Decompilation Survey Screening Rules の除外基準 EC1（No ML/LLM）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3283, "latency_ms": 105861}}
{"key": "WOS:000589187000048", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "a set of free or inexpensive tools was used to retrieve and disassemble the monitor's onboard software", "explanation": "要旨からは機械学習や大規模言語モデルを使用したことが記載されておらず、従来のツールによる手作業の逆コンパイルのみであるため、ML/LLM不使用と判断し、ex_no_mlで除外します。"}], "reasoning": "本稿は BIS モニタのハードウェアからソフトウェアを取得し、手動で逆アセンブル・注釈付けを行うフォレンジック解析を報告していますが、機械学習や大規模言語モデルを手法の中心に用いた記述がありません。したがって、Decompilation Survey の対象である「LLM/ML を用いたデコンパイル」には該当せず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3432, "latency_ms": 102650}}
{"key": "WOS:000592654700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "applying the social network analysis by R packages, which include k-core decomposition", "explanation": "本文では機械学習や大規模言語モデルの使用が言及されておらず、単なる統計・ネットワーク解析手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "k-core decomposition and the examination of the application programming interface of terminal applications", "explanation": "入力はバイナリやアセンブリといった低水準コードではなく、データネットワークや API の解析であり、デコンパイルの対象となる低水準表現が存在しない。"}], "reasoning": "本稿はデータアクセスと競争構造の実証分析であり、機械学習・LLM を用いたバイナリ/アセンブリ等の低水準コードから高水準コードへの変換（デコンパイル）に関する研究ではない。したがって、ML/LLM 不使用と低水準入力の欠如という除外基準に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3348, "latency_ms": 106432}}
{"key": "WOS:000597138700009", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "deep learning model is configured to detect cloned apps", "explanation": "本文はディープラーニングでクローンアプリを検出することが目的であり、復元・可読化や高水準コード生成を行うものではないため、コード生成（復元）の意図がなく除外します。"}], "reasoning": "本論文は Android アプリのクローン検出を目的としており、ML はクローン判定の分類タスクに用いられています。デコンパイルは前処理として実施されますが、最終的な出力は検出結果であり、L1–L3 のコード生成や復元を行わないため、除外基準 EC3（No Reconstruction Intent）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3300, "latency_ms": 105488}}
{"key": "WOS:000602074600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "perform classification", "explanation": "アブストラクトでは、低水準入力からコードを復元するのではなく、バイナリのオペコード n‑gram を用いてマルウェアを分類することが主目的と記載されているため、コード生成・復元の意図がなく除外すべきです。"}], "reasoning": "本論文はバイナリからオペコード n‑gram を抽出し、浅層ニューラルネットワークでマルウェアを分類する手法を提案しています。目的は復元・可読化ではなく分類であり、LLM/ML をデコンパイル（コード生成）に用いた例ではないため、除外基準 EC3（No Reconstruction Intent）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3355, "latency_ms": 109683}}
{"key": "WOS:000604998900011", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "decompile the conceptual prototype from the pattern composition", "explanation": "「decompile」はコード復元ではなく概念的な原型抽出を指しており、低水準バイナリから高水準コードへの変換ではないため、デコンパイル調査の対象外です。"}, {"code": "ex_no_lowlevel_input", "evidence": "design of batik patterns ... based on shape grammar, and relies on the artificial neural network (ANN) to model the nonlinear mapping between design parameters and visual cognitive image (VCI) values", "explanation": "入力はデザインパラメータや形状文法で、バイナリ・アセンブリ・バイトコードなどの低水準表現が示されていないため、除外基準 EC2 に該当します。"}], "reasoning": "本論文はバティック模様の生成デザイン手法を提案しており、低水準コードから高水準コードへの復元を目的としていない。入力も低水準表現ではなく、ML はパラメータ‑視覚認知マッピングに用いられるだけで、デコンパイルとは無関係であるため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3511, "latency_ms": 113202}}
{"key": "WOS:000606730100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "predict potential cloned applications by training features", "explanation": "本文はクローン検出（分類）が目的であり、コード生成や復元は主目的ではないため、復元意図がなく除外すべきと判断した。"}, {"code": "ex_no_ml", "evidence": "deep learning model ... Recurrent Neural Network (RNN) is designed", "explanation": "MLはクローン判別に用いられているが、デコンパイル（低レベルから高レベルコード生成）には使用されていないため、対象外とした。"}], "reasoning": "本論文は Android アプリのクローン検出を目的とした分類タスクであり、LLM/ML は CFG からクローン判定を行うために使用されています。デコンパイル自体は前処理として JDEX デコンパイラを利用していますが、生成されたコードは最終成果物ではなく、復元・可読化が主目的ではありません。そのため、復元意図がないことから除外と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3414, "latency_ms": 110995}}
{"key": "WOS:000611120200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the detection and classification of malicious apps can be realized", "explanation": "要旨からは、目的がマルウェアの検出・分類であり、コードの復元や可読化といった再構成が主目的ではないことが明らかです。"}, {"code": "ex_no_lowlevel_input", "evidence": "generating a function call graph for the decompiled Android application", "explanation": "入力はすでに decompiled された Android アプリケーションであり、低水準バイナリやアセンブリが直接入力として用いられていないため除外基準に該当します。"}], "reasoning": "本論文はデコンパイル技術そのものや高水準コードの生成を目指すものではなく、既にデコンパイルされたコードから関数呼び出しグラフを構築し、マルウェア検出・分類を行う手法です。復元・可読化が目的でないため、include 基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3318, "latency_ms": 111529}}
{"key": "WOS:000618528800004", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The pipeline is based on IFCL, an intermediate firewall language equipped with a formal semantics, and it is implemented in an open source tool called FWS.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されておらず、形式的手法とZ3ソルバーのみが利用されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はファイアウォール設定のデコンパイルやトランスコンパイルを行うツールを紹介しているが、手法は形式的解析とSMTソルバーに基づくもので機械学習・LLM は用いられていない。したがって Exclude Criteria の EC1（No ML/LLM）に該当し、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3508, "latency_ms": 112216}}
{"key": "WOS:000632639400003", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Android malware dataset is decompiled to identify the suspicious API classes/methods", "explanation": "抽出されたのは API のクラス・メソッド名という属性情報であり、L1–L3 のソースコードや擬似コードは生成していないため L4‑only と判断し除外する"}, {"code": "ex_no_code_generation", "evidence": "The model classifies an unknown application as benign or malicious based on the log likelihood score", "explanation": "目的はマルウェア検出・分類であり、コードの復元・可読化が主目的ではないため除外基準 EC3 に該当する"}], "reasoning": "本論文はバイナリをデコンパイルして API 情報を抽出し、取得した属性を用いて HMM によるマルウェア検出を行う手法を提示している。出力はコードそのものではなく属性情報（L4）であり、復元・可読化が主目的ではないため、L1–L3 の出力を伴うデコンパイル研究としては除外対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3522, "latency_ms": 119915}}
{"key": "WOS:000649389100006", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a control flow‑based feature extraction dynamic programming algorithm", "explanation": "要旨に機械学習・LLMの使用が記載されておらず、純粋にアルゴリズムによる特徴抽出のみなのでML/LLMが使われていないと判断したため"}, {"code": "ex_no_code_generation", "evidence": "detect malicious code with higher accuracy than traditional text‑based methods", "explanation": "目的はマルウェア検出という分類・検知であり、コードの復元・可読化などの生成は行わないため"}], "reasoning": "本稿は低水準バイナリからのデコンパイルやコード生成を目的とせず、ML/LLM を用いた高水準表現の復元も行わないため除外とした。アルゴリズムは既にデコンパイル済みの実行コードから特徴を抽出し、マルウェア検出に利用するだけで、デコンパイル（L1–L3）に該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 3209, "latency_ms": 110768}}
{"key": "WOS:000658941200001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "function call graphs (FCGs), sensitive permissions, and application programming interfaces (APIs) are generated from the decompiled files of malware.", "explanation": "要旨からは機械学習／LLM が使用されている記述がなく、従来の構造解析とサブグラフマイニングのみが述べられているため、ML/LLM 不使用のため除外"}, {"code": "ex_no_code_generation", "evidence": "test applications' safety can be automatically identified and classified into malware families by matching their FCGs with malicious structural features.", "explanation": "目的はマルウェア検出・分類であり、コードの復元・生成が主目的ではないため除外"}], "reasoning": "本論文は decompiled ファイルを入力としてサブグラフマイニングによるマルウェア検出手法を提案しており、ML/LLM を用いたデコンパイルや高水準コード生成は行っていない。したがって、デコンパイルのコア目的（復元・可読化）から外れ、除外基準 (ex_no_ml, ex_no_code_generation) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3282, "latency_ms": 111018}}
{"key": "WOS:000672841700001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "converts low-level PL into high-level PL while acquiring legibility", "explanation": "低水準のバイナリ／アセンブリから高水準のプログラム言語へ変換している点が、LLM/ML を中核としたコアデコンパイルに該当するため。"}, {"code": "in_core", "evidence": "attention‑based neural machine translation (NMT) mechanism", "explanation": "ニューラル機械翻訳というML手法を中心に用いていることが、ICのML中核要件を満たす根拠。"}], "reasoning": "本稿はバイナリ・アセンブリといった低水準コードを入力とし、注意機構を備えたニューラル機械翻訳で高水準ソースコード（L1）を生成する手法を提案している。入力・手法・目的ともにデコンパイルの定義を満たすため、L1–L3 のコアデコンパイル研究として採択すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3265, "latency_ms": 107735}}
{"key": "WOS:000685203900086", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present the first static technique ensuring modularity ... harnessing SMT solvers.", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、SMTソルバーによる静的解析のみが述べられているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿はスマートコントラクトのモジュラリティ検証を目的とした静的解析手法を提案しており、ML/LLM を用いたデコンパイルは行っていない。したがって、Decompilation Survey の採択基準で定められた「ML/LLM が中核手法である」条件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3556, "latency_ms": 117164}}
{"key": "WOS:000691101100002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "deep learning network for classification and discrimination", "explanation": "アブストラクトはコードベクトル化後に深層学習でマルウェアかどうかを分類することが目的であり、コードの復元や高水準表現の生成は行わないため、復元・生成意図がなく除外すべきです"}], "reasoning": "本稿はAPKをデコンパイルして特徴抽出を行い、得られたベクトルを用いてマルウェア検出を分類することが主目的です。デコンパイルは手段であり、低水準コードから高水準コードを生成すること（L1‑L3 の出力）を目的としていないため、除外基準 EC3 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3135, "latency_ms": 103740}}
{"key": "WOS:000695854600007", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "provides the stochastic generation of large amounts of standard C code", "explanation": "低水準（バイナリ・アセンブリ等）の入力が存在せず、生成対象は高水準のCソースであるため除外"}, {"code": "ex_no_ml", "evidence": "Cnerator, a Python application that provides the stochastic generation of large amounts of standard C code", "explanation": "手法はLLM/MLではなく、単なる確率的コード生成であるため除外"}], "reasoning": "本論文は低水準入力から高水準コードを生成するデコンパイル手法を提案しているわけではなく、ML を用いたデコンパイルそのものも行っていません。したがって、EC2（低水準入力なし）および EC1（ML 非使用）に該当し、L1–L3 のデコンパイル対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3426, "latency_ms": 117394}}
{"key": "WOS:000709490700009", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "convolution neural network is used to classify the fused samples", "explanation": "要旨はCNNでマルウェアを分類することが目的であり、コードの復元・生成は行っていないため除外基準EC3に該当します。"}], "reasoning": "本論文は低水準のASMやバイト列から特徴を抽出し、CNNでマルウェアの分類を行うことを目的としている。デコンパイルによるコード復元や高水準表現の生成は目的に含まれず、MLは分類タスクに用いられているだけなので、除外基準EC3（復元・生成が主目的でない）により除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3168, "latency_ms": 110475}}
{"key": "WOS:000712025300005", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "malware classification ... using deep learning model for sequence learning", "explanation": "要旨はバイナリをIRに変換しそのシーケンスでマルウェアを分類することが目的であり、コードの復元や可読化を行うことは示されていないため、復元・生成が主目的でない（ICに該当しない）と判断した。"}], "reasoning": "本論文はバイナリリフティングで得た中間表現を用いたマルウェア分類手法を提案しており、目的は分類でありコード生成や高水準表現の復元ではない。したがって、復元・可読化を目的としたデコンパイル研究のインクルード基準を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3152, "latency_ms": 109687}}
{"key": "WOS:000737527800001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the researchers have focused on how to solve class-imbalance to improve the performance of Android malware detection", "explanation": "要旨はクラス不均衡を解消してマルウェア検出性能を向上させることが目的であり、コードの復元や高水準表現の生成は含まれていないため、復元・生成意図がない（EC3）と判断した。"}], "reasoning": "本文は Android マルウェア検出のためのクラス不均衡学習手法を提案しており、デコンパイルやコード生成を目的としていない。入力は機能特徴であり低水準バイナリやアセンブリからの変換ではないため、デコンパイルの対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3389, "latency_ms": 115254}}
{"key": "WOS:000748533600001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "reverse engineering techniques-specifically decompilation", "explanation": "要旨は従来のリバースエンジニアリングによるデコンパイルを述べており、ML/LLM の使用は示されていないため除外します。"}], "reasoning": "本稿は Adobe Flash の作品を保存するために逆コンパイル技術を用いることを報告していますが、機械学習や大規模言語モデルを手法の中核としている記述がなく、EC1 の「No ML/LLM」に該当します。そのため L1–L3 の対象でも除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3115, "latency_ms": 108457}}
{"key": "WOS:000771288000001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Sensor switches monitor the chassis status at all times", "explanation": "要旨はセンサーによる物理的侵入検知であり、ML/LLM の使用は示されていないため ex_no_ml と判断した"}, {"code": "ex_no_lowlevel_input", "evidence": "We here propose a physical security system that can protect data from unauthorized access when the computer chassis is opened", "explanation": "入力はバイナリやアセンブリなどの低水準コードではなく、ハードウェアの状態情報であるため low‑level 入力がなく ex_no_lowlevel_input と判定した"}], "reasoning": "本論文はハードウェアベースの物理侵入検知システムを提案しており、ML/LLM を用いたコード復元や高水準表現生成を目的としていない。入力も低水準プログラム表現ではなく、低水準コードに対するデコンパイル査読の対象外であるため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3446, "latency_ms": 118481}}
{"key": "WOS:000790329300013", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "by employing several high-precision techniques and making them scalable", "explanation": "要旨に機械学習や大規模言語モデルの使用が明示されておらず、従来の静的解析技術のみが言及されているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本論文は Ethereum スマートコントラクトのバイトコードを対象とした decompiler を提案しているが、手法は高精度な静的解析技術であり、機械学習や大規模言語モデルの使用は記載されていない。したがって、Decompilation Survey の包括基準（ML/LLM が中核手法）を満たさず、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3318, "latency_ms": 110239}}
{"key": "WOS:000798201400013", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The Stacked-Long Short-Term Memory (S-LSTM) deep learning model is designed to predict possible clones.", "explanation": "本文はクローン検出（分類）を目的としており、コードの復元・可読化などの生成目的が示されていないため、復元・生成意図がなく除外します。"}], "reasoning": "本論文はAndroidアプリのクローン検出を目的とした分類手法であり、低水準バイナリから高水準コードを生成するデコンパイル目的が示されていません。したがって、復元・生成意図が欠如していると判断し、除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3191, "latency_ms": 110229}}
{"key": "WOS:000804579300001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LSTM-ESO is employed to detect the unknown mobile applications as benign or malicious.", "explanation": "論文の目的はマルウェアの分類・検出であり、コード生成や高水準表現の復元は行っていないため除外基準 EC3 に該当します。"}, {"code": "ex_no_ml", "evidence": "Androguard tool is used for decompiling and disassembling the android applications.", "explanation": "ML/LLM は検出モデル（LSTM）に使用されていますが、デコンパイル自体は従来ツールで行われ、ML がデコンパイルの中心手法ではないため除外の補助理由とします。"}], "reasoning": "本稿は Android アプリを Androguard でデコンパイルし、抽出した特徴を LSTM-ESO によるマルウェア検出に利用することが主目的であり、復元・可読化・高水準コード生成を目的としていません。そのためデコンパイルは前処理に過ぎず、IC を満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3416, "latency_ms": 116434}}
{"key": "WOS:000838998100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the proposed scheme can improve the classification performance of malware variants under obfuscation.", "explanation": "アブストラクトは分類性能の向上を目的としており、コード生成や復元が主目的ではないため除外基準 EC3 に該当します。"}, {"code": "ex_out_of_scope", "evidence": "we first generated a malware variant dataset using the obfuscation technique based on the disassembly and decompilation of malware.", "explanation": "デコンパイルはデータセット作成の副次的手段であり、L1–L3 のコード出力を提供していないため、本バージョンの対象外（L4‑only）と判断します。"}], "reasoning": "本論文はマルウェア変種の検出モデルの構築と分類性能の向上を主目的としており、デコンパイルはデータセット生成のための前処理に過ぎません。出力はコードや擬似コードではなく API 呼び出しシーケンスであり、L1–L3 の高水準コード生成が行われていないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3682, "latency_ms": 124670}}
{"key": "WOS:000849409500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "machine learning classification algorithms are used to classify the malicious and benign applications", "explanation": "要旨は画像化した APK を分類することでマルウェア検出を行うことが目的であり、コードの復元や高水準表現の生成は行わないため、復元・生成が主目的でない（ex_no_code_generation）と判断した。"}], "reasoning": "本稿は Android アプリを画像化しテクスチャ特徴を抽出して機械学習でマルウェアか否かを分類する手法を提案している。低水準バイナリからソースコードや疑似コードを生成することはなく、復元・可読化を目的としたデコンパイル手法ではないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3131, "latency_ms": 108461}}
{"key": "WOS:000849434800002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The method proposed in this paper does not need to decompile the Android APK installation package ... to realize the multiple classifications of the Android malware family.", "explanation": "アブストラクトはコード生成や復元ではなく、マルウェアファミリの分類を目的としており、復元・可読化が主目的でないため除外基準 EC3 に該当する。"}], "reasoning": "本稿はバイナリやXMLを画像化し深層学習でマルウェアを多クラス分類する手法を提案している。デコンパイルやコード復元を行わず、検出・分類が主目的であるため、デコンパイル調査の対象外となる。したがって、除外（ex_no_code_generation）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3402, "latency_ms": 112805}}
{"key": "WOS:000864735500003", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "The arrival of the Bourbons to the Hispanic Monarchy brought with it new ways of conceiving of the society attached to its body politic.", "explanation": "抽象的に歴史・社会学の研究であり、低水準コードやML/LLMを用いたデコンパイルとは無関係なため、対象外と判断した。"}], "reasoning": "アブストラクトは18世紀の植民地社会に関する歴史的分析を記述しており、デコンパイルや機械学習手法に関する記述が全く見られない。したがって本サーベイの対象（低水準入力から高水準コードを生成するML/LLM手法）から外れている。", "model": "openai/gpt-oss-120b", "tokens_used": 3315, "latency_ms": 117486}}
{"key": "WOS:000867635500021", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "evaluate a decomposition approach to solve the initial problem recursively", "explanation": "本文はエネルギー変換問題のアルゴリズム的分解を扱っており、低水準バイナリからのコード生成やLLM/MLの使用は示されていないため、デコンパイル（L1-L3）対象外です。"}], "reasoning": "本稿はエネルギー変換モデルと問題分解手法について述べており、低水準コードやバイナリを高水準表現に変換するデコンパイル研究とは無関係です。ML/LLM の利用も示唆されていないため、スクリーニング基準の対象外 (L4‑only除外) と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 110503}}
{"key": "WOS:000870301800008", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "our learned labeling model can be combined with an existing decompilation tool, Ghidra, to achieve substantially improved performance in function call recovery", "explanation": "ML を用いたラベリングモデルを既存デコンパイラ (Ghidra) に組み合わせ、関数呼び出しの復元精度を向上させている点が、デコンパイラ出力の改善（LLM/ML が中心手法）に該当するため"}], "reasoning": "本論文はバイナリを入力とし、機械学習を用いて最適化された関数呼び出しを復元する手法を提案している。既存デコンパイラの出力を入力として活用し、LLM/ML が中心となって L1–L3 レベルのコード構造（関数呼び出し情報）の再構成・改善を行う点で、Decompiler Enhancement に該当する。したがって含めるべき論文と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3888, "latency_ms": 128359}}
{"key": "WOS:000873911200001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "The DGA data is first mapped to a high-dimensional space.", "explanation": "アブストラクトは入力としてバイナリやアセンブリではなく、変圧器のDGAデータを扱っているため、低水準入力がなく除外基準 EC2 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "the TSSA-RF model is introduced to classify the DGA data", "explanation": "目的はデータの分類・診断であり、コード生成や復元を目的としていないため、再構築意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿は電力変圧器の故障診断を目的としたデータ前処理と機械学習分類手法の提案であり、入力は DGA データという高レベルの測定データです。バイナリやアセンブリといった低水準入力から高水準コードを生成するデコンパイルの要件を満たさず、ML/LLM を用いたコード復元も行っていないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3460, "latency_ms": 118969}}
{"key": "WOS:000875660200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "most feature extraction methods ... lack the decompiled code and execution flow structure of the PE samples", "explanation": "論文はマルウェア検出を目的としており、コードの復元や可読化を行うことが主目的ではなく、分類のための特徴抽出とグラフ学習に焦点を当てているため、復元・生成目的がないと判断した。"}], "reasoning": "本稿はPEファイルから抽出した制御フローグラフを用いたマルウェア検出手法を提案しており、LLMは特徴ベクトル生成に使用されるが、低水準コードから高水準コードへの再構成（デコンパイル）を行う目的が示されていない。したがって、復元・可読化を目的としたデコンパイル研究の対象外であると判断し、除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3334, "latency_ms": 114480}}
{"key": "WOS:000885209600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to distinguish malicious applications from benign applications... we leverage Random Forest (RF) and Convolutional Neural Networks (CNN) to train a ... classifier", "explanation": "アブストラクトはマルウェア検出のための分類器構築が目的であり、コードの復元・生成は行わないため、復元・可読化目的ではなく除外基準 EC3 に該当する"}], "reasoning": "本論文は Android アプリの権限情報と API 呼び出しシーケンスを特徴量として抽出し、機械学習分類器でマルウェアかどうかを判定することが主目的です。LLM/ML は分類器訓練に用いられていますが、低水準コードから高水準コードを生成するデコンパイルやその改善を目的としていません。そのため、復元・コード生成意図がなく除外基準 EC3（No Reconstruction Intent）に該当し、除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3440, "latency_ms": 117606}}
{"key": "WOS:000900131300002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "BinVulDet ... is a binary level vulnerability detection tool for accurate known and unknown vulnerability detection.", "explanation": "論文の目的はバイナリの脆弱性検出であり、デコンパイルは高レベル表現取得の前処理に過ぎず、コード生成・復元が主目的ではないため除外基準 EC3 に該当する。"}], "reasoning": "本研究は低レベルバイナリをデコンパイルして疑似コードを得た上で、BiLSTM‑attention を用いて脆弱性パターンを抽出し検出することが主目的であり、復元や可読化といったコード生成を目的としていない。したがって、ML/LLM が使用されているものの、コード生成意図がなく除外基準 ex_no_code_generation に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3256, "latency_ms": 112389}}
{"key": "WOS:000935184700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Decompilers are indispensable tools in Android malware analysis and app security auditing.", "explanation": "要旨ではデコンパイラの利用や性能評価について述べられているが、機械学習／LLM の使用は言及されておらず、ML を用いないため除外基準 EC1 に該当する。"}], "reasoning": "本稿は既存の Android デコンパイラの性能を大規模に評価する経験的研究であり、機械学習や大規模言語モデルを手法の中心に用いていない。したがって、Decompilation Survey の採択基準（LLM/ML 使用必須）を満たさず、除外 (ex_no_ml) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3295, "latency_ms": 113878}}
{"key": "WOS:000970588900012", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "focus on the variable renaming problem using one such machine learning model, DIRE", "explanation": "論文は変数名の復元（識別子復元）を主目的としており、MLモデルで名前を予測しているため、IC4 に該当する。"}, {"code": "in_decompiler_enhancement", "evidence": "machine learning to predict missing information like variable names", "explanation": "既存のデコンパイラが生成したコードに対し、変数名を付与して可読性を向上させる手法であり、デコンパイラ出力の改善にあたる。"}], "reasoning": "本研究はバイナリからデコンパイルされたコードに対し、ニューラルネットワークを用いて変数名を付与し可読性を高めることを目的としている。入力はデコンパイラ出力（低水準から派生した表現）で、出力は変数名が付与された擬似コード（L2）であるため、L1‑L3 の対象に該当し、ML が中心手法であることから採択基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 4065, "latency_ms": 133018}}
{"key": "WOS:000976384800001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we first decompile the Android application to generate a function call graph (FCG)", "explanation": "アブストラクトではデコンパイルは関数呼び出しグラフ作成のために行われており、最終目的はマルウェア検出であり、コードの復元・生成は行わないため除外基準 EC3 に該当します。"}], "reasoning": "本論文はデコンパイルをマルウェア検出の前処理として利用しており、目的は分類・検知です。復元や高水準コード生成を主目的としていないため、デコンパイルの再構成インテントがなく除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3277, "latency_ms": 115865}}
{"key": "WOS:000985293800001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "This paper aims to detect vulnerabilities via the Bug Injection framework and transfer learning techniques.", "explanation": "目的が脆弱性検出であり、コードの復元・可読化ではなく分類・検知が主目的なので除外基準 EC3 に該当します。"}], "reasoning": "本研究はスマートコントラクトの脆弱性検出を目的としており、ML 手法は検出モデルの学習に用いられています。低水準コードのデコンパイルは入力生成の一部に過ぎず、最終的な出力は脆弱性ラベルであり、L1‑L3 の高水準コード生成を目的としていません。そのため、復元・可読化を主目的とするデコンパイル研究ではなく、除外基準 EC3（コード生成・復元意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3396, "latency_ms": 115212}}
{"key": "WOS:000991628700004", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we improve an existing decompilation tool by leveraging the characteristics of JNI programs", "explanation": "抄録では機械学習や大規模言語モデルの使用が言及されておらず、従来のツール改良だけであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はバイナリを C ソースへデコンパイルして JNI 静的解析を行う手法を提案していますが、機械学習や LLM の利用は示されていません。したがって、除外基準 EC1（ML/LLM 未使用）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3124, "latency_ms": 110800}}
{"key": "WOS:000995629300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we also discuss the importance of preventing client and server decompilation during its implementation", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、単なるプライバシー保護アルゴリズムの説明であるため、ML/LLM未使用として除外"}], "reasoning": "本稿はデータプライバシー保護アルゴリズムの提案であり、デコンパイル技術や機械学習・LLMの活用について述べていない。したがって、Decompilation Survey の対象外（ML/LLM未使用）と判断し除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3188, "latency_ms": 113268}}
{"key": "WOS:000998081700001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "source code is ... represented with tree structures", "explanation": "アブストラクトでは低水準バイナリやアセンブリではなく、Java のソースコード（木構造）を対象としているため、低水準入力がなく除外基準 EC2 に該当します。"}], "reasoning": "本稿は Java ソースコードの構文情報を機械学習で分析することが目的であり、低水準バイナリやバイトコードから高水準表現を復元するデコンパイルとは無関係です。入力が高水準のソースコードであることから、Decompilation Survey の対象外（EC2: No Low-level Input）と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3142, "latency_ms": 112569}}
{"key": "WOS:000998226600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.87, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The experimental result shows that our approach enhances the node feature differences in an FCG, and the detection accuracy is greater than that of models using other features, suggesting that malware detection based on a graph structure and GNNs has a lot of space for future study.", "explanation": "要旨は、機能呼び出しグラフを用いたマルウェア検出精度の向上を目的としており、コード復元や高水準表現の生成ではなく分類が主目的であるため、decompilation の目的を満たさないと判断した。"}], "reasoning": "本論文は decompiled APK から抽出したグラフ特徴を用いたマルウェア検出手法を提案しており、ML の使用は分類モデル（GCN）に限られる。復元・可読化・高水準コード生成といった decompilation の目的がなく、L1‑L3 のコード出力も示されていないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3409, "latency_ms": 117157}}
{"key": "WOS:001005701900019", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "hardware loop rerolling leverages clone detection and program synthesis techniques", "explanation": "抽象からは機械学習／LLM が使用された旨が全く示されておらず、手法はクローン検出とプログラム合成のみなので、ML/LLM 不使用として除外する"}], "reasoning": "本論文はハードウェア・デコンパイルにおけるループ再構成手法を提案しているが、低水準入力（netlist）や HDL 生成という点では対象になるものの、核心手法として機械学習や大規模言語モデルが用いられていないため、Include 基準を満たさず Exclude（ex_no_ml）と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3272, "latency_ms": 116373}}
{"key": "WOS:001027789500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "we decompiled and analysed 420 open-source applications by extending an existing tool", "explanation": "要旨から機械学習やLLMの利用が記載されておらず、従来のツール拡張で解析しているためML/LLMが使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "looking for known energy patterns in applications by decompiling them and analysing the resulting code", "explanation": "目的はエネルギーパターンの検出であり、コードの生成・復元ではなく分類・分析が主であるためコード生成目的ではない。"}], "reasoning": "本稿はデコンパイルしたAPKを静的解析しエネルギーパターンを検出する研究で、機械学習やLLMを用いたコード復元や高水準表現の生成は行っていない。したがって、ML/LLM不使用かつコード生成目的でないことから除外 (ex_no_ml, ex_no_code_generation) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3565, "latency_ms": 119392}}
{"key": "WOS:001038327600001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Our approach ... is non-invasive, since it leverages a process to obtain application's features that does not infringe licenses and terms of use", "explanation": "要旨から、本手法はバイナリやアセンブリといった低水準表現を入力に取らず、非侵襲的に特徴を取得すると明示されているため低水準入力が無いと判断した。"}, {"code": "ex_no_code_generation", "evidence": "we propose an approach to detect Android malware", "explanation": "目的がマルウェア検出であり、コードの復元や生成を主目的としていないため、再構築・コード生成が意図されていないと判断した。"}], "reasoning": "本論文は Android マルウェア検出を目的とした手法で、低水準バイナリやアセンブリを入力とせず、コードの復元や生成も行わないことが要旨から明らかです。したがって、デコンパイル（L1–L3 の出力）に該当せず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3609, "latency_ms": 125299}}
{"key": "WOS:001070689400010", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose BiAn, a source code level smart contract obfuscation method...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、従ってML/LLMを用いていないと判断したため。"}], "reasoning": "本稿はスマートコントラクトのソースコードレベルでの難読化手法を提案しており、デコンパイルや低水準から高水準への変換を目的としていない。さらに、機械学習やLLMの利用が言及されていないため、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2995, "latency_ms": 111354}}
{"key": "WOS:001094893100006", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "A novel program code obfuscation approach involving the x86 mode switching is proposed", "explanation": "要旨に機械学習や大規模言語モデルの使用が示されておらず、単なるコード混乱手法であるためML/LLMを用いていないと判断した。"}], "reasoning": "本稿は x86 モードスイッチングを用いたコード難読化手法を提案し、リバースエンジニアリングツールへの影響を評価しているだけで、ML/LLM を用いたデコンパイル手法は含まれていない。したがって除外基準 EC1 (ex_no_ml) に該当し、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3025, "latency_ms": 116150}}
{"key": "WOS:001102195500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "method implements a Convolutional Neural Network (CNN) for malware classification", "explanation": "抽象からは、目的がランサムウェアの分類であり、コードの復元や高水準表現の生成ではないため、コード生成（復元）を目的としたデコンパイル研究ではないと判断した。"}], "reasoning": "本論文は Android APK を画像化し CNN でランサムウェアかどうかを分類する手法を提案しており、ML は用いられるものの出力は分類ラベルであり、コード復元や高水準表現の生成（L1‑L3）を目的としていない。したがってデコンパイルの再構成目的を満たさず、除外基準 EC3（復元・生成が主目的でない）に該当するため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3242, "latency_ms": 118198}}
{"key": "WOS:001119002600001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we first leverage a decompiling tool to extract multiple features", "explanation": "抄録ではデコンパイルは従来のツールで行われており、ML/LLM の利用は記載されていないため、EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "InfoMap is applied to perform the clustering", "explanation": "目的はマルウェアのクラスタリングであり、コード生成・復元は主目的ではないため、EC3 に該当します。"}], "reasoning": "本論文はデコンパイルツールを用いて特徴を抽出し、得られた特徴でマルウェアをクラスタリングする手法を提案しています。デコンパイル自体に機械学習や大規模言語モデルは使用されておらず、コードの復元や可読化といったデコンパイルの目的も示されていないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3514, "latency_ms": 123734}}
{"key": "WOS:001136012000001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a new method for Android malware classification ... using images ... achieved ... in the classification task", "explanation": "アブストラクトはマルウェアの分類が主目的であり、コードの復元や高水準表現の生成を行わないため、復元・可読化の目的がなく除外します"}], "reasoning": "本論文はAndroidアプリのAPKを画像化しCNNでマルウェアを分類する手法を提案しており、目的は分類精度の向上です。デコンパイルによるコード生成や高水準表現の復元を目的としていないため、除外基準 EC3（復元・生成が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3215, "latency_ms": 119912}}
{"key": "WOS:001166549700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Food chemicals have a fundamental role ... chemoinformatics approaches.", "explanation": "要旨に機械学習・LLMの使用は言及されておらず、従来の化学情報学手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "public food chemical libraries containing up to 26,500 compounds ... more than 70,000 compounds", "explanation": "入力は化学化合物のデータベースであり、バイナリやアセンブリ等の低水準コードではないため、低水準入力が存在しないと判断した。"}], "reasoning": "本論文は食料化学物質の多様性と化学空間の分析を行う化学情報学的研究であり、デコンパイル（低水準コードから高水準表現への変換）や機械学習・LLM を用いたコード再構成とは無関係です。そのため、Include 基準を満たさず、除外基準の『ML/LLM 未使用』および『低水準入力なし』に該当し除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3323, "latency_ms": 120099}}
{"key": "WOS:001174314700019", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "increase the efficiency of detecting functionally similar fragments of program code", "explanation": "アブストラクトはコードの類似性検出を目的としており、復元・可読化・高水準意味回復が主目的ではないため、コード生成（復元）目的がないと判断した"}], "reasoning": "本論文はバイナリから疑似コードを生成し、その疑似コードを用いて機械学習で類似性検出を行う手法を提案しています。目的は類似フラグメントの検出であり、復元や可読化といったデコンパイルの主目的とは異なるため、除外基準 EC3（コード生成目的がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3300, "latency_ms": 124322}}
{"key": "WOS:001191292200001", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.82, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "decompile the reservoir's internal representation and dynamics into an analytic basis of its inputs", "explanation": "抽象的な内部表現を解析的基底へ変換しており、従来のバイナリやアセンブリ等の低水準コードから L1–L3 のソース/擬似コードを生成するデコンパイルとは異なるため、本バージョンの対象外（L4‑only相当）と判断した。"}], "reasoning": "本稿はリザーバコンピュータの内部状態を解析的に表現することに焦点を当てており、従来のバイナリ/アセンブリ等の低水準入力からコンパイル可能なコードや擬似コードを生成するデコンパイル研究とは範囲が異なる。出力はコード生成ではなく理論的な表現であり、L1–L3 の出力要件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3579, "latency_ms": 126785}}
{"key": "WOS:001208845200025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach is based on automated program transformation to manipulate Java bytecode", "explanation": "本文・要旨からは機械学習・LLMの利用が全く示されておらず、従来のプログラム変換手法のみが記述されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は Java バイトコードのデバッグ攻撃緩和を目的とした自己デバッグ方式の提案であり、ML/LLM を用いたデコンパイルやコード生成は行われていない。デコンパイルの定義（低水準入力から高水準コード生成）にも合致せず、除外基準 EC1（ML/LLM 未使用）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3415, "latency_ms": 121235}}
{"key": "WOS:001209927600050", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We conduct the study by investigating 333 unique bugs from three popular Java decompilers.", "explanation": "抽象からは機械学習・LLM の利用が全く言及されておらず、従来の手法のみでバグ調査を行っているため、ML/LLM 不使用と判断し除外しました。"}], "reasoning": "本稿は Java デコンパイラのバグ分析とテストフレームワークの提案であり、ML/LLM を中心手法として用いていない。したがって、Include Criteria を満たさず Exclude Criteria の ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3372, "latency_ms": 116619}}
{"key": "WOS:001217002000001", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "suggest variable names for decompiled code", "explanation": "論文は変数名の提案という属性（L4）だけを出力しており、L1–L3 のソースや擬似コード・AST といった高水準表現を生成しないため、対象外と判断した。"}], "reasoning": "本研究は統計的機械翻訳を用いてデコンパイルされたコードの変数名を推測することに焦点を当てているが、出力は変数名という属性情報のみであり、コンパイル可能なソースコードや擬似コード、AST などの L1–L3 出力を提供しない。したがって、本バージョンの採択基準（L1–L3 のみ）に該当せず除外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3706, "latency_ms": 127971}}
{"key": "WOS:001237837300001", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "this article offers a thorough examination and organized summary of the pertinent material of smart contract security analysis", "explanation": "本文はスマートコントラクトセキュリティの調査・レビューであり、研究手法や新規デコンパイル手法を提示していないため、サーベイ論文として除外します。"}], "reasoning": "タイトルとアブストラクトから、この論文はスマートコントラクトのセキュリティに関する包括的サーベイであり、デコンパイルやML/LLM を用いた手法の提案・評価が中心ではありません。そのため除外基準 EC4（Survey/Review）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2989, "latency_ms": 112357}}
{"key": "WOS:001247013900001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we carried out both a dynamic and a static analysis of decompiled Locker.CB!tr ransomware source code", "explanation": "要旨に機械学習や大規模言語モデルの利用が記載されておらず、従来の動的/静的解析のみであるため、ML/LLM未使用として除外"}, {"code": "ex_no_code_generation", "evidence": "the novelty of our approach lies on exploiting the communication ... to fully impersonate the command and control server", "explanation": "目的はランサムウェアの復旧・制御奪取であり、コードの復元や生成が主目的ではないため、復元意図がなく除外"}], "reasoning": "本稿は低水準バイナリからのデコンパイルやコード生成を目的とせず、動的・静的解析と C&C 通信の模倣によるランサムウェア復旧手法を提案している。要旨に機械学習・LLM の利用が示されていないことと、コード生成・復元が目的でないことから、除外基準 EC1 と EC3 に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3619, "latency_ms": 127774}}
{"key": "WOS:001256552500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detects malware but also classifies its variants with a high degree of accuracy", "explanation": "アブストラクトはマルウェア検知・分類が目的であり、コード生成や復元（L1–L3）の記述がなく、復元・可読化が主目的ではないため除外"}], "reasoning": "本稿はバイナリリフティングで抽出したIR opcode を用いて機械学習によりマルウェアの検知・バリアント分類を行うもので、コード生成や高水準表現の復元を目的としていない。したがってデコンパイルの目的・出力条件を満たさず、除外基準 EC3（No Reconstruction Intent）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3094, "latency_ms": 118195}}
{"key": "WOS:001263763900001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "this paper proposes a two-layer general framework for Android malware classification and adversarial training", "explanation": "要旨はマルウェアの分類と変種生成によるデータ拡張であり、コードの復元・生成が主目的ではないため除外基準 EC3 に該当します"}], "reasoning": "本稿は低水準バイナリから高水準コードを復元することを目的としておらず、主にマルウェアの分類と変種生成（データ増幅）に焦点を当てています。そのため、復元・可読化を目的としたデコンパイル研究ではなく、除外基準 EC3（コード生成・復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3452, "latency_ms": 125184}}
{"key": "WOS:001320166600005", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The presented graph methods have been implemented in C++ as a part of a decompilation program", "explanation": "本文はグラフ手法をC++で実装しており、機械学習や大規模言語モデルの使用が言及されていないため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文はトランジスタレベル回路をゲートレベルへ変換する手法を提案しているが、使用技術は C++ 実装のグラフアルゴリズムであり、機械学習や LLM が中心手法として記述されていない。したがって、Decompilation Survey の包括基準（ML/LLM 使用必須）を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3035, "latency_ms": 118337}}
{"key": "WOS:001322090400005", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a PLC decompile framework named CLEVER, which can analyze the control application and extract the control logic.", "explanation": "要旨ではML/LLMの利用について言及がなく、手法はシミュレーション実行、データフロー解析、順次パースといった従来の解析手法のみであるため、ML/LLMを用いていないと判断した。"}], "reasoning": "本論文はPLCの制御ロジックを解析・再構築するフレームワークを提案していますが、手法はシミュレーション実行やヒューリスティックデータフロー解析に基づくもので、LLM/MLを中心としたアプローチが記載されていません。そのため、Include基準のIC0（ML/LLMが中核手法）を満たさず、除外基準EC1に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3157, "latency_ms": 118219}}
{"key": "WOS:001332656400001", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "We present a pre-trained sequence-to-sequence model called IRaDT tailored to refine decompilation outputs at the intermediate representation level.", "explanation": "抽象的に既存デコンパイラの出力（IR）をMLモデルで改善し、LLVM IRというL3レベルの高水準表現を生成しているため、Decompiler Enhancement に該当する。"}], "reasoning": "本稿はバイナリから生成された低水準出力を、LLMベースのシーケンス‑ツー‑シーケンスモデルで LLVM IR（L3）に再構成・可読性向上させる手法を提案している。入力は低水準バイナリであり、MLが中心手法として用いられ、最終的にコンパイル可能な高水準IRを出力する点が、インクルード基準を全て満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3646, "latency_ms": 129448}}
{"key": "WOS:001336094300001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we can fingerprint reused functions, within stripped binaries, across processor architectures", "explanation": "要旨は関数の指紋付け（同定）であり、復元・高水準コード生成が目的ではなく、分類・検出が主目的なので除外基準 EC3 に該当する"}], "reasoning": "本稿は Ghidra の SLEIGH デコンパイラと ML 手法を組み合わせてバイナリ関数の指紋付けを行うもので、復元や可読化といったコード生成を目的としていません。そのため、デコンパイルの再構成目的 (IC) を満たさず、除外基準 EC3（コード生成・再構成が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3035, "latency_ms": 120780}}
{"key": "WOS:001350308700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Static taint analysis is a widely used method to identify vulnerabilities in Android applications.", "explanation": "本文・要旨では機械学習や大規模言語モデルの使用について言及されておらず、従来の静的解析手法のみが記述されているため、ML/LLM を用いていないと判断しました。"}], "reasoning": "本論文は Android アプリの静的 taint 解析手法を提案しており、ML/LLM を用いたデコンパイル手法とは無関係です。デコンパイルは手段の一部として言及されるだけで、ML を中核に据えたコード復元や高水準表現生成は行っていません。したがって除外基準 EC1 (No ML/LLM) に該当し、exclude とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3281, "latency_ms": 119108}}
{"key": "WOS:001368390400002", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "REMaQE automated framework for reverse engineering of math equations", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用が全く言及されておらず、ML手法が用いられていないと判断したため"}, {"code": "ex_out_of_scope", "evidence": "REMaQE successfully recovers a semantically matching equation for all 25,096 binaries", "explanation": "出力が数式（semantic equation）のみであり、コンパイル可能なソースや擬似コード等の L1‑L3 に該当するコード表現ではなく属性情報（L4）に留まるため"}], "reasoning": "本論文はバイナリから数学的方程式を抽出するフレームワークを提案しているが、機械学習・LLM の利用が示されていない上、出力はコードではなく数式という高レベル属性にとどまる。したがって、Decompilation Survey の対象である L1‑L3 のコード生成型デコンパイルとは範囲が合わず、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3847, "latency_ms": 132906}}
{"key": "WOS:001377798100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify vulnerabilities in Android applications... analysis of security logs", "explanation": "LLM は脆弱性の識別やログ解析を支援することが主目的であり、コードの復元・生成を目的としていないため、復元志向がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿は LLM を用いてセキュリティアナリストの支援を行うことに焦点を当てており、低水準バイナリから高水準コードを生成するデコンパイル目的ではありません。したがって、復元・生成を目的とした IC を満たさず、除外基準 EC3（コード生成・復元意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3125, "latency_ms": 119387}}
{"key": "WOS:001397990500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we introduce a decoding algorithm that utilizes a sliding window approach", "explanation": "摘要ではスライディングウィンドウ方式のデコードアルゴリズムを述べており、機械学習・LLM の使用は示されていないため除外です。"}, {"code": "ex_out_of_scope", "evidence": "first paper to disclose a decompression method for commercial FPGAs", "explanation": "対象はビットストリームの圧縮解除であり、L1–L3 の高水準コード生成や再構成ではなく属性のみ（L4）であるため本サーベイの対象外です。"}], "reasoning": "本稿は FPGA ビットストリームの圧縮解除手法を提案しており、機械学習や大規模言語モデルを用いた手法ではありません。また出力は圧縮解除されたバイナリであり、L1–L3 の高水準コードや AST などの出力を提供しないため、デコンパイル調査の対象外（L4‑only）と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3295, "latency_ms": 123915}}
{"key": "WOS:001403092200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "code similarity detection identifies code by analyzing similarities ... hierarchical LSTM-attention network to facilitate the representation and similarity measurement of functions", "explanation": "アブストラクトはコードの類似性測定が目的であり、復元やソースコード生成を行わず、コード生成（L1‑L3）の出力は示されていないため"}], "reasoning": "本稿はバイナリとソースの表現統合によるコード類似性検出を目的としており、デコンパイルによる高水準コードの生成や復元を行う研究ではない。出力は埋め込み表現であり、L1‑L3 のコード生成が含まれないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3518, "latency_ms": 124805}}
{"key": "WOS:001420041900001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "VARLIFTER interprets every read or written field of a data region as at least one potential variable", "explanation": "抽象からは機械学習やLLMの使用が言及されておらず、手法は決定的な解析に基づくためML/LLMが使用されていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "recovering variables and their types from Solidity bytecode", "explanation": "出力は変数名と型という属性情報（L4）であり、L1‑L3 のコード生成や擬似コード等の高水準表現を提供していないため除外対象となる。"}], "reasoning": "本論文はバイトコードから変数と型情報を回復することに焦点を当てており、機械学習やLLMを用いた手法の記述がない上で、出力もコードやASTではなく属性情報のみである。したがって、Decompilation Survey の対象である L1‑L3 の出力を伴うML/LLMベースのデコンパイル研究には該当せず、除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3880, "latency_ms": 132007}}
{"key": "WOS:001429826200001", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "extracting standard .NET method names... used as features for detecting .NET malware", "explanation": "出力はメソッド名という属性のみで、L1–L3 のコード再構成やコンパイル可能なソースは提供していないため L4‑only と判断し除外する"}, {"code": "ex_no_ml", "evidence": "The results indicate that XGBoost outperforms the other models... for malware detection", "explanation": "機械学習はマルウェア検出の分類に使用されており、デコンパイル自体に ML/LLM が用いられていないため除外基準に該当する"}], "reasoning": "本稿は .NET 実行ファイルをデコンパイルして得たメソッド名を特徴量としてマルウェア検出を行う分類タスクであり、デコンパイルの目的はコードの復元や可読化ではなく属性抽出です。出力はコードそのものではなく属性（メソッド名）に留まり、ML は検出モデルにのみ使用されているため、L1–L3 のデコンパイル研究対象外（L4‑only）と判断して除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3638, "latency_ms": 129449}}
{"key": "WOS:001448323100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "introduces a novel malware detection approach utilizing an ensemble of Convolutional Neural Networks (CNNs) for enhanced classification accuracy", "explanation": "抽象から分かるように、ML はマルウェアの分類（検出）を目的としており、コードの復元・可読化などの生成（L1‑L3 出力）を意図していないため除外基準 EC3 に該当する"}], "reasoning": "本論文は Android アプリをデコンパイルしてバイトコード化する前処理はあるものの、主たる目的は CNN によるマルウェアの分類であり、デコンパイルによる高水準コード生成や復元は行っていない。したがって、復元・生成を目的としない点で除外基準 EC3（No Reconstruction Intent）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3207, "latency_ms": 118104}}
{"key": "WOS:001450844300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Step 1 ... undergoes decompilation to convert it into source code. ... training and evaluating the ability to detect Android malware based on popular machine learning algorithms", "explanation": "ML/LLM はマルウェア検出の分類にのみ使われており、デコンパイル自体は従来のツールで行われているため、デコンパイルのコア手法として ML が使われていない。"}, {"code": "ex_no_code_generation", "evidence": "Finally, training and evaluating the ability to detect Android malware based on popular machine learning algorithms", "explanation": "論文の目的はコード生成や再構成ではなく、APK のマルウェア分類であり、復元・可読化が主目的ではないため除外基準 EC3 に該当する。"}], "reasoning": "本稿はデコンパイルを前処理として利用し、ML はマルウェア検出の分類モデル構築に用いている。デコンパイル自体の生成や改善を目的とした LLM/ML 手法が提示されていないため、インクルード基準を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3828, "latency_ms": 128832}}
{"key": "WOS:001470367300014", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "CF-GKAT ... suitable for the verification of control-flow manipulating procedures, such as decompilation and goto-elimination.", "explanation": "要旨に機械学習・LLM の利用について言及がなく、純粋に代数的手法で検証を行うため、ML/LLM を使用していないと判断した。"}], "reasoning": "本稿は低水準バイナリを高水準コードに変換することを目的としたデコンパイル手法ではなく、代数的検証フレームワークを提案している。抽象だけでは ML/LLM の利用は確認できず、デコンパイルのコア生成に関わらないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3089, "latency_ms": 117160}}
{"key": "WOS:001488140900040", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "PRD lifts suspect binary functions to source, ... and creates a patched binary using source- and binary-level techniques.", "explanation": "本文はバイナリ関数をソースへ変換し、ソース・バイナリ手法で修正すると述べており、ML/LLM の利用は示されていないため除外と判断した。"}], "reasoning": "本論文はバイナリ関数をソースコードにデコンパイルし、手動または自動修正を行う手法を提案しているが、機械学習や大規模言語モデルを中核手法としている記述がない。したがって、ML/LLM 不使用のため除外（ex_no_ml）となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3404, "latency_ms": 121790}}
{"key": "WOS:001498227900001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "existing static methods mainly rely on taint analysis, which has high overhead and high false alarm rates.", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、従来のタイント解析のみを述べているため、ML/LLM が用いられていないと判断し、EC1 に該当します。"}], "reasoning": "本稿はIoTデバイス向けの指向性ファジング手法を提案しており、デコンパイルされたコード上でのデータフロー解析を利用していますが、機械学習や大規模言語モデルを用いた手法は記述されていません。そのため、ML/LLM 不使用という除外基準 EC1 に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3232, "latency_ms": 120858}}
{"key": "WOS:001503249300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our method utilizes the Ghidra decompiler in conjunction with a custom-built transpiler to reconstruct highlevel C++ source code from binary executables.", "explanation": "抄録に機械学習・大規模言語モデルの使用が記載されておらず、従来のデコンパイラと独自トランスパイラだけで実装されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はバイナリから高水準 C++ ソースを復元するデコンパイル技術を利用しているが、機械学習や大規模言語モデルを手法の中核として用いている記述がなく、ルールベース／ツールベースのアプローチに留まっている。したがって、ML/LLM が欠如している点で除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3331, "latency_ms": 121181}}
{"key": "WOS:001517603500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "classify compiler versions using compiled executable files", "explanation": "目的はバイナリからコンパイラバージョンを分類することであり、コードの復元・可読化といった生成目的ではないため除外と判断した。"}], "reasoning": "本稿はバイナリを逆コンパイルして得たアセンブリを特徴量として利用し、機械学習でコンパイラバージョンを分類することが主目的です。復元や高水準コード生成を目指すデコンパイルではなく、分類タスクに焦点を当てているため、Decompilation Surveyの採択基準（IC）を満たさず、除外基準 EC3 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3271, "latency_ms": 121019}}
{"key": "WOS:001539888300001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.85, "reason_codes": [{"code": "in_core", "evidence": "decompilation, source code analysis, automated translation using ChatGPT", "explanation": "抽象的に低水準コードをデコンパイルし、LLM が直接高水準の Python ソースを生成しているため、Core Decompilation に該当する。"}], "reasoning": "本論文はレガシーなバイナリをデコンパイルし、LLM（ChatGPT）を用いて Python へのソースコード変換（L1）を行う手法を提案しており、低水準入力と LLM/ML を中核とした復元目的が明示されている。したがって、L1–L3 の出力を伴う Core Decompilation 研究として採択対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3487, "latency_ms": 127815}}
{"key": "WOS:001551990000001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Obfuscated SCs resist decompilation by tools such as Objdump", "explanation": "本文はML/LLMを用いたデコンパイル手法ではなく、デコンパイル耐性を示す防御手法であり、ML/LLMの利用がないため除外"}], "reasoning": "本論文は産業制御システム向けの防御モデルを提案しており、ブロックチェーンやゼロ知識証明、スマートコントラクトの難読化を通じてデコンパイル耐性を高めることが目的です。ML/LLM を用いた低水準コードから高水準コードへの復元研究ではなく、デコンパイル防止が主旨であるため、Include 基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3290, "latency_ms": 122587}}
{"key": "WOS:001556094500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present novel techniques for estimating the number, as well as the boundaries, of compile-units in binary executables", "explanation": "要旨に機械学習や大型言語モデルの利用が記載されておらず、従来のアルゴリズムによる手法と示されているため除外します。"}, {"code": "ex_out_of_scope", "evidence": "recovering object files from stripped binary executables ... recover information that improves the precision degree in reverse engineering tasks", "explanation": "出力はオブジェクトファイルの境界情報のみで、L1–L3 のコードや擬似コード・AST などの高水準表現ではなく属性情報（L4）に留まるため除外します。"}], "reasoning": "本論文は低水準バイナリからコンパイル単位（オブジェクトファイル）の境界情報を推定する手法を提案しているが、機械学習やLLM を用いた手法は示されていない。また、生成物は高水準コードや擬似コードではなく構造的メタ情報にとどまるため、L1–L3 の出力要件を満たさず除外対象となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3574, "latency_ms": 125183}}
{"key": "WOS:001560856600001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We developed an aramid-fiber decompilation/reconstruction process using ultrasound-assisted hydrothermal cracking", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、純粋に材料加工手法を述べているため、ML/LLM が利用されていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "decompilation/reconstruction process using ultrasound-assisted hydrothermal cracking to produce platelet nanofibers", "explanation": "「デコンパイル」という語は材料分解を指しており、プログラムコードの低水準表現から高水準表現への変換とは無関係であるため、本サーベイの対象外（L4‑only でもない）と判断した。"}], "reasoning": "本研究は材料工学における構造再構築手法を扱っており、プログラムコードのデコンパイルや機械学習・LLM の利用が全く示されていない。そのため、デコンパイル調査の範囲外とし、除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3352, "latency_ms": 122146}}
{"key": "WOS:001561843400001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "proposes ... hybrid malware detection model", "explanation": "概要はマルウェア検出モデルの提案であり、復元・可読化を目的としたコード生成は行わないため除外と判断した。"}, {"code": "ex_no_ml", "evidence": "text-based methods for malware detection face decompilation errors due to obfuscation", "explanation": "ML/LLM は検出タスクに用いられているが、デコンパイル（低水準から高水準コード生成）には使用されていないため除外の補足理由とした。"}], "reasoning": "本稿はマルウェア検出のためのハイブリッドモデルを提案しており、低水準バイナリから高水準コードを生成するデコンパイル目的の手法は示されていない。ML は検出タスクに利用されているが、復元・可読化を主目的とする出力は存在しないため、除外基準 EC3（コード生成なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3543, "latency_ms": 127332}}
{"key": "WOS:001566975200005", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This survey provides an extensive evaluation of recent AI-based reverse engineering techniques...", "explanation": "アブストラクトが調査論文（survey）であると明示しているため、除外基準 EC4 に該当します。"}], "reasoning": "本文は AI を用いたリバースエンジニアリング全般の調査・レビューであり、実装されたデコンパイル手法の提案や評価を行っていないため、除外基準 EC4（Survey/Review）に該当します。したがって、L1‑L3 のデコンパイル研究としては採択対象外です。", "model": "openai/gpt-oss-120b", "tokens_used": 2934, "latency_ms": 117162}}
{"key": "WOS:001571912000001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "ensemble-based classification", "explanation": "アブストラクトはマルウェア検出のための分類器を中心に述べており、コードの復元・生成が目的ではないため EC3 に該当し除外します。"}], "reasoning": "本稿は Android アプリのマルウェア検出を目的としたフレームワークであり、低水準コードから高水準コードを生成するデコンパイルは行わない。ML/LLM は検出モデルに使用されているが、復元・可読化というデコンパイルの目的がなく、コード生成が主目的でないため除外基準 EC3（No Reconstruction Intent）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3500, "latency_ms": 126788}}
{"key": "WOS:001597451300043", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "blockchain-integrated trusted detection framework for ICS (BCTD-ICS)", "explanation": "要旨ではブロックチェーンとゼロ知識証明を用いた検出フレームワークを提案しており、ML/LLM の利用は言及されていないため、EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "privacy leakage risks caused by decompilation techniques and integrity verification deficiencies in reverse engineering", "explanation": "本研究の目的はコードの検出・トレーサビリティであり、復元・コード生成が主目的ではなく、分類・検出が中心であるため EC3 に該当します。"}], "reasoning": "本稿は産業制御システムのコード検出とプライバシー保護をブロックチェーン技術で実現することを目的としており、ML/LLM を用いたデコンパイル手法の提案や実装は含まれていません。そのため、デコンパイル（L1–L3）に関する本サーベイの対象外と判断し除外しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3331, "latency_ms": 122588}}
{"key": "WOS:001616881300004", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "This research presents a novel MalSFF: Multi-Architecture Malware Detection Using Multi-Static Feature Fusion Based on visual image analysis and transfer learning.", "explanation": "要旨はマルウェア検出が目的であり、コードの復元や高水準表現の生成は行っていないため、復元・生成意図がなく除外基準 EC3 に該当する。"}], "reasoning": "本論文はバイナリを逆アセンブルして画像化し、転移学習でマルウェア分類を行う手法を提案しているが、デコンパイルの目的は可読化やコード生成ではなく特徴抽出に過ぎない。したがって、復元・可読化を主目的とするインクルード基準を満たさず、除外基準 EC3（コード生成・復元意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3314, "latency_ms": 122952}}
{"key": "WOS:001623665300001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "end-to-end decompilation method based on large language models (LLMs) converts assembly code back into high-level source", "explanation": "抽象から、LLM を中心手法として低水準のアセンブリを入力とし、直接高水準ソースコード（L1）を生成しているため、Core Decompilation に該当する"}], "reasoning": "本論文は低水準のアセンブリを入力とし、LLM によるエンドツーエンド手法で高水準ソースコードを生成することを目的としている。出力はコンパイル可能なコード（L1）であり、復元・可読化というデコンパイル目的を満たす。したがって、Include 基準をすべて満たすため採択候補と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3381, "latency_ms": 127296}}
{"key": "WOS:001631663000010", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "labels each instruction as Inlined or Not inlined and recovers the inlined-function boundaries", "explanation": "アブストラクトはインライン検出と境界復元をラベル付けとして述べており、ソースコードや擬似コードなど L1–L3 の高水準表現を生成することは示されていないため、復元・コード生成が主目的ではなく分類タスクに留まると判断した。"}], "reasoning": "本論文はバイナリ内のインライン関数を検出し境界をラベル付けすることに焦点を当てており、LLM/MLは使用されているものの、低水準入力からコンパイル可能なコードや擬似コードなど L1–L3 の出力を生成していない。したがって、デコンパイル（コード生成）を目的とした研究ではなく、分類タスクに該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3553, "latency_ms": 128029}}
{"key": "WOS:001639031400025", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "enhances decompiler output by combining static analysis (SA) and large language models (LLM)", "explanation": "LLM を用いて既存デコンパイラの出力を改善している点が IC2 (Decompiler Enhancement) に該当するため"}, {"code": "in_type_recovery", "evidence": "precision of 90.40% ... for variable types", "explanation": "変数型の復元精度向上が主要評価項目であり、型回復 (Type Recovery) を目的としているため"}], "reasoning": "本稿は Solidity バイトコードから生成されたデコンパイラ出力を、静的解析で得た依存関係情報と LLM により最適化し、コードや型情報を高品質に再構成する手法を提案している。入力は低水準のバイトコード由来の出力、出力は L1–L3 レベルの再構成コードであり、LLM が中心手法として用いられているため、Include 基準を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3644, "latency_ms": 129520}}
{"key": "WOS:001641511700015", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.87, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "producing detailed and interpretable Android malware analysis reports", "explanation": "アブストラクトではLLMが生成するのはマルウェア分析レポートであり、コード（L1‑L3 の高水準表現）ではないため、デコンパイルの対象外となります。"}, {"code": "ex_no_code_generation", "evidence": "generating precise malware reports", "explanation": "目的はレポート生成であり、コード生成や復元を行わないため、復元・可読化というデコンパイルの目的を満たしていません。"}], "reasoning": "本論文はLLMを用いて Android マルウェアの分析レポートを生成することを目的としており、出力は自然言語のレポートでありコードや擬似コードではありません。したがって、L1‑L3 の高水準コード生成というデコンパイルの定義を満たさず、対象外 (ex_out_of_scope) と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3599, "latency_ms": 130397}}
{"key": "WOS:001657340000001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "binary decompilation model based on fine-tuned large language models designed to generate high-precision decompiled code", "explanation": "LLM を中核手法として低水準バイナリから高水準コード（コンパイル可能）を直接生成しているため、Core Decompilation に該当する。"}, {"code": "in_core", "evidence": "compilation success rate, functional correctness", "explanation": "生成されたコードのコンパイル成功率や機能的正しさを評価していることから、出力は L1（コンパイル可能なソース）であると判断できる。"}], "reasoning": "本論文はバイナリを入力とし、ファインチューニングした大規模言語モデルで直接高精度のデコンパイルコードを生成する手法を提案している。LLM が手法の中心にあり、生成物はコンパイル可能なソースコードであることが示されているため、L1–L3 の対象範囲に該当し、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3391, "latency_ms": 125185}}
{"key": "WOS:001662944300026", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "outputs highly structured meta-level attributes of cryptographic functions via a large language model (LLM)", "explanation": "LLM が出力するのは属性情報のみで、L1–L3 のコードや疑似コードは生成されていないため L4‑only と判断し除外する。"}, {"code": "ex_no_code_generation", "evidence": "detects vulnerabilities through a query-driven approach", "explanation": "目的が脆弱性検出・分類であり、コード復元・生成が主目的ではないため除外する。"}], "reasoning": "本稿はデコンパイルで高水準コードを生成することを目的としておらず、LLM は属性情報や脆弱性検出結果を出力するだけです。出力は L4 レベル（属性）のみであり、L1–L3 のコード生成がないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3758, "latency_ms": 133748}}
{"key": "Wu2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.85, "reason_codes": [{"code": "in_core", "evidence": "decompiling assembly code", "explanation": "アブストラクトは ChatGPT がアセンブリコードを直接デコンパイルし高水準コードを生成することを示しており、LLM が低水準入力から L1‑L3 の出力を生成するコアデコンパイルに該当します。"}], "reasoning": "本稿は LLM（ChatGPT）を用いてアセンブリという低水準入力からコードを生成するデコンパイルを評価しており、目的も復元・可読化に焦点があるため、L1‑L3 の出力を伴うコアデコンパイル研究と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3624, "latency_ms": 131689}}
{"key": "Wu2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We presented a novel framework for empirically evaluating C-based decompilers", "explanation": "要旨にML/LLMの利用について言及がなく、従来のデコンパイラ評価手法のみを述べているため、ML/LLMを使用していないと判断した"}], "reasoning": "本稿はWebAssemblyバイナリからのデコンパイル結果を評価する比較研究であり、ML/LLMを用いたデコンパイル手法の提案や活用は示されていない。そのため、ML/LLMが中心手法であるというインクルード基準を満たさず、除外基準の『No ML/LLM』に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3126, "latency_ms": 122798}}
{"key": "Xie2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "reverse-engineering high-level quantum algorithms from low-level circuit representations", "explanation": "低水準の量子回路表現（量子アセンブリ）を入力として、遺伝的プログラミングを核とした手法で高水準の Qiskit アルゴリズム（ソース）を生成しているため、Core Decompilation に該当します。"}, {"code": "in_core", "evidence": "genetic programming‑based decompiler framework", "explanation": "遺伝的プログラミングは機械学習手法の一種であり、ML が中心手法として用いられていることを示しています。"}], "reasoning": "本稿は低水準の量子回路（量子アセンブリ）を入力とし、遺伝的プログラミングやシンボリック回帰といった機械学習ベースの手法で高水準の Qiskit ソースコードを復元するという、デコンパイルの核心目的を満たしています。出力はコンパイル可能なソースコード（L1）であり、IC の全要件を満たすため採択対象と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3264, "latency_ms": 125969}}
{"key": "Xu2024", "action": "keep", "reason": "uns_unclear_output", "details": {"decision": "uncertain", "confidence": 0.62, "reason_codes": [{"code": "uns_unclear_output", "evidence": "recover variable names ... improves the state-of-the-art name recovery precision", "explanation": "アブストラクトでは変数名の復元を目的としているが、出力がソースコード全体（L1）や擬似コード（L2）なのか、名前だけ（L4）なのかが明示されていないため、出力レベルが不明です。"}, {"code": "uns_unclear_method", "evidence": "leverage the strengths of generative models ... pre-trained generative models CodeGemma-2B, CodeLlama-7B", "explanation": "LLM／ML の使用は示唆されているが、具体的にデコンパイル工程でどのように組み込んでいるかが抽象的で、方法の中心性が判明しにくいです。"}], "reasoning": "本論文はストリップドバイナリから変数名を復元することを目的としており、LLM を用いた手法が述べられていますが、出力が L1–L3 のコード全体か単なる名前情報（L4）のみかが抽象からは判断できません。そのため、出力レベルと手法の中心性が不明確であり、判断を保留します。", "model": "openai/gpt-oss-120b", "tokens_used": 4037, "latency_ms": 139174}}
{"key": "You2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "depyf decompiles bytecode generated by PyTorch back into equivalent source code", "explanation": "アブストラクトはデコンパイル機能のみを述べており、ML/LLM を用いた手法についての記載がないため、ML/LLM 不使用として除外します。"}], "reasoning": "本稿は Python バイトコードをソースコードに変換するツールを紹介しているが、機械学習や大規模言語モデルを手法の中心に用いている記述がない。したがって、Include 基準の「LLM/ML が中核手法として使われている」を満たさず、除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3179, "latency_ms": 123974}}
{"key": "Zhang2026", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "make use of on-the-fly symbolic techniques via SAT solvers", "explanation": "本文はSATソルバーを用いたシンボリック手法を述べており、ML/LLM の利用が示されていないため、EC1 に該当します。"}, {"code": "ex_out_of_scope", "evidence": "efficient decision procedures for trace equivalence of GKAT automata", "explanation": "対象はGKAT オートマトンの等価性判定であり、デコンパイル（低水準コードから高水準コード生成）とは無関係なので、L1–L3 の範囲外です。"}], "reasoning": "本稿は GKAT オートマトンのトレース等価性判定手法を提案しており、ML/LLM を使用したデコンパイルとは無関係です。また、入力は低水準バイナリやアセンブリではなく形式的オートマトンであり、出力もコード生成ではなく判定結果です。したがって、除外基準 (EC1: No ML/LLM, EC5: Out of scope) に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3403, "latency_ms": 130544}}
{"key": "Zhou2025", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.62, "reason_codes": [{"code": "uns_unclear_input", "evidence": "enhances decompiled code accuracy and readability", "explanation": "アブストラクトではバイナリやアセンブリといった低水準入力について言及されておらず、入力が低水準かどうかが不明なため"}], "reasoning": "本稿はLLM（RAG）を用いて既存のデコンパイル結果を改善する手法を提案しているが、入力が機械語・バイナリなどの低水準表現であることが明示されていない。低水準入力の有無が判定できないため、現時点では include も exclude もできず uncertain とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3767, "latency_ms": 134975}}
{"key": "Zhou2025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "we conduct a benchmark-driven evaluation of decompilation quality", "explanation": "抄録にML/LLMを用いた手法の記述がなく、従来のデコンパイラ評価のみを行っているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はRustバイナリのデコンパイル品質を評価する実証研究であり、手法として機械学習や大規模言語モデルを使用していない。デコンパイル手法そのものの提案やLLM/ML を中核とした復元は含まれないため、除外基準 EC1（ML/LLM 不使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3017, "latency_ms": 123753}}
{"key": "Zou2025", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "LLMs to refine decompiler output", "explanation": "LLM が既存のデコンパイラ出力を入力に取り、可読性と正確性を向上させることが目的であるため、デコンパイラ出力の改善（Decompiler Enhancement）に該当する。"}], "reasoning": "本論文はバイナリから得られるデコンパイラの出力（ソースコード）を LLM で再構成・改善し、L1（コンパイル可能なソース）レベルの出力を提供している。LLM が手法の中核であり、復元・可読化が主要目的であることから、Include 基準の IC2 (Decompiler Enhancement) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3433, "latency_ms": 127453}}
