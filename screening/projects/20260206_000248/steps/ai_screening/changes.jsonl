{"key": "10.1109/ASE.2019.00064", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_input", "evidence": "uses both lexical and structural information recovered by the decompiler", "explanation": "本文だけでは、ML 手法が直接バイナリやアセンブリといった低水準表現を入力に取っているかが不明であり、低水準入力の有無が判断できないため不確かとした。"}], "reasoning": "要旨は LLM/ML を用いた変数名復元モデルを提案している点で目的はデコンパイル支援に該当し、手法も機械学習であるが、入力がバイナリ等の低水準表現なのか、デコンパイラの出力（擬似コード）だけかが明示されていないため、採択基準の IC0 を満たすか判定できない。したがって現時点では uncertain とし、入力情報の明確化が必要である。", "model": "openai/gpt-oss-120b", "tokens_used": 3807, "latency_ms": 52430}}
{"key": "10.1109/ASE56229.2023.00099", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.6, "reason_codes": [{"code": "uns_unclear_input", "evidence": "Decompilation is a widely used process ... lifting assembly code to a higher-level C-like language, pseudo-code.", "explanation": "抄録だけでは、HexT5 が直接バイナリやアセンブリを入力としているかは明示されておらず、入力が低水準表現かどうかが不明です。"}, {"code": "uns_unclear_output", "evidence": "downstream tasks, including code summarization, variable name recovery, function name recovery, and similarity detection.", "explanation": "出力がコード要約や名前復元（属性レベル）であることは分かりますが、L1‑L3 の高水準コード生成かどうかは判別できません。"}], "reasoning": "抄録からは、HexT5 が低水準のバイナリ/アセンブリを直接入力として受け取り、LLM/ML を用いて高水準コードや属性を生成することが明確に示されていません。そのため、インクルード基準の IC0（低水準入力）が満たされているか判断できず、保留（uncertain）とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3590, "latency_ms": 42984}}
{"key": "10.1109/CGO57630.2024.10444788", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "Small Language model Decompiler based on a sequence-to-sequence Transformer trained over real‑world code", "explanation": "LLM（シーケンス‑ツー‑シーケンスTransformer）を用いて低水準のアセンブリから直接ソースコードを生成しているため、Core Decompilation に該当します。"}, {"code": "in_type_recovery", "evidence": "augmented with a type inference engine", "explanation": "型推論エンジンを組み合わせて、コード生成時に型情報を回復・付与している点が Type Recovery に該当します。"}], "reasoning": "本稿は最適化されたアセンブリ（低水準入力）を入力とし、シーケンス‑ツー‑シーケンスTransformer を中心とした小規模言語モデルで可読性と正確性の高いソースコードを生成することを目的としている。ML 手法が核となっており、さらに型推論エンジンで型情報を復元するので、Decompilation の Core と Type Recovery の両側面を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3345, "latency_ms": 30317}}
{"key": "10.1109/ICSE.2019.00120", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "Key to these improvements is Gigahorse's use of a declarative, logic-based specification", "explanation": "本文では機械学習や大規模言語モデルの利用が言及されておらず、宣言的ロジックベースの手法のみが説明されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は EVM バイトコードから高水準 3‑アドレスコードへのデコンパイル手法を提案しているが、手法の中心として機械学習や大規模言語モデルを用いている記述がなく、ルールベース／宣言的ロジックによるアプローチのみである。従って、Decompilation Survey の採択基準にある「LLM または ML を手法の中核として用いる」条件を満たさないため、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3185, "latency_ms": 22113}}
{"key": "10.1109/ICSE55347.2025.00231", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper presents an approach to formally proven correct binary-level pointer analysis.", "explanation": "要旨からは機械学習や大規模言語モデルの利用が全く言及されておらず、従って除外基準 EC1 (No ML/LLM) に該当します。"}], "reasoning": "本稿はバイナリレベルのポインタ解析を形式的に検証する手法を提案しており、ML/LLM を用いたデコンパイルやコード生成は行っていません。したがって、除外基準の「ML/LLM を使用していない」ことから除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3076, "latency_ms": 21301}}
{"key": "10.1145/3019612.3019926", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect theft by measuring application similarity", "explanation": "本文は類似度測定による盗難検出が目的であり、低水準コードから高水準コードを復元・生成することを主目的としていないため、コード生成・復元の意図がなく除外基準EC3に該当する。"}], "reasoning": "本稿はAndroid実行ファイルの類似性をテキストマイニングで測定し盗難検出を行うことを目的としている。デコンパイルによる高水準コードの復元や生成が主目的ではなく、分類・検出タスクに焦点を当てているため、Decompilation Surveyの採択基準を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3149, "latency_ms": 22462}}
{"key": "10.1145/3098954.3103152", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "by using the open source decompiler Dagger", "explanation": "要旨はバイナリを Dagger という従来のデコンパイラで LLVM IR に変換しているだけで、ML/LLM の使用は言及されておらず、したがって機械学習手法が用いられていないと判断した。"}], "reasoning": "本稿はバイナリを従来型デコンパイラで LLVM IR に変換し、静的解析を行う手法を提案しているが、機械学習や大規模言語モデルを中核手法として使用している記述がなく、除外基準 EC1（ML/LLM を使用していない）に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3069, "latency_ms": 21574}}
{"key": "10.1145/3106237.3121274", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_variable_naming", "evidence": "suggest variable names that are natural given the context", "explanation": "要約では変数名の自動付与を目的としており、これはデコンパイル後のコードから識別子を復元することに該当するため、in_variable_naming が最も適切です。"}, {"code": "in_decompiler_enhancement", "evidence": "decompiled code lacks meaningful variable names", "explanation": "既存のデコンパイル出力（名前のない C コード）を入力とし、LLM/ML 手法で可読性を向上させている点から、デコンパイラ出力の改善に該当します。"}], "reasoning": "本論文は統計的機械翻訳という機械学習手法を用いて、デコンパイルされた C コードから意味のある変数名を推測することを目的としている。入力は低水準のバイナリから生成されたデコンパイルコードであり、出力は変数名という高水準属性（L4）であるため、変数名復元（in_variable_naming）かつデコンパイラ出力の可読性向上（in_decompiler_enhancement）として採択すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3367, "latency_ms": 41032}}
{"key": "10.1145/3176258.3176319", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we have developed the first decompiler for ladder logic programs ... transforms a low-level representation to its corresponding high-level original representation", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く言及されておらず、従来型のデコンパイラ手法のみが説明されているため、ML/LLM が中核手法であるという条件を満たさないと判断した。"}], "reasoning": "本稿はラダー論理プログラムを対象としたデコンパイラを提示しているが、機械学習・LLM を用いた手法についての記述がなく、ルールの Exclude Criteria (EC1) に該当する。したがって、サーベイ対象外として除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3183, "latency_ms": 23836}}
{"key": "10.1145/3191737", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "We employ a range of techniques, such as protocol analysis, software decompiling, and both static and dynamic embedded code analysis", "explanation": "アブストラクトではML/LLMの利用が言及されておらず、従来のリバースエンジニアリング手法のみが記載されているため、除外基準EC1に該当します。"}], "reasoning": "本稿はFitbitデバイスの脆弱性を実証するために従来のデコンパイルや静的・動的解析を用いたセキュリティ調査であり、機械学習・大規模言語モデルを用いたデコンパイル手法を提案していません。したがって、Decompilation Surveyの対象外（ML/LLM不使用）と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3148, "latency_ms": 21049}}
{"key": "10.1145/3196321.3196330", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_input", "evidence": "we consider decompiler output to be a noisy distortion of the original source code", "explanation": "アブストラクトは入力として「decompiler output」しか言及しておらず、バイナリやアセンブリといった低水準表現が明示されていないため、低水準入力があるかどうかが不明です。"}], "reasoning": "本稿は統計的機械翻訳というML手法を用いて、デコンパイラ出力の変数名を自然なものに置き換える手法を提案しています。目的はコードの可読性向上であり、デコンパイル改善に該当します。しかし、入力が低水準バイナリ等であるかがアブストラクトからは判断できず、インクルード判定に必要なIC0を満たすかが不明です。そのため、現時点では \"uncertain\" としています。", "model": "openai/gpt-oss-120b", "tokens_used": 3934, "latency_ms": 54672}}
{"key": "10.1145/3212480.3212487", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a way to decompile 64-bit ARM binaries to their LLVM intermediate representation (IR).", "explanation": "要旨に機械学習や大規模言語モデルの利用が一切記載されておらず、従来の静的解析手法のみで実装されていると判断できるため、EC1 に該当し除外します。"}], "reasoning": "本稿はバイナリを LLVM IR にデコンパイルし、静的解析とポインタ解析を用いて暗号 API の誤用を検出する手法を提案していますが、機械学習・LLM の使用が示されていません。したがって、Decompilation Survey の採択基準で要求される LLM/ML の中核的利用がないため除外と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3269, "latency_ms": 27379}}
{"key": "10.1145/3236794", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "All our prototypes have been implemented in OCaml", "explanation": "要旨では機械学習や大規模言語モデルの使用は言及されておらず、実装は従来のプログラミング言語（OCaml）で行われているため、ML/LLM が手法の中心でないと判断した。"}], "reasoning": "本稿は CAD のコンパイル・逆コンパイル手法を関数型言語とプログラム合成で提案しているが、機械学習や大規模言語モデルを利用した旨の記述がない。したがって、Decompilation Survey の採択基準で定められた「LLM/ML が中核手法である」条件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3240, "latency_ms": 25911}}
{"key": "10.1145/3276486", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach combines a control-flow-analysis-based decompiler and declarative program-structure queries.", "explanation": "本文ではデコンパイルを利用した静的解析を行うと述べているが、機械学習やLLM の使用は示されておらず、ルールベース手法に該当するため除外基準 ex_no_ml に該当する。"}], "reasoning": "本稿はガス不足に起因する脆弱性を検出するための静的解析手法を提案しており、デコンパイルは解析の一部として用いられるが、ML/LLM を中心手法として用いていない。したがって、Decompilation Survey の採択基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3198, "latency_ms": 21723}}
{"key": "10.1145/3293880.3294102", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_core", "evidence": "decompilation-into-logic methodology supporting both x86-64 assembly and machine code", "explanation": "アブストラクトは低水準の x86-64 バイナリ/アセンブリ を入力とし、論理的な高水準表現（big step semantics）を直接生成する手法であると述べているため、Core Decompilation に該当する。"}, {"code": "ex_no_ml", "evidence": "leveraging machine-learned semantics to build a formal machine model", "explanation": "機械学習で得られたセマンティクスを利用していることが明記されており、ML が手法の中核であることが確認できる。"}], "reasoning": "本論文は低水準の x86‑64 バイナリを入力とし、機械学習を用いて高水準の意味論表現（big step semantics）へ変換する手法を提案している。目的はバイナリの形式的検証であり、コード復元・可読化を目的とした decompilation の核心的研究に該当するため、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3566, "latency_ms": 42671}}
{"key": "10.1145/3319535.3363255", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a practical Android app decompilation system ... that automatically stitches the results from multiple decompilers together", "explanation": "抽象からは機械学習や大規模言語モデルを使用している記述がなく、従来のデコンパイラを組み合わせる手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文は複数の既存デコンパイラの出力を統合する実装システムを提案しているが、手法として機械学習や大規模言語モデルの利用が示されていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3025, "latency_ms": 21284}}
{"key": "10.1145/3320269.3384766", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "The algorithm is designed from the ground up ...", "explanation": "要旨に機械学習や大規模言語モデルの使用は言及されておらず、従来のアルゴリズムによる手法とみられるため、ML/LLM が中心手法でないと判断した。"}], "reasoning": "本稿はバイナリから制御フローグラフを再構築し、C コードを生成する手法を提案しているが、機械学習や大規模言語モデルの利用は示されていない。したがって、Decompilation Survey の包括基準である「LLM/ML が中核手法」である条件を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2984, "latency_ms": 18951}}
{"key": "10.1145/3321705.3329833", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We implemented a prototype of DeClassifier using Binary Analysis Platform (BAP)", "explanation": "本文はBAPという静的解析フレームワークを用いて実装しており、機械学習や大規模言語モデルの使用は言及されていないため、ML/LLM が手法の中核でないと判断した。"}], "reasoning": "本稿はバイナリ解析によるクラス継承推論手法を提案しており、機械学習・LLM を用いた手法ではない。したがって本サーベイの包括基準（IC0 の「LLM/ML が中核手法として使われている」）を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3009, "latency_ms": 17902}}
{"key": "10.1145/3324884.3418905", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we envisage and investigate an approach to (i) dynamically detect clipboard access behaviour, and (ii) determine privacy leaks via static data flow analysis", "explanation": "要旨に機械学習や大規模言語モデルの使用は全く記述されておらず、従来の動的検出と静的データフロー解析のみであるため、EC1に該当します。"}, {"code": "ex_no_lowlevel_input", "evidence": "lack of monitoring and control of Android application's access to the clipboard data", "explanation": "入力はクリップボードデータへのアクセスであり、バイナリ・アセンブリ・バイトコードなどの低水準表現ではないため、EC2に該当します。"}], "reasoning": "本稿は Android クリップボードへのアクセス検出とプライバシ漏洩解析を扱うもので、機械学習やLLMは使用されていない上、低水準バイナリ等の入力も対象としていません。したがって、デコンパイル調査の対象外であり除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3163, "latency_ms": 26829}}
{"key": "10.1145/3338503.3357725", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "In this tutorial, the Ghidra software reverse engineering framework will be presented, its characteristics highlighted and its features ... compared against.", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用についての記述がなく、従来のツール紹介のみであるため、EC1の「ML/LLM を用いていない」項目に該当し除外します。"}], "reasoning": "本稿は Ghidra の機能やデコンパイラの説明・デモを行うチュートリアルであり、機械学習や大規模言語モデルを手法の中心に用いた研究ではない。したがって本サーベイの採択基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3049, "latency_ms": 23039}}
{"key": "10.1145/3338906.3338956", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a general strategy for reducing such graphs... novel algorithm for reduction called Binary Reduction", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用が全く言及されておらず、手法はアルゴリズム的なグラフ削減であるため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は Java バイトコードの依存グラフを削減するアルゴリズムを提案しており、デコンパイルや高水準コード生成を目的とした機械学習手法は含まれていない。したがって、LLM/ML が中核手法であるという採択基準を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2980, "latency_ms": 19834}}
{"key": "10.1145/3340422.3343639", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "features extracted from intermediate code representations ... are used for ... predicting android malware applications", "explanation": "アブストラクトは、デコンパイルで得た中間表現を特徴量として機械学習モデルを訓練し、マルウェアか否かを予測（分類）することが目的であり、コードの復元・生成を行う意図が示されていないため、除外基準 EC3 に該当します。"}], "reasoning": "本研究はデコンパイルした中間表現を特徴量として利用し、マルウェア検出という分類タスクを実施しています。デコンパイル自体が復元・可読化を目的とした研究ではなく、コード生成や高水準表現の再構築を行わないため、除外基準 EC3（コード生成・復元が主目的でない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3209, "latency_ms": 26588}}
{"key": "10.1145/3341161.3350841", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a text mining all repeated pattern detection method ...", "explanation": "要旨ではテキストマイニングとパターン検出手法のみが言及されており、機械学習や大規模言語モデルの使用は示されていないため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本研究はデコンパイルされたファイルを用いたマルウェアの分類手法を提案しており、目的はコード生成や復元ではなく分類である。さらに、要旨に機械学習やLLM の使用は記載されていないため、除外基準 EC1（ML/LLM 不使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3337, "latency_ms": 29561}}
{"key": "10.1145/3342195.3387550", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Existing binary lifting tools are based on static disassembly... we present BinRec, a new approach... lifts dynamic traces of a binary to a compiler-level intermediate representation (IR)", "explanation": "アブストラクトからは機械学習や大規模言語モデルの利用が全く言及されておらず、手法は動的トレースによるリフティングとコンパイラパスに基づくため、EC1の「ML/LLM を用いていない」に該当し除外すべきです。"}], "reasoning": "本稿は動的バイナリリフティングと再コンパイルを提案しており、低水準バイナリから高水準IRへの変換は行うが、手法に機械学習やLLMは一切使用していない。従って、Decompilation Survey Screening Rules の除外基準 EC1（No ML/LLM）に該当し、include の条件を満たさないため除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3175, "latency_ms": 22706}}
{"key": "10.1145/3371307.3371312", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach is based on a series of periodic checks on the execution environment ... and send to a server for validation.", "explanation": "要旨からは機械学習・LLM の利用が示されておらず、単なる環境チェックによる検出手法なので、ML/LLM が用いられていないことが確認できました。"}], "reasoning": "本稿は Android アプリに対する悪意あるリバースエンジニアリングの検出手法を提案しており、機械学習や大規模言語モデルを用いたデコンパイルやコード生成は行っていません。そのため、除外基準 EC1 (No ML/LLM) に該当し、サーベイ対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2981, "latency_ms": 19472}}
{"key": "10.1145/3372297.3417251", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present an efficient technique to detect virtual inheritance in C++ binaries", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及せず、従来の解析手法による検出と回復を述べているため、ML/LLM が用いられていないと判断した"}], "reasoning": "本稿はバイナリから仮想継承情報を検出・回復する技術を提案しているが、手法が機械学習や大規模言語モデルに基づく旨の記述がなく、ルールベース／静的解析的アプローチとみられる。したがって、Decompilation Survey の採択基準で要求される LLM/ML の利用がなく、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3049, "latency_ms": 16348}}
{"key": "10.1145/3375894.3375895", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a new approach that leverages the human analyst expertise ... a set of GDB extensions that intercept and introspect into executed functions", "explanation": "要旨では ML/LLM の使用が全く言及されておらず、手法は GDB 拡張と人間の分析者による指示に基づくため、除外基準 EC1（ex_no_ml）に該当します。"}], "reasoning": "本稿はデバッグ指向のマルウェアデコンパイル手法を提案していますが、機械学習や大規模言語モデルを中核手法として使用している記述がなく、ルールベース／人間主導のアプローチにとどまっています。そのため、Decompilation Survey の対象外（ML/LLM 未使用）として除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3183, "latency_ms": 21891}}
{"key": "10.1145/3385412.3386012", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present Szalinski, a tool that uses Equality Saturation with semantics-preserving CAD rewrites...", "explanation": "要旨に機械学習や大規模言語モデルの使用は言及されておらず、手法は等価飽和とCADリライトという従来のプログラム合成技術のみであるため、ML/LLM が中核手法でないと判断した。"}], "reasoning": "本稿は三角メッシュから CSG 表現へのデコンパイルと、その結果をさらに最適化する手法を提案しているが、機械学習・LLM を利用した手法は示されていない。したがって、Include Criteria の IC0（ML/LLM が中核手法）を満たさず、Exclude Criteria の EC1 に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3189, "latency_ms": 26813}}
{"key": "10.1145/3395363.3397370", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "In this work, we test decompilation correctness to present an up-to-date understanding regarding modern C decompilers.", "explanation": "アブストラクトではML/LLMを用いた手法について言及されておらず、従来のデコンパイラの評価のみを行っているため、ML/LLMが使用されていないと判断した。"}], "reasoning": "本稿は既存Cデコンパイラの正確性をテストしバグを報告する評価研究であり、ML/LLMを用いた手法は示されていない。したがって除外基準 EC1 (No ML/LLM) に該当し、include には該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 3368, "latency_ms": 25469}}
{"key": "10.1145/3395363.3404365", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose EShield, an automated security enhancement tool for protecting smart contracts against reverse engineering.", "explanation": "要旨にML/LLMの使用は言及されておらず、単なるバイトコード書き換え手法であるため、除外基準EC1（ML/LLM未使用）に該当します。"}], "reasoning": "本論文はスマートコントラクトのバイトコードを改変して逆コンパイルを妨害する保護手法を提案しており、ML/LLMを用いたデコンパイルやコード復元を目的としていません。そのため除外基準EC1（ML/LLM未使用）に該当し、サーベイ対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3173, "latency_ms": 28435}}
{"key": "10.1145/3405962.3405980", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "we developed a classification dataset from collected anti-malware data looking for fraudulent anti-malware products", "explanation": "アブストラクトからは低水準バイナリ・アセンブリ等の入力は示されておらず、データは主にアンチマルウェアのメタ情報であると解釈できるため、低水準入力がないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "applied various machine learning algorithms... provides high accuracy over various evaluation tests", "explanation": "研究の目的は偽アンチマルウェアの分類であり、コードの復元や生成は行わないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本論文は偽アンチマルウェア検出のためのデータセット構築と分類モデルの適用を扱っており、低水準バイナリからのコード復元やデコンパイルを目的としていない。したがって、デコンパイル調査の包括基準を満たさず除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3282, "latency_ms": 33104}}
{"key": "10.1145/3411764.3445249", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "a synthesis-powered visualization tool", "explanation": "概要では機械学習や大規模言語モデルの利用が言及されておらず、プログラム合成だけが中心となっているため、EC1 の「ML/LLM を用いていない」に該当します。"}, {"code": "ex_out_of_scope", "evidence": "allows users to specify visualizations ... without needing to worry about data layout", "explanation": "研究対象はデータ可視化の自動化であり、バイナリやアセンブリから高水準コードを生成するデコンパイルとは無関係なので、EC5 の「範囲外」に該当します。"}], "reasoning": "本稿は可視化ツールの自動生成に関するもので、入力はデータレイアウト、出力は可視化仕様であり、低水準バイナリ等の入力やコード復元を目的としていません。また、機械学習や LLM を用いた手法も示されていないため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3237, "latency_ms": 30102}}
{"key": "10.1145/3411764.3445535", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose IGScript... develop a code generator (decompiler) to translate the interactive data exploration animations back into script codes", "explanation": "要旨に機械学習や大規模言語モデルの使用について言及がなく、従来のコンパイラ・コードジェネレータ手法のみが述べられているため、ML/LLM が中核手法でないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "translate the interactive data exploration animations back into script codes", "explanation": "入力とされているのは「インタラクティブなデータ探索アニメーション」であり、バイナリやアセンブリ等の低水準表現ではないため、低水準入力が欠如していると判断した。"}], "reasoning": "本稿は科学データプレゼンテーション用の対話型文法ツールを提案し、アニメーションからスクリプトへの変換を行うが、手法は従来のコンパイラ技術であり機械学習は使用していない。また、入力は高水準のアニメーションであり、デコンパイルの対象となる低水準表現が含まれていないため、Decompilation Survey の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3323, "latency_ms": 31531}}
{"key": "10.1145/3422337.3450321", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose OBFUS, a web-based tool that can easily apply obfuscation techniques ...", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用は言及されておらず、従って本サーベイのML/LLM使用条件を満たさないため除外します。"}], "reasoning": "本論文はバイナリをLLVM IRにデコンパイルしてから難読化するツールを提案していますが、目的は復元・可読化ではなく難読化であり、ML/LLM を用いた手法の記述もありません。そのため、インクルード基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3033, "latency_ms": 24192}}
{"key": "10.1145/3428151", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "proposed ... malware threat detection framework ... detection accuracy", "explanation": "要旨はマルウェア検出であり、コードの復元や生成を目的としていないため、コード生成・復元が目的ではないことが示されています。"}], "reasoning": "本論文は Android デバイス上のマルウェア検出を目的としたハイブリッド深層学習フレームワークを提案しており、低水準バイナリから高水準コードを生成するデコンパイルの目的や手法は提示されていません。そのため、デコンパイルに関する研究とは無関係であり、除外基準 EC3（コード生成/復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3059, "latency_ms": 17904}}
{"key": "10.1145/3441296", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "relevant topics range from ... decompilation, program generation, and abstract interpretation.", "explanation": "アブストラクトはワークショップの概要を述べているだけで、ML/LLM を用いた手法について言及しておらず、機械学習が使用されていないことが明らかです。"}, {"code": "ex_no_lowlevel_input", "evidence": "relevant topics range from ... decompilation, program generation, and abstract interpretation.", "explanation": "論文は特定の研究内容を示さず、低水準入力（バイナリやアセンブリ）に関する記述がないため、対象外です。"}], "reasoning": "本稿は PEPM 2021 のワークショップ開催報告であり、個別の研究成果や手法を提示していないため、ML/LLM を用いたデコンパイル研究とは無関係です。したがって除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3251, "latency_ms": 28776}}
{"key": "10.1145/3442381.3450138", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper presents a comprehensive empirical study of 8,461 unique WebAssembly binaries", "explanation": "要旨では機械学習や大規模言語モデルの利用について言及されておらず、単なる調査研究であるためML/LLMが使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "calling for techniques to decompile and reverse engineer WebAssembly", "explanation": "本稿はデコンパイル手法の提案やコード生成を目的としておらず、むしろ今後の技術開発の必要性を訴えているため、復元・コード生成の意図がないと判断した。"}], "reasoning": "要旨はWebAssembly バイナリの実態調査に焦点を当てており、デコンパイルや高水準コード生成を行うML/LLM手法の提示は含まれていない。したがって、本サーベイの採択基準を満たさないと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3361, "latency_ms": 29517}}
{"key": "10.1145/3453483.3454033", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "We describe a new approach ... combines a configurable proof term transformation with a decompiler from proof terms to suggested tactic scripts.", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が記載されておらず、従来のアルゴリズム的手法のみであるため、EC1 の「ML/LLM を用いていない」に該当します。"}], "reasoning": "本稿は Coq 証明項からタクティックスクリプトへ変換するデコンパイラを提案していますが、機械学習や LLM を手法の中核として使用していないため、インクルード基準を満たしません。したがって除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3161, "latency_ms": 27746}}
{"key": "10.1145/3453483.3454091", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we run an algorithm that finds a small, valid, failure-inducing input", "explanation": "要旨に機械学習や大規模言語モデルの使用は言及されておらず、従来のアルゴリズム的手法のみが述べられているため"}, {"code": "ex_no_code_generation", "evidence": "we can reduce Java bytecode to 4.6 percent of its original size", "explanation": "目的はバイトコードのサイズ削減であり、高水準コードや擬似コードの生成・復元を行うものではないため"}], "reasoning": "本稿は Java バイトコードのサイズ削減手法を提案しており、機械学習やLLM を用いた手法は示されていない。また、出力は縮小されたバイトコードであり、ソースコードや高水準表現の生成を目的としないため、デコンパイル研究の採択基準を満たさない。", "model": "openai/gpt-oss-120b", "tokens_used": 3265, "latency_ms": 29026}}
{"key": "10.1145/3461666", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Successful software authorship de-anonymization ... the process requires an efficient extraction of authorship attributes.", "explanation": "本文はバイナリやソースから著者属性を抽出し、作者識別（分類）することが目的であり、コードの復元や生成を行う decompilation ではないため、EC3 に該当します。"}], "reasoning": "本稿は低水準バイナリやソースコードから著者属性を学習し、著者を識別することを目的とした機械学習手法を提案しています。デコンパイルによる高水準コードの生成や復元を目指すものではなく、分類タスクに該当するため除外基準 EC3（コード生成・復元目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3307, "latency_ms": 20519}}
{"key": "10.1145/3465481.3470040", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "perform the classification", "explanation": "アブストラクトはマルチビュー学習で再パッケージ化されたマルウェアを分類・検出することが目的であり、コードの生成や復元は行っていないため、コード生成・再構築の意図がなく除外基準EC3に該当します。"}], "reasoning": "本稿はマルチビュー学習を用いた再パッケージ化マルウェアの検出手法を提案しており、目的は分類・検知です。デコンパイルや高水準コードの復元を行うことはなく、LLM/MLをコード生成に利用していないため、除外基準EC3（コード生成・復元が主目的でない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3144, "latency_ms": 23198}}
{"key": "10.1145/3465481.3470077", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "framework aimed to inject a malicious payload in two or more different Android applications", "explanation": "要旨はマルウェアペイロードの注入とコラボレーティング攻撃の評価であり、デコンパイルや低水準コードの復元とは無関係であるため、サーベイの対象外です"}], "reasoning": "本稿は Android アプリへのマルウェアペイロード注入フレームワークを提案しており、低水準バイナリから高水準コードを生成するデコンパイル研究とは目的も手法も異なる。ML/LLM の使用も言及されていないため、除外基準（EC5: out of scope）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3196, "latency_ms": 22389}}
{"key": "10.1145/3468264.3468607", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_type_recovery", "evidence": "Binary type inference is a critical reverse engineering task ... our model ... to infer types.", "explanation": "アブストラクトは低水準バイナリから型情報（属性）を推測することを目的としており、LLM/ML が中心手法であるため、タイプ回復（Type Recovery）に該当する。"}], "reasoning": "本論文はバイナリを入力とし、ニューラルネットワークを用いて変数や関数の型を推定する手法を提案している。入力が低水準表現であり、出力は型情報という高水準属性で、目的は復元・可読化支援であるため、Peripheral かつ Type Recovery に該当し、インクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3225, "latency_ms": 22284}}
{"key": "10.1145/3474369.3486865", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_type_recovery", "evidence": "recover stack frame information of binary functions ... predict ... stack size", "explanation": "抽象から、バイナリを入力としてスタックフレームサイズ（高水準属性）を予測することが主目的であり、これは型・レイアウト情報の復元に相当するため「type recovery」と判断した。"}], "reasoning": "本稿はバイナリ（低水準表現）を入力に、Transformer を用いた機械学習で関数のスタックフレームサイズという高水準属性を予測する手法を提案している。目的はバイナリのリバースエンジニアリングや書き換え支援であり、ML が中心手法であるため、Decompilation Survey の包括基準を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3492, "latency_ms": 35723}}
{"key": "10.1145/3479394.3479399", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a novel reduction theory for Moggi’s computational λ-calculus...", "explanation": "本文は計算ラムダカルチャの理論的構築であり、機械学習や大規模言語モデルの使用について言及していないため、EC1に該当します。"}, {"code": "ex_no_lowlevel_input", "evidence": "The delimited-control operator shift0 has been formally shown to capture the operational semantics of deep handlers...", "explanation": "対象は高水準のλ項や制御演算子であり、バイナリやアセンブリといった低水準表現を入力としていないため、EC2に該当します。"}], "reasoning": "本稿はプログラム言語の制御演算子とその変換理論を扱う純粋な形式的研究で、ML/LLM を利用したデコンパイル手法や低水準コードからの高水準コード復元を目的としていない。従って、Decompilation Survey の採択基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3079, "latency_ms": 20180}}
{"key": "10.1145/3486860", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This article provides the first systematic review of existing binary code fingerprinting approaches...", "explanation": "アブストラクトが調査・レビューであることを明示しているため、サーベイ論文であり本サーベイの対象外です。"}], "reasoning": "本文はバイナリコード指紋付け手法の体系的レビューであり、LLM/ML を用いたデコンパイルやコード生成を行う研究ではありません。また、調査・レビュー論文は除外基準 EC4 に該当するため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2956, "latency_ms": 16997}}
{"key": "10.1145/3488932.3497764", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "Decompilers are tools designed to recover a high-level language representation (typically in C code) from program binaries.", "explanation": "アブストラクトではデコンパイラそのものや実験手法が述べられているが、機械学習や大規模言語モデルの使用についての記述がなく、ML/LLM が手法の中核であることが確認できないため除外とした。"}], "reasoning": "本稿は既存デコンパイラの評価を中心とした実験報告であり、ML/LLM を用いたデコンパイル手法の提案や改善が行われていない。したがって、インクルード基準の IC0（LLM/ML が中核手法）を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3159, "latency_ms": 21964}}
{"key": "10.1145/3490725.3490733", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect malicious applications... locate malicious code fragments", "explanation": "アブストラクトはマルウェア検出とコード位置特定を目的としており、コードの復元や擬似コード生成といった出力は示されていないため、コード生成・復元が主目的ではないと判断した。"}], "reasoning": "本論文はグラフニューラルネットワークを用いたマルウェア検出と悪意あるコードノードのスコア付け・位置特定を行うもので、低水準表現から高水準コードを生成するデコンパイルを目的としていない。したがって、デコンパイルに該当するコード生成・再構成の目的が欠如しているため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3215, "latency_ms": 26718}}
{"key": "10.1145/3494110.3528244", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "craft adversarial malware to evade detection", "explanation": "要旨はマルウェアの対抗的生成と回避手法であり、デコンパイルや高水準コード復元を目的としていないため本サーベイの範囲外です。"}], "reasoning": "本稿はマルウェア検出回避のための対抗的マルウェア生成について論じており、低水準コードから高水準コードへの復元や LLM/ML を用いたデコンパイル手法を扱っていない。したがってデコンパイル調査の対象外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3234, "latency_ms": 29491}}
{"key": "10.1145/3498361.3538938", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "DisPatch first decompiles binary instructions and recovers controller functions ... using symbolic execution and data flow analysis.", "explanation": "要旨ではシンボリック実行やデータフロー解析といった従来手法のみが述べられ、ML/LLM の使用が示されていないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿はバイナリからのリバースエンジニアリングとパッチ適用を目的とし、シンボリック実行やデータフロー解析を用いた従来技術のみを利用しています。LLM/ML を中心手法としていない点から、Decompilation Survey Screening Rules の除外基準 (No ML/LLM) に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3120, "latency_ms": 16992}}
{"key": "10.1145/3502718.3524744", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "students develop tools that automatically detect and exploit program vulnerabilities", "explanation": "本文ではMLやLLMの利用について言及されておらず、従来の手法での自動検出・利用が中心であるため、ML/LLM不使用として除外します。"}], "reasoning": "本稿は大学のバイナリ逆解析コースでの自動エクスプロイト生成コンテストの設計と経験を報告しており、デコンパイルやML/LLMを用いた高水準コード生成とは無関係です。そのため除外基準EC1（ML/LLM未使用）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2833, "latency_ms": 16343}}
{"key": "10.1145/3507657.3528555", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We design a novel automated tool, PITracker, to detect the PendingIntent vulnerabilities in Android apps.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されておらず、従って本調査の除外基準 EC1（ML/LLM 未使用）に該当します。"}], "reasoning": "本論文は Android アプリの Intent フロー解析による脆弱性検出を目的としており、機械学習/LLM を用いた手法や低水準バイナリから高水準コードへの復元を行うことは示されていない。したがって、Decompilation Survey のインクルード基準を満たさず、除外基準 EC1 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3006, "latency_ms": 20390}}
{"key": "10.1145/3510454.3516854", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "ACID utilizes API differences and static analysis of Android apps to detect both API invocation compatibility issues and API callback compatibility issues.", "explanation": "本文は機械学習や大規模言語モデルを使用せず、静的解析のみでAPI互換性問題を検出すると述べているため、ML/LLMが手法の中心にないと判断し除外します。"}], "reasoning": "本論文はAndroidアプリのAPI互換性問題を検出するツールであり、機械学習やLLMを用いた手法を採用していない。デコンパイルや高水準コード生成を目的とした研究ではなく、分類・検知系の静的解析に焦点を当てているため、スクリーニング基準の除外条件 EC1（No ML/LLM）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3035, "latency_ms": 22635}}
{"key": "10.1145/3519939.3523449", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_type_recovery", "evidence": "recovering precise, high-level parameter and return types for WebAssembly functions", "explanation": "抽象から、低水準のWebAssemblyバイナリから高水準の型情報（属性）を予測することが目的であり、ニューラルseq2seqというML手法を用いているため、タイプ回復の研究に該当する。"}, {"code": "ex_no_code_generation", "evidence": "type recovery ... is no longer a classification task but sequence prediction", "explanation": "本研究はコードそのものの生成（L1‑L3）ではなく型属性の復元を行うが、IC3の例外として許容されるため、コード生成目的ではないことを確認した。"}], "reasoning": "WebAssemblyバイナリという低水準入力から、ニューラルシーケンス‑ツー‑シーケンスモデルを用いて関数のパラメータ・戻り値型という高水準属性を予測するので、デコンパイルの周辺対象であるタイプ回復に該当する。ML手法が中核であり、目的も復元・可読化支援であるため、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3333, "latency_ms": 30304}}
{"key": "10.1145/3519939.3523702", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present the first approach to provably overapproximative x86-64 binary lifting.", "explanation": "本文は形式的検証と証明義務に基づくリフティング手法を提案しており、機械学習や大規模言語モデルの使用は言及されていないため、EC1 に該当し除外します。"}], "reasoning": "この論文はバイナリを高レベル表現に変換する形式的手法を紹介していますが、ML/LLM を中心手法として用いている記述がなく、除外基準 EC1（No ML/LLM）に該当します。そのため含めず除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 2940, "latency_ms": 15489}}
{"key": "10.1145/3519939.3523719", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Static binary translation (SBT) is a process where a program’s binary is automatically translated...", "explanation": "本文はバイナリ間の変換手法を提案しており、ML/LLM の利用について言及がなく、EC1 に該当するため除外します。"}], "reasoning": "本稿は低水準バイナリを別アーキテクチャ向けに変換する静的バイナリ翻訳手法を紹介しており、LLM/ML を用いた手法ではない。デコンパイル（低水準から高水準コード生成）や ML の活用が目的でないため、除外基準 EC1（No ML/LLM）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3041, "latency_ms": 17915}}
{"key": "10.1145/3520084.3520103", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper proposed the de-obfuscation method against for DNR (dynamic name resolution) obfuscation method.", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が全く記載されておらず、従来の静的/動的解析手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本文は動的名前解決の難読化手法を対象にしたデオブフュスケーション手法の提案であり、機械学習や大規模言語モデルを用いたアプローチが示されていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3145, "latency_ms": 28770}}
{"key": "10.1145/3520312.3534867", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "pairs real-world C code taken from GitHub with IO examples", "explanation": "アブストラクトはソースコード（C 関数）を扱っており、バイナリやアセンブリといった低水準表現が入力ではないため除外基準 EC2 に該当します。"}], "reasoning": "本論文は実行可能な C 関数のデータセット構築を目的としており、低水準バイナリから高水準コードへの復元（デコンパイル）や LLM/ML を用いたコード生成とは直接関係しません。そのため、スクリーニング基準の除外条件「低水準入力がない」(ex_no_lowlevel_input) に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3072, "latency_ms": 20833}}
{"key": "10.1145/3524452", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "adopts LLVM, extends CRIU, and integrates with Docker.", "explanation": "抄録に機械学習や大規模言語モデルの使用は言及されておらず、従来のシステム技術だけが述べられているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は異種ISA間でコンテナ化されたバイナリをそのまま移行させるシステムを提案しており、ML/LLM を中心とした手法は含まれない。デコンパイルや高水準コード生成を目的としていないため、除外基準 EC1（No ML/LLM）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3251, "latency_ms": 23872}}
{"key": "10.1145/3533767.3534222", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "static analysis at the bytecode level", "explanation": "要旨はバイトコード上での静的解析を行うと述べており、ML／LLM の使用は示唆されていないため"}, {"code": "ex_no_code_generation", "evidence": "framework for detecting cross-contract vulnerability", "explanation": "研究目的は脆弱性の検出であり、コードの生成・復元が主目的ではないため"}], "reasoning": "本論文はバイトコードを入力とした静的解析による脆弱性検出手法を提案しており、ML/LLM を用いた復元・コード生成を目的としていない。したがって、デコンパイル調査の対象外である。", "model": "openai/gpt-oss-120b", "tokens_used": 3223, "latency_ms": 25466}}
{"key": "10.1145/3544902.3546240", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect supply chain vulnerabilities based on these graphs", "explanation": "論文は擬似コードを特徴抽出し、グラフマッチングネットワークで脆弱性を検出することを目的としており、コードの復元や生成は目的に含まれないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は低水準コードから擬似コードを抽出し、ML（GMN）で脆弱性検出を行う分類タスクであり、デコンパイルによる高水準コード生成・復元が目的ではない。したがって、コード生成・再構築が主目的でないという除外基準に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3265, "latency_ms": 25459}}
{"key": "10.1145/3548636.3548651", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Two-path Android malware detection model ... N-gram feature extraction ... Neural network is used to classify the fused features.", "explanation": "アブストラクトでは低水準バイナリやアセンブリなどの入力について言及されておらず、アプリケーションの特徴抽出と分類が主目的であるため、低水準入力が存在しないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "Neural network is used to classify the fused features.", "explanation": "目的はマルウェアの検出・分類であり、コードの復元や生成は行わないため、復元・生成意図がないと判定した。"}], "reasoning": "本稿は Android アプリの N‑gram 特徴を用いたマルウェア検出手法を提案しており、低水準バイナリから高水準コードを生成するデコンパイルとは無関係です。入力はアプリのファイル属性であり、出力は検出結果のラベルであるため、Decompilation Survey の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3177, "latency_ms": 27529}}
{"key": "10.1145/3550355.3552396", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose the OSATE Declarative-Instance Mapping Tool (OSATE-DIM1)...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が言及されておらず、従って本調査のML/LLM使用基準を満たさないため除外します。"}, {"code": "ex_no_lowlevel_input", "evidence": "instance model is a simple object tree ... from a base 'declarative' model", "explanation": "入力はAADLの宣言モデルやインスタンスモデルという高水準のモデリング情報であり、バイナリやアセンブリといった低水準表現ではないため除外基準に該当します。"}], "reasoning": "本稿はモデル変換ツールの提案であり、低水準コードから高水準コードへの復元を目的としたデコンパイル研究ではない。さらに機械学習・LLM を手法の中心に用いていないため、Decompilation Survey の採択基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3112, "latency_ms": 21111}}
{"key": "10.1145/3551349.3559505", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "We introduce a reusable automated model-based GUI testing technique for Android apps", "explanation": "本文はAndroidアプリのGUIテスト手法を提案しており、デコンパイルや低水準コード復元とは無関係です。"}, {"code": "ex_no_code_generation", "evidence": "guiding the follow‑up testing runs to quickly cover major app functionalities", "explanation": "目的はテスト実行の指導であり、コードの生成や復元を行うことは記載されていません。"}], "reasoning": "本論文はAndroidアプリのGUIテストに関する手法を紹介しており、入力として低水準バイナリやアセンブリを扱うことも、LLM/ML を用いてコードを復元・再構成することも示されていません。そのため、デコンパイル調査のスコープ外と判断し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3245, "latency_ms": 27129}}
{"key": "10.1145/3551349.3561339", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The approach is based on clone detection ... to remove library code and to enhance arbitrary analysis tools’ scalability.", "explanation": "アブストラクトはコードのライブラリ/アプリ分離と解析ツールのスケーラビリティ向上を目的としており、ソースコードや擬似コードの生成・復元は行わないため、コード生成・復元を目的としたデコンパイル研究ではないと判断した。"}], "reasoning": "本稿は Android アプリからライブラリコードを除去して解析のスケールを向上させる手法を提案しており、低水準バイナリから高水準コードを生成することを目的としていない。また、LLM/ML を用いる記述もなく、コード生成・復元が主目的ではないため、除外基準 EC3（コード生成・復元が主目的でない）に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3153, "latency_ms": 25905}}
{"key": "10.1145/3556223.3556257", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "goal of malware family classification based on the static features of Android applications", "explanation": "アブストラクトはマルウェアの分類・検出が目的であり、低レベルコードから高レベルコードを生成・復元することは述べられていないため、コード生成/復元の意図がなく除外基準 EC3 に該当する"}], "reasoning": "本稿は Android アプリの静的特徴を用いたマルウェア分類・検出手法を提案しており、デコンパイルやコード復元を目的としていない。ML/LLM を用いたコード生成や高レベル表現の生成が行われていないため、除外基準 EC3 (ex_no_code_generation) に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3100, "latency_ms": 22638}}
{"key": "10.1145/3571786.3573015", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "A reflection is a relationship between compiling and decompiling functions.", "explanation": "要旨に機械学習や大規模言語モデルの利用が記載されておらず、純粋に理論的なコンパイル/デコンパイル関係の研究であるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はコンパイルとデコンパイルの関係性（reflection）を理論的に検討しており、機械学習や大規模言語モデルを用いた手法の記述がない。したがって、デコンパイルに ML/LLM を中心手法として用いる本サーベイの対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 2877, "latency_ms": 17572}}
{"key": "10.1145/3582016.3582058", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper presents SPLENDID, an LLVM-IR to C/OpenMP decompiler...", "explanation": "アブストラクトには機械学習や大規模言語モデルの使用が記載されておらず、従来のコンパイラ技術に基づくデコンパイラであるため、ML/LLM が中核手法でないと判断した。"}], "reasoning": "本稿は LLVM-IR から C/OpenMP へのデコンパイル手法を提案しているが、機械学習や大規模言語モデルの利用について言及がないため、除外基準 EC1（No ML/LLM）に該当する。したがってインクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3104, "latency_ms": 19824}}
{"key": "10.1145/3597503.3639100", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "BinaryAI ... detects the reused TPLs based on the ratio of matched source functions.", "explanation": "要旨ではバイナリ関数とソース関数をマッチングしてライブラリを検出することが目的であり、バイナリから高水準コードを生成・復元することは示されていないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿はバイナリとソースコードのマッチングによるソフトウェア構成分析を提案しており、デコンパイルによるコード復元や可読化を目的としていない。したがって、デコンパイル調査の包括基準（IC）を満たさず、EC3（コード生成・復元が主目的でない）に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3298, "latency_ms": 23818}}
{"key": "10.1145/3597503.3639140", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "bytecode-level Permission re-delegation vulnerability detector", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、単なるバイトコード分析ツールであるため、ML/LLM が中核手法でないことが明らかです。"}], "reasoning": "本論文はスマートコントラクトのバイトコードを対象に脆弱性検出を行う手法を提案しているが、機械学習や大型言語モデルの利用は言及されていない。デコンパイルや高水準コード生成を目的とした LLM/ML 手法が欠如しているため、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3152, "latency_ms": 22790}}
{"key": "10.1145/3597503.3639153", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "We implement BlockWatchdog using cross-contract static dataflow techniques", "explanation": "本文では機械学習や大規模言語モデルの使用は言及されておらず、静的データフロー解析だけが用いられているため、EC1の「ML/LLM を使用していない」に該当します。"}], "reasoning": "この論文はイーサリアムコントラクトのバイトコードを入力とし、再入可能性脆弱性を検出する静的解析ツールを提案していますが、機械学習やLLM を用いた手法は示されていません。デコンパイルや高水準コード生成を目的とした研究ではないため、除外基準 (ex_no_ml) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3111, "latency_ms": 19752}}
{"key": "10.1145/3597926.3598068", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present DITWO, a differential testing framework to uncover missed optimizations (MO) of wasm optimizers.", "explanation": "抽象では機械学習や大規模言語モデルの使用が全く言及されておらず、従ってML/LLMを用いていないと判断した"}], "reasoning": "本稿はWebAssembly最適化の欠如を検出するための差分テストフレームワークを提案しており、デコンパイルやコード生成を目的とした機械学習手法は採用されていない。したがって、Decompilation Survey の採択基準を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3151, "latency_ms": 20623}}
{"key": "10.1145/3597926.3598124", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.87, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose DeFiTainter, an inter-contract taint analysis framework for detecting price manipulation vulnerabilities.", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用について言及されておらず、従ってML/LLMを使用していないと判断したため。"}, {"code": "ex_no_code_generation", "evidence": "detecting price manipulation vulnerabilities", "explanation": "目的が脆弱性検出であり、コードの復元や高水準表現の生成・改善を目指すものではないため。"}], "reasoning": "本稿はスマートコントラクトの価格操作脆弱性を検出するための taint analysis フレームワークを提案しており、機械学習やLLMの利用は示されていない。また、目的はコード復元や可読化ではなく脆弱性検出であり、デコンパイル研究の対象外となるため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3179, "latency_ms": 25899}}
{"key": "10.1145/3603273.3635055", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we use soft attention to fuse two modalities features to finish classification", "explanation": "アブストラクトはマルウェアの分類を目的としており、コードの復元や高水準表現の生成は行っていないため、デコンパイルの目的から外れます。"}], "reasoning": "本稿はAndroidアプリのバイナリ（Dex）と関数呼び出しグラフを用いたマルウェア検出モデルを提案しており、最終的な出力はマルウェアか否かの分類ラベルです。デコンパイルやソースコードの復元を目的としていないため、除外基準 EC3（コード生成・復元が主目的でない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3005, "latency_ms": 18215}}
{"key": "10.1145/3605762.3624428", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "heuristic prediction approach", "explanation": "要旨では機械学習や大規模言語モデルの使用は言及されておらず、手法はヒューリスティックであるとだけ記載されているため、ML/LLM が利用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "automated extraction method for third‑party libraries", "explanation": "研究の目的はライブラリの検出・抽出であり、低水準コードから高水準コードを生成・復元すること（デコンパイル）ではないため、コード生成・復元を目的とした研究ではないと判断した。"}], "reasoning": "本稿はミニアプリ内のサードパーティライブラリを検出する手法を提案しており、機械学習やLLM を用いた手法は示されていない。また、目的はコードの復元や可読化ではなくライブラリ抽出であり、デコンパイルの定義に合致しないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3213, "latency_ms": 28905}}
{"key": "10.1145/3605762.3624432", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we design a novel analysis framework for the security risk assessment of miniapps", "explanation": "要旨では機械学習や大規模言語モデルの使用が言及されておらず、従ってML/LLMは利用されていないと判断できるため"}, {"code": "ex_no_lowlevel_input", "evidence": "the security of miniapps can directly impact compromising the integrity of sensitive data", "explanation": "入力はミニアプリのウェブインタフェースや設定情報であり、バイナリ・アセンブリなどの低水準表現ではないため"}], "reasoning": "本稿はミニアプリのセキュリティ評価と脆弱性分類に関する研究であり、デコンパイルや低水準コードから高水準表現への変換を目的としていない。さらに、機械学習・LLM の手法が使用されている記述もなく、除外基準 EC1（ML/LLM 未使用）および EC2（低水準入力なし）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3088, "latency_ms": 22090}}
{"key": "10.1145/3611643.3616343", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_type_recovery", "evidence": "first leverages deep learning techniques to automatically infer function signatures and returns", "explanation": "LLM/ML が中心手法で、低水準のバイトコードから関数シグネチャ（型情報）を復元することが主目的であるため、タイプリカバリに該当します。"}, {"code": "ex_no_lowlevel_input", "evidence": "bytecode runs on Ethereum Virtual Machine", "explanation": "入力がバイトコード（低水準表現）であることが明示されているため、低水準入力の要件を満たします。"}], "reasoning": "本論文はバイトコードという低水準入力から関数シグネチャという高水準属性（型情報）を深層学習で推測する手法を提案しており、目的は復元・可読化に直結するタイプリカバリです。ML が手法の中核であり、デコンパイルの周辺領域（L4属性）として本サーベイの採択基準を満たすため、include と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3262, "latency_ms": 27331}}
{"key": "10.1145/3611643.3617852", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "utilizes a Java dynamic analysis tool to record calls to core Java libraries", "explanation": "入力がバイナリやアセンブリなど低水準表現ではなく、Java の実行時トレースであるため低水準入力が存在しません。"}, {"code": "ex_no_code_generation", "evidence": "effective method source code retrieval from a candidate set", "explanation": "目的はコードの検索・取得であり、低水準入力から高水準コードを生成・復元することではないためコード生成／復元の意図がありません。"}], "reasoning": "本稿は Java アプリケーションの実行トレースを用いて BERT を学習し、既存のコードベースから該当メソッドを検索・取得する手法を提案しています。入力が低水準表現でなく、目的も復元・可読化ではなく検索であるため、デコンパイル調査の包括基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3149, "latency_ms": 29233}}
{"key": "10.1145/3617184.3630160", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper presents a method for recognizing traffic from encrypted webshells...", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、従ってML/LLMを用いた手法ではないため除外基準EC1に該当します。"}, {"code": "ex_out_of_scope", "evidence": "identifying traffic from encrypted webshells, extracting and filtering encrypted request and response packets...", "explanation": "研究対象はネットワークトラフィックの暗号解析・検出であり、低水準コードから高水準コードへの復元（デコンパイル）とは無関係なので除外基準EC5に該当します。"}], "reasoning": "本稿は暗号化されたWebシェルのトラフィック検出手法を提案しており、機械学習やLLMを用いたコード復元・生成は行っていません。そのため、デコンパイル調査の対象外であり、除外 (exclude) と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3043, "latency_ms": 23865}}
{"key": "10.1145/3617686", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "based on the low-level virtual machine (LLVM) compiler infrastructure... from LLVM intermediate representations", "explanation": "アブストラクトは LLVM IR を入力として扱っており、バイナリやアセンブリ等の低水準表現ではないため、デコンパイルの入力条件を満たさないと判断した。"}, {"code": "ex_no_ml", "evidence": "We propose a compilation tool to automatically migrate legacy programs...", "explanation": "ML/LLM の利用が言及されておらず、手法はコンパイラベースの最適化であるため、除外基準の EC1 に該当する。"}], "reasoning": "本稿は LLVM IR を用いたコンパイル支援ツールであり、低水準バイナリから高水準コードへの復元を目的としていない上、機械学習や大規模言語モデルを使用していないため、デコンパイル調査の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3252, "latency_ms": 26583}}
{"key": "10.1145/3623759.3624544", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We describe the design of the language and its verified compiler", "explanation": "要旨では機械学習や大規模言語モデルの利用は言及されておらず、ML手法が用いられていないと判断できるため。"}, {"code": "ex_no_lowlevel_input", "evidence": "a new language for verifiable, low-level systems programming", "explanation": "対象は低水準システム向けの新言語・コンパイラであり、入力がバイナリやアセンブリといった低水準表現ではなくソースコードレベルであると要旨から読み取れるため。"}], "reasoning": "本稿はデコンパイルを目的とした研究ではなく、低水準システム向け言語とその検証コンパイラの設計を紹介している。機械学習やLLMの使用も示されておらず、低水準バイナリ入力からの高水準コード生成というサーベイの対象外である。", "model": "openai/gpt-oss-120b", "tokens_used": 3192, "latency_ms": 29488}}
{"key": "10.1145/3643744", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we first introduces R2I, a specialized metric tailored to evaluate decompiled code", "explanation": "要旨ではML/LLMを用いた手法について言及されず、評価指標の提案のみであるためML/LLMが使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "R2I can be computed by i) taking code snippets across different decompilers as input and ii) extracting pre-defined features from an abstract syntax tree", "explanation": "本研究の目的はコードの可読性を測定する指標を算出することであり、コードの復元や生成を行うものではないため、コード生成/復元の意図がないと判断した。"}], "reasoning": "本稿はデコンパイルされたコードの可読性を測る指標 R2I を提案する研究であり、ML/LLM を利用したデコンパイル手法やコード生成は行っていない。したがって、Include 基準を満たさず Exclude 基準（ML未使用、コード生成意図なし）に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3412, "latency_ms": 31417}}
{"key": "10.1145/3646547.3688433", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "We develop a semi-automated general methodology involving off-the-shelf tools to examine information disclosure during the setup phase.", "explanation": "アブストラクトはオフ・ザ・シェルフツールによる手法を述べており、機械学習や大規模言語モデルの利用は示されていないため、EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "We characterize the potential information leakage from IoT platforms during their setup phase.", "explanation": "目的は情報漏洩の特定・評価であり、コードの生成や復元は主目的ではなく、EC3 に該当します。"}], "reasoning": "本稿は IoT デバイスの設定時の情報漏洩を評価するセキュリティ調査であり、低水準バイナリから高水準コードを再構築することや、ML/LLM を用いたデコンパイル手法は扱っていません。したがって、除外基準 (EC1, EC3) に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3244, "latency_ms": 29482}}
{"key": "10.1145/3650212.3652133", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The generator uses static analysis techniques to deduce the correct calling sequences...", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、静的解析のみが用いられているため、EC1 の「ML/LLM を使用していない」に該当します。"}, {"code": "ex_no_code_generation", "evidence": "Atlas consists of an automatic harness generator and a fuzzer...", "explanation": "生成されるハーネスはテスト実行用のコードであり、復元・可読化・高水準コード生成を目的としたデコンパイルではないため、EC3 の「コード生成／復元が主目的でない」ことに該当します。"}], "reasoning": "本稿は Android の閉源ネイティブライブラリ向けに自動ハーネス生成とファジングを行うフレームワークを提案しており、機械学習や LLM を用いたデコンパイル手法を扱っていません。そのため、Decompilation Survey の採択基準を満たさず除外されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3310, "latency_ms": 27855}}
{"key": "10.1145/3650212.3652144", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "Identifying and analyzing the problems of existing decompilers and making targeted improvements...", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、従来の手法・評価に限定しているためML/LLMが使われていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "We systematically evaluate current mainstream decompilers’ semantic consistency and readability.", "explanation": "本研究はデコンパイラの出力を評価・分析することが目的であり、低水準入力から新たに高水準コードを生成することは行っていない。"}], "reasoning": "この論文は既存デコンパイラの評価と改善提案を行う調査研究であり、ML/LLM を用いた手法やコード生成・復元の目的は示されていない。そのため、除外基準 EC1（ML未使用）および EC3（コード生成目的でない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3344, "latency_ms": 31420}}
{"key": "10.1145/3650212.3680301", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our analysis uses a novel abstract domain to systematically track the \"structure\" of computed code pointers without relying on syntactic pattern-matching", "explanation": "抽象ドメインを用いた手法であり、機械学習や大規模言語モデルの使用が言及されていないため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "Resolving these indirect jumps is critical for constructing a complete control-flow graph, which is an essential first step for most applications involving binaries", "explanation": "目的は制御フローグラフの構築やバイナリ解析・ハードニングであり、ソースコードや高水準表現の生成・復元を目指すものではなく、コード生成・復元の意図が無いと判断した。"}], "reasoning": "本稿はバイナリ中のジャンプテーブル解析手法を提案しており、機械学習や大規模言語モデルを使用した記述がなく、また生成や復元を目的としたコード出力も示されていないため、デコンパイル調査の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3241, "latency_ms": 28424}}
{"key": "10.1145/3650215.3650347", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_variable_naming", "evidence": "binary function naming is a code analysis task that generates functional descriptions of functions", "explanation": "抽象的に「関数名」を生成することが目的であり、これは高水準属性（L4）であり命名復元に該当するため"}, {"code": "in_variable_naming", "evidence": "A2N extracts the function variable features of binary files ... establish a mapping between the AST and the binary function names", "explanation": "入力がバイナリであり、ニューラルネットワーク翻訳モデル（ML）を中心手法として使用していることが示されているため"}], "reasoning": "本研究はバイナリを入力とし、ニューラル翻訳モデルを用いて関数名（識別子）を予測する手法を提案している。入力は低水準バイナリで、出力は関数名という高水準属性であり、目的は逆解析支援のための名前復元であるため、Peripheral の「Variable/Function Naming」カテゴリに該当し、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3625, "latency_ms": 43059}}
{"key": "10.1145/3652588.3663324", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Loop analysis is a key component of static analysis tools.", "explanation": "アブストラクトは静的解析ツールにおけるループ解析を扱っており、バイナリやアセンブリ等の低水準入力についての記述がないため、低水準入力が無いと判断した。"}, {"code": "ex_no_ml", "evidence": "This paper presents a collection of examples and \"folklore\" challenges in loop analysis.", "explanation": "本文は例示と課題の提示に留まり、機械学習／大規模言語モデルの使用に関する記述が全くないため、ML/LLM を使用していないと判断した。"}], "reasoning": "本稿は C 言語のループに関する誤解と境界事例を提示するもので、低水準コードから高水準表現への復元や LLM/ML 手法の適用を目的としていない。したがって、デコンパイル調査の対象外であり、除外基準 (EC2, EC1) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2965, "latency_ms": 23266}}
{"key": "10.1145/3652628.3652786", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we present a novel Android app repackaging classification method ... achieves 87.53% accuracy for repackaged apps classification", "explanation": "要旨から本研究の目的はリパッケージされたアプリの分類であり、コードの復元・生成を目的としていないため、EC3 に該当し除外と判断した。"}], "reasoning": "本稿は低レベルの smali から埋め込みを抽出し、ニューラルネットワークでリパッケージアプリを分類する手法を提案している。目的は分類・検出であり、デコンパイルによるソースコードや高レベル表現の復元・生成ではない。したがって、除外基準 EC3（コード生成・復元目的でない）に該当し、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3152, "latency_ms": 25462}}
{"key": "10.1145/3658644.3670340", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_variable_naming", "evidence": "recover variable symbols, including ... names and types", "explanation": "抽象から、LLM がバイナリから変数名を復元することが主目的であると読み取れ、変数命名回復に該当するため"}, {"code": "in_type_recovery", "evidence": "recover variable symbols, including both primitive and complex types such as user-defined data structures", "explanation": "同様に型情報（プリミティブ型・ユーザ定義構造体）の復元も目的として記載されており、型回復に該当するため"}], "reasoning": "本論文は LLM とプログラム解析を組み合わせ、ストリップドバイナリから変数名と型情報を復元する手法を提案している。低水準入力（バイナリ）と高水準属性（名前・型）を扱い、復元・可読化を目的としているため、Peripheral Decompilation に該当し、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3342, "latency_ms": 32050}}
{"key": "10.1145/3658644.3690244", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an approach to lift position-independent x86-64 binaries to symbolized NASM.", "explanation": "アブストラクトに機械学習／LLM の利用が全く記載されておらず、手法は形式検証や定理証明によるものであるため、EC1 の「ML/LLM を用いていない」に該当します。"}], "reasoning": "本稿はバイナリをシンボライズされたアセンブリへリフトする手法を提案しており、ML/LLM を中心手法として使用していません。したがって、除外基準 EC1 (ex_no_ml) に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3144, "latency_ms": 24391}}
{"key": "10.1145/3658644.3691386", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "We focus on the lifting from assembly to the IR P-Code ... we leverage machine-learned x86-64 semantics", "explanation": "アブストラクトは、低水準のアセンブリから高水準の P-Code (IR) へ変換することを目的としており、機械学習によるセマンティクスを用いているため、LLM/ML が中核手法として decompilation（L1‑L3）を実施していると判断した。"}], "reasoning": "この論文は、バイナリ（アセンブリ）を入力とし、機械学習を活用して高水準IR（P-Code）へ変換する手法を提案している。出力は L3 に該当し、目的は逆コンパイルプロセスの一部であるリフティングの正式検証であるため、コアデコンパイル研究として採択する。", "model": "openai/gpt-oss-120b", "tokens_used": 3481, "latency_ms": 36889}}
{"key": "10.1145/3659211.3659272", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "we propose an improvement scheme for OLLVM obfuscation, which improves the degree of obfuscation ...", "explanation": "概要はコード難読化の手法提案であり、デコンパイルや高水準復元を目的としていないため、サーベイ対象外です。"}, {"code": "ex_no_ml", "evidence": "we propose an obfuscation scheme for code rearrangement; ... add an enhancement obfuscation module", "explanation": "本文中に機械学習や大規模言語モデルの使用についての記述がなく、ML/LLM が手法の中核でないため除外基準に該当します。"}], "reasoning": "本論文は OLLVM の難読化手法の改良を提案しており、低水準コードから高水準コードを復元することを目的としていないうえ、機械学習・LLM を用いた手法の記述もない。したがって、デコンパイル調査のスコープ外であり除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3112, "latency_ms": 23819}}
{"key": "10.1145/3663530.3665020", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "our pilot study reviews prevalent data challenges across various SE tasks", "explanation": "本文はデータ課題の調査・レビューであり、実装されたデコンパイル手法やLLM/MLを用いたコード生成を提示していないため、サーベイ/レビュー論文に該当します"}], "reasoning": "本稿は自動化ソフトウェア工学タスクにおけるデータ課題をレビューする調査論文であり、デコンパイルやLLM/MLによるコード復元を扱う研究ではありません。そのため除外基準EC4（Survey/Review）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2807, "latency_ms": 15323}}
{"key": "10.1145/3664476.3664486", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we conduct a large-scale analysis of TEE utilization in Android applications", "explanation": "アブストラクトにML/LLMの使用について言及がなく、単なる統計的分析であるためMLが使われていないと判断した"}, {"code": "ex_no_code_generation", "evidence": "our analysis illuminates the implementation of TEE-related features and their contextual usage", "explanation": "目的はTEE機能の利用実態の調査であり、コード生成や復元は行わないためコード生成・復元の意図がないと判断した"}], "reasoning": "本文はAndroidアプリにおけるTEE機能の使用状況を大規模に調査する研究であり、デコンパイルやコード復元を目的としていない上に、機械学習・大規模言語モデルの利用も示されていない。そのため、本サーベイの除外基準（ML未使用、コード生成目的なし）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3246, "latency_ms": 30023}}
{"key": "10.1145/3672608.3707995", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "without resorting to any disassembly or decompilation, which are undecidable in general.", "explanation": "本文はML/LLMを利用した手法について言及しておらず、従来の実行ベースの解析手法のみを紹介しているため、除外基準EC1に該当します。"}], "reasoning": "本稿はELFバイナリを共有ライブラリ化し、具体的な実行によって関数パラメータや戻り値を回復する手法を提案していますが、機械学習や大規模言語モデルを用いたアプローチは示されていません。したがって、Decompilation Survey Screening Rulesの除外基準『ML/LLMを使用していない』に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2975, "latency_ms": 18725}}
{"key": "10.1145/3677999.3678276", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we show how we can use rewrite rules and specialisation to get GHC to partition our Haskell programs", "explanation": "タイトル・アブストラクトに機械学習や大規模言語モデルの使用は言及されておらず、手法は rewrite rules と specialisation であるため、ML/LLM が使われていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "partition our Haskell programs (almost) for free, if they are written using the Haste App or HasChor framework", "explanation": "入力は Haskell のソースコードであり、バイナリ・アセンブリ・バイトコードといった低水準表現が示されていないため、低水準入力が存在しないと判断した。"}], "reasoning": "本稿は Haskell プログラムのリライトと特殊化によるプログラム分割手法を提案しており、機械学習・LLM の利用やバイナリ等の低水準入力を伴うデコンパイルとは無関係である。そのため除外基準 (EC1, EC2) に該当し、サーベイの対象外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3391, "latency_ms": 36613}}
{"key": "10.1145/3678232.3678233", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "higher-order unification procedure ... heuristics when the terms fall outside the pattern fragment", "explanation": "要旨では機械学習や大規模言語モデルの利用は言及されておらず、従来の論理フレームワークの手法のみが説明されているため"}, {"code": "ex_no_lowlevel_input", "evidence": "encoding of Coq terms that is suitable for meta programming", "explanation": "入力はバイナリやアセンブリ等の低水準表現ではなく、Coq の高レベル項やメタ言語の表現であることが示されているため"}], "reasoning": "この論文は高階統一を用いた証明探索手法を提案しており、バイナリやアセンブリといった低水準コードのデコンパイルとは無関係です。また、機械学習や大規模言語モデルを手法の中心に用いている記述もなく、除外基準の EC1 と EC2 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3923, "latency_ms": 32744}}
{"key": "10.1145/3678890.3678892", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we surveyed 21 professional malware analysts ... to hear their opinions about existing tools, practices, and the challenges they face", "explanation": "要旨には機械学習や大規模言語モデルの使用が言及されておらず、ML/LLM が手法の中核であるという条件を満たさないため"}, {"code": "ex_survey_or_meta", "evidence": "To answer these questions, we surveyed 21 professional malware analysts ...", "explanation": "本研究は実験的手法ではなく、実務者へのアンケート調査であり、サーベイ論文に該当するため"}], "reasoning": "本稿はマルウェア分析者へのアンケート調査を行ったサーベイであり、デコンパイルやML/LLM を用いた高水準コード生成を対象とした研究ではない。したがって除外基準（EC1: No ML/LLM、EC4: Survey/Review）に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3130, "latency_ms": 22992}}
{"key": "10.1145/3686215.3690147", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LLMs ... bypassing evasion techniques ... provide step-by-step reasoning", "explanation": "要旨はLLMが回避手法を提案・説明することであり、ソースコードや擬似コード等の高水準コード生成・復元を目的としていないため、コード生成/再構成の意図がないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "evasive code, symbolic analysis", "explanation": "抽象からは入力がバイナリやアセンブリなどの低水準表現であることが明示されておらず、入力が低水準かどうか不明であるため除外基準に該当すると判断した。"}], "reasoning": "本論文はLLMを用いてマルウェアの回避技術を特定・説明することに焦点を当てており、コードやソースの復元・生成を目的としていない。また、低水準入力（バイナリ・アセンブリ等）の使用も抽象からは確認できないため、デコンパイルに関するサーベイの採択基準を満たさないと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3417, "latency_ms": 32574}}
{"key": "10.1145/3691620.3695012", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we first extract four types of feature ... by executing the program symbolically", "explanation": "本文ではシンボリック実行とSMTソルバを用いて特徴抽出・比較を行うと記述されており、機械学習や大規模言語モデルの使用は示されていないため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "match the features to determine the presence of a patch with an SMT solver", "explanation": "目的はパッチ有無の判定であり、ソースコードや擬似コード等の高水準表現を生成することはなく、復元・可読化を目的としたコード生成が行われていないため除外基準に該当する。"}], "reasoning": "本稿はバイナリとソースから抽出したIR特徴を用いたパッチ有無検出手法を提案しており、機械学習・LLM を用いたデコンパイルやコード生成は行っていない。したがって、Decompilation Survey の対象外（除外基準 EC1 と EC3）となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3237, "latency_ms": 38079}}
{"key": "10.1145/3691620.3695020", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "fine-tuned LLM to interpret and decompile Wasm binary code into a higher-level, more comprehensible source code representation", "explanation": "LLM が低レベルの Wasm バイナリを直接入力として高水準のソースコード（L1）を生成しており、目的も可読化・復元であるため Core Decompilation に該当する。"}], "reasoning": "本稿は WebAssembly バイナリを入力とし、LLM を中心手法として高水準ソースコード（コンパイル可能な形）を生成する研究である。入力が低水準バイナリ、出力がコード、目的が復元・可読化であり、除外基準に該当しないため、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3242, "latency_ms": 35753}}
{"key": "10.1145/3691620.3695271", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "combine ... heuristic pattern matching to detect and classify malicious code poisoning attacks", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、ヒューリスティックなパターンマッチングのみであり、ML/LLM が使用されていないため除外基準 EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "detect and classify malicious code poisoning attacks", "explanation": "本研究の目的はコードの検出・分類であり、低水準コードから高水準コードを生成・復元することはなく、コード生成・再構成の意図がないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はプリトレインドモデルハブに対するマルウェア検出パイプラインを提示しているが、低水準バイナリから高水準コードを復元するデコンパイルや、LLM/ML を中心とした手法は用いられていない。したがってデコンパイル調査の対象外と判断し、除外 (exclude) とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3377, "latency_ms": 43456}}
{"key": "10.1145/3691620.3695502", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_type_recovery", "evidence": "Type recovery in stripped binaries ... machine learning methods ... few-shot learning", "explanation": "要旨はバイナリという低水準入力から型情報という高水準属性を予測することを目的としており、Few‑shot Learning を用いた機械学習手法が中心であるため、タイプリカバリ研究に該当します。"}], "reasoning": "本稿はバイナリを入力とし、機械学習（Few‑shot Learning）で型を予測することを目的としているため、デコンパイルの属性回復（Peripheral）に該当し、IC3 の条件を満たすと判断しました。ML が中心手法である点と、復元目的が明示されている点から include と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3363, "latency_ms": 47399}}
{"key": "10.1145/3696410.3714790", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "LLM-powered web application that decompiles smart contract bytecodes ... into ... re-compilable source code", "explanation": "LLMが中心手法として低水準バイトコードから高水準のソースコード（L1）を直接生成しているため、Core Decompilation に該当します。"}], "reasoning": "本稿は低水準のスマートコントラクトバイトコードを入力とし、LLMを中心手法として人間が読める再コンパイル可能なソースコードを生成することを目的としている。これらはInclude Criteriaをすべて満たすため、調査対象としてincludeと判定します。", "model": "openai/gpt-oss-120b", "tokens_used": 3497, "latency_ms": 46768}}
{"key": "10.1145/3696630.3728508", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identifying compliance issues", "explanation": "アブストラクトはLLMを用いてコードの GDPR 適合性を検証し、コンプライアンス問題を特定することを目的としているが、ソースコードや擬似コードの生成・復元は行わないため、コード生成・復元の目的が無く除外基準 EC3 に該当する。"}], "reasoning": "本論文は Smali という低水準表現を入力に、LLM でプライバシー規制の適合性をチェックする手法を提案しているが、出力はコンプライアンス違反の検出であり、デコンパイル（高水準コードやASTの生成）とは無関係である。したがって、コード生成・復元を目的としないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3163, "latency_ms": 39715}}
{"key": "10.1145/3696630.3731468", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "the safety and security of the software controlling the CPS are directly linked with the safety and security of human bystanders", "explanation": "抽象はソフトウェアレベルの安全性について述べており、バイナリやアセンブリといった低水準入力については言及していないため、低水準入力が存在しないと判断した。"}, {"code": "ex_no_ml", "evidence": "This thesis aims to reconcile both parties.", "explanation": "本文中に機械学習や大規模言語モデルの利用が一切記載されておらず、ML/LLM が手法として用いられていないと判断した。"}], "reasoning": "本稿はサイバーフィジカルシステムのソフトウェア適合性評価を対象としており、低水準コードやバイナリのデコンパイル、またそれに関連する機械学習手法の使用は示されていない。したがって、デコンパイル調査の対象外となり除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3584, "latency_ms": 57483}}
{"key": "10.1145/3698062.3698068", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "leverages Long Short-Term Memory (LSTM) networks to scrutinize native code opcodes... detection of obscured malicious code", "explanation": "要旨は LSTM を用いたマルウェア検出であり、コードの復元や高水準表現の生成を目的としていないため、コード生成・再構築の意図がないと判断した。"}], "reasoning": "本論文は Android のネイティブコードから特徴を抽出し LSTM でマルウェアを検出する手法を提案しているが、デコンパイルや高水準コードの生成を目的としていない。したがって、コード生成・復元を伴わないため除外基準 EC3 (ex_no_code_generation) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3156, "latency_ms": 42211}}
{"key": "10.1145/3700058.3700123", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "static and dynamic analysis, and proposes a combined dynamic and static detection method", "explanation": "アブストラクトではML/LLMの利用について言及されておらず、静的・動的解析のみが述べられているため、ML/LLMを使用していないと判断した。"}], "reasoning": "本稿はスマートコントラクトの脆弱性検出手法を提案しており、デコンパイルやコード生成を目的としていない上に、ML/LLMを用いた手法の記述がないため、除外基準EC1（ex_no_ml）に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3315, "latency_ms": 52591}}
{"key": "10.1145/3702977", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose ReuNify to improve Soot-based static analysis coverage... ReuNify converts Hermes bytecode to Soot’s intermediate representation.", "explanation": "アブストラクトに機械学習や大規模言語モデルの利用が記載されておらず、従来のコンパイラ/変換技術のみで実装されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は Hermes バイトコードを Soot IR に変換する手法を提案しており、入力は低水準バイトコードであるものの、機械学習や大規模言語モデルを用いる旨の記述が全くない。したがって、Decompilation Survey の採択基準で要求される「LLM/ML が中核手法として使われている」条件を満たさず、除外基準 EC1 (ex_no_ml) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3232, "latency_ms": 42658}}
{"key": "10.1145/3708821.3733877", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we perform the first comprehensive empirical study on state-of-the-art C decompilers", "explanation": "要旨からは機械学習や大規模言語モデルの利用が記載されておらず、従来のデコンパイラを評価する調査であるため、ML/LLM が使用されていないと判断した"}], "reasoning": "本稿は既存のCデコンパイラを評価し、性能指標とエラー分類を提示する実証的研究であり、抽象的にMLやLLMを用いた手法は提示されていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、include の条件を満たさない。", "model": "openai/gpt-oss-120b", "tokens_used": 2992, "latency_ms": 35385}}
{"key": "10.1145/3713081.3731728", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Binary Code Similarity Detection (BCSD) is essential for security tasks such as vulnerability identification", "explanation": "要旨はバイナリ類似性検出という分類/検知タスクであり、ソースコードの復元や生成を目的としていないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリコードの類似性を検出する手法を提案しており、デコンパイルや高水準コードの再構築を目的としていません。したがって、除外基準「コード生成・復元が主目的でない」(EC3) に該当し、インクルード対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3097, "latency_ms": 42966}}
{"key": "10.1145/3713081.3731745", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "evaluate the effectiveness of Code LLMs in Android malware analysis... malicious function identification and malware purpose summarization", "explanation": "要旨はLLMを用いてコードを解析し機能識別や要約を行うことが目的であり、低水準コードから高水準コードを生成・復元すること（デコンパイル）は行わないため、コード生成/再構築の意図がないと判断した。"}], "reasoning": "本論文はデコンパイルそのものではなく、既にデコンパイルされたAndroidマルウェアコードを対象にLLMを評価・解析することに焦点を当てている。目的がコード生成や復元ではなく、機能識別や要約といった分析タスクであるため、除外基準 EC3（コード生成・再構築意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3120, "latency_ms": 40301}}
{"key": "10.1145/3714393.3726486", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "we manually crafted repairs ... covering 176 Java-based and 96 XML-based violations from Android Java classes and Manifest files", "explanation": "アブストラクトは低水準バイナリやアセンブリではなく、Java ソースコードと XML マニフェストを対象としているため、低水準入力が存在せず除外基準 EC2 に該当します"}], "reasoning": "本稿は Android アプリのセキュリティ違反を修正するためのデータセットと、LLM を用いた自動プログラム修正（APR）の評価に焦点を当てており、デコンパイルや低水準コードから高水準コードへの復元を目的としていません。入力はソースコードレベルであるため、デコンパイル調査の範囲外と判断し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3047, "latency_ms": 38601}}
{"key": "10.1145/3715780", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "produce customized summaries tailored to multiple intents", "explanation": "要旨からは出力が自然言語のサマリーであり、コードやソース・擬似コードの復元ではないため、復元・生成を目的としたデコンパイルとはみなせません。"}], "reasoning": "本稿はバイナリコードを入力として自然言語の要約を生成することを目的としており、コードやソースレベルの高水準表現の復元を行わないため、デコンパイルの定義（コード生成/再構成）に該当しません。したがって除外基準 EC3（コード生成・復元意図がない）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3221, "latency_ms": 42209}}
{"key": "10.1145/3719027.3760714", "action": "keep", "reason": "uns_unclear_method", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_method", "evidence": "HarvETHter ... leverages it to decompile smart contracts to Solidity source code.", "explanation": "抄録では機械学習や大規模言語モデルの使用が明示されておらず、手法が ML/LLM かどうか判断できないため"}], "reasoning": "本稿はEVMバイトコードを入力とし、Solidityソースへのデコンパイルを目的としている点はIC0を満たすが、手法としてML/LLMが用いられているかが抄録だけでは不明である。したがって、ML/LLM の有無を確認できるまで判定を保留とする。", "model": "openai/gpt-oss-120b", "tokens_used": 2898, "latency_ms": 38520}}
{"key": "10.1145/3719027.3762169", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present JaDX-ACVTool, a plugin that bridges this gap by integrating code coverage information from ACVTool directly into JaDX-GUI.", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、単なるプラグインによるコードカバレッジの統合であるため、EC1 の「ML/LLM が使用されていない」基準に該当します。"}], "reasoning": "本稿は Android アプリの逆解析支援ツールを紹介しており、機械学習・LLM を用いたデコンパイル手法は含まれていません。したがって、除外基準 EC1（ex_no_ml）に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3038, "latency_ms": 43335}}
{"key": "10.1145/3719027.3765040", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This work presents the first large‑scale study on human‑assisted Python decompilation...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が言及されておらず、単なる実証的調査であるため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_survey_or_meta", "evidence": "Our study reveals common patterns observed in the patching process...", "explanation": "研究は実データの観測とユーザスタディに基づく調査であり、新手法の提案ではなくサーベイ/実証研究に該当する。"}], "reasoning": "本稿は Python バイトコードのデコンパイルに関する大規模調査と人間によるパッチ適用の分析を行っているが、機械学習や LLM を手法として利用している記述がなく、デコンパイル手法そのものの提案でもない。したがって、Decompilation Survey の採択基準 (ML/LLM 使用、コード生成目的) を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3169, "latency_ms": 40466}}
{"key": "10.1145/3719027.3765089", "action": "keep", "reason": "uns_unclear_method", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_method", "evidence": "leveraging probabilistic constraints to estimate the likelihood of each function signature recovery result", "explanation": "要旨では確率的制約を用いると記載されているが、機械学習やLLMが中心手法であることは明示されていないため、ML/LLMの使用が不明です。"}], "reasoning": "本論文はバイナリを入力とし関数シグネチャ（型・パラメータ情報）を復元することを目的としている点でデコンパイル領域に該当しますが、手法が機械学習／LLMを中核としているかが要旨からは判断できません。そのため、include／exclude を決定するには全文の確認が必要です。", "model": "openai/gpt-oss-120b", "tokens_used": 3359, "latency_ms": 50935}}
{"key": "10.1145/3719027.3765144", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We implement our dedicated obfuscation schemes as an end-to-end obfuscation toolchain called NeuroShield.", "explanation": "本文は新しいオブフュスケーション手法を提案しており、ML/LLM を用いた手法についての記述がなく、ML/LLM が中心技術ではないため除外します。"}, {"code": "ex_no_code_generation", "evidence": "NeuroShield reduces the operator recovery rate to 3.03% for CV models and 47.18% for NLP models.", "explanation": "目的は逆コンパイル（デコンパイル）によるモデル復元の防止であり、コードの復元や生成は行わないため、コード生成・復元が主目的でないことが除外基準に該当します。"}], "reasoning": "この論文は DNN バイナリ向けのオブフュスケーション手法を提案しており、ML/LLM を用いたデコンパイルやコード生成・復元を目的としていない。したがって、Decompilation Survey の対象範囲外であり、除外基準 (ex_no_ml, ex_no_code_generation) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3287, "latency_ms": 44942}}
{"key": "10.1145/3720524", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "We formalize the process of binary lifting with heuristic-based assumptions used in real-world lifters", "explanation": "要旨は形式手法での二値リフトを議論しており、ML/LLM の利用は言及されていないため除外基準 EC1 に該当します"}], "reasoning": "本稿はバイナリリフティングの形式的正当性を扱うもので、機械学習や大規模言語モデルを手法の中核として使用していないため、除外基準 ex_no_ml に基づき除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3077, "latency_ms": 39539}}
{"key": "10.1145/3722041.3723097", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "decompiling the binary file through neural decompilation ... on the decompiled source code", "explanation": "ニューラル（ML）を用いてバイナリ（低水準入力）からソースコード（高水準表現）を直接生成しているため、コアデコンパイル研究に該当する。"}], "reasoning": "本論文はバイナリコードを入力とし、ニューラル・デコンパイル（ML手法）でソースコードを生成し、その上で脆弱性予測を行うという目的を持つ。入力が低水準であり、MLが中心手法、生成された高水準コードが主要成果物であることから、Include 基準を満たす Core Decompilation（in_core）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3080, "latency_ms": 44634}}
{"key": "10.1145/3722572.3727926", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we integrate an energy-aware networking stack with reverse-engineered Wi-Fi drivers", "explanation": "本文では逆コンパイルを行っているが、ML/LLM を用いた手法についての記述がなく、ルールベースや手動のリバースエンジニアリングと推測されるため除外基準 EC1 に該当する。"}], "reasoning": "抄録では低水準バイナリからドライバをリバースエンジニアリングしているが、機械学習や大規模言語モデルを手法の中核として使っている旨の記述がない。したがって、Decompilation Survey の対象となる ML/LLM ベースの研究ではなく、除外基準 ex_no_ml により除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3185, "latency_ms": 42249}}
{"key": "10.1145/3723498.3723739", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "speculative game design... fantasy console development communities on itch.io", "explanation": "抽象ではゲームデザインやファンタジーコンソールの創作について述べており、デコンパイルやバイナリから高水準コードへの変換とは無関係です。"}, {"code": "ex_no_ml", "evidence": "The paper examines the emergence and rise of speculative game design communities", "explanation": "本文中に機械学習や大規模言語モデルの使用についての言及がなく、ML/LLM が手法の中心であるという条件を満たしていません。"}], "reasoning": "本稿はゲーム産業における創造的抵抗やファンタジーコンソールの開発を社会学的に分析したもので、デコンパイルや逆コンパイルに関する技術的研究ではありません。また、機械学習や大規模言語モデルの活用も示されていないため、サーベイの対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3197, "latency_ms": 41632}}
{"key": "10.1145/3726101.3726103", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect malwares in android application... the results ... will be ultimately determining whether the APK given is malicious or benign.", "explanation": "要旨は Android APK のマルウェア検知を目的としており、コードの復元・可読化などの生成・再構成は行わないため、コード生成・復元を目的としたデコンパイルとは無関係です。"}], "reasoning": "本稿は機械学習を用いたマルウェア検出システムを提案しており、低水準バイナリから高水準コードを生成することが目的ではなく、分類・判定が主目的です。そのため、デコンパイルを目的とした研究の除外基準 EC3 に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3071, "latency_ms": 39388}}
{"key": "10.1145/3728911", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "hashes binaries into program-level representations through large language model (LLM)-generated function embeddings", "explanation": "抽象ではLLMを用いてバイナリを埋め込みに変換しているが、目的は類似性評価であり、コードや擬似コードの生成・復元を行わないため除外基準EC3に該当する"}], "reasoning": "本稿はバイナリを関数埋め込みへ変換し大規模類似検索を高速化することを目的としており、復元・可読化といったデコンパイルの主目的が示されていない。出力は埋め込みでありコード生成ではないため、除外基準EC3（コード生成・復元意図がない）に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3290, "latency_ms": 45979}}
{"key": "10.1145/3728935", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Shrnkr manages to achieve drastic improvements ... using static-analysis ...", "explanation": "アブストラクトでは静的解析やシンボリック実行を用いた手法のみが述べられており、ML/LLM の利用は示されていないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿は EVM バイナリのデコンパイルに焦点を当て、静的解析ベースの新手法を提案していますが、機械学習や大規模言語モデルを用いた旨が記載されていません。したがって、Decompilation Survey Screening Rules の除外基準 EC1（ML/LLM 未使用）に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3088, "latency_ms": 38386}}
{"key": "10.1145/3728958", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "automatically correcting decompiler outputs into compilable versions", "explanation": "LLM が既存のデコンパイラ出力（疑似コード）を入力とし、コンパイル可能なコードに修正する手法であり、デコンパイラ出力の可読性・再コンパイル性を向上させることが主目的なので `in_decompiler_enhancement` に該当します。"}], "reasoning": "本稿はバイナリから生成されたデコンパイル結果を LLM で修正し、コンパイル可能なソースコードに変換することを目的としている。LLM が手法の中心であり、出力は L1 のコンパイル可能なコードであるため、デコンパイル領域のコア（Core）対象の「デコンパイラ強化」に該当し、除外基準には当てはまらない。", "model": "openai/gpt-oss-120b", "tokens_used": 3676, "latency_ms": 59311}}
{"key": "10.1145/3729373", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "LLMs-based EVM decompilation pipeline... lift it into smart contract code.", "explanation": "LLM が低水準の EVM バイトコードから直接コンパイル可能な Solidity ソースコードを生成しているため、Core Decompilation に該当します。"}, {"code": "in_type_recovery", "evidence": "semantic enhancement based on a novel type-aware graph model to infer stripped variables", "explanation": "型情報の推論・回復を目的とした手法が組み込まれており、Type Recovery の要素も含んでいます。"}], "reasoning": "アブストラクトは低水準のバイトコードを入力とし、LLM を中心手法としてソースコードを生成することを目的としているため、Decompilation Survey の core 目的を満たします。また、型推論を行う技術も明示されているため、Type Recovery も関連するサブカテゴリです。", "model": "openai/gpt-oss-120b", "tokens_used": 3293, "latency_ms": 49761}}
{"key": "10.1145/3732365.3732428", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "combining static analysis with fuzzing techniques", "explanation": "抽象からは機械学習や大規模言語モデルの利用が一切示されておらず、従来の静的解析とファジングのみが使用されているため、ML/LLM が不可欠な本サーベイの対象外です。"}, {"code": "ex_no_code_generation", "evidence": "guide the seed file mutation technique, hence improving the accuracy and efficiency of fuzzing activities", "explanation": "目的はファジング用シードの変異・最適化であり、低水準コードから高水準コードや擬似コードを生成することはなく、復元・可読化が主目的ではないため除外基準に該当します。"}], "reasoning": "本論文は UEFI ファームウェアの構造解析とファジング手法の改良に焦点を当てており、機械学習／LLM の利用やコード復元・生成といったデコンパイル的目的が示されていません。そのため、Decompilation Survey のインクルード基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3246, "latency_ms": 49037}}
{"key": "10.1145/3732771.3742714", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "TranspileJS leverages a multi‑stage architecture that converts JS to TypeScript, which is compiled into Wasm using the AssemblyScript compiler.", "explanation": "要約からは機械学習や大規模言語モデルの利用が示されておらず、従来のコンパイルパイプラインのみが記述されているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "automatically selecting and translating JS snippets into Wasm", "explanation": "入力は JavaScript（高水準言語）であり、バイナリやアセンブリといった低水準表現が入力ではないため、除外基準 EC2 に該当すると判断した。"}], "reasoning": "本稿は JavaScript を WebAssembly に変換するトランスパイラを提案しており、入力は高水準ソースコードで低水準入力ではない。また、手法は従来のコンパイラチェーンであり機械学習や LLM を用いていないため、デコンパイル調査の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3325, "latency_ms": 50614}}
{"key": "10.1145/3732771.3742724", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our work introduces Alpakka, a source-to-source compiler for Android's Smali syntax.", "explanation": "要旨にML/LLMの使用が言及されておらず、従来のコンパイラ手法のみであると判断したため、除外基準 EC1 に該当します。"}], "reasoning": "本文は低水準の Smali を入力にしたソース間コンパイラを提案していますが、機械学習や大規模言語モデルの利用は示されていません。デコンパイルを目的としたML/LLM手法ではないため、本サーベイの対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3200, "latency_ms": 49874}}
{"key": "10.1145/3733817.3762702", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an empirical evaluation of the Tigress obfuscator...", "explanation": "要旨に機械学習や大規模言語モデルの使用について言及がなく、手法は従来のオブフュスケーションと静的解析の比較のみであるため。"}, {"code": "ex_no_code_generation", "evidence": "assess how these transformations affect the analyzability of C programs", "explanation": "目的はコードの可読化や復元ではなく、オブフュスケーションが解析ツールの精度に与える影響を評価することであり、コード生成・再構成は行わない。"}], "reasoning": "本稿は Tigress オブフュスケータの効果を評価する実証研究であり、機械学習/LLM を用いたデコンパイルやコード再構成を目的としていない。入力は C ソースであり、低水準バイナリからの高水準コード生成や型・命名・制御構造の復元といったデコンパイル関連の要件を満たさないため、除外基準に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3091, "latency_ms": 46212}}
{"key": "10.1145/3733822.3764668", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "ideco provides users with the ability to create rules which rewrite parts of the decompilation.", "explanation": "この記述から、手法はルールベースの書き換えであり、ML/LLM が中心手法として用いられている兆候がなく、除外基準 EC1 に該当すると判断した。"}], "reasoning": "抄録では、低レベル入力からのデコンパイル結果をルールで書き換えるフレームワークであると説明されており、ML/LLM が主要手法として使用されていることは示されていない。したがって、除外基準「No ML/LLM（ex_no_ml）」に該当し、include できないと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3269, "latency_ms": 55237}}
{"key": "10.1145/3733822.3764672", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "In reverse engineering our goal is to build systems that help people to understand software.", "explanation": "本文・要旨では機械学習や大規模言語モデルの利用が言及されておらず、従ってML/LLMを用いていないと判断したため。"}], "reasoning": "この論文はソフトウェア理解の評価手法を提案するものであり、ML/LLMを利用したデコンパイル手法や高水準コード生成に関する記述がない。したがって、Decompilation Survey Screening Rules の除外基準 EC1 (No ML/LLM) に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 2954, "latency_ms": 41777}}
{"key": "10.1145/3733822.3764673", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_type_recovery", "evidence": "Recovering semantic information from binary code ... we aim to analyze the types and roles of structural elements ...", "explanation": "低水準バイナリを入力とし、構造体メンバの型や役割といった属性を推論することが主目的であり、ML（GNN）を用いた型回復研究に該当するため"}], "reasoning": "本稿はバイナリコードを入力として Graph Neural Networks を利用し、構造体メンバの型情報など高水準属性を推測する手法を提示している。入力が低水準であり、ML が中心手法、目的が型回復（ソース復元支援）であるため、Peripheral の Type Recovery に該当し、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3289, "latency_ms": 48357}}
{"key": "10.1145/3733822.3764675", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper presents a benchmark study of five decompilers...", "explanation": "概要では既存デコンパイラを評価するだけで、機械学習やLLMを用いた手法について言及されていないため、EC1に該当します。"}, {"code": "ex_no_code_generation", "evidence": "The results highlight the relative strengths and weaknesses of each decompiler...", "explanation": "目的はデコンパイラの型推論性能比較であり、コード生成や復元そのものを行う研究ではないため、EC3に該当します。"}], "reasoning": "本稿は既存デコンパイラの型推論精度を比較評価するベンチマーク研究であり、ML/LLM を用いた新手法の提案やコード生成・復元を目的としていません。そのため、除外基準 EC1（ML/LLM 非使用）および EC3（コード生成目的非該当）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3139, "latency_ms": 44638}}
{"key": "10.1145/3735971", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we train a detection model that does not require expert experience based on publicly available on-chain bytecode and off-chain contract labels", "explanation": "本文はバイトコードから高次表現を生成して解析し、ポンジ契約の検出（分類）を目的としているため、コード生成や復元が主目的ではなく、除外基準EC3に該当する。"}], "reasoning": "本論文はバイトコードを解析してポンジ詐欺コントラクトを検出することを目的としており、LLM/MLは検出モデルの学習に使用されていますが、復元やソースコード生成といったデコンパイルの主目的はありません。そのため除外基準 EC3（コード生成・復元目的でない）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3350, "latency_ms": 48122}}
{"key": "10.1145/3746252.3761266", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "ORCAS ... scores their semantic similarity more robustly.", "explanation": "アブストラクトはバイナリ関数間の類似度をスコアリングすることが目的であり、コードやソースの生成・復元を行わないため、コード生成・再構成を目的としたデコンパイル研究には該当しません。"}], "reasoning": "本稿はバイナリコード類似性評価のためのグラフベース機械学習モデルを提案しており、出力は類似度スコアです。デコンパイルの目的である高水準コードや構造の復元・生成を行わないため、除外基準 EC3（コード生成・再構成が目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3197, "latency_ms": 44192}}
{"key": "10.1145/3749988", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "We develop REMEND, a neural decompilation framework to reverse engineer math equations from binaries", "explanation": "抽象的にバイナリ（低水準入力）から数学方程式という高水準表現を直接生成することを目的としており、LLM（Transformer）を中心手法として用いているため、Core Decompilation に該当すると判断した。"}], "reasoning": "本論文はバイナリ実行ファイルを入力とし、Transformerベースのニューラルデコンパイラで数学方程式という高水準コード/表現を生成する点で、IC0 の要件（低水準入力、ML/LLM 中核、復元目的）を満たす。したがって Core decompilation として採択すべきである。", "model": "openai/gpt-oss-120b", "tokens_used": 3402, "latency_ms": 50685}}
{"key": "10.1145/3755881.3755883", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "function identification ... key aspect", "explanation": "アブストラクトは関数判別を目的としており、コード生成やソース復元を行わないため、コード生成・復元の意図がなく除外基準EC3に該当します。"}], "reasoning": "本稿はスマートコントラクトのバイトコードから関数境界を識別する手法を提案しており、LLM/MLは使用しているものの、低水準入力から高水準コードや擬似コードを生成することを目的としていません。デコンパイルの主要目的であるコード復元・可読化が含まれないため、除外基準EC3（コード生成・復元が主目的でない）に該当し、exclude と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3672, "latency_ms": 70099}}
{"key": "10.1145/3756681.3756954", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "code completion focuses on integrating new lines or blocks of code into an existing codebase... we evaluate CCCI using 289 Java snippets", "explanation": "アブストラクトから、入力は既存のソースコード（Java スニペット）であり、バイナリやアセンブリといった低水準表現が存在しないことが明示されているため、低水準入力がないと判断した。"}], "reasoning": "本稿は LLM を用いたコード補完手法を提案しているが、入力は高水準のソースコードであり、デコンパイルの定義で求められる低水準入力が存在しない。そのため、インクルード基準を満たさず除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3219, "latency_ms": 48301}}
{"key": "10.1145/3757735", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Software protection refers to a range of methods used to protect applications against reverse engineering.", "explanation": "アブストラクトには機械学習や大規模言語モデルの使用について言及されておらず、ML/LLM が手法の中心であるという条件を満たさないため。"}, {"code": "ex_out_of_scope", "evidence": "This article presents a taxonomy categorizing and describing the main techniques used to secure Android applications.", "explanation": "研究対象は Android アプリの保護技術の分類であり、デコンパイルや低水準コードから高水準コードへの復元とは無関係であるため。"}], "reasoning": "本文は Android アプリの保護手法の調査・分類を行うサーベイであり、低水準バイナリからのデコンパイルや LLM/ML を用いたコード復元を目的としていない。したがって、除外基準（ML未使用、対象外領域）に該当し、インクルードできないと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3125, "latency_ms": 45902}}
{"key": "10.1145/3759425.3763387", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "automate function renaming", "explanation": "LLM を用いて関数名（変数/関数識別子）を自動付与することが主目的であるため、Variable/Function Naming に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "streamline the labor-intensive process of analyzing decompiled code and assigning meaningful function names", "explanation": "既存の逆コンパイラ（デコンパイラ）から得たコードを入力とし、LLM で可読性と命名を向上させる手法であるため、Decompiler Enhancement と判定しました。"}], "reasoning": "本稿はデコンパイルされたファームウェアコードに対し、LLM（ChatGPT）を用いて関数名を自動付与するシステムを提案している。入力はデコンパイルコードという低水準表現由来で、出力は関数名という高水準属性であり、目的は逆コンパイル結果の可読化・分析支援であるため、インクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3501, "latency_ms": 62815}}
{"key": "10.1145/3759425.3763397", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "statically detecting vulnerabilities at the binary level ... Recent efforts that leverage Large Language Models (LLMs) for vulnerability detection", "explanation": "要旨はバイナリの脆弱性検出であり、コード生成や高水準表現の復元が目的ではなく、分類/検知が主目的なので除外基準 EC3 に該当する"}], "reasoning": "本稿はLLMを用いたバイナリ脆弱性検出フレームワークであり、デコンパイルや高水準コードの再構成を目指すものではない。従って、コード生成・復元を目的としないため除外基準 EC3 に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3131, "latency_ms": 47981}}
{"key": "10.1145/3772368", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "codealign generates equivalence alignments, ... more detailed than existing evaluation metrics", "explanation": "抽象からはコード生成や復元が目的ではなく、ニューラルデコンパイラの評価手法を提案しているため、復元・生成という目的を満たさないと判断した。"}], "reasoning": "本稿はニューラルデコンパイラの出力を評価するための等価性測定手法を提案しており、実際に低水準入力から高水準コードを生成することが主目的ではない。したがって、Decompilation Survey の採択基準である「復元/可読化/意味回復を目的としたコード生成」には該当せず、除外基準 EC3（コード生成・復元意図の欠如）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3134, "latency_ms": 48158}}
{"key": "10.5555/3507788.3507824", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a method of control flow obfuscation using the InvokeDynamic instruction with native call site bootstrapping.", "explanation": "本文はオブフュスケーション手法を提案しており、機械学習や大規模言語モデルの使用が示されていないため、ML/LLM が用いられていないと判断しました。"}, {"code": "ex_out_of_scope", "evidence": "Modern obfuscation techniques aim to prevent reverse engineering and unauthorized use or modification to software.", "explanation": "研究の目的は逆コンパイルやコード復元ではなく、JVM バイトコードの制御フローを隠すオブフュスケーションであり、デコンパイル調査の範囲外です。"}], "reasoning": "この論文は JVM バイトコードに対する制御フローオブフュスケーション手法を提案しており、機械学習やLLM の利用が記載されていない上、目的もコードの復元や可読化ではなく保護であるため、デコンパイルに関するサーベイの除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3100, "latency_ms": 46917}}
{"key": "10.5555/3615924.3615947", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "deep learning-based approach for code similarity detection in binaries", "explanation": "目的がバイナリのコード類似性検出・脆弱性検出であり、復元や高水準コード生成が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリの類似性評価を通じた脆弱性検出を目的としており、LLM/ML はデコンパイルされたコードの表現学習に用いられていますが、復元や高水準コード生成が主たる目標ではありません。そのため、コード生成・再構築が目的でないという除外基準 (ex_no_code_generation) により除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3165, "latency_ms": 47636}}
{"key": "10043270", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "code obfuscation techniques are applied to smart contracts ...", "explanation": "アブストラクトでは機械学習や大規模言語モデルの使用について一切言及されておらず、純粋にオブフスケーション手法のみが述べられているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "current source code obfuscation methods have insufficient anti-decompilation ability", "explanation": "本研究の目的はデコンパイルを阻害するためのバイトコード難読化であり、デコンパイルそのものの復元や可読化を目指すものではなく、サーベイ対象の「復元・可読化」目的から外れているため除外する。"}], "reasoning": "本論文はスマートコントラクトのバイトコード難読化手法を提案しており、機械学習や大規模言語モデルを用いたデコンパイル技術ではない。入力は低水準バイトコードだが、目的はデコンパイルの阻害であり、復元・可読化を中心とした研究範囲外であるため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3151, "latency_ms": 50770}}
{"key": "10050059", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The experimental results show that the proposed method is effective for the vulnerability detection of smart contracts.", "explanation": "アブストラクトは脆弱性検出という分類タスクが主目的であり、コードの復元や高水準表現の生成を行っていないため、コード生成/再構成の意図がなく除外基準EC3に該当します。"}], "reasoning": "本論文はバイトコードを逆アセンブルしてオペコードを取得し、CFG を構築した上で GNN による脆弱性検出を行うもので、デコンパイルは前処理に過ぎません。目的は分類であり、LLM/ML が直接高水準コード（L1‑L3）を生成するわけではないため、除外基準 EC3（コード生成・復元が主目的でない）に該当し除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3142, "latency_ms": 44196}}
{"key": "10077138", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Replacing these instructions with another more complex order ... without changing the result of the program ... which is the core principle of code obfuscation.", "explanation": "要旨の中に機械学習や大規模言語モデルの使用が一切記載されておらず、ルール EC1 の「ML/LLM を用いていない」ことに該当するため除外と判断した。"}], "reasoning": "本稿は LLVM を用いたコード難読化手法を提案しており、デコンパイルやその支援を目的としていない上、機械学習・LLM の利用が示されていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1 に該当し、インクルード対象外と判定する。", "model": "openai/gpt-oss-120b", "tokens_used": 2982, "latency_ms": 44804}}
{"key": "10123452", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "summarise de-compiled binary functions", "explanation": "アブストラクトでは入力としてバイナリから逆コンパイルされたコード（高水準表現）を扱っており、低水準バイナリやアセンブリが直接入力になっていないため、EC2 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "summarise de-compiled binary functions", "explanation": "目的はコードの要約（自然言語説明）であり、コードや高水準プログラム表現の生成・復元ではないため、EC3 に該当します。"}], "reasoning": "本論文はデコンパイルされた関数を入力として自然言語の要約を生成することを目的としており、低水準バイナリからの直接的なコード復元や高水準コード生成を行っていません。そのため、入力が低水準でないこと、コード生成を目的としていないことの二つの除外基準に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3595, "latency_ms": 61702}}
{"key": "10123564", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we conduct ... empirical study of smart contract decompilers", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及されておらず、既存のデコンパイラを評価するだけであることから、ML/LLM が使用されていないと判断した。"}, {"code": "ex_survey_or_meta", "evidence": "first and most comprehensive large‑scale empirical study of smart contract decompilers", "explanation": "既存のデコンパイラツールを対象にした大規模な実証的調査であり、新手法の提案ではなくサーベイ的研究に該当する。"}], "reasoning": "本稿はスマートコントラクトバイトコードからソースコードへのデコンパイラを評価する実証的調査であり、LLM/ML を用いた新たなデコンパイル手法の提案や生成は行っていない。したがって、除外基準の「ML/LLM を使用していない」および「サーベイ／実証研究」に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3533, "latency_ms": 60166}}
{"key": "10123584", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose an LLVM-based code virtualization tool, namely xVMP", "explanation": "抽象からは機械学習や大規模言語モデルの利用が全く言及されておらず、従って本サーベイの除外基準 EC1 に該当するため除外と判断した。"}], "reasoning": "本稿はコード仮想化による難読化手法を提案しており、デコンパイルや逆解析支援を目的としていない。また、手法の中核として ML/LLM を使用していないため、Decompilation Survey の対象外である。", "model": "openai/gpt-oss-120b", "tokens_used": 3196, "latency_ms": 45246}}
{"key": "10174218", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_type_recovery", "evidence": "lack of semantic information like variable types makes comprehending binaries difficult", "explanation": "抽象からバイナリの型情報回復が主要目的であることが分かるため、タイプ回復に該当する。"}, {"code": "in_variable_naming", "evidence": "augmenting decompiled code with variable names and types", "explanation": "変数名の復元も目的に含まれているため、変数命名回復のコードを付与する。"}], "reasoning": "本稿はバイナリから抽出したデコンパイル出力を入力とし、Transformerベースのモデルで変数型と名前を予測・付加する手法を提案している。低水準バイナリに由来する入力と、型・識別子という高水準属性の復元という目的が明示されているため、Decompilation Survey のインクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3549, "latency_ms": 65312}}
{"key": "10179314", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Extensible static checking tools... However, the majority of these tools are inapplicable to binary-only analysis.", "explanation": "アブストラクトからは機械学習や大規模言語モデルの使用が全く言及されておらず、従来の静的解析・シンボリック解析手法のみが説明されているため、EC1に該当し除外します。"}], "reasoning": "本稿はデコンパイルされたコード上でクエリを実行するシンボリック解析フレームワークを提案しているが、手法の中心にML/LLMが用いられている記述がない。したがって、Decompilation Survey Screening Rules の除外基準 EC1（ML/LLM 未使用）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3146, "latency_ms": 42007}}
{"key": "10179370", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our key intuition is that we can resolve the decompilation errors by transforming error-inducing code blocks in the input binary into another form.", "explanation": "アブストラクトには機械学習や大規模言語モデルの利用が全く記載されておらず、手法はバイナリ変換に基づくルールベースのアプローチであるため、ML/LLM が中核手法であるという条件を満たさないと判断した。"}], "reasoning": "本稿は Python バイナリを変換して既存デコンパイラのエラーを回避する手法を提案しているが、機械学習・LLM の利用が示されていない。したがって、Decompilation Survey の採択基準（ML/LLM が中心手法）を満たさず、除外基準 ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3139, "latency_ms": 46728}}
{"key": "10183629", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we provide an overview of the main tools used in Android reverse engineering", "explanation": "アブストラクトはツールの概要をまとめた調査・レビューであり、独自の decompilation 手法や ML/LLM の使用を示していないため、除外基準 (Survey/Review) に該当します"}, {"code": "ex_no_ml", "evidence": "The study's finding shows App Cloner and Mt manager tools have the highest precision", "exexplanation": "本文中に機械学習や大規模言語モデルの利用が言及されておらず、ML/LLM を用いた研究ではないため、除外基準 (No ML/LLM) にも該当します"}], "reasoning": "本論文は Android アプリの逆解析ツールを体系的にまとめたサーベイであり、デコンパイル手法そのものや LLM/ML の活用に関する研究成果が示されていません。そのため、Survey/Review の除外基準に該当し、さらに機械学習手法を使用していない点でも除外されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3065, "latency_ms": 49007}}
{"key": "10188657", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "For static analysis, we implement a Ghidra processor module for decompilation and analysis of decrypted microcode.", "explanation": "要旨では Ghidra プラグインによる解析・デコンパイルを述べているが、機械学習や大規模言語モデルの利用は言及されておらず、EC1 に該当するため除外と判断した。"}], "reasoning": "本稿は Intel マイクロコードの逆解析とカスタマイズ手法を提示しているが、手法の中心に ML/LLM が使用されていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1（ex_no_ml）に該当し、include できない。", "model": "openai/gpt-oss-120b", "tokens_used": 3169, "latency_ms": 45153}}
{"key": "10195624", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "We propose a multi-label learning-based binary function naming model BContext2Name.", "explanation": "抽象的にバイナリ関数へ名前付けを行うことが主目的であり、変数・関数名の復元に特化した研究なので in_variable_naming に該当する。"}, {"code": "in_decompiler_enhancement", "evidence": "align pseudocode and basic blocks based on disassembly and decompilation, identify concrete or abstract values of API parameters by variable tracking, and construct API-enhanced control flow graphs.", "explanation": "バイナリから逆コンパイルした疑似コードや基本ブロック情報を活用し、属性情報を拡張して名前付けに利用している点が既存デコンパイラ出力の改善に該当する。"}], "reasoning": "本論文は低水準バイナリを入力とし、ニューラルネットワークを用いたマルチラベル学習で関数名を自動生成する手法である。目的は逆コンパイル結果の可読性向上であり、デコンパイルに直接寄与する属性（関数名）を復元するため、Peripheral ですが Inclusion 条件を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3538, "latency_ms": 60170}}
{"key": "10197775", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "SootDiff analysis tool, a bytecode comparison tool", "explanation": "要旨では機械学習や大規模言語モデルの利用について言及されておらず、従来のツールによる比較手法だけが述べられているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "compiled and decompiled bytecodes ... were compared to analyze the unique differences", "explanation": "研究の目的はバイトコードを比較して改ざんを検知することであり、コードの生成や復元は行わず、単なる差分検出にとどまっているためコード生成・復元の意図がないと判断した。"}], "reasoning": "本稿はバイトコード比較によるコード改ざん検出を目的としており、機械学習やLLMを用いた高水準コードの復元・生成は行われていない。したがって、Decompilation Survey の採択基準（IC）を満たさず、除外基準（EC1, EC3）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3322, "latency_ms": 56826}}
{"key": "10320193", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_variable_naming", "evidence": "reassign descriptive names for binary functions ...", "explanation": "関数名の再割り当てを目的としており、低水準表現から関数名（識別子）を復元するタスクであるため、変数/関数命名（in_variable_naming）に該当します。"}], "reasoning": "本稿はバイナリのアセンブリ・IR・疑似コードといった低水準表現を入力とし、ニューラルネットワークで関数名を予測する手法を提案している。ML 手法が核心であり、目的は逆コンパイル支援としての名前復元であるため、decompilation の範囲内の命名復元研究として採択 (include) します。", "model": "openai/gpt-oss-120b", "tokens_used": 3414, "latency_ms": 58627}}
{"key": "10410676", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Using a decompiler, models can be updated (retrained) and sent to other nodes", "explanation": "要旨ではデコンパイラは従来型のツールとして言及されており、LLM/ML をデコンパイルに利用した旨が示されていないため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は IoT 向け仮想化 VM とモデル配布に関する研究であり、デコンパイルは付随的に言及されるだけで、LLM や機械学習をデコンパイル手法の中心に据えていない。したがって除外基準 EC1 (No ML/LLM) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3034, "latency_ms": 46881}}
{"key": "10491696", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The experimental results show that the vulnerability semantic features extracted by SimFilter are highly interpretable, and the accuracy rate is increased by 10.8% compared with other models.", "explanation": "要旨はバイナリ脆弱性検出の精度向上を目的としており、コードの生成・再構成ではなく分類・検出が主目的であるため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿はバイナリ関数のデコンパイルを前段階として利用し、キー文の特徴抽出と類似度計算による脆弱性検出手法を提案しているが、目的は脆弱性の検出・分類であり、低水準入力から高水準コードを生成することではない。したがって、除外基準 EC3（コード生成・復元が主目的でない）に該当し、exclude と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3299, "latency_ms": 55158}}
{"key": "10500201", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present a model ... which relies on an interpreted programming language and a distributed file system.", "explanation": "要旨に機械学習や大規模言語モデルの使用について言及がなく、ML/LLM が手法の中核として用いられていないと判断したため。"}, {"code": "ex_no_lowlevel_input", "evidence": "the code does not need to be compiled and thus would not need to be run through a decompiler", "explanation": "低水準バイナリやアセンブリを入力とすることが前提ではなく、コンパイル不要なインタプリタ言語を使用する旨が示されているため。"}], "reasoning": "本稿はブロックチェーン上でインタプリタ言語（Python）を用いたスマートコントラクト実装を提案しており、ML/LLM を用いたデコンパイル手法は含まれない。入力は低水準バイナリではなく、高水準のインタプリタコードであることが示唆されるため、除外基準 (ex_no_ml, ex_no_lowlevel_input) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3364, "latency_ms": 60364}}
{"key": "10515515", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.82, "reason_codes": [{"code": "in_core", "evidence": "use ... genetic algorithms to restore the source code of software executed in the form of machine code", "explanation": "低水準のマシンコードを入力とし、遺伝的アルゴリズムという機械学習手法で直接 C ソースコード（L1）を生成しているため、Core Decompilation に該当します。"}], "reasoning": "本稿は機械コードを入力として遺伝的アルゴリズム（ML）を用い、コンパイル可能な C ソースコードを復元する手法を提案している。デコンパイルの目的（復元・可読化）を明示しており、IC0 をすべて満たすため Include と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3232, "latency_ms": 50610}}
{"key": "10545392", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "standard IDS features ... are not resilient for detecting (control logic) binary programs, such as entropy, n-gram, and decompilation.", "explanation": "アブストラクトには機械学習や大規模言語モデルの使用が記載されておらず、単に既存の IDS 手法と decompilation を比較しているだけであるため、ML/LLM を用いたデコンパイル研究ではないと判断した。"}], "reasoning": "本稿は PLC 制御ロジックへの攻撃手法を提示し、既存 IDS の検知限界を示すもので、デコンパイル手法そのものや ML/LLM を用いた高水準コード生成・復元を目的としていない。したがって、除外基準 EC1 (ML/LLM 未使用) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3237, "latency_ms": 47986}}
{"key": "10581196", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "The tool employs an intuitive user interface, providing a seamless experience for users with limited technical expertise.", "explanation": "要旨からは機械学習や大規模言語モデルの利用が全く言及されておらず、従来型の自動化手法とUIに焦点を当てているため、ML/LLMが使用されていないと判断した。"}], "reasoning": "本稿は APK の静的解析とデコンパイル機能を提供するフォレンジックツールを紹介しているが、機械学習や大規模言語モデルを手法の中心に用いる旨の記述がない。したがって、Decompilation Survey の採択基準で定義された「LLM/ML を中核手法として使用」要件を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3022, "latency_ms": 43293}}
{"key": "10589897", "action": "keep", "reason": "in_control_structure", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_control_structure", "evidence": "identifying inline functions in the binary code ... getting rid of the constraints imposed by the limited size of the candidate set", "explanation": "インライン関数を検出することで、バイナリ中の制御構造や関数境界を復元し、デコンパイル結果の可読性向上に直接寄与しているため、Control Structure Recovery に該当すると判断した。"}], "reasoning": "本論文はバイナリを入力とし、深層学習を用いてインライン関数（＝制御構造の一種）を自動的に識別する手法を提案している。目的はデコンパイル後のコード可読性向上であり、出力は関数境界という高水準属性になるため、Peripheral の Control Structure Recovery として include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3398, "latency_ms": 63169}}
{"key": "10590654", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "decompiling them into Smali code, and then trans-forming them into C++ code", "explanation": "本文は Smali から C++ への変換手法を述べているが、機械学習や LLM の利用について言及されていないため、EC1 の「No ML/LLM」に該当します。"}], "reasoning": "本論文は低水準コード（Smali）を高水準コード（C++）に変換する方法を提案していますが、手法の中心に機械学習や大規模言語モデルが使われている記述がなく、除外基準 EC1（ML/LLM 未使用）に該当するため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3117, "latency_ms": 46581}}
{"key": "10594168", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "decompiling component is used to get the source of the procedure to be tested.", "explanation": "要旨ではデコンパイルは単に入力ソースを取得するための前処理として言及されており、LLM/ML がデコンパイル手法の中核として用いられている証拠がないため除外基準 EC1 に該当する。"}, {"code": "ex_no_code_generation", "evidence": "malicious application or software classification training ... KNN and RF classification algorithms", "explanation": "研究の主目的はマルウェア検出のための分類であり、コードの復元や生成は目的に含まれないため除外基準 EC3 に該当する。"}], "reasoning": "本論文はデコンパイルをマルウェア検出のための前処理として利用し、LLM/ML をデコンパイルに用いていない上、主目的は分類・検出でコード復元・生成を目指していない。そのため、除外基準 (ML未使用、コード生成目的なし) に該当し、include には該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 3397, "latency_ms": 60578}}
{"key": "10596484", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we propose GraphBinMatch, an approach ... that learns the similarity between binary and source codes.", "explanation": "アブストラクトはバイナリとソースコード間の類似度を学習しマッチングすることを目的としており、コードの生成や復元は行わないため、復元・可読化を目的としたデコンパイルとは異なります。"}], "reasoning": "本研究はバイナリとソースコードの類似性学習によるマッチング手法であり、低水準入力から高水準コードを生成することを目的としていません。したがって、デコンパイル（復元・可読化）を目的とした研究の基準を満たさず、除外基準EC3（コード生成・復元意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3158, "latency_ms": 51070}}
{"key": "10625666", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "the whole process adopts the method of JNI call, the application core code is placed in the Java layer, the digital signature mechanism and integrity verification are placed in the Native layer", "explanation": "抽象では機械学習や大規模言語モデルの利用が全く言及されておらず、従ってML/LLMが手法の中核であるという条件を満たさないため除外します。"}], "reasoning": "本稿は Android アプリの保護機構を提案しており、デジタル署名や JNI を用いた実装手法を説明していますが、LLM/ML を用いたデコンパイルやコード復元に関する記述がありません。そのため、インクルード基準の IC0（ML/LLM の使用）が欠如していると判断し、除外としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3081, "latency_ms": 47632}}
{"key": "10646727", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "predict meaningful variable names in decompilation output", "explanation": "抽象では入力がバイナリやアセンブリといった低水準表現ではなく、すでにデコンパイルされたコード（高水準表現）から変数名を予測することのみが述べられているため、低水準入力が存在しないと判断した。"}], "reasoning": "本論文はデコンパイル済みコード上の変数名予測に焦点を当てており、入力として低水準バイナリやアセンブリを直接扱っていない。スクリーニング基準の除外条件 EC2（低水準入力がない）に該当するため、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3658, "latency_ms": 64848}}
{"key": "10649756", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "This chapter explores the steps necessary to get started reverse engineering an application.", "explanation": "要旨に機械学習や大規模言語モデルに関する記述がなく、従来の手法のみを説明しているため、ML/LLM を使用していないと判断した。"}], "reasoning": "アブストラクトは逆解析の手順やデコンパイルの概念を述べているだけで、機械学習や大規模言語モデルを用いた手法についての記載が全くない。したがって、本サーベイの採択基準である「LLM/ML が中核手法として使用されている」条件を満たさず、除外基準 EC1 (ex_no_ml) に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3116, "latency_ms": 53030}}
{"key": "10649762", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This chapter describes at a high level some advanced techniques and tools on the cutting edge of reverse engineering.", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、ML/LLM が手法の中核でないため EC1 に該当する。"}, {"code": "ex_survey_or_meta", "evidence": "This chapter describes at a high level some advanced techniques and tools on the cutting edge of reverse engineering.", "explanation": "「章」であり、技術やツールの概要を高水準に述べるだけであり、オリジナル研究ではなくレビュー的性格を持つため EC4 に該当する。"}], "reasoning": "本文は逆向きエンジニアリング技術の概観を提供する章であり、機械学習や大規模言語モデルを用いたデコンパイル手法についての具体的な記述がない。したがって、ML/LLM が中核でないことと、実質的にサーベイ/レビューであることから除外基準に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3403, "latency_ms": 64609}}
{"key": "10679822", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "introduce a code virtualization method, VMENP, which splits the code into multiple modules and uses polymorphic and modular encryption mechanisms", "explanation": "要旨からは機械学習や大規模言語モデルの利用が全く言及されておらず、従ってML/LLMが手法の中核ではないと判断したため。"}, {"code": "ex_no_code_generation", "evidence": "preventing the code from being decompiled", "explanation": "本研究の目的はコードの保護・難読化であり、復元や高水準コードの生成・再構築が主目的ではないため、コード生成目的のデコンパイル研究とは異なる。"}], "reasoning": "本稿はコード仮想化による実行時バイナリ保護手法を提案しており、機械学習や大規模言語モデルを利用したデコンパイル（復元・可読化）を目的としていない。そのため、Decompilation Survey の採択基準である LLM/ML の使用が欠如しており、除外対象となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3315, "latency_ms": 53020}}
{"key": "10743227", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "combines decompilation and diversification compilation techniques", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、従来の手法のみであるため、EC1に該当し除外します"}], "reasoning": "本論文はバイナリからのデコンパイルを利用したソフトウェア多様化手法を提案していますが、ML/LLM を中心手法として用いている記述がなく、ルールベースのアプローチとみなされます。したがって、除外基準 EC1 (No ML/LLM) に該当するため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3010, "latency_ms": 46584}}
{"key": "10773695", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present IRENE, a decompiler that produces recompilable decompilation for patching.", "explanation": "抄録に機械学習や大規模言語モデルの使用が言及されておらず、従来のデコンパイラ手法のみが説明されているため、ML/LLM が核心手法であるという条件を満たさない。"}], "reasoning": "本稿はバイナリを入力としたデコンパイル手法を提示しているが、機械学習や大規模言語モデルを用いる旨の記述がなく、ルールの EC1（ML/LLM 未使用）に該当するため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3296, "latency_ms": 56689}}
{"key": "10776359", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "develop a hybrid machine learning model to detect and anticipate malware on Android devices", "explanation": "要旨はマルウェア検知が目的であり、コードの復元や高水準表現の生成は行わないため、コード生成・再構築の意図がないと判断した。"}], "reasoning": "本稿は Android アプリのマルウェア検出を目的とした機械学習モデルの構築を述べており、デコンパイルは特徴抽出のための前処理として言及されるだけで、低水準入力から高水準コードや AST などを生成することが主目的ではない。したがって、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3363, "latency_ms": 55675}}
{"key": "10795101", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present Erase, the first approach to reverse the self-recursive inlining optimization technique.", "explanation": "要旨に機械学習や大規模言語モデルの利用が記述されておらず、従来の静的解析手法のみであると判断したため、EC1に該当し除外します。"}], "reasoning": "本稿はバイナリの自己再帰インライン化を除去してデコンパイラ出力を改善する手法を提案していますが、機械学習・LLM の活用が示されていません。そのため、インクルード基準の IC0（ML/LLM が中核手法）を満たさず、EC1 の「No ML/LLM」に該当し除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3215, "latency_ms": 51801}}
{"key": "10857519", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we propose a method ... malware detection using byte n-grams and machine learning", "explanation": "アブストラクトはバイト n-gram を用いたマルウェア検出を目的としており、コードの復元や擬似コード生成といったコード生成・再構成の意図が示されていないため、除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリのバイト n-gram を用いたマルウェア分類を対象としており、デコンパイルや高水準コードの復元を目的としていません。したがって、コード生成・復元が主目的である本サーベイの採択基準を満たさず、除外されます。", "model": "openai/gpt-oss-120b", "tokens_used": 3097, "latency_ms": 50470}}
{"key": "10911787", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "designed to ... enhance classification performance", "explanation": "アブストラクトはCNN‑BiLSTMモデルによるマルウェアの分類・検出を目的としており、ソースコードや擬似コードの生成・復元は行わないため除外基準EC3に該当します。"}], "reasoning": "本稿はバイナリを画像化・オペコード列に変換し、CNN‑BiLSTMでマルウェアを分類する手法を提案しています。デコンパイルは特徴抽出の一部として利用されていますが、主目的はコードの復元や可読化ではなく検出・分類であるため、除外基準EC3（コード生成・復元意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3231, "latency_ms": 53545}}
{"key": "10937558", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "It utilizes novel simplification methods that take ideas from compiler construction and simplification performed on parse trees.", "explanation": "要約に機械学習や大規模言語モデルの利用が記述されておらず、手法はコンパイラ構築やパースツリー簡略化といった従来型アルゴリズムであるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は MBA 混合ブール‑算術オブfuscation の簡略化を行うプラグインを紹介しているが、手法はルールベースの最適化であり機械学習を用いていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1（ex_no_ml）に該当し、除外と決定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3072, "latency_ms": 53135}}
{"key": "10965404", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "filters out suspected counterfeit applications ... determine whether the application is counterfeit", "explanation": "要旨は偽アプリ判別という分類・検知が主目的であり、コードの復元や生成を目的としていないため"}], "reasoning": "本稿はデコンパイルして得たメタ情報を用いて偽アプリを識別する分類モデルを提案しており、コードの復元・可読化を目的としていない。したがって、復元・生成が主目的でない点が除外基準 EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3364, "latency_ms": 61934}}
{"key": "10967090", "action": "keep", "reason": "in_control_structure", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_control_structure", "evidence": "many Java decompilers cannot recover ... the selection statement, i.e., if statement", "explanation": "抽象から、if 文などの制御構造の復元が主目的であり、低水準バイトコードから制御フローを分類してデコンパイル精度向上を狙っているため、IC5 に該当すると判断した。"}], "reasoning": "本稿は Java バイトコードを入力とし、機械学習（遺伝的アルゴリズム・KNN）で制御フローを分類し、デコンパイラの if 文復元を支援する手法を提案している。入力は低水準表現で、目的はデコンパイル精度の向上であり、出力は制御構造情報（L4）であるため、Peripheral な制御構造復元として含める。", "model": "openai/gpt-oss-120b", "tokens_used": 3453, "latency_ms": 65964}}
{"key": "10986108", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "by replacing bytecode opcodes and adding certain Java programming language constructs that hinder decompilation", "explanation": "本文はバイトコードの改変と構文追加でデコンパイル耐性を高める手法を述べており、機械学習やLLMの使用は記述されていないため、EC1に該当します。"}, {"code": "ex_no_code_generation", "evidence": "aimed at its destruction. ... demonstrate that specific constructs ... increase the likelihood of incorrect decompilation", "explanation": "目的はデコンパイルを妨害することであり、復元・高水準コード生成が主目的ではないため、EC3にも該当します。"}], "reasoning": "本稿はデコンパイル攻撃に耐えるデジタル透かし埋め込み手法を提案しており、ML/LLM を利用した高水準表現の復元や生成を目的としていない。そのため、Decompilation Surveyの採択基準を満たさず、除外基準 (ML未使用、コード生成非目的) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3145, "latency_ms": 53926}}
{"key": "11023256", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "create a Python decompiler ... compiled PYC binaries", "explanation": "抽象から、バイトコード（低水準入力）を入力とし、ML/NLP コンポーネントで高水準の Python ソースを生成することが示されており、コアデコンパイルに該当します。"}], "reasoning": "本稿はバイトコード (PYC) を入力とし、データ駆動型 NLP（ML）手法で Python ソースコードを復元することを目的としている。目的が復元・可読化であり、LLM/ML が中心手法として用いられるため、Decompilation Survey の include 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3273, "latency_ms": 54593}}
{"key": "11023499", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_type_recovery", "evidence": "LLM-assisted double-elimination framework to select the best-fit type declaration", "explanation": "LLM が型宣言の選択に用いられ、低水準のストリップドバイナリから合成データ型を復元することが主目的なので、タイプリカバリに該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "assessing the readability of the decompiled code", "explanation": "LLM が生成した型情報に基づき、デコンパイル結果の可読性を向上させるためのフレームワークであり、既存デコンパイラ出力の改善にも寄与しています。"}], "reasoning": "本研究はストリップドバイナリという低水準入力から、LLM を中心に用いて合成データ型を自動合成・選択し、型情報を復元することを目的としているため、デコンパイルのタイプリカバリ（Peripheral）に該当し、インクルード対象となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3447, "latency_ms": 62736}}
{"key": "11028410", "action": "keep", "reason": "uns_unclear_method", "details": {"decision": "uncertain", "confidence": 0.62, "reason_codes": [{"code": "uns_unclear_method", "evidence": "genetic algorithms", "explanation": "本文は遺伝的アルゴリズムを用いると述べているが、ML/LLM として認識できるか不明であるため"}, {"code": "uns_unclear_input", "evidence": "difficult-to-analyze machine code", "explanation": "機械コードが対象と示唆されているが、実際に入力として使用するか明示されていないため"}, {"code": "uns_unclear_output", "evidence": "higher-level representations", "explanation": "高水準表現を取得すると述べているが、具体的にソースコード、疑似コード、AST など L1‑L4 のどれに該当するか不明であるため"}], "reasoning": "抄録だけでは、手法が機械学習／LLM として位置付けられるか、入力がバイナリ等の低水準表現か、出力が L1‑L4 のどのレベルに該当するかが判定できません。そのため、包括的な判断のために uncertain としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3492, "latency_ms": 69288}}
{"key": "11050729", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "integration of the Ghidra framework with the Heros IFDS solver", "explanation": "要旨では機械学習や大規模言語モデルは言及されておらず、従来の静的解析フレームワークの統合が中心であるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は Ghidra と Heros IFDS の統合による静的解析手法を提案しており、機械学習・LLM を用いたデコンパイル手法ではない。したがって除外基準 EC1（ML/LLM 不使用）に該当し、インクルード対象外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3089, "latency_ms": 56377}}
{"key": "11052915", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "Future enhance automation; explore machine learning enhancements for improved zero-day threat detection.", "explanation": "要旨からは現在ML/LLMを用いた手法は示されておらず、将来の検討としか記載されていないため、MLが中核手法であるとは判断できません。"}, {"code": "ex_no_code_generation", "evidence": "Apktool enables low-level decompilation of smali code, while Quark focuses on malware behavior detection through API call analysis.", "explanation": "研究の目的はセキュリティ評価であり、復元・コード生成が主目的ではなく、単に逆向き解析ツールを利用しているだけです。"}], "reasoning": "本論文はモバイルアプリのセキュリティ評価を目的としており、ML/LLM をデコンパイルの中心技術として用いていないうえ、コード生成や高水準表現の復元が主目的ではないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3392, "latency_ms": 65615}}
{"key": "11068876", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.85, "reason_codes": [{"code": "in_variable_naming", "evidence": "AI ... enhance decompiler output by recovering original variable names ...", "explanation": "AI が変数名を自動復元している点が変数名復元研究に該当するため"}, {"code": "in_type_recovery", "evidence": "AI ... enhance decompiler output by recovering ... types", "explanation": "AI が型情報を自動復元している点が型回復研究に該当するため"}], "reasoning": "本稿はバイナリから生成されたデコンパイラ出力を入力とし、LLM/ML により変数名と型情報を自動復元し、可読性向上を評価している。目的がコード復元・可読化であり、低水準入力と機械学習手法が中心であるため、デコンパイル改善（Peripheral）としてインクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3765, "latency_ms": 81514}}
{"key": "11081372", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "using Ghidra. The proposed malware analysis framework decompiles malware samples automatically", "explanation": "本文では Ghidra のスクリプトによる静的解析を用いており、機械学習や大規模言語モデルの使用は言及されていないため、ML/LLM が手法の中核でないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "identifying malicious code, using decompilation to extract features, ... to improve detection", "explanation": "目的はマルウェア検出・特徴抽出であり、生成した高水準コードの再利用やコンパイル可能性の向上が主目的ではないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿は Ghidra を用いた静的マルウェア解析フレームワークであり、ML/LLM の手法は使用していない。さらに、デコンパイルの目的はコードの復元や可読化ではなく、マルウェア検出のための特徴抽出であるため、Decompilation Survey の対象外となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3078, "latency_ms": 55642}}
{"key": "11086752", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "propose a ... binary code similarity detection approach", "explanation": "アブストラクトはコードの類似性を検出することが目的であり、復元や高水準コード生成を行うことは示されていないため、コード生成・再構成を目的としたデコンパイルではないと判断した。"}], "reasoning": "本稿はバイナリを逆アセンブルしてASTを取得し、GAT を用いた類似性検出モデルを構築することに焦点を当てている。目的はコードの復元や可読化ではなく、バイナリ間の類似性判定であるため、デコンパイルの「復元・生成」目的を満たさず、除外基準 EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3149, "latency_ms": 54826}}
{"key": "11118682", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "integrates advanced unpacking techniques, decompilation using Ghidra, and artificial intelligence analysis", "explanation": "要旨では AI が分析に使われていると述べられていますが、デコンパイル自体は Ghidra（ML/LLM を使わない従来のデコンパイラ）に依存しており、ML/LLM がデコンパイル工程の中心手法であることが示されていないため除外基準 EC1 に該当します。"}], "reasoning": "本稿は Ghidra による従来型デコンパイルと AI を用いた解析を組み合わせたシステムを紹介していますが、デコンパイル工程に ML/LLM が使用されている根拠が要旨からは得られません。そのため、LLM/ML が中核手法である本サーベイの採択基準を満たさず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3328, "latency_ms": 70444}}
{"key": "11129273", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "In this paper, we systematize the intrinsic challenges of control-flow structuring ... we review existing methods, comparing them ...", "explanation": "本文は既存手法のレビューと課題の体系化を目的としており、研究成果の新規提案ではないため除外基準 EC4 に該当します。"}, {"code": "ex_no_ml", "evidence": "pattern-matching approaches remain prevalent among both commercial and open-source decompilers ...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示唆されず、従来のパターンマッチング手法の議論に留まっているため除外基準 EC1 に該当します。"}], "reasoning": "本論文はデコンパイルにおける制御フロー構造化の課題を整理し、既存手法をレビューする SoK 論文であり、LLM/ML を用いた新たなデコンパイル手法の提示ではない。したがって除外基準（Survey/Review および ML 未使用）に該当し、インクルードすべき対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3142, "latency_ms": 58785}}
{"key": "11139736", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "This paper will present a multi-staged hybrid framework for malware detection ...", "explanation": "要旨はマルウェア検出を目的としており、デコンパイルは分析工程の一部にすぎず、コード生成・復元が主目的ではないため除外基準 EC3 に該当すると判断した。"}], "reasoning": "本稿はマルウェア検出手法の提案であり、デコンパイルは検出パイプラインの副次的ステージとして言及されているだけです。デコンパイル結果の生成や高水準コード復元が主要目的でなく、ML/LLM がデコンパイルに中心的に用いられている記述もないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3322, "latency_ms": 70104}}
{"key": "11166547", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "introduces a high-accuracy detection framework ... to identify Android ransomware.", "explanation": "アブストラクトはSMALIコードから特徴を抽出し、機械学習でランサムウェアかどうかを分類することが目的であり、コードやソースの復元・生成を行う記述がないため、コード生成/復元を目的としたデコンパイルとはみなせません。"}], "reasoning": "本研究は低水準表現（SMALI）を入力に機械学習でランサムウェア検出を行う分類タスクであり、デコンパイルによる高水準コード生成や再構成を目的としていない。そのため、除外基準 EC3（コード生成・復元が主目的でない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3005, "latency_ms": 57228}}
{"key": "11185876", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a new technique for identifying abstract syntax tree components", "explanation": "本文の要旨では機械学習や大規模言語モデルの使用について言及されておらず、従来の解析手法のみが説明されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本論文はバイナリ解析におけるスイッチ文の復元手法を提案しているが、機械学習や大規模言語モデルを用いることは明示されていない。したがって、Decompilation Survey Screening Rules の Exclude Criteria の EC1（No ML/LLM）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3042, "latency_ms": 54295}}
{"key": "11205440", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "detecting malware from decompiled.c code derived from Portable Executable (PE) files", "explanation": "入力はバイナリやアセンブリではなく、すでにデコンパイルされた C ソースであり、低水準表現ではないため除外基準 EC2 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "effectiveness of three LLMs ... for detecting malware ... source-code-based malware detection", "explanation": "研究目的はマルウェアの分類・検出であり、コードの復元や生成は目的に含まれないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はデコンパイルされた C コードを入力として、LLM を用いたマルウェア検出（分類）を評価しています。入力が高水準のデコンパイルコードであり、復元・高水準表現生成が目的ではないため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3235, "latency_ms": 67539}}
{"key": "11208400", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach represents sandbox profiles as dependency graphs and compares decompiled profiles...", "explanation": "アブストラクトでは機械学習・LLM の使用が全く言及されておらず、従来の手法による評価・最適化のみが述べられているため、ML/LLM を中核手法としていないと判断した。"}], "reasoning": "論文は iOS サンドボックスプロファイルのデコンパイル精度を評価・最適化するフレームワークを提示しているが、機械学習や大規模言語モデルを用いた手法は記載されていない。したがって、Decompilation Survey の含有基準（IC0）を満たさず、除外基準 EC1 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3088, "latency_ms": 59122}}
{"key": "11241815", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "propose an innovative ensemble deep learning model designed to classify Android applications as benign or malicious", "explanation": "アブストラクトはマルウェアの検出（分類）を目的としており、コードの復元や高水準表現の生成は行っていないため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿は decompilation を前処理として利用し、取得したバイトコードから画像を生成し分類モデルを学習させることでマルウェア検出を行う研究です。目的はコードの復元や可読化ではなく、悪性/良性の判別であり、デコンパイルの直接的な成果物生成を伴わないため除外基準 EC3 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3135, "latency_ms": 61938}}
{"key": "11264981", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Our DeepWalk-DeepGraphCNNs and TCN model demonstrated superior performance with 95.10% accuracy", "explanation": "この記述は本研究の主目的がマルウェア検出という分類タスクであり、コードの生成・復元を行うものではないことを示しているため、EC3 に該当し除外と判断した。"}], "reasoning": "本文は Dalvik バイトコードのデコンパイルを行って CFG を抽出し、グラフ埋め込みとディープラーニングでマルウェア検出を行うことに焦点を当てている。出力は高水準コードや擬似コードではなく、検出用の特徴ベクトルおよび分類モデルであり、デコンパイルによるコード復元が目的ではないため、除外基準 EC3（コード生成・復元意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3320, "latency_ms": 68768}}
{"key": "11307212", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "AI-based malware classification approach using Vision Transformer (ViT) on bytecode images", "explanation": "本文はバイトコード画像を用いたマルウェアの分類が目的であり、コードの復元・生成や高水準表現への変換を行わないため、コード生成／復元の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿は Android アプリのバイトコードを画像化し ViT でマルウェアかどうかを判別する分類手法を提案しており、デコンパイルによる高水準コード生成や属性回復を目的としていません。したがって、デコンパイル調査の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3167, "latency_ms": 59836}}
{"key": "11334294", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "LLMs hold promise for PTX-to-CUDA de-compilation ...", "explanation": "LLM が低水準 PTX を入力として直接 CUDA ソースコード（高水準コード）を生成することを目的としているため、Core Decompilation に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "our approach yields ... significant enhancements in generated code readability", "explanation": "生成された CUDA の可読性向上が強調されている点で、既存の逆コンパイル出力の品質改善要素も含まれますが、主目的は直接的なコード生成なので補助コードとして付記します。"}], "reasoning": "本稿は低水準表現である PTX を入力とし、LLM を中心手法として CUDA の高水準ソースコードを生成することを目的としているため、Decompilation Survey の核心である Core Decompilation 研究に該当します。入力の低水準性、ML 手法の使用、復元・可読化という目的がすべて満たされています。", "model": "openai/gpt-oss-120b", "tokens_used": 3356, "latency_ms": 66412}}
{"key": "11334528", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a novel file format-based anti-decompilation strategy that systematically exploits structural vulnerabilities in APK files", "explanation": "抽象からは機械学習や大規模言語モデルを使用している記述が全くなく、単に構造的脆弱性を利用した保護手法を述べているため、EC1に該当します。"}], "reasoning": "本稿は低水準バイナリを高水準コードに復元することを目的とした研究ではなく、デコンパイラの脆弱性を利用したアンチデコンパイル手法を提案しています。さらに機械学習やLLMを中核手法として用いている記述がなく、除外基準EC1（ML/LLM未使用）に該当するため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3298, "latency_ms": 64036}}
{"key": "11334626", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "refactor distorted pseudocode ... utilizes ... LLM ... to efficiently refactor distorted pseudocode", "explanation": "本文はバイナリやアセンブリといった低水準入力ではなく、既にデコンパイルされたC疑似コードを入力として扱っているため、低水準入力の要件を満たさない"}], "reasoning": "本稿は既存のデコンパイラが生成した疑似コードを対象に、構造歪みを修正するフレームワークを提案している。入力は低水準表現ではなく高水準の疑似コードであり、Decompilation Survey のインクルード基準で定義された「低水準入力」条件を満たさないため除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3600, "latency_ms": 79866}}
{"key": "11352404", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we introduce a structural analysis algorithm specifically for PHP syntax", "explanation": "Abstract では機械学習や大規模言語モデルの利用が言及されておらず、従来のアルゴリズムによる構文解析が中心であるため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は PHP バイトコードからのデコンパイル手法を提案しているが、手法は構造解析アルゴリズムに基づくものであり、機械学習や大規模言語モデルの利用が明示されていない。したがって、Decompilation Survey Screening Rules の Exclude Criteria EC1（No ML/LLM）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3175, "latency_ms": 60575}}
{"key": "11367734", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "integrating a pre-trained assembly encoder ... improves the model’s ability to capture the intricacies of assembly-to-source code mapping", "explanation": "この記述は、アセンブリという低水準表現を入力とし、ソースコードを出力することを示し、LLMベースのモデルを中心手法として用いているため、Core decompilationに該当する。"}], "reasoning": "本稿はアセンブリからC言語ソースコードへの変換を目的としたニューラルデコンパイラを提案しており、ML/LLM を中核手法として使用している。低水準入力・高水準出力の生成という目的が明確で、除外基準に該当しないためインクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3460, "latency_ms": 74279}}
{"key": "7880502", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We study effects of compilation and decompilation to code clone detection in Java.", "explanation": "要旨に機械学習や大規模言語モデルの使用は記載されておらず、ML/LLM を用いていないため。"}, {"code": "ex_no_code_generation", "evidence": "We suggest to use decompilation as normalisation to compliment clone detection.", "explanation": "デコンパイルはクローン検出の前処理として利用されており、復元・コード生成が主目的ではないため。"}], "reasoning": "本研究はデコンパイルをコードクローン検出の正規化手段として利用しており、ML/LLM を用いた復元や高水準コード生成が目的ではない。したがって、除外基準 EC1（ML未使用）と EC3（コード生成・復元が主目的でない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3491, "latency_ms": 78906}}
{"key": "7889345", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "the information can be found in most of the binary files. This paper investigates ... without decompiling the binary code.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、従来の手法のみでコンパイラ情報を取得しようとしているため、EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "retrieving the information about compiler name and version based on the content of the binary code, without decompiling the binary code.", "explanation": "目的はコンパイラ名・バージョンの取得であり、ソースコードや擬似コード等の高水準表現の生成がなく、EC3 に該当します。"}], "reasoning": "本稿はバイナリからコンパイラ情報を抽出することを目的としており、機械学習やLLMの利用は示されていない上、コード生成や高水準表現の復元を行わないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3088, "latency_ms": 65101}}
{"key": "7921975", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Step 2, the unprecedented ones were captured and decompiled to acquire new app's name", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、従来の手法のみでデコンパイルを行っているため、EC1 の『ML/LLM を用いていない』に該当します。"}], "reasoning": "本稿はネットワークトラフィックからアプリパッケージを識別する手法を提案しており、デコンパイルは名前取得の副次的ステップに過ぎません。また、要旨に機械学習・LLM の利用が示唆されていないため、除外基準 EC1（ex_no_ml）に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3159, "latency_ms": 65649}}
{"key": "8005920", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This study proposes a scheme based on the Java Native Interface (JNI) and the Advanced Encryption Standard (AES) to protect the Java source code.", "explanation": "アブストラクトに機械学習・LLM の使用が記載されておらず、純粋に暗号化と JNI を用いた保護手法のみが述べられているため、ML/LLM を用いた手法ではないと判断した。"}], "reasoning": "本稿は Java ソースコードの暗号化保護手法を提案しており、デコンパイルやコード復元を目的としたものではない。また、機械学習や大規模言語モデルを使用した旨の記述が全くなく、除外基準 EC1（ML/LLM 未使用）に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3097, "latency_ms": 67542}}
{"key": "8029506", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "Static analysis is to decompile the applications to generate intermediate code and then analyze the usage of permissions.", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及されておらず、従来の静的解析のみであるため、ML/LLM を用いていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "Our method can efficiently detect the above three kinds of permission over claim problems", "explanation": "研究目的は権限過剰要求の検出であり、コードやソースの復元・生成が主目的ではないため、コード生成・復元意図がないと判断した。"}], "reasoning": "本論文は Android アプリの権限過剰要求を検出するための静的解析と意味的類似度計算を行う研究であり、機械学習/LLM を用いた手法の記述がなく、コード生成や高水準表現の復元が目的ではない。したがって、除外基準 EC1 と EC3 に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3442, "latency_ms": 73787}}
{"key": "8054016", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a technique to decompile the bytecode of PLC program", "explanation": "本文では機械学習や大規模言語モデルの利用について言及されておらず、従来のテンプレートベース手法のみを述べているため、ML/LLM が中核手法ではないと判断した。"}], "reasoning": "本稿はPLC バイトコードのデコンパイル手法を提案しているが、機械学習や大規模言語モデルを用いた手法についての記述がなく、除外基準 EC1（ML/LLM 不使用）に該当するため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 2916, "latency_ms": 58789}}
{"key": "8076511", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose and develop a universal unpacking system, named CrackDex, which is capable of extracting the original DEX file", "explanation": "抄録では機械学習や大規模言語モデルの使用について一切言及されておらず、シミュレーション実行や再構築といった従来手法のみが述べられているため、ML/LLM が中核手法であるという条件を満たさないと判断した。"}], "reasoning": "本稿は Android アプリのパッキング解除・DEX 抽出手法を提案しており、機械学習や大規模言語モデルを利用したデコンパイル手法ではない。したがって、Include Criteria の 『LLM/ML が中核手法として使われている』 要件を欠き、除外基準 EC1（No ML/LLM）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3204, "latency_ms": 63578}}
{"key": "8080433", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Our agent ... uses genre-related corpora (including fantasy books and decompiled games) to create language models", "explanation": "アブストラクトは自然言語テキストが入力であり、バイナリやアセンブリといった低水準表現は使用していないため、除外基準 EC2 に該当する。"}, {"code": "ex_no_code_generation", "evidence": "we present our approach to tackle the problem... measured agent's performance on interactive fiction games", "explanation": "目的はゲームプレイのエージェント性能評価であり、コードの復元・生成や可読化は主目的ではないため、除外基準 EC3 に該当する。"}], "reasoning": "本稿はテキストベースのゲームエージェントの設計・評価に関するもので、低水準バイナリから高水準コードを生成するデコンパイルとは無関係です。入力は自然言語テキストで、出力もコードではなくゲーム行動の選択です。したがって、除外基準（低水準入力がない、コード生成が目的でない）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3288, "latency_ms": 74208}}
{"key": "8109245", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We create an automation tool for performance verification, experiment with five commercial office apps...", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用が全く言及されておらず、従来のツールや手法のみが説明されているため、ML/LLM を用いていないと判断しました。"}], "reasoning": "本稿はバイナリを逆コンパイルしてセキュリティポリシーコードを挿入する手法を提案していますが、機械学習や大規模言語モデルを用いる記述がなく、ルールの EC1（ML/LLM 未使用）に該当するため除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3170, "latency_ms": 64613}}
{"key": "8109451", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We evaluate current Java bytecode decompilers.", "explanation": "アブストラクトではLLMや機械学習の使用について言及されておらず、単に既存のデコンパイラの出力を評価しているだけなので、EC1 に該当し除外します。"}], "reasoning": "本稿は Java バイトコードデコンパイラの評価を行う研究であり、LLM/ML を手法の中心に用いた記述が無いため、除外基準 EC1（ML/LLM 未使用）に該当します。そのためインクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2923, "latency_ms": 58946}}
{"key": "8210757", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "methodology consists in attempting to decompile the application HeartKeeper", "explanation": "アブストラクトでは decompile を行うことは述べられているが、機械学習や大規模言語モデルの利用については言及されていないため、EC1 に該当し除外する"}], "reasoning": "本稿は Android アプリのセキュリティ監査を目的とし、デコンパイルは手段の一つとして使用されていますが、手法として ML/LLM が用いられている記述がなく、除外基準 EC1（ML/LLM 不使用）に該当します。そのため本サーベイの対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3181, "latency_ms": 63582}}
{"key": "8284326", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "by disassembling, decompiling and debugging application's code using Disassembler", "explanation": "本文は従来のディスアセンブラを用いた手法であり、機械学習や大規模言語モデルの使用が示唆されていないため、EC1 に該当します。"}], "reasoning": "アブストラクトからはML/LLMを利用した手法の記述がなく、伝統的な逆コンパイル手法のみが述べられています。そのため、除外基準 EC1（ML/LLM 不使用）に該当し、include にはできません。", "model": "openai/gpt-oss-120b", "tokens_used": 2992, "latency_ms": 62457}}
{"key": "8299877", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "code obfuscation technique ... using preventive design obfuscation and insertion of self-modifying code at the binary level", "explanation": "本文では機械学習や大規模言語モデルの利用が全く言及されておらず、ML/LLM が手法の中核でないため除外します。"}], "reasoning": "本稿は逆リバースエンジニアリング防止のためのコード難読化手法を提案しており、機械学習やLLM を用いたデコンパイルやコード復元を目的としていません。そのため、含めるべき基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3054, "latency_ms": 62661}}
{"key": "8327566", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "decompilation techniques driven by the contract structure definition", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及されておらず、従来のルールベースのデコンパイル手法のみが示されているため、ML/LLM を使用していないと判断した。"}], "reasoning": "本文は Solidity コントラクトの状態解析を目的としたデコンパイル手法を紹介しているが、機械学習や大規模言語モデルを利用したことは示されていない。したがって、本サーベイの採択基準で求められる LLM/ML を中核手法とするデコンパイル研究には該当せず、除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 2936, "latency_ms": 62165}}
{"key": "8330222", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "present a novel technique for decompiling binary code snippets using a model based on Recurrent Neural Networks", "explanation": "RNN を中心とした機械学習手法でバイナリ（低水準入力）からソースコード（高水準出力）を直接生成しているため、Core Decompilation に該当します。"}, {"code": "in_variable_naming", "evidence": "recovering ... variable or function names", "explanation": "抽象的に変数・関数名の復元を目的に掲げており、名前付け回復の研究領域に該当します。"}, {"code": "in_control_structure", "evidence": "recovering control flow constructs", "explanation": "制御フロー構造の復元・構造化も目的の一つとして明示されているため、制御構造回復に該当します。"}], "reasoning": "本稿はバイナリを入力とし、RNN を用いた機械学習手法で直接ソースコードを生成することを目的としているため、Decompilation の Core 研究に該当します。また、変数名・関数名や制御構造の復元も主要な目的として記述されているため、関連するサブカテゴリも含めて採択します。", "model": "openai/gpt-oss-120b", "tokens_used": 3345, "latency_ms": 72418}}
{"key": "8406593", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a tool that decompiles real firewall configurations ... and uses the Z3 solver to synthesize the abstract specification", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用が全く言及されておらず、Z3によるシンセサイズのみが説明されているため、ML/LLM を使用していないと判断した。"}], "reasoning": "本稿はファイアウォール設定を低水準言語から抽象的仕様へ変換する手法を提案しているが、手法の中心として機械学習や大規模言語モデルは用いられていない。したがって、Decompilation Survey のインクルード基準（IC0）の『LLM/ML が中核手法として使われている』を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3123, "latency_ms": 62344}}
{"key": "8572021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The aim of this paper is to present a strictly limited set of low-level attack patterns", "explanation": "要旨は攻撃パターンの提示であり、ML/LLM を用いた手法については言及されていないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿は低レベル制御フロー操作の攻撃手法を示すことが目的であり、機械学習や大規模言語モデルを用いたデコンパイル手法の紹介はありません。したがって、除外基準 EC1 (ML/LLM 未使用) に該当し、インクルード対象外と判断されます。", "model": "openai/gpt-oss-120b", "tokens_used": 2909, "latency_ms": 64035}}
{"key": "8600052", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "uses optimized deep Convolutional Neural Network to learn from opcode sequences ... to detect malicious program", "explanation": "アブストラクトはオペコード列からマルウェアを分類・検出することが目的であり、コードの復元や高水準表現の生成を行わないため除外基準 EC3 に該当します。"}, {"code": "ex_out_of_scope", "evidence": "malware detection system ... to detect more accurately", "explanation": "研究の主目的はマルウェア検出であり、デコンパイルやソース復元とは無関係なのでスコープ外です。"}], "reasoning": "本稿は低水準情報（オペコード列）を用いたマルウェア検出手法を提案しており、生成・復元を目的としたデコンパイル研究ではないため除外します。ML 手法は使用されていますが、コード生成や高水準表現への変換が主目的でない点が除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3146, "latency_ms": 69181}}
{"key": "8668959", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Based on the static analysis method, we propose a method for automatically collecting forensic artifact.", "explanation": "抽象からは機械学習やLLMの利用が言及されておらず、静的解析のみが用いられているため、ML/LLM不使用と判断した。"}], "reasoning": "本稿は Android アプリのデコンパイルを用いたフォレンジックアーティファクト収集手法を提案しているが、手法は静的解析に基づくものであり、機械学習や大規模言語モデルの活用は示されていない。したがって、Decompilation Survey の採択基準で要求される ML/LLM 使用が欠如しているため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3055, "latency_ms": 69177}}
{"key": "8728471", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we propose a deep learning framework for classification of malware", "explanation": "目的がマルウェアの分類であり、コードの復元や生成が主目的ではないため除外基準 EC3 に該当する"}, {"code": "ex_no_lowlevel_input", "evidence": "Usual methods like disassembly, decompiling, de-obfuscation or execution of the binary need not be done", "explanation": "低水準バイナリやアセンブリを入力として使用せず、代わりに画像データで学習しているため除外基準 EC2 にも該当する"}], "reasoning": "本稿はマルウェアの分類手法を提案しており、デコンパイルやコード復元を目的としていない。また、入力はバイナリやアセンブリではなく画像データであり、低水準入力や高水準コード生成が欠如しているため、デコンパイル調査のスコープ外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3244, "latency_ms": 71963}}
{"key": "8859456", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "We present an algorithm for generating test runtime-environment-set to exercise mobile apps.", "explanation": "要約には機械学習や大規模言語モデルの使用が言及されておらず、従来のアルゴリズムによるコード解析のみが記述されているため、ML/LLM が中心手法である条件を満たさないと判断した。"}], "reasoning": "本稿は Android アプリのテスト環境生成アルゴリズムを提案しており、デコンパイルやコード生成を目的とした機械学習手法の使用が明示されていない。したがって、Decompilation Survey のインクルード基準（ML/LLM が中核）を満たさず、除外基準 EC1（No ML/LLM）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3016, "latency_ms": 65346}}
{"key": "8930870", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "We study the effectiveness of eight Java decompilers ...", "explanation": "本文の要旨では既存の Java デコンパイラを評価しているだけで、機械学習または大規模言語モデルを使用した手法については言及されていないため、ML/LLM が用いられていないと判断しました。"}], "reasoning": "この論文は Java バイトコードデコンパイラの品質比較を行う実証研究であり、ML/LLM を手法の中心に据えていないため除外基準 EC1（No ML/LLM）に該当します。したがってサーベイ対象外と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3004, "latency_ms": 62664}}
{"key": "8936022", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "The method of decompiled code static analysis has been improved.", "explanation": "要旨では機械学習や大規模言語モデルの利用が言及されておらず、従来の静的解析手法の改善のみが述べられているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は難読化コードの品質測定手法を提案しており、ML/LLM の利用が示されていない。したがって、Decompilation Survey の採択基準である LLM/ML を中核としたデコンパイル研究には該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 2864, "latency_ms": 62819}}
{"key": "8945606", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we propose a novel method of android malware classification using Object-Oriented Software Metrics and machine learning algorithms.", "explanation": "アブストラクトでは主目的がマルウェア分類であり、コードの復元や生成は目的として記載されていないため、デコンパイルによるコード生成・再構成が主目的ではないと判断した。"}], "reasoning": "本稿は Android アプリをデコンパイルしてメトリクスを抽出し、機械学習でマルウェアか否かを分類することが主目的であり、低水準コードから高水準コードを生成・復元することを目的としていない。したがって、デコンパイルの出力を利用したコード生成・再構成が目的ではない点で除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3115, "latency_ms": 70441}}
{"key": "8965960", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "By decompiling and processing APK files, the multi-class behavior features of Android application are extracted, and the classification is achieved through an integrated learning framework...", "explanation": "要旨はデコンパイルしたコードから特徴を抽出し、機械学習でマルウェアを分類することが主目的であり、コードの復元や高水準表現の生成は行っていないため、コード生成/復元の意図がないと判断した。"}], "reasoning": "本稿はAPK をデコンパイルして特徴抽出を行い、ML によりマルウェア検出を行う手法を提案している。デコンパイルは前処理であり、生成・復元を目的とした研究ではないため、除外基準 EC3（コード生成・復元目的ではない）に該当し除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 2909, "latency_ms": 66177}}
{"key": "8987703", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We classify .NET files as either benign or malicious ... decompiling the given file.", "explanation": "要旨はバイナリをデコンパイルして得たグラフを特徴量化し、マルウェア分類器を学習させることであり、復元・高水準コード生成が目的ではなく分類が主目的なので除外基準 EC3 に該当します。"}, {"code": "ex_no_ml", "evidence": "train a vanilla random forest on 2.5 million samples of decompiled .NET", "explanation": "機械学習（ランダムフォレスト）は分類器の学習に用いられており、デコンパイルそのものに LLM/ML が中心手法として使われていないため除外基準 EC1 にも該当します。"}], "reasoning": "本研究はデコンパイルしたコードからグラフを生成し、マルウェア分類のための特徴量ベクトル化とランダムフォレストによる分類を行うもので、コードの復元や高水準表現の生成が目的ではありません。また、デコンパイル工程に LLM/ML が用いられていないため、包括基準を満たさず除外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3379, "latency_ms": 77778}}
{"key": "9115191", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "reverse decompilation of installation package, malicious code injection, application piracy", "explanation": "アブストラクトでは逆コンパイルやセキュリティ問題について言及しているが、機械学習や大規模言語モデルを用いた手法は示されておらず、ML/LLM が使用されていないため除外基準 ex_no_ml に該当する"}], "reasoning": "本稿はモバイルアプリの情報セキュリティに関する課題と対策を論じているが、デコンパイルを実現するための機械学習／LLM 手法については記述がなく、ルールベースや手動分析に留まっていると判断した。したがって、Inclusive Criteria を満たさず Exclude Criteria の ex_no_ml に基づき除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3129, "latency_ms": 69272}}
{"key": "9117398", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our system named PILDroid adopts tainted analysis based on static method.", "explanation": "要旨からは機械学習や大規模言語モデルの利用が示されておらず、従来の静的解析のみが述べられているため、ML/LLM を用いた研究ではないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "PILDroid can perform the analysis more easily and effectively than the assembly-based analysis systems because it decompiles a JNI into LLVM IR instead of assembly language.", "explanation": "デコンパイルは解析の前処理として利用されており、最終目的はプライバシー情報漏洩の検出であり、コード生成や復元が主目的ではないため除外基準 EC3 に該当する。"}], "reasoning": "本稿は JNI のバイナリを LLVM IR に変換し、静的汚染解析でプライバシー情報漏洩を検出するシステムを提案しているが、機械学習/LLM の使用はなく、コード復元や可読化が目的ではない。したがって、Decompilation Survey の対象外（除外基準）となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3121, "latency_ms": 70642}}
{"key": "9141591", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our research is to simulate the operating conditions of the VBE system and use the platform to test the VBE", "explanation": "要旨に機械学習・LLMの利用について一切言及がなく、従って ML/LLM が使用されていないと判断したため"}, {"code": "ex_no_lowlevel_input", "evidence": "research decompiles the VBE system", "explanation": "対象は電力送電システムの VBE であり、バイナリやアセンブリ等の低水準コードではないと解釈できるため"}], "reasoning": "本文では VBE システムの解析・テストが中心であり、機械学習や大規模言語モデルを用いたコード生成・復元の手法は示されていない。加えて、入力は電力システムであり低水準プログラム表現ではないと考えられるため、除外基準 EC1 と EC2 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3298, "latency_ms": 80703}}
{"key": "9259834", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "machine learning models were created ... for malware detection", "explanation": "論文はマルウェア検出という分類タスクを目的としており、コードの復元・生成を行わないため除外基準 EC3 に該当します"}], "reasoning": "本稿は低水準の smali ファイルを特徴量として機械学習でマルウェアか否かを判定する分類研究であり、デコンパイルや高水準コードの生成・復元を目的としていません。そのため、コード生成・復元を主目的としない除外基準 EC3 に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2988, "latency_ms": 66213}}
{"key": "9282282", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Stan can generate four categories of descriptions... to help users comprehend them.", "explanation": "要旨はバイトコードから自然言語による機能説明を生成することを述べており、ソースコードや擬似コード等の高水準プログラム表現の生成ではないため、復元・コード生成を目的としたデコンパイルとはみなせません。"}], "reasoning": "本稿はバイトコードから自然言語の説明文を生成するシステムを提案しており、コードや擬似コードといった高水準プログラム表現の復元を目的としていないため、デコンパイルのコア目的である「コード生成/再構成」には該当しません。そのため除外基準 EC3（コード生成・復元が主目的でない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3351, "latency_ms": 80338}}
{"key": "9282790", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we present a combination of existing and new tools", "explanation": "要旨では機械学習や大規模言語モデルの利用について言及せず、従来のツール（remill など）を組み合わせているだけなので、ML/LLM が使用されていないと判断した"}], "reasoning": "本稿はバイナリから LLVM IR を抽出し、形式的検証やシンボリック実行を行う手法を紹介しているが、機械学習や大規模言語モデルを手法の中核として用いていない。したがって除外基準 EC1 (ex_no_ml) に該当し、include の条件を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3123, "latency_ms": 71389}}
{"key": "9315052", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "performed a series of experiments using a machine learning (ML) model; the model drew on the ML.net library and was implemented in C#.net.", "explanation": "アブストラクトは ML を用いたマルウェア分類を目的としており、コード生成や復元は行っていないため、デコンパイルの主目的が満たされていません。"}], "reasoning": "本論文は APK をデコンパイルしてマニフェストを抽出し、取得した権限情報をもとに機械学習でマルウェアを分類することが目的です。デコンパイルはデータ取得の前処理であり、LLM/ML を用いた高水準コードの生成や復元は行っていません。そのため、デコンパイルの出力生成を目的とした研究基準を満たさないため除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3257, "latency_ms": 75572}}
{"key": "9331988", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "This research proposed a methodology to protect the application assets from piracy using the cryptographic algorithm.", "explanation": "要旨に機械学習や大規模言語モデルの使用記述がなく、暗号化手法のみが述べられているため、ML/LLM が使われていないと判断しました。"}, {"code": "ex_out_of_scope", "evidence": "Android ... can be extracted and decompiled to reveal the source code and the assets file.", "explanation": "論文はデコンパイル自体の手法や復元を対象にせず、資産の暗号化による保護を目的としているため、デコンパイル領域の範囲外です。"}], "reasoning": "本稿は暗号化による資産保護を提案しており、機械学習/LLM を用いたデコンパイルやコード復元の研究ではない。入力が低水準表現でもMLが関与していない点、目的がコード生成・復元でない点から、除外基準 (ex_no_ml, ex_out_of_scope) に該当すると判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3299, "latency_ms": 78975}}
{"key": "9410081", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Through obfuscation, the compiled program is strengthened at the three levels of grammar, control flow, and data flow.", "explanation": "要旨では機械学習や大規模言語モデルの利用について言及されておらず、単にコード難読化手法を提案しているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はモバイルアプリの難読化手法を提案しており、デコンパイル自体やその復元・可読化を目的とした研究ではない。さらに、機械学習やLLM の使用が示唆されていないため、除外基準 EC1（ex_no_ml）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2949, "latency_ms": 64030}}
{"key": "9421647", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect whether the target area has stack overflow vulnerabilities", "explanation": "アブストラクトはバイナリのスタックオーバーフロー脆弱性を検出することを目的としており、コード生成や復元は行わないため、コード生成/復元が主目的であるICを満たさず除外基準EC3に該当します。"}], "reasoning": "本論文はバイナリの脆弱性検出を目的とした注意機構を用いたニューラルネットワーク手法であり、デコンパイルや高水準コードの生成・復元を行わないため、除外基準EC3（コード生成・復元が主目的でない）に該当します。したがって、本サーベイの対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3077, "latency_ms": 71959}}
{"key": "9425937", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "In addition to the state-of-the-art Dalvik bytecode decompiler jadx, we used three popular Java decompilers.", "explanation": "本文は既存のデコンパイラのみを使用しており、ML/LLM 手法は用いられていないため除外基準 EC1 に該当します。"}], "reasoning": "この研究は Android アプリのデコンパイル失敗率を大規模に測定する実証的調査であり、ML／LLM を用いた新たなデコンパイル手法の提案や改善を行っていません。したがって、Decompilation Survey の対象となる LLM/ML 中核手法が欠如しているため除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3272, "latency_ms": 69182}}
{"key": "9445905", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "code obfuscation or ELF shell (special in Android) were provided and then applied widely.", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及がなく、暗号化や難読化といった従来手法のみが述べられているため、ML/LLM が利用されていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "protects native code from being decompiled and stolen in situation where ELF file is called by JAVA in Linux.", "explanation": "本研究の目的は ELF バイナリの保護・暗号化であり、デコンパイル自体の復元や高水準コード生成を行うものではないため、デコンパイルサーベイのスコープ外と判断した。"}], "reasoning": "本文は ELF バイナリの保護手法（暗号化・難読化）を提案しており、機械学習や LLM を利用したデコンパイル手法の研究ではない。したがって、ML/LLM 不使用とデコンパイル目的外という両点から除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3420, "latency_ms": 83185}}
{"key": "9453483", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we retrieve the Bytecode from the target and decompile the Bytecode to STL source code", "explanation": "アブストラクトには機械学習やLLMの利用が記載されておらず、従来のバイトコード逆コンパイル手法のみが述べられているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿はPLCのバイトコードを取得し従来的な手法でSTLソースに逆コンパイルし、攻撃を実証するセキュリティ研究であり、機械学習や大規模言語モデルを手法の中心に用いていない。したがって、Decompilation Survey の採択基準で要求される ML/LLM を用いたデコンパイル研究には該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 3203, "latency_ms": 72942}}
{"key": "9464996", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "provides comments and observations regarding decompilation of a Pascal compiler for the BESM-6", "explanation": "要旨では機械学習や大規模言語モデルの利用について言及されておらず、従来の手法によるコメント・観察であると判断できるため、ML/LLM が使われていないとみなす"}], "reasoning": "本文要旨からは、BESM-6 のシミュレータや Pascal コンパイラのデコンパイルに関する観察が述べられているが、機械学習や LLM の利用は示されていない。したがって、本サーベイの採択条件で必須とされる「ML/LLM を中核手法として用いる」要件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2960, "latency_ms": 72127}}
{"key": "9474328", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The key idea of MMGUARD is to verify the deep learning model in the app before inference", "explanation": "抄録ではモデル検証が手法として述べられ、デコンパイルのための機械学習や大規模言語モデルの利用は示されていないため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "can be stolen by decompiling the apps directly", "explanation": "研究の目的はコードやソースを生成・復元することではなく、モデル盗難防止のための認証機構を提供することにあるため、コード生成・復元を主目的としたデコンパイル研究ではない。"}], "reasoning": "本稿は Android アプリ内のディープラーニングモデルを保護する認証フレームワークを提案しており、デコンパイルによるコード復元や高水準表現の生成を目的としていない。抄録からはデコンパイルに LLM/ML を中核手法として用いる記述がなく、したがって本サーベイの対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3515, "latency_ms": 88146}}
{"key": "9519451", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a novel probabilistic technique for variable and structure recovery.", "explanation": "抄録では機械学習や大規模言語モデルの利用が言及されておらず、確率的手法のみが説明されているため、EC1の「ML/LLM を用いていない」に該当します。"}], "reasoning": "本稿は低水準バイナリから変数やデータ構造を復元する手法を提案していますが、手法は確率的解析であり機械学習やLLMを中心としたアプローチではありません。したがって、Decompilation Survey Screening Rules の除外基準 EC1 に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3029, "latency_ms": 68285}}
{"key": "9589721", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we discuss an approach... employs a decompiler to convert the stolen compiled bytecode (low-level) to its decompiled version (high-level)", "explanation": "要旨に機械学習や大規模言語モデルの利用が全く記述されておらず、従来のデコンパイラとコンパイラを用いた手法だけなので、EC1 に該当し除外します"}], "reasoning": "本論文は PLC のバイナリをデコンパイルし、手動で改変して再コンパイルする攻撃手法を示しているが、ML/LLM を用いた手法は示されていない。したがって、Decompilation Survey の含める基準 (IC0) を満たさないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3153, "latency_ms": 71018}}
{"key": "9631736", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "The purpose of the article is to develop a methodology that allows you to determine the java-module ...", "explanation": "要旨に機械学習や大規模言語モデルの使用は記載されておらず、従ってML/LLMが手法の中核であるという条件を満たさないため除外します。"}, {"code": "ex_no_code_generation", "evidence": "It is necessary that the digital watermark is not damaged during the decompilation of the entire system ...", "explanation": "本研究はデジタル透かしの耐性評価とモジュール置換検出が目的であり、コードの復元・生成が主目的ではないため除外します。"}], "reasoning": "本論文は Java バイトコードに対するデジタル透かし埋め込みとその耐性評価を扱っており、ML/LLM を用いたデコンパイルによる高水準コード生成や再構成を目的としていない。したがって、Include Criteria を満たさず、Exclude Criteria の「ML/LLM 未使用」および「コード生成目的でない」ことから除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3151, "latency_ms": 74782}}
{"key": "9631860", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The exploration used the static analysis method, where the source code of the two applications were decompiled, compared, and analyzed.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く示されておらず、従来の静的解析ツール（MobSF）だけが用いられているため、EC1に該当し除外と判断した。"}], "reasoning": "本稿はバイナリをMobSFでデコンパイルし、静的比較を行うだけで、ML/LLM を手法の中核として用いていない。デコンパイルは目的の一部だが、調査対象はマルウェア判定であり、デコンパイル手法の改善や生成は行っていないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3129, "latency_ms": 71271}}
{"key": "9638928", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "decompile the APK file to obtain the opcode features", "explanation": "アブストラクトではデコンパイルはマルウェア検出のための特徴抽出にしか使われており、コード生成や高水準表現の復元を目的としていないため、除外基準 EC3 に該当します。"}], "reasoning": "本稿は Android アプリのマルウェア検出を目的とした手法であり、デコンパイルは特徴抽出の前処理としてのみ利用されています。復元・可読化といったデコンパイル本来の目的がなく、コード生成や高水準表現の再構築が主目標でないため、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3105, "latency_ms": 73791}}
{"key": "9647781", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "our method does not require manual work to create the patterns for matching idioms", "explanation": "アブストラクトにML/LLMを用いたことは記載されておらず、手作業でパターンを作成しないと述べている点から、機械学習は使用していないと判断したため"}], "reasoning": "本稿はアセンブリ命令パターンを用いてコンパイライディオムを復元する手法を提案しているが、MLやLLMを利用した旨の記述がなく、ルールベースまたは手作業によるパターン生成と見なせるため、Include Criteria の「LLM/ML が中核手法として使われている」要件を満たさない。したがって除外 (ex_no_ml) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3214, "latency_ms": 73991}}
{"key": "9718856", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_ml", "evidence": "This paper proposes a method to measure the similarity of smart contract bytecode.", "explanation": "要旨に機械学習や大規模言語モデルの使用が全く記載されておらず、従来の手法（パターンマッチング・CFG 分析）に基づく類似度測定であるため、EC1 に該当します。"}, {"code": "ex_no_code_generation", "evidence": "the similarity measurement of smart contract bytecode ... can be used for vulnerability mining, contract upgrading and malicious contract detection.", "explanation": "目的はバイトコードの類似度評価であり、コードの復元・生成（L1‑L4）を行うことはなく、EC3 の「コード生成・復元が主目的でない」条件に該当します。"}], "reasoning": "本稿は低水準バイトコードを入力として CFG ベースの特徴抽出により類似度を測定する手法を提案しているが、機械学習／LLM を用いた手法は示されていない。さらに、コードの復元や高水準表現生成を目的としていないため、デコンパイル調査の採択基準を満たさず除外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3214, "latency_ms": 79862}}
{"key": "9719255", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The experimental results show that the average accuracy of the proposed scheme for the detection of APT attack malicious code ... can reach 98.84%.", "explanation": "要旨はAPTマルウェアの検出・分類が目的であり、コードの復元や高水準表現の生成は行っていないため、コード生成・復元目的が欠如していると判断した。"}], "reasoning": "本論文はバイナリを画像化してDenseNetでAPTマルウェアを検出することを目的としており、デコンパイルによる高水準コードの復元や生成を行わない。したがって、デコンパイル研究のInclude Criteriaを満たさず、Exclude Criteriaの「コード生成・復元目的がない」(ex_no_code_generation) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3176, "latency_ms": 75941}}
{"key": "9724320", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Mapping a binary function ... to the same function in the original source code ... to carry out function matching.", "explanation": "アブストラクトはバイナリ関数とソース関数のマッチングを目的としており、コードの生成・復元ではなく検索・類似度判定であるため、コード生成・復元の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本研究はバイナリ関数とソースコード関数の対応付け（マッチング）を行うもので、復元や可読化を目的としたコード生成が含まれません。そのため、デコンパイルの主要目的である高水準コード生成・復元とは異なり、除外基準（コード生成・復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3064, "latency_ms": 72555}}
{"key": "9833799", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This paper conducts an in-depth study of binary lifters...", "explanation": "アブストラクトは二値リフタの調査と評価を行う系統的研究であり、手法としてのML/LLMは示されていないため、レビュー論文に該当します。"}, {"code": "ex_no_ml", "evidence": "No mention of machine learning or large language models is present in the abstract.", "explanation": "抽象からはML/LLMを使用している旨が全く記載されていないため、除外基準EC1に該当します。"}], "reasoning": "本稿はバイナリリフタの調査・比較を行うSoKであり、ML/LLM を用いたデコンパイル手法の提案や実装がないため、除外基準のSurvey/Review (ex_survey_or_meta) および No ML (ex_no_ml) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3398, "latency_ms": 77781}}
{"key": "9850326", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the attack exploits ... subverts the engineering software’s decompilation function", "explanation": "要旨からは機械学習・大型言語モデルの使用が全く言及されておらず、単なる攻撃手法の提案であるため、ML/LLM が用いられていないと判断しました。"}], "reasoning": "本論文は制御ロジックの難読化を利用した攻撃手法を提示しており、デコンパイル機能を妨害することが目的です。しかし、手法として機械学習や大型言語モデルの利用は示されていません。したがって、Decompilation Survey の対象となるML/LLM を用いたデコンパイル研究ではなく、除外基準 EC1（ex_no_ml）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2969, "latency_ms": 70103}}
{"key": "9948365", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the accuracy of vulnerability detection on SARD data set is 96.92%", "explanation": "本文はバイナリをpcodeにデコンパイルして特徴抽出し、脆弱性検出（分類）を行うことが目的であり、コードの生成や復元を目指していないため、コード生成・復元が主目的であるEC3に該当します。"}], "reasoning": "本研究はバイナリをpcodeに変換し、ニューラルネットワークで特徴を抽出して脆弱性検出を行う分類タスクです。デコンパイルは前処理として利用されており、復元や高水準コード生成を目的としていないため、除外基準EC3（コード生成・復元が主目的でない）に該当し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3168, "latency_ms": 78725}}
{"key": "Achamyeleh2026", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "reframes LLM-based decompilation as a structured reasoning task", "explanation": "LLM が低水準バイナリの制御フロー情報を受け取り、高水準のコンパイル可能コードを直接生成しているため、Core Decompilation に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "supplied to a general-purpose LLM, along with raw decompiler output", "explanation": "既存のデコンパイラ出力を入力として利用し、LLM が可読性・コンパイル可能性を向上させているため、デコンパイラ強化にも該当します。"}], "reasoning": "本論文はバイナリを入力とし、LLM を中心手法として再構成・コンパイル可能なソースコードを生成することを目的としている。さらに、既存デコンパイラの出力を改善するプロセスも含んでいるため、Core Decompilation と Decompiler Enhancement の両カテゴリに該当し、包含すべき研究と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3436, "latency_ms": 82380}}
{"key": "Arasteh2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify modules in stripped binaries and associate them with high-level natural language descriptions", "explanation": "要旨はバイナリからモジュールを特定し自然言語で説明することを目的としており、コードや高水準表現（L1‑L4）の生成・復元を行わないため、コード生成・復元の目的がないと判断した"}], "reasoning": "本研究は低水準バイナリを入力に LLM を用いてモジュールを検出し自然言語で説明することに焦点を当てており、ソースコードや擬似コード、AST などの高水準コード表現を生成することは目的としていない。したがって、デコンパイルのコード生成・再構築という採択基準を満たさないため除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3395, "latency_ms": 85600}}
{"key": "Armengol-Estapé2022", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "produce x86 assembler from C code", "explanation": "アブストラクトは C（高水準） を入力とし x86 アセンブリ（低水準） を出力しているため、デコンパイルの定義で求められる低水準入力が存在しません。"}], "reasoning": "本研究は高水準言語（C）から低水準表現（x86 アセンブリ）への変換、すなわちニューラルコンパイルを扱っており、デコンパイル（低水準入力から高水準出力）の要件を満たさないため除外しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2912, "latency_ms": 72626}}
{"key": "Arranz-Olmos2025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We develop CT-RetDec, a CT analysis tool based on a modified version of the LLVM-based decompiler RetDec.", "explanation": "本文では機械学習／大規模言語モデルの利用が言及されておらず、従来のデコンパイラ改変のみで実装しているため、ML/LLM が使用されていないと判断しました。"}], "reasoning": "アブストラクトからは、バイナリを入力としデコンパイラを改良して constant‑time 解析を行う手法が述べられていますが、機械学習や大規模言語モデルを用いる記述が全くありません。したがって、Decompilation Survey Screening Rules の除外基準 EC1（ML/LLM を使用していない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3295, "latency_ms": 77195}}
{"key": "arXiv:2201.07420", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "matching the binary code and source code ... by jointly learning the embeddings ... in a common vector space", "explanation": "アブストラクトはバイナリとソースコードの埋め込みを学習しマッチングすることを目的としており、コードの復元や高水準表現の生成は行わないため、コード生成/再構築の目的がないと判断した。"}], "reasoning": "本論文はバイナリとソースコードのマッチングを行う手法を提案しており、デコンパイルや高水準コード生成を目的としていない。したがって、復元・可読化を主目的とする本サーベイの採択基準を満たさず、コード生成が目的でない点から除外 (ex_no_code_generation) と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3113, "latency_ms": 74710}}
{"key": "arXiv:2306.14168", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "binary code similarity detection (BCSD) ... using ... feature representation vector of binary code", "explanation": "アブストラクトでは、目的がバイナリコードの類似性検出であり、コードの復元や高水準表現の生成ではなく、特徴ベクトルによる比較・分類であると明示されているため、コード生成・再構成の意図がないと判断した。"}], "reasoning": "本研究はバイナリコードの類似性検出を目的としており、低水準入力から高水準コードを生成するデコンパイルや復元を行わない。したがって、デコンパイルに該当する生成・再構成の目的が欠如しているため、除外基準EC3（コード生成・再構成意図なし）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3113, "latency_ms": 75423}}
{"key": "arXiv:2405.19581", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_variable_naming", "evidence": "binary function name recovery", "explanation": "関数名という識別子の復元が主目的であり、低水準バイナリ入力から属性（名前）を生成しているため。"}, {"code": "in_core", "evidence": "probe-and-recover framework that incorporates a binary-source encoder-decoder model and black-box LLMs", "explanation": "LLM/ML を中心手法としてバイナリを入力に人間が読める情報（名前や要約）を生成するフレームワークであるため。"}], "reasoning": "本稿はバイナリを入力とし、LLM/ML を用いて関数名や要約といった高水準属性を復元することを目的としている。低水準入力の使用と ML 手法の中心的利用が明示されており、デコンパイルの周辺タスク（属性復元）に該当するためインクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3979, "latency_ms": 108180}}
{"key": "arXiv:2509.14646", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "fine‑tunes an LLM using the reconstructed SALT to generate decompiled code", "explanation": "論文はバイナリ（アセンブリ）を入力とし、LLMを中心手法として高水準のソースコードを生成しているため、Core Decompilation に該当します。"}], "reasoning": "本稿はバイナリ/アセンブリを低水準入力とし、LLM を用いてソースレベルの抽象ロジックツリーを介してコードを生成する手法を提案している。目的は復元・可読化であり、出力は高水準コード（L1）であるため、Decompilation Survey の包括基準を満たすと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3317, "latency_ms": 79046}}
{"key": "Banerjee2021", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_variable_naming", "evidence": "infer variable names in decompiled code based on Masked Language Modeling", "explanation": "抽象的に変数名の復元を主目的としているため、変数名回復（Variable Naming）に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "takes raw decompiler output ... as input, and enriches it using our proposed finetuning technique", "explanation": "既存のデコンパイラ出力（低品質の擬似コード）を入力として、LLM/ML により可読性と命名を改善しているため、デコンパイラ強化に該当します。"}], "reasoning": "本研究はバイナリから直接生成するのではなく、既存デコンパイラの出力を入力として変数名を予測・付与する手法を提案しており、LLM（BERT/Transformer）を核としたML技術を用いている点でIC0 を満たす。目的は復元・可読化であり、変数名回復が主目的なので in_variable_naming を主コードとし、デコンパイラ出力の改善という側面から in_decompiler_enhancement も補助コードとして付与した。", "model": "openai/gpt-oss-120b", "tokens_used": 3559, "latency_ms": 93959}}
{"key": "Bielik2020", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Machine learning ... decompilation, type inference and many others.", "explanation": "アブストラクトではコードタスク全般を扱うと述べられているが、入力がバイナリやアセンブリといった低水準表現であることは示されておらず、主にソースコードや抽象的なコード表現を対象としているため、低水準入力が欠如していると判断した。"}, {"code": "ex_no_code_generation", "evidence": "we explore this issue by: (i) instantiating adversarial attacks for code ... (iii) combining ... to improve robustness", "explanation": "研究の目的はコードモデルの adversarial robustness を評価・改善することであり、復元・可読化・コード生成といったデコンパイル目的のコード生成は行わないため、コード生成・再構築の意図がないと判断した。"}], "reasoning": "本稿はコードに対する敵対的攻撃とロバストネスの向上を扱うもので、低水準表現から高水準コードを生成するデコンパイルを目的としていない。入力はソースコード等の高水準表現であり、LLM/ML はロバストネス評価に用いられるが、デコンパイルの核心手法ではないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3181, "latency_ms": 84476}}
{"key": "Bu2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect vulnerabilities directly from bytecode", "explanation": "アブストラクトはバイトコードから脆弱性を検出することを目的としており、復元や高水準コード生成ではなく分類タスクであるため除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイトコードを入力として脆弱性検出（分類）を行うことが主目的であり、コードの復元や高水準表現の生成を目指していない。したがって、デコンパイルの成果物生成を目的とした研究ではなく、除外基準 EC3（コード生成・復元意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3141, "latency_ms": 77300}}
{"key": "Butz2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We fill this gap by proposing SPN2BN, an algorithm that decompiles an SPN into a BN.", "explanation": "本文はアルゴリズムを提案しており、機械学習・LLM の使用は示されていないため、EC1 に該当し除外となります。"}, {"code": "ex_out_of_scope", "evidence": "tools to convert between BNs and SPNs are desirable... decompiling SPNs into BNs.", "explanation": "対象は確率的グラフィカルモデル間の変換であり、プログラムのバイナリやアセンブリから高水準コードへの復元とは異なるため、スコープ外です。"}], "reasoning": "本論文は SPN からベイジアンネットワークへの変換手法を提案しており、プログラムコードのデコンパイルとは異なる領域です。また、ML/LLM を中心手法として使用していないため、除外基準に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3295, "latency_ms": 82799}}
{"key": "Caliskan2017", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "We examine programmer de-anonymization ... using a novel set of features that include ones obtained by decompiling the executable binary to source code.", "explanation": "本研究はバイナリをデコンパイルして特徴を抽出し、作者識別（分類）を目的としているため、コードの復元・生成が主目的ではなく除外基準 EC3 に該当する。"}], "reasoning": "本文はバイナリからデコンパイルしたコードを特徴として利用し、プログラマの匿名性を破ること（著者帰属）を目的とした機械学習ベースの分類タスクです。デコンパイルは手段であり、復元・可読化・意味回復といったコード生成が目的ではないため、インクルード基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3240, "latency_ms": 78769}}
{"key": "Cao2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "transform a low-level program language (LPL) (eg., binary file) into its functionally-equivalent high-level program language (HPL) (e.g., C/C++)", "explanation": "低水準バイナリから高水準C/C++コードへの変換を目的としており、ML（GNN）を中心手法として用いているため、コアデコンパイル研究に該当する。"}, {"code": "in_core", "evidence": "NeurDP uses a graph neural network (GNN) model to convert LPL to an intermediate representation (IR)", "explanation": "低水準入力をMLモデルで処理し、高水準表現（IR から最終的にソース）を生成する点が Core Decompilation に該当する。"}], "reasoning": "本稿はバイナリという低水準表現を入力とし、GNN を中心とした機械学習手法で高水準ソース（C/C++）を生成することを目的としている。目的・入力・手法すべてがデコンパイルの定義を満たすため、Include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3360, "latency_ms": 85659}}
{"key": "Chakraborty2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We develop correct and efficient translations between the concurrency models of two mainstream architecture families: x86 and ARM", "explanation": "要旨に機械学習や大規模言語モデルの利用が一切記載されておらず、従来の手法による翻訳・フェンス挿入が中心であるため、ML/LLM を用いたデコンパイルとはみなせません。"}], "reasoning": "本稿は並行性プリミティブの正しいアーキテクチャ間マッピングとフェンス挿入手法を提案しており、機械学習や大規模言語モデルを用いた手法は示されていません。そのため、Decompilation Survey の対象となる ML/LLM を中心としたデコンパイル研究には該当せず、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3173, "latency_ms": 81352}}
{"key": "Chawla2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LLMs in classifying executable code as either benign or malicious.", "explanation": "目的はマルウェアの分類であり、コード生成や復元が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は、Ghidra によるデコンパイルを前処理として利用し、LLM でマルウェアか否かを分類することが主目的です。デコンパイル自体は既存ツールの使用に留まり、LLM がコード復元や可読化に用いられていないため、デコンパイル研究の範囲（復元・可読化）を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3274, "latency_ms": 88736}}
{"key": "Chen2021", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "a novel technique for improving the quality of decompiler output that automatically generates meaningful variable names and types", "explanation": "既存デコンパイラの出力を入力とし、LLM/ML で変数名と型を付与して品質を向上させることが目的であるため、IC2 の Decompiler Enhancement に該当する。"}, {"code": "in_variable_naming", "evidence": "automatically generates meaningful variable names", "explanation": "変数名の復元・生成が主要な貢献の一つであることを示す。"}, {"code": "in_type_recovery", "evidence": "automatically generates ... types", "explanation": "型（型情報）の復元・推論が本研究の目的に含まれるため、Type Recovery に該当する。"}], "reasoning": "本稿はデコンパイラの出力に対して機械学習を用いて変数名と型を自動付与し、可読性と解析性を向上させる手法を提案している。入力はデコンパイルされたコードという低水準由来の表現であり、出力は変数名・型という高水準属性であるが、デコンパイラ出力全体の品質改善が主目的であるため Core の Decompiler Enhancement とみなす。したがって include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3666, "latency_ms": 104058}}
{"key": "Chukkol2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "VulCatch ... transforms raw binary code into pseudocode using CodeT5 ... for deep analysis", "explanation": "本文はバイナリを擬似コードに変換して脆弱性検出の前処理としていますが、主目的は検出であり、復元・可読化・意味回復が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本論文は CodeT5 を用いてバイナリから擬似コードを生成し、その出力を脆弱性検出に利用していますが、研究の主要な目的は脆弱性検出であり、デコンパイル自体の復元や可読化が中心ではありません。そのため、目的が復元・意味回復でないという除外基準 EC3 に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3407, "latency_ms": 93449}}
{"key": "Cristea2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detect binary malware... and ... identify Common Vulnerabilities and Exposures (CVEs)", "explanation": "要旨ではLLMはマルウェア検出とCVE分類という分類・検出タスクのために使用されており、復元や高水準コード生成が主目的ではないため除外基準EC3に該当する"}], "reasoning": "本稿はLLMを用いてバイナリ(JAR)からマルウェアを検出し、CVE を関連付けることを目的としており、デコンパイルによるコード生成や可読化は副次的な前処理に過ぎません。デコンパイルの復元・生成が主要目的でないため、除外基準EC3（コード生成/復元意図がない）に該当し、インクルード対象外です。", "model": "openai/gpt-oss-120b", "tokens_used": 3262, "latency_ms": 84558}}
{"key": "David2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "leverages Large Language Models (LLMs) to transform Ethereum Virtual Machine (EVM) bytecode into human-readable and semantically faithful Solidity code", "explanation": "LLM が低水準の EVM バイトコードを直接 Solidity ソースコード (L1) に変換しているため、Core Decompilation に該当します。"}, {"code": "in_variable_naming", "evidence": "recovers meaningful variable names", "explanation": "生成された Solidity コードが変数名を復元していることから、変数/関数命名の復元目的が含まれます。"}, {"code": "in_control_structure", "evidence": "intricate control flow", "explanation": "デコンパイル結果に制御構造（if/else/loop 等）を再構築している点が、制御構造復元に該当します。"}], "reasoning": "本稿は EVM バイトコードという低水準入力を LLM により Solidity ソースコードへ変換し、可読性と意味的忠実性を高めることを目的としているため、Decompilation Survey の Include 基準を満たします。変数名や制御構造の復元も明示的に述べられているため、追加のサブカテゴリとしても評価できます。", "model": "openai/gpt-oss-120b", "tokens_used": 3504, "latency_ms": 92355}}
{"key": "Enders2022", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We introduced our decompilation approach dewolf. We developed a variety of improvements over the previous academic state-of-the-art decompiler...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が言及されておらず、従来の手法によるデコンパイル改善のみが述べられているため、EC1 に該当し除外と判断した。"}], "reasoning": "本稿は既存デコンパイラの改善手法を提示しているが、ML/LLM を中心手法として用いている記述がなく、除外基準 EC1（No ML/LLM）に該当する。したがって本サーベイの対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3040, "latency_ms": 74706}}
{"key": "Escalada2021", "action": "keep", "reason": "in_type_recovery", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_type_recovery", "evidence": "we build different classification models capable of inferring the high-level type returned by functions", "explanation": "MLモデルで関数の戻り型（高水準属性）を推測しており、型回復が主目的であるため"}, {"code": "in_decompiler_enhancement", "evidence": "supervised machine learning models aimed at improving existing decompilers", "explanation": "既存デコンパイラの型推定精度を向上させることが研究の目的で、デコンパイラ出力の改善に該当する"}], "reasoning": "本論文はバイナリから低水準入力を取り、ML を用いて関数戻り型という高水準属性を推定し、既存デコンパイラの型情報を改善することを目的としている。入力がバイナリであり、ML が中心手法で、復元・可読化というデコンパイル目的に直結しているため、Peripheral でも採択基準を満たす。したがって include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3275, "latency_ms": 88018}}
{"key": "Fang2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "decompile complex WebAssembly code into readable C++ snippets", "explanation": "低水準のWebAssemblyを入力とし、LLMを用いて高水準のC++ソースコードを直接生成しているため、Core Decompilationに該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "combines Large Language Models (LLMs) with advanced program analysis", "explanation": "LLMがプログラム解析結果を活用し、従来のデコンパイル手法を補強している点がデコンパイラ強化に該当します。"}], "reasoning": "本論文はWebAssemblyという低水準バイナリ表現を入力とし、LLMを中心手法として可読なC++コード（L1レベル）を生成することを目的としています。入力が低水準であり、出力が高水準コードで、復元・可読化が主目的であるため、Core Decompilation (in_core) として採択します。また、LLMが静的解析と組み合わされて既存デコンパイラの出力を改善している点から、デコンパイラ強化 (in_decompiler_enhancement) も補助的に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3132, "latency_ms": 84033}}
{"key": "Feng2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "Fine-grained Alignment Enhancement (FAE), which meticulously aligns assembly code with source code at the statement level by leveraging debugging information", "explanation": "アブストラクトはアセンブリという低水準入力とソースコードという高水準出力を直接対応付けており、LLM/ML を用いて復元（デコンパイル）を行うことが目的と示されているため、Core Decompilation に該当します。"}], "reasoning": "本稿はアセンブリコードを入力とし、LLM を中心に用いて高水準のソースコードを生成する手法を提案している。目的は decompilation の性能向上であり、出力は再実行可能なコード（L1）であるため、Include の基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3308, "latency_ms": 88850}}
{"key": "Feng2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "end-to-end decompile method based on large langauge models (LLMs)", "explanation": "LLM が中心手法として低水準コード（assembly）から高水準言語へ直接変換しているため、コアデコンパイルに該当する。"}, {"code": "in_type_recovery", "evidence": "Function Call strategy infers variable types and retrieves missing variable information from binary files", "explanation": "変数型の推測・復元を目的とした手法が述べられており、型回復に該当する。"}, {"code": "in_control_structure", "evidence": "Relabelling strategy replaces jump target addresses with labels, preserving control flow clarity", "explanation": "ジャンプ先をラベル化して制御フローを明示する手法は制御構造の復元に該当する。"}], "reasoning": "本稿は LLM を核としたエンドツーエンドのデコンパイル手法であり、低水準のアセンブリ入力から高水準コードを生成することを主目的としている。加えて、型推論や制御フローの明示といった要素技術も提供しているため、Core デコンパイルとして採択する。", "model": "openai/gpt-oss-120b", "tokens_used": 3348, "latency_ms": 91092}}
{"key": "Fu2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "first end-to-end neural-based framework for code decompilation", "explanation": "ニューラルネットワークを用いてバイナリ実行ファイルから直接抽象構文木（AST）や高水準コードを生成しているため、Core decompilation に該当する。"}], "reasoning": "本稿はバイナリ（低水準入力）を対象に、エンコーダ‑デコーダ型ニューラルネットワークでASTを生成し、コードスケッチを復元するエンドツーエンドのデコンパイラを提案している。ML 手法が中心であり、目的はソースコードの復元・可読化なので Inclusion 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3292, "latency_ms": 84032}}
{"key": "Gao2025", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "we present DecompileBench, the first comprehensive framework that enables effective evaluation of decompilers", "explanation": "本文はデコンパイル手法の生成や改善ではなく、デコンパイラを評価するベンチマークの提案であり、デコンパイル自体の研究対象外と判断したため"}], "reasoning": "本稿は低水準コードから高水準表現を生成することを目的とした手法ではなく、既存デコンパイラの評価基盤を提供することが主旨です。LLMは評価者（LLM-as-Judge）として使用されており、デコンパイルのコア手法には該当しません。そのためスクリーニング基準の除外基準（範囲外）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3340, "latency_ms": 88885}}
{"key": "Green2024", "action": "keep", "reason": "uns_unclear_method", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_method", "evidence": "predicts variable names and types by matching sequences of decompiler tokens to those found in training data", "explanation": "抽象だけでは本手法が機械学習／LLM を中心に使用しているか判定できないため"}, {"code": "uns_unclear_input", "evidence": "matching sequences of decompiler tokens", "explanation": "入力が低水準バイナリかアセンブリか、あるいは既存デコンパイラの出力かが明示されていない"}], "reasoning": "本文では変数名・型の復元を目的としているが、使用手法が機械学習／LLM であること、入力が低水準表現であることが明確に示されていない。そのため、現時点では include か exclude かを確定できず、uncertain と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3290, "latency_ms": 91500}}
{"key": "Hosseini2022", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "using techniques from neural machine translation to automate the process in decompilation", "explanation": "ニューラル機械翻訳（ML手法）でアセンブリから高水準ソースを直接生成しており、復元・可読化が目的なのでCore Decompilationに該当する"}], "reasoning": "本稿はアセンブリという低水準入力をニューラル機械翻訳というML手法で処理し、Go・Fortran・OCaml などの高水準ソースコードを生成することを目的としている。目的がデコンパイル（ソース復元）であり、生成物はコンパイル可能なコード（L1）に相当するため、Include 基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3193, "latency_ms": 85357}}
{"key": "Hussain2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the novel application of LLMs to detect vulnerabilities within these binary files", "explanation": "アブストラクトはLLMを用いた脆弱性検出が主目的であり、コードの復元や高水準表現の生成は目的としていないため、コード生成／復元意図が無いと判断した。"}], "reasoning": "本稿はLLMを活用したバイナリ脆弱性検出手法を提案しており、デコンパイルは脆弱性検出を支援する前処理として登場するが、主要な研究目的は分類・検出であり、復元・可読化・高水準コード生成ではない。そのため除外基準EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3210, "latency_ms": 82802}}
{"key": "Jiang2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.82, "reason_codes": [{"code": "in_core", "evidence": "assess model performance across ... decompilation ...", "explanation": "LLM が低水準の IR を入力として直接コード（高水準表現）を生成する decompilation タスクを実施しており、目的はコード復元であるため Core Decompilation に該当する"}, {"code": "ex_no_ml", "evidence": "", "explanation": ""}], "reasoning": "本論文は IR（低水準表現）を入力にし、LLM を用いて decompilation を実行しその性能を評価している。LLM/ML が手法の中心であり、復元・可読化が目的と明示されているため、Core Decompilation（in_core）として採択する。", "model": "openai/gpt-oss-120b", "tokens_used": 3760, "latency_ms": 109448}}
{"key": "Jiang2025", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.78, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Nova, a generative LLM for assembly code... outperforms existing techniques on binary code decompilation", "explanation": "本稿はバイナリからアセンブリを生成することに焦点を当てており、出力は低水準のアセンブリであり、定義された高水準表現（ソース/疑似コード/AST 等）には該当しないため、デコンパイルの対象外と判断した。"}], "reasoning": "要旨からは、LLM を用いてバイナリをアセンブリへ変換することが目的と示されているが、出力は高水準コードや属性ではなく低水準アセンブリである。デコンパイル調査のスコープは L1‑L4 の高水準表現に限定されるため、本研究は範囲外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 4023, "latency_ms": 117235}}
{"key": "Katz2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "convert a program in low-level representation back to a higher-level human-readable programming language", "explanation": "低水準表現（LLVM IR, x86 アセンブリ）から高水準の C ソースコードを生成することが目的で、手法はニューラル機械翻訳という ML 手法であるため、Core Decompilation に該当します。"}, {"code": "in_core", "evidence": "we used our framework to decompile both LLVM IR and x86 assembly to C code", "explanation": "入力がバイナリ/アセンブリ系の低水準表現で、出力がコンパイル可能な C ソース（L1）であることが明示されており、ML が中心手法である点から Core Decompilation と判断します。"}], "reasoning": "本稿は低水準表現（LLVM IR および x86 アセンブリ）を入力とし、ニューラル機械翻訳という機械学習手法で高水準の C ソースコードを直接生成することを目的としている。したがって、Decompilation Survey の Core Decompilation カテゴリに該当し、include と判断する。", "model": "openai/gpt-oss-120b", "tokens_used": 3135, "latency_ms": 84554}}
{"key": "KC2023", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "we survey the NMT for code generation literature", "explanation": "アブストラクトが調査・レビューを行うことを述べており、研究成果の新規提案ではないため除外基準EC4に該当します。"}], "reasoning": "本稿はNeural Machine Translation を用いたコード生成に関する文献調査を目的としており、デコンパイル手法の新規提案や実装は含まれていません。したがって、サーベイ論文として除外基準EC4（Survey/Review）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2880, "latency_ms": 76949}}
{"key": "Kim2023", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Malware detection on binary executables provides a high availability to even binaries which are not disassembled or decompiled.", "explanation": "アブストラクトはバイナリの検出・分類を目的としており、コードの復元や高水準表現の生成は目的に含まれていないため、コード生成/復元意図がないと判断した。"}], "reasoning": "本論文はバイナリ実行ファイルのマルウェア検出を目的とした特徴量エンジニアリングとCNNを用いた分類手法を提案している。デコンパイルや高水準コードの生成を目指す研究ではなく、単なる分類タスクであるため、除外基準 EC3 (No code generation / reconstruction intent) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3040, "latency_ms": 86051}}
{"key": "Kumar2018", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Control flow obfuscation (CFO) alters the control flow path of a program without altering its semantics.", "explanation": "アブストラクトに機械学習または大規模言語モデルを利用した旨の記述がなく、純粋にオブフュスケーション手法の調査・分類であるため、ML/LLM を用いていないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "We systematically study CFO techniques proposed for Java programs, both from papers and commercially available tools.", "explanation": "研究対象は Java プログラムの制御フロー難読化の調査であり、デコンパイルや低水準コードから高水準コードへの復元を目的としたものではないため、スコープ外と判断した。"}], "reasoning": "本稿は Java プログラムに対する制御フロー難読化技術の体系的調査であり、機械学習や大規模言語モデルを用いたデコンパイル手法の開発・改善を目的としていない。したがって、対象外（exclude）となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3250, "latency_ms": 85596}}
{"key": "Li2019", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "We propose a fault-tolerant Java decompiler based on machine translation models.", "explanation": "「Java decompiler」という表現から、低水準のバイトコードを入力とし、ソースコード（L1）を生成することが目的であると判断でき、LLM/ML（NMT・Transformer）が中心手法として用いられているため、Core Decompilation に該当します。"}, {"code": "ex_no_ml", "evidence": "Our model is based on attention‑based Neural Machine Translation (NMT) and Transformer architectures.", "explanation": "本文は機械翻訳モデル（NMT・Transformer）を使用していると明示しており、ML/LLM が手法の中核であることを示しています。"}], "reasoning": "本稿は Java バイトコード（低水準表現）を入力とし、ニューラル機械翻訳モデルを用いて高水準のソースコードを生成するデコンパイラを提案しているため、コアデコンパイル研究に該当します。ML 手法が中心であり、復元・可読化が目的である点から採択基準を満たしています。", "model": "openai/gpt-oss-120b", "tokens_used": 3665, "latency_ms": 106611}}
{"key": "Li2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "NeuroDeX can recover DNN executables into high-level models", "explanation": "低水準のDNN実行バイナリを入力として、LLMを用いて高レベルのモデル表現（コード／モデル定義）を直接生成しているため、Core Decompilation に該当します。"}, {"code": "in_type_recovery", "evidence": "perform operator type recognition, operator attribute recovery", "explanation": "研究の主要なサブタスクとして演算子の型や属性を復元しており、型回復タスクに該当します。"}], "reasoning": "本稿は低水準のディープラーニング実行バイナリを入力に取り、LLM を中心手法として高レベルのモデル（ソースレベル表現）へ復元することを目的としているため、Decompilation Survey の include 基準を満たします。また、演算子型・属性の回復という型回復要素も含むため、補助的に in_type_recovery を付加しています。", "model": "openai/gpt-oss-120b", "tokens_used": 3340, "latency_ms": 92214}}
{"key": "Li2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "detecting binary security patches", "explanation": "アブストラクトはバイナリパッチからセキュリティパッチを識別することを目的としており、コードの復元や高水準表現の生成ではなく分類タスクであるため、コード生成/復元の目的がないと判断した。"}], "reasoning": "本論文はコードLLMを用いてバイナリパッチのセキュリティパッチ検出を行う分類研究であり、デコンパイルや高水準コード生成を目的としていない。したがって、除外基準 EC3（コード生成・復元が主目的でない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3189, "latency_ms": 84031}}
{"key": "Liang2021", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "translate low-level PL into accurate and user-friendly high-level PL", "explanation": "低水準コード（バイナリ）から高水準コード（C/C++）を直接生成することが目的で、手法の中心にニューラル機械翻訳（ML/LLM）が使われているため、Core Decompilation に該当する。"}], "reasoning": "本稿はバイナリ等の低水準表現を入力とし、ニューラル機械翻訳により C/C++ 等のソースコードを生成する手法を提案している。目的はコードの復元・可読化であり、ML が中核手法であることから Inclusion 基準を満たす。したがって Core Decompilation（in_core）として採択する。", "model": "openai/gpt-oss-120b", "tokens_used": 3181, "latency_ms": 84366}}
{"key": "Liu2021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "SMT solvers, which serve as a foundation for these tools, have thus increased support for bitvector reasoning", "explanation": "本文は SMT ソルバーや線形近似による検証手法を説明しており、機械学習・LLM の利用は言及されていないため除外基準 EC1 に該当します。"}], "reasoning": "本研究はビットベクトルプログラムとデコンパイル済みバイナリの検証手法を提案しており、ML/LLM を中心手法として使用していません。したがって、インクルード基準の IC0 を満たさず、除外基準 ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2999, "latency_ms": 78595}}
{"key": "Liu2022", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "BTD takes DNN executables and outputs full model specifications, including types of DNN operators, network topology, dimensions, and parameters", "explanation": "低水準の実行ファイル（binary）を入力とし、ML 手法で演算子やネットワーク構造を推定し、モデル仕様という高水準表現を生成しているため、Core Decompilation に該当します。"}, {"code": "ex_no_ml", "evidence": "It employs learning-based techniques to infer DNN operators", "explanation": "本文中で「learning‑based techniques（学習ベースの手法）」と明記されており、ML／LLM が手法の中心であることが確認できるため、除外基準は当てはまりません。"}], "reasoning": "本論文はバイナリ（x86 DNN 実行ファイル）を入力として、ML を用いて演算子種別やネットワークトポロジー、パラメータ等の高水準モデル仕様を復元する手法を提案している。出力はコンパイル可能なモデル定義に相当し、Decompilation の目的と手法要件を満たすため、include と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3403, "latency_ms": 94310}}
{"key": "Liu2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.94, "reason_codes": [{"code": "in_core", "evidence": "generate highly readable source code", "explanation": "LLM がバイナリ入力から直接コンパイル可能なソースコード（L1）を生成していることから、コアデコンパイル研究に該当します。"}, {"code": "in_control_structure", "evidence": "incorporates control flow graphs (CFG) and explicit data mappings to improve LLM-based decompilation", "explanation": "CFG とデータマッピングを用いて制御構造の復元を強化しているため、制御構造復元も主要な目的の一つです。"}], "reasoning": "本稿はバイナリを入力とし、LLM を中心手法として高可読性のソースコードを生成するエンドツーエンドデコンパイル手法を提案しています。さらに制御フローグラフとデータマッピングを活用し、制御構造の回復を改善している点から、コアデコンパイル研究（in_core）と制御構造復元（in_control_structure）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3416, "latency_ms": 91852}}
{"key": "Manuel2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identifying; classifying; describing vulnerabilities... detecting binary code vulnerabilities", "explanation": "論文の主目的は脆弱性の検出・分類であり、コードの生成や復元が主目的ではないため除外基準 EC3 に該当する。"}, {"code": "ex_no_lowlevel_input", "evidence": "decompiled binary code ... for the task of ... recovering function names", "explanation": "入力として扱われているのは既にデコンパイルされたコードであり、低水準バイナリやアセンブリといった入力条件を満たさないと判断できる。"}], "reasoning": "本稿は LLM を用いてデコンパイルされたバイナリコード上で脆弱性の検出・分類を行うことが主目的であり、コード生成や復元を目的としていない上、入力は低水準表現ではなくデコンパイル後のコードであるため、デコンパイル研究の包括基準を満たさないと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 4294, "latency_ms": 120233}}
{"key": "Manuel2025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "CodableLLM, a Python framework designed to automate the creation and curation of datasets by mapping decompiled functions to their corresponding source functions.", "explanation": "要旨にはML/LLMが手法の中核として使用されている記述がなく、単なるフレームワークによるマッピングなのでEC1に該当する。"}, {"code": "ex_no_code_generation", "evidence": "The process enhances the alignment between decompiled and source code representations, facilitating the development of large language models ...", "explanation": "目的はデータセット生成であり、コードの復元や生成が主目的ではないためEC3に該当する。"}], "reasoning": "本稿は既存デコンパイラの出力とソースコードを対応付けるデータセット生成ツールを紹介しているが、ML/LLM を手法の中心に据えていない上、コード復元や高水準表現の生成を目的としていないため、除外基準 (ex_no_ml, ex_no_code_generation) に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3312, "latency_ms": 97138}}
{"key": "Mihajlenko2021", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We developed the algorithms for the following operations: preprocessing assembly code, searching data accesses, extracting system values, decompiling arithmetic operations and recovering data types.", "explanation": "抽象からは機械学習や大規模言語モデルの使用が全く言及されておらず、従って本研究はML/LLMを手法の中核としていないため、除外基準 EC1 に該当します。"}], "reasoning": "本論文は AMD GCN アセンブリから OpenCL ソースへの変換アルゴリズムをルールベースで提案しており、機械学習やLLM の利用が示されていない。そのため、Decompilation Survey Screening Rules の除外基準 EC1（No ML/LLM）に該当し、include できません。", "model": "openai/gpt-oss-120b", "tokens_used": 3026, "latency_ms": 83220}}
{"key": "Minn2026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "another agent generates dynamic instrumentation scripts that satisfy activation conditions", "explanation": "本稿は低水準コードから高水準コードを復元することを目的とせず、テスト用のインストゥルメンテーションスクリプト生成が主目的であるため、コード生成/復元の意図がなく除外基準 EC3 に該当すると判断した。"}], "reasoning": "本研究はデコンパイルされた Smali コードを入力として利用し、AI エージェントがテストカバレッジ向上のための動的インストゥルメンテーションを生成することに焦点を当てている。目的はコードの復元や可読化ではなく、GUI テストの自動化であるため、Decompilation Survey の対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3570, "latency_ms": 99184}}
{"key": "Palmarini2024", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "\"decompiling its amortized knowledge to extract relevant program components\"", "explanation": "アブストラクトは低水準のバイナリやアセンブリを入力としていることを示さず、知識（ニューラルポリシー）を「デコンパイル」することを述べているため、低水準入力がなく除外基準に該当する"}], "reasoning": "本研究は DreamCoder のニューラル検索ポリシーからプログラムコンポーネントを抽出する手法であり、バイナリやアセンブリといった低水準表現を入力としていない。Decompilation の定義上、低水準入力が必須であるため本サーベイの対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3038, "latency_ms": 85753}}
{"key": "Pearce2022", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we investigate prompting Codex to identify the purpose, capabilities, and important variable names or values from code", "explanation": "本文はコードから情報を抽出し回答を生成することに焦点を当てており、ソースコードや擬似コード等の高水準プログラム表現を生成する目的ではないため、コード生成/復元の意図がなく除外基準 EC3 に該当する。"}, {"code": "ex_no_lowlevel_input", "evidence": "even when the code is produced through decompilation", "explanation": "入力として扱っているのはデコンパイル後のコードであり、バイナリやアセンブリといった低水準表現ではないため、除外基準 EC2 にも該当する。"}], "reasoning": "本論文は LLM を用いてデコンパイル済みコードから目的や変数情報を抽出する研究であり、低水準バイナリから高水準コードを生成するデコンパイルそのものや、既存デコンパイラの出力を改善することを目的としていない。したがって、コード生成・復元の意図がなく、入力も低水準ではないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3789, "latency_ms": 113836}}
{"key": "Pochelu2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "transforms any JAX function into an editable Python code", "explanation": "要旨に機械学習や大規模言語モデルの利用が全く記載されていないため、ML/LLM が手法の中核であると判断できず、除外基準 EC1 に該当します。"}], "reasoning": "この論文は JAX の中間表現 Jaxpr を高水準の Python ソースへ変換するツールを紹介していますが、抽象的に機械学習や LLM の使用は示されていません。したがって、デコンパイル研究で要求される「ML/LLM を中心手法とする」条件を満たさないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3154, "latency_ms": 92734}}
{"key": "Pordanesh2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "analyzing the LLM's performance in interpreting and explaining human-written and decompiled codes", "explanation": "アブストラクトはLLMがコードを「解釈」・「説明」することを評価しており、低水準バイナリから高水準コードを生成・復元することが目的ではないため、コード生成・復元の意図がなく除外基準EC3に該当する"}], "reasoning": "本論文はLLM (GPT-4) のバイナリ逆解析におけるコード理解力を評価するもので、低レベル入力から高レベルコードを生成することが目的ではない。したがって、復元・可読化を目的としたコード生成が行われていないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3095, "latency_ms": 89238}}
{"key": "Qin2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose the first empirical study on the understandability of Java decompiled code", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が言及されておらず、手法は実証的評価であるためML/LLMが用いられていないと判断した。"}], "reasoning": "本稿はJavaデコンパイルコードの可読性を評価する実証研究であり、デコンパイル自体の生成やML/LLMを用いた改善を目的としていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1（ML/LLM 未使用）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3139, "latency_ms": 84769}}
{"key": "Rao2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We devise a method for register aggregation, to identify relationships between the data flip-flops in a netlist...", "explanation": "要旨では手法がアルゴリズム的に記述されており、機械学習や大規模言語モデルの利用は言及されていないため、ML/LLM を使用していないと判断した。"}], "reasoning": "本稿はゲートレベルのネットリストから HDL へ変換するハードウェア・デコンパイル手法を提案しているが、機械学習や LLM を利用したことが示されていない。したがって、Decompilation Survey の採択基準で要求される「LLM/ML が中核手法として用いられる」条件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3188, "latency_ms": 86585}}
{"key": "Reis2020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We provide an automated decompiler of Michelson smart contracts to Tezla.", "explanation": "要旨では機械学習や大規模言語モデルの使用は言及されておらず、従来の自動デコンパイル手法のみが示されているため、ML/LLM が中核手法でないと判断した。"}], "reasoning": "本稿は Michelson バイトコードを Tezla 中間表現へ変換する自動デコンパイラを紹介しているが、機械学習や大規模言語モデルの利用が示されていない。したがって、Decompilation Survey の採択基準で要求されるML/LLM利用が欠如しているため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3027, "latency_ms": 88167}}
{"key": "Saul2024", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "perform function similarity searches ... and evaluate ML binary function similarity models", "explanation": "本文は関数類似度の検出・ベンチマーク構築が目的であり、コードの復元や高水準表現の生成を行わず、分類・検索が主目的なので除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリ関数の類似性検出とベンチマーク作成を目指す研究で、低水準入力から高水準コードを生成するデコンパイル目的ではない。MLは類似度モデルに使用されているが、コード生成や復元が主目的ではないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3088, "latency_ms": 84025}}
{"key": "Shang2025", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "introduce BinMetric ... to evaluate the performance of large language models on binary analysis tasks, including decompilation, code summarization, assembly instruction generation", "explanation": "本文はLLMを用いたデコンパイル手法を提案せず、LLMの性能評価用ベンチマークを提示しているだけで、コード生成・復元そのものは行っていないため除外基準 ex_no_code_generation に該当する。"}], "reasoning": "本稿はデコンパイル手法の提案ではなく、LLM のバイナリ解析能力を測るベンチマークの構築と評価に焦点を当てている。入力や出力の生成に関する具体的な手法や成果物が示されておらず、IC を満たさないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3462, "latency_ms": 100068}}
{"key": "Shokri2023", "action": "keep", "reason": "in_control_structure", "details": {"decision": "include", "confidence": 0.84, "reason_codes": [{"code": "in_control_structure", "evidence": "reconstructing control algorithms from embedded system binaries", "explanation": "抽象から、低水準バイナリを入力として制御アルゴリズム（制御構造）を高水準の数学表現に復元することが目的であるため、制御構造の回復に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "static analysis on decompiled binary files of the controller", "explanation": "既存のデコンパイル結果（バイナリの逆コンパイル）を解析し、そこからスケッチを作成している点でデコンパイラ出力を利用した拡張研究とみなせます。"}, {"code": "in_core", "evidence": "perform an evolutionary-based search to find the correct semantic", "explanation": "進化的検索（ML 手法）を中心に、高レベルの制御ロジック（数学的表現）を直接生成しているため、コアデコンパイル研究に該当します。"}], "reasoning": "本稿は埋め込みシステムのバイナリ（低水準入力）を対象に、進化的探索という機械学習手法を用いて制御アルゴリズムの高レベルな数学的表現を復元することを目的としている。デコンパイル結果の解析から始める点でデコンパイラ出力の活用・改善も含み、制御構造の回復という主目的に合致するため、インクルードと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3738, "latency_ms": 114439}}
{"key": "Stuglik2023", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "The process consists of a few steps. First step is a process of decompilation of JVM and its translation to internal abstract syntax tree...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が全く言及されておらず、ルールベースの変換手法とみなせるため、EC1 に該当し除外と判断した。"}], "reasoning": "本文ではバイトコードからAST への変換や並列化ルールによるコード生成が述べられているが、LLM/ML を用いた手法は示されていない。従って、Decompilation Survey Screening Rules の除外基準 EC1（No ML/LLM）に該当し、include できない。", "model": "openai/gpt-oss-120b", "tokens_used": 3266, "latency_ms": 95155}}
{"key": "Su2026", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "attacker logic can be recovered from low-level transaction traces ... translated into executable exploits by leveraging the code-generation capabilities of large language models (LLMs).", "explanation": "LLM を用いて低レベルのトランザクショントレースから実行可能な擬似コードを生成しているため、Core Decompilation に該当します。"}, {"code": "in_decompiler_enhancement", "evidence": "dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode.", "explanation": "既存の実行情報（トレース）をデコンパイラ的手法で加工し、LLM が読みやすい高水準表現に変換している点がデコンパイラ出力の改善に相当します。"}], "reasoning": "本稿は低レベルのトランザクショントレース（バイナリ／バイトコードに相当）を入力とし、LLM を中心手法として擬似コード／PoC を自動生成することで、コードの復元と可読化を目的としています。これらはデコンパイルの Core 目的に合致し、LLM 活用が核となっているため include と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3558, "latency_ms": 105221}}
{"key": "Szafraniec2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "we leverage low-level compiler intermediate representations (IR) ... generating programming source code from IR", "explanation": "抽象的にLLVM IRという低水準表現を入力とし、ML（NMT）でソースコードを生成しているため、LLM/MLが核心手法でL1-L3の高水準コードを直接復元していると判断した。"}], "reasoning": "本論文は低水準のLLVM IRを入力として、ニューラル機械翻訳モデルを用いてソースコードを生成するという decompilation 手法を提案している。ML が中心手法であり、目的もコードの復元・可読化にあるため、Core Decompilation（in_core）に該当し、除外基準に該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 3278, "latency_ms": 95735}}
{"key": "Tan2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "LLM4Decompile-End models to decompile binary directly", "explanation": "抽象から、LLM が低水準バイナリを入力として直接高水準ソースコードを生成していることが分かるため、Core Decompilation に該当する。"}, {"code": "in_decompiler_enhancement", "evidence": "refine the decompiled code from Ghidra", "explanation": "既存デコンパイラ（Ghidra）の出力を LLM で更に改善する手法が記載されているため、デコンパイラ改善にも該当する。"}], "reasoning": "この論文はバイナリを入力として LLM を中心に高水準ソースコードを生成し、さらに Ghidra の出力を LLM でリファインして可読性・実行可能性を向上させている。入力が低水準であり、ML/LLM が手法の中核、目的が復元・可読化であることから、Include 基準を満たす Core Decompilation 研究と位置付けられる。", "model": "openai/gpt-oss-120b", "tokens_used": 3306, "latency_ms": 97848}}
{"key": "Tan2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "translate a program's binary code to an Intermediate Representation (IR) as deriving the program's \"skeleton\"", "explanation": "バイナリという低水準入力をLLMベースのモデルでIR（高水準表現）に変換している点から、コアのデコンパイル研究に該当します。"}, {"code": "in_variable_naming", "evidence": "Identifier Naming model to produce meaningful identifiers which reflect actual program semantics", "explanation": "生成されたIRに対して識別子を復元する独立したフェーズがあり、変数・関数名の回復が主要な目的の一つです。"}], "reasoning": "本稿はバイナリを入力とし、LLM/ML を中核手法として用いて高水準のIRや擬似コードを生成し、さらに識別子を復元する二段階のデコンパイル手法を提案しています。入力が低水準であり、復元・可読化が目的で、LLM が中心的に利用されているため、包括的にインクルード対象と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3399, "latency_ms": 99180}}
{"key": "Tan2025", "action": "keep", "reason": "uns_need_fulltext", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_need_fulltext", "evidence": "we introduce Decompile-Bench, the first open-source dataset ...; fine-tuning with Decompile-Bench causes a 20% improvement", "explanation": "要旨だけでは本稿が新たな LLM/ML を用いたデコンパイル手法を提案しているのか、単にベンチマーク提供だけなのか判断できないため、全文で手法の詳細を確認する必要がある"}], "reasoning": "アブストラクトは大規模バイナリ‑ソースペアデータセットの提供と評価実験を述べており、LLM を用いたデコンパイル手法そのものの有無が不明です。デコンパイル生成や改善を目的とした具体的なコア手法が示されていないため、含めるか除外するかを判断できず、全文確認が必要と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3765, "latency_ms": 111751}}
{"key": "Thurnherr2024", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "aim of recovering the RASP code from the compiled model", "explanation": "抽象化されたトランスフォーマー重み（低水準表現）からRASPプログラム（高水準コード）を生成することが目的であり、LLM/ML を中心手法としているため、Core Decompilation に該当します。"}], "reasoning": "この研究は、トランスフォーマーの重みという低レベルの表現から RASP と呼ばれる高レベル言語のコードを再構築することを目的とし、LLM/ML を用いたモデルで実現しています。入力が低水準、出力が高水準コード、復元が主目的と明示されているため、Inclusion 基準を満たします。", "model": "openai/gpt-oss-120b", "tokens_used": 3173, "latency_ms": 94345}}
{"key": "Wan2025", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "training a VLM to decompile raster images into programs composed of Bézier curves", "explanation": "アブストラクトでは入力が「raster images」（画像）と記載されており、バイナリやアセンブリといった本稿の定義上の低水準表現が存在しないため除外基準 EC2 に該当します。"}], "reasoning": "本稿は画像を入力として幾何プログラムを生成するタスクであり、低水準プログラム表現（binary/assembly/bytecode 等）から高水準コードへ変換する \"デコンパイル\" とは定義が合致しません。したがって除外基準「入力が低水準でない」(ex_no_lowlevel_input) に該当し、include できません。", "model": "openai/gpt-oss-120b", "tokens_used": 3116, "latency_ms": 91554}}
{"key": "Wang2023", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we designed a GNN-based model for vulnerability detection", "explanation": "要旨では、低水準バイトコードをデコンパイルして特徴抽出に利用しているが、主目的は脆弱性の検出であり、コードや高水準表現の生成・復元は行っていないため、コード生成・再構築の意図がなく除外基準EC3に該当する"}], "reasoning": "本稿はバイトコードをデコンパイルして得たOpcodeを用いて制御フローグラフを構築し、GNNで脆弱性を分類する手法を提案している。デコンパイルは前処理として利用されているものの、生成・復元する高水準コードは出力されず、目的は分類であるため、除外基準EC3（コード生成・再構築が主目的でない）に該当し除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3142, "latency_ms": 90077}}
{"key": "Wong2023", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "we investigate the feasibility of using LLMs to augment decompiler outputs, thus delivering recompilable decompilation", "explanation": "LLM が中心手法として既存のデコンパイラ出力（C コード）を入力に取り、再コンパイル可能なコードへ改善しているため、Decompilation Enhancement に該当します。"}], "reasoning": "本稿はバイナリから生成された C デコンパイラ出力を LLM で補正し、再コンパイル可能な高水準コードを生成することを目的としている。入力は低水準バイナリに由来するデコンパイル結果であり、LLM が主手法として利用されている点が IC0 を満たす。したがって Core ではなく Decompiler Enhancement に分類され、include と判定します。", "model": "openai/gpt-oss-120b", "tokens_used": 3377, "latency_ms": 96327}}
{"key": "WOS:000396087900059", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "the extraction of patterns through pattern extraction (PE) algorithm from SFS", "explanation": "この記述から本研究は機械学習やLLMを用いていないことが明らかで、EC1に該当するため除外する。"}], "reasoning": "本稿はソフトウェア実行シーケンスから重要関数を抽出する手法を提案しており、デコンパイルやコード生成を目的としていない上に、機械学習・LLM を使用していない。したがって、Decompilation Survey の採択基準を満たさないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3209, "latency_ms": 93496}}
{"key": "WOS:000397194600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "search for patterns in binary code... allows finding patterns not detected with the manual approach.", "explanation": "要旨はバイナリ中のパターン検出・抽出を目的としており、ソースコードや擬似コードの生成・復元は行わないため、コード生成・復元の目的がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿は機械学習を用いたバイナリパターン抽出プラットフォームの構築を報告しており、デコンパイル（低レベル入力から高レベルコード・IR の生成）を目的としていません。したがって、デコンパイルサーベイの対象外となり除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3068, "latency_ms": 92944}}
{"key": "WOS:000399815400003", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "the authors propose ... a cloud-based framework, which employs a systematic method to identify and analyse security threats at API level.", "explanation": "要旨に機械学習や大規模言語モデルの使用は言及されておらず、従来のルールベース手法のみであるため、EC1 に該当し除外と判断しました。"}], "reasoning": "本稿は Android アプリの API レベルでのセキュリティ認証を目的としたフレームワークを提案しており、ML/LLM を用いた手法は示されていません。デコンパイルは入力として既に取得されたコードを利用していますが、復元や高水準表現生成が主目的ではなく、分類・評価が中心です。したがって、除外基準 EC1 に該当し、exclude としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3110, "latency_ms": 89421}}
{"key": "WOS:000403121900083", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "A software program written in Adobe AIR for a desktop platform programmed in ActionScript 3.0", "explanation": "抽象からは機械学習や大規模言語モデルの使用が全く言及されておらず、従来のプログラム実装のみなので、EC1 に該当し除外されます。"}], "reasoning": "本稿はデジタル動画をフレームに分解し、相関係数による滴定終点検出を行う手法を提案していますが、機械学習・LLM の利用は記載されていません。また入力はバイナリやアセンブリといった低水準コードではなく動画データであり、デコンパイルの定義にも合致しません。そのため除外基準 ex_no_ml に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3429, "latency_ms": 96107}}
{"key": "WOS:000412054600026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "focus on ... Android malware detection ... feature selection ... from the decompiled source codes", "explanation": "要旨はマルウェア検出のための特徴選択であり、コード生成や復元・可読化が目的ではないため、復元/生成インテントが欠如していると判断した。"}], "reasoning": "本研究は decompiled source code を特徴抽出の材料として利用し、機械学習による特徴選択とマルウェア検出を行うことが主目的である。デコンパイル自体の復元や高水準コード生成を目指す内容ではなく、コード生成・復元のインテントがないため除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3177, "latency_ms": 94128}}
{"key": "WOS:000415662500002", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "We also present a Genetic algorithm (GA) for the global search approach", "explanation": "本文は遺伝的アルゴリズムを用いているが、LLM や機械学習手法が使用されている記述がなく、ML/LLM が中心手法であることが確認できないため除外と判定した。"}], "reasoning": "本研究は組み込みバイナリの制御構造回復を目的とし、遺伝的アルゴリズムによる探索手法を提案しているが、LLM や機械学習を中核手法として用いていることが示されていない。したがって、Decompilation Survey の包括基準である「ML/LLM が中心手法」である条件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3362, "latency_ms": 105736}}
{"key": "WOS:000419845600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a novel static Android malware detection method which uses LSTM to directly learn from the raw opcode sequences", "explanation": "アブストラクトは LSTM を用いてオペコード列からマルウェアを検出することが目的であり、コードの復元や高水準表現の生成は行わないため、コード生成・復元が目的でないという除外基準 EC3 に該当します。"}], "reasoning": "本論文は低水準オペコード列を入力とし、ML 手法（LSTM）でマルウェア検出を行う分類タスクであり、デコンパイルによる高水準コード生成や復元を目的としていません。そのため、除外基準 EC3（復元・生成が主目的でない）に該当し、exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3218, "latency_ms": 95555}}
{"key": "WOS:000425569100004", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we are working on the problem that: to obfuscate an Android application ... while not substantially \"slowing it down\".", "explanation": "対象は Android アプリの難読化と性能コストの最適化であり、コードの復元・生成を目的としていないため、decompilation のコード生成/復元目的に該当しません。"}], "reasoning": "本稿は Android アプリの難読化手法とその性能影響を評価・最適化する研究であり、低水準バイナリから高水準コードを生成することや既存デコンパイラ出力の改善を目的としていません。したがって、デコンパイル（復元・可読化）に関する目的を満たさないため除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3202, "latency_ms": 93459}}
{"key": "WOS:000428354700001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "takes a stacking ensemble for malware classification", "explanation": "抽象から見て、研究の目的はマルウェアの分類であり、コードやソースの復元・生成を行わないため"}], "reasoning": "本稿はバイナリ画像と IDA で抽出した opcode シーケンスを用いてマルウェア検出・分類を行う手法を提案しており、復元や可読化といったデコンパイル目的ではなく、分類が主目的です。したがって、コード生成・復元を伴わない点で EC3 に該当し、除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3070, "latency_ms": 90805}}
{"key": "WOS:000435804100020", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We evaluate 30 code similarity detection techniques and tools...", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示唆されておらず、従来の評価手法のみであるため。"}, {"code": "ex_no_code_generation", "evidence": "Our experimental results show ... compilation/decompilation as a normalisation technique.", "explanation": "本研究の目的はコード類似度検出器の性能評価であり、コードの生成・復元が主目的ではなく、デコンパイルは正規化手段にすぎない。"}], "reasoning": "本稿はコード類似度解析手法の大規模比較評価を目的としており、デコンパイルは評価プロセスの一部として言及されるだけで、ML/LLM を用いたデコンパイルやコード生成の研究ではない。そのため除外基準 EC1（ML/LLM 未使用）と EC3（コード生成・復元が目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3361, "latency_ms": 95493}}
{"key": "WOS:000448568500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a classifier is trained for the malware detection and classification tasks", "explanation": "アブストラクトでは、デコンパイルしたオペコード列を特徴量として機械学習分類器を訓練し、マルウェアの検出・分類を行うことが目的と述べられており、コードの復元や高水準表現の生成は行われていないため、コード生成・復元を目的としたデコンパイル研究ではないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "opcode sequence decompiled from Android Dalvik Executable files", "explanation": "低水準入力はあるものの、目的がコード復元ではなくマルウェア検出であり、IC条件を満たさないため除外基準に該当する。"}], "reasoning": "本研究はデコンパイルしたバイトコードから特徴を抽出し、マルウェア検出・分類のための機械学習モデルを構築することを目的としている。コードの復元や可読化といったデコンパイルの主目的ではなく、分類タスクに焦点を当てているため、除外基準 EC3 (No Code Generation / Reconstruction Intent) に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3272, "latency_ms": 101637}}
{"key": "WOS:000448653700147", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "This study uses a dynamic analysis method to inspect an executing app", "explanation": "要旨に機械学習や大規模言語モデルの使用が言及されておらず、純粋に動的解析だけが述べられているため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "using comparisons of graph similarities", "explanation": "目的はネットワーク振る舞いの類似度比較による広告ライブラリの信頼性判定であり、コードや高水準表現の復元・生成は行われていないため、コード生成／復元の意図がないと判断した。"}], "reasoning": "本論文は APK のネットワーク振る舞いを動的に解析し、グラフ類似度で広告ライブラリを分類する手法を提案しているが、機械学習・LLM の使用や低水準バイナリから高水準コードへの復元は行っていない。したがって、デコンパイル調査の対象外（除外基準 EC1 および EC3）として除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3487, "latency_ms": 106204}}
{"key": "WOS:000450592600010", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "defect prediction ... is the main purpose ... no code generation ...", "explanation": "抄録ではバイナリから特徴を抽出し欠陥予測モデルを構築することが目的と記載されており、コードの復元や高水準表現の生成は行われていないため、コード生成・復元が主目的である EC3 に該当します。"}], "reasoning": "本研究は Android バイナリ（APK）から smali を用いた特徴抽出と DNN による欠陥予測を行うもので、デコンパイルによるコード復元や可読化が目的ではありません。ML 手法は使用されていますが、出力は予測ラベルであり高水準コード生成とは無関係です。そのため除外基準 EC3（コード生成・復元意図がない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3245, "latency_ms": 95738}}
{"key": "WOS:000459709500083", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "including application binary decompilation", "explanation": "抄録ではバイナリのデコンパイルを実施していると記載されているが、機械学習・大規模言語モデルの使用について言及がなく、EC1に該当するため除外と判断した。"}], "reasoning": "本稿はIoT玩具のセキュリティ・プライバシー分析を目的としており、デコンパイルは分析手法の一部に過ぎない。抽象的にML/LLMが用いられている跡がなく、ICの条件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2907, "latency_ms": 89967}}
{"key": "WOS:000459807600022", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "Our approach learns a probabilistic model from \"Big Code\" and uses this model to predict properties of new, unseen programs.", "explanation": "アブストラクトでは入力が大規模なソースコード（\"Big Code\"）であり、バイナリやアセンブリといった低水準表現が無いことが示されているため、除外基準 EC2 に該当します。"}], "reasoning": "本研究はソースコード（高水準）を入力としてプログラム属性（名前や型）を予測するもので、デコンパイルの定義で求められる低水準入力から高水準コードを復元する目的とは異なる。したがって除外基準 EC2（低水準入力がない）に該当し、include できません。", "model": "openai/gpt-oss-120b", "tokens_used": 3072, "latency_ms": 91504}}
{"key": "WOS:000460845200059", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "using Min Hashing techniques applied to applications' meta-data", "explanation": "概要では機械学習や大規模言語モデルの利用が示されておらず、単にハッシュ手法で類似度を測っているため、ML/LLM を使用していないと判断した。"}], "reasoning": "本稿は Android アプリのメタデータを用いたクローン検出手法を提案しており、低水準バイナリやアセンブリからのコード復元を目的とした decompilation ではない。また、機械学習や LLM を用いる記述がなく、分類／検出が主目的であるため除外基準 (EC1, EC2, EC3) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 2982, "latency_ms": 92337}}
{"key": "WOS:000463843700059", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "target structures immediately decompiled into the constituent building blocks and assembly sequences", "explanation": "アブストラクトは化学的組み立てを扱っており、入力はバイナリやアセンブリなどの低水準コードではなく分子ビルディングブロックであるため、低水準入力が存在しません。"}, {"code": "ex_no_ml", "evidence": "Polycyclic saturated heterocycles ... are assembled by iterative couplings of bifunctional stannyl amine protocol (SnAP) reagents", "explanation": "手法は化学合成手順の記述であり、機械学習・大規模言語モデルの使用は示されていません。"}], "reasoning": "本稿は化学合成に関する研究であり、低水準コードやバイナリを入力としたデコンパイルは対象外です。また、機械学習やLLMを用いた手法も記載されていないため、デコンパイル調査の対象基準を満たさず除外と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3134, "latency_ms": 98462}}
{"key": "WOS:000495504500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "TensorFlow with Keras deep learning model is designed to predict clones in Android applications.", "explanation": "アブストラクトはクローン検出（分類）を目的としており、コードの復元・生成が主目的ではないため除外基準EC3に該当します。"}], "reasoning": "本研究はAndroidアプリのクローン検出を目的とした機械学習分類手法を提案しており、デコンパイルによる高水準コード生成や復元が中心ではありません。デコンパイラは特徴抽出の前処理として使用されているだけで、復元・可読化を目的とした研究ではないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3382, "latency_ms": 103072}}
{"key": "WOS:000497359300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Existing methods based on static decompiling technology to detect SSL security vulnerabilities ... cannot cope with the increasingly common packed applications.", "explanation": "要旨からは機械学習や大規模言語モデルの使用が示されておらず、従来の静的デコンパイルや動的解析手法のみが言及されているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本文は SSL 脆弱性検出のための動的トラバーサル手法を提案しており、機械学習や大規模言語モデルを用いた手法の記述がない。デコンパイルは目的ではなく検出手段の一部にすぎず、ML/LLM が中心手法でないため除外基準 (EC1) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3185, "latency_ms": 93445}}
{"key": "WOS:000508186400109", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "process to automate the decompilation of all the applications on a user's mobile device", "explanation": "本文では自動化されたデコンパイル手法は述べられていますが、機械学習や大規模言語モデルの利用は言及されていないため、ML/LLM が使用されていないと判断しました。"}], "reasoning": "アブストラクトは Android アプリの自動デコンパイルと脆弱性評価に焦点を当てており、ML/LLM を用いた手法については記載がありません。そのため、除外基準 EC1（ML/LLM 不使用）に該当し、include ではなく exclude と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 2950, "latency_ms": 90766}}
{"key": "WOS:000536764600007", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach contains two components: pre-compilation and compile-time virtualization.", "explanation": "要旨に機械学習や大規模言語モデルの使用は記載されておらず、従来のコンパイル/仮想化技術のみが述べられているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本文は Android アプリ向けのコード仮想化手法を提案しており、主目的は難読化・保護であり、逆コンパイルやソース復元を目指すものではない。また、機械学習や大規模言語モデルを手法の中心に用いている記述がないため、除外基準 EC1（ML/LLM 未使用）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3114, "latency_ms": 90475}}
{"key": "WOS:000541153400012", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "use of a decompiled source code for malicious code classification", "explanation": "要旨はデコンパイルしたコードを分類に利用することを目的としており、復元やコード生成が主目的ではないため除外基準EC3に該当します。"}, {"code": "ex_no_lowlevel_input", "evidence": "the proposed methodology decompiles the Android Package Kit files, then ... tokens are extracted", "explanation": "機械学習・LLM が扱う入力はデコンパイル後のソースコードであり、低水準表現（バイナリ等）を直接入力としていないため除外基準EC2に該当します。"}], "reasoning": "本論文はデコンパイルしたAPKのソースコードを特徴抽出に用い、マルウェアの分類・検出を行うことが主目的です。ML/LLM は分類モデルとして使用されており、デコンパイル自体の復元や高水準コード生成を目的としていないため、除外基準EC3（コード生成・復元が目的でない）およびEC2（低水準入力を直接扱わない）に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3604, "latency_ms": 111972}}
{"key": "WOS:000551423500007", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "train a detection model and apply it to classify malware", "explanation": "要旨はバイトコードを画像化してCNNでマルウェアを分類することであり、コードの復元や高水準表現の生成を目的としていないため、コード生成/復元の意図がなく除外基準EC3に該当する。"}], "reasoning": "本稿はバイトコード画像を用いたマルウェア検出を目的とした分類手法であり、デコンパイルによる高水準コードや属性の復元を行わない。したがって、目的が復元・可読化ではなく分類のみであるため、除外基準EC3に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3072, "latency_ms": 96824}}
{"key": "WOS:000557871300009", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a new decompiler called Arlecchino that leverages the diversity of existing decompilers.", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用が言及されておらず、従来の手法でデコンパイラを構築しているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本研究は Java バイトコードからソースコードを生成する新しいデコンパイラを提案しているが、手法に機械学習や大規模言語モデルは含まれない。したがって、Decompilation Survey の包括基準（LLM/ML が中核手法）を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3227, "latency_ms": 97133}}
{"key": "WOS:000565246000013", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "the malicious program can be detected more accurately", "explanation": "アブストラクトは低水準オペコード列からマルウェアを検出することを目的としており、コードの復元や高水準表現の生成は行っていないため、コード生成・復元目的ではないと判断した。"}], "reasoning": "本論文はCNNを用いてデコンパイルされたAndroidファイルのオペコード列からマルウェアを分類・検出することを目的としており、デコンパイルによる高水準コード生成や復元が主目的ではない。したがって除外基準 EC3（コード生成・復元意図がない）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3094, "latency_ms": 95083}}
{"key": "WOS:000569691600001", "action": "keep", "reason": "uns_unclear_input", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_input", "evidence": "... three different tasks ... LaTeX decompilation ...", "explanation": "アブストラクトでは LaTeX decompilation がタスクの一つと記載されているが、入力がバイナリやアセンブリなどの低水準表現であるかは明示されておらず、低水準入力の有無が判断できないため不確かである。"}], "reasoning": "本文はエンコーダ‑デコーダネットワークを用いた汎用的なテキスト処理手法を紹介しており、タスクに LaTeX decompilation が含まれることは示すが、入力が低水準表現かどうかが記載されていない。したがって、デコンパイルのコア要件を満たすか判定できず、現時点では include も exclude もできない。", "model": "openai/gpt-oss-120b", "tokens_used": 3396, "latency_ms": 107068}}
{"key": "WOS:000570595700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a two-phase detection scheme to achieve fast and accurate clone detection", "explanation": "アブストラクトに機械学習や大規模言語モデルの使用は記載されておらず、手法はハッシュやレイアウト木の類似度計算のみであるため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "cloned apps are detected by calculating the similarity between MLTs", "explanation": "目的はクローンアプリの検出であり、コード生成や復元を行うことはなく、類似度計算による分類・検出が主であるため、コード生成・復元の意図がないと判断した。"}], "reasoning": "本稿は Android アプリのクローン検出手法を提案しており、機械学習や LLM を用いたデコンパイルやコード再構成は行わない。入力はアプリの UI レイアウト情報であり、出力は類似度スコアであって高水準コード生成とは無関係であるため、サーベイの対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3433, "latency_ms": 109651}}
{"key": "WOS:000575515300019", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "MadMax combines a smart contract decompiler and semantic queries in Datalog.", "explanation": "要旨ではML/LLMの利用は言及されておらず、静的解析とデコンパイラのみが用いられているため、ML/LLMを利用しない点で除外基準EC1に該当します。"}], "reasoning": "本論文はスマートコントラクトのガス関連脆弱性検出を目的とした静的解析手法を提案しており、ML/LLM を中核手法として使用していません。したがって、除外基準EC1（No ML/LLM）に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3198, "latency_ms": 99361}}
{"key": "WOS:000582272700012", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_ml", "evidence": "Reditus is based on the observation that an engineering software has a built-in decompiler that can transform the control logic into its source-code.", "explanation": "本文は既存の組み込みデコンパイラを利用しており、機械学習や大規模言語モデルの使用について言及がなく、EC1 に該当するため除外と判断した。"}], "reasoning": "本稿は低水準バイナリからソースコードへの復元を目的としているが、手法の中核として機械学習・LLM を使用している記述がない。したがって、Include Criteria の IC0 を満たさず、Exclude Criteria の ex_no_ml に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3057, "latency_ms": 94004}}
{"key": "WOS:000589187000048", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "A set of free or inexpensive tools was used to retrieve and disassemble the monitor's onboard software.", "explanation": "本文中に機械学習や大規模言語モデルの使用が明記されておらず、従来のツールと手作業による逆コンパイルのみであるため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本稿は BIS モニタのハードウェアからソフトウェアを取得し、手動で逆アセンブル・逆コンパイルする手法を紹介しているが、機械学習や大規模言語モデルを中心手法として用いていない。したがって、Decompilation Survey の採択基準 (IC0) を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3350, "latency_ms": 97137}}
{"key": "WOS:000592654700001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "k‑core decomposition and multilevel community detection from the data connectedness", "explanation": "要旨はデータネットワークの解析であり、バイナリやアセンブリといった低水準コード入力は示されていないため、デコンパイルの対象外です。"}, {"code": "ex_no_ml", "evidence": "applying the social network analysis by R packages", "explanation": "使用されているのは R パッケージによるグラフ分析であり、LLM／機械学習を中心手法として用いた記述がないため除外基準に該当します。"}], "reasoning": "本稿は中国の配車プラットフォームにおけるデータ接続性を社会ネットワーク分析で評価しているだけで、低水準コード（バイナリ等）を入力として高水準コードを生成するデコンパイル研究ではなく、ML/LLM を使用した手法も示されていません。そのため、除外基準（低水準入力なし、ML未使用）に該当し、除外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3374, "latency_ms": 105786}}
{"key": "WOS:000597138700009", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "deep learning model ... to detect cloned apps", "explanation": "本稿の主目的はクローン検出（分類）であり、コードや高水準表現の生成・復元は行わないため、コード生成・復元志向の除外基準 EC3 に該当します。"}], "reasoning": "本論文は Android アプリのクローン検出を目的としたディープラーニング手法を提案しており、デコンパイルは特徴抽出の前処理として利用されているだけです。復元・可読化などの高水準コード生成が主目的ではなく、分類タスクであるため、除外基準 EC3（コード生成・復元が主目的でない）に該当し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3238, "latency_ms": 101129}}
{"key": "WOS:000602074600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "perform classification", "explanation": "アブストラクトはマルウェアの分類を目的としており、コードの復元や高水準表現の生成は行わないため"}, {"code": "ex_no_ml", "evidence": "shallow neural network-based malware classifier (SNNMAC)", "explanation": "ML は分類モデルとして使用されているが、デコンパイルの目的ではなく分類が主目的であるため除外基準に該当"}], "reasoning": "本稿はバイナリから n‑gram を抽出し、浅層ニューラルネットワークでマルウェアを分類することに焦点を当てている。デコンパイルによる高水準コード生成や復元は目的に含まれず、分類・検知が主目的であるため、除外基準 EC3（コード生成・復元意図がない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3189, "latency_ms": 100820}}
{"key": "WOS:000604998900011", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "relies on the artificial neural network (ANN) to model the nonlinear mapping between design parameters and visual cognitive image (VCI) values", "explanation": "入力はデザインパラメータであり、バイナリやアセンブリといった低水準表現が示されていないため、除外基準 EC2 に該当する"}], "reasoning": "本稿はバティック模様の生成手法を提案しており、低水準コードやバイナリを入力として高水準コードを復元することを目的としていない。抽象的に「decompile」という語が使われているものの、デコンパイルの定義に合致しないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3311, "latency_ms": 103471}}
{"key": "WOS:000606730100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "RNN is designed to predict potential cloned applications", "explanation": "本文はクローンアプリケーションの検出・分類が主目的であり、コードの復元・可読化といったデコンパイル目的のコード生成は行っていないため除外する。"}], "reasoning": "本稿は Android アプリのクローン検出を目的としており、低水準バイナリからのコード復元自体は前処理的に JDEX デコンパイラを用いるだけで、ML 手法はクローン判別の分類器として使用されている。デコンパイルによる高水準コード生成や再構成が主目的でないため、EC3 に該当し除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3288, "latency_ms": 103429}}
{"key": "WOS:000611120200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Thus the detection and classification of malicious apps can be realized.", "explanation": "アブストラクトはマルウェア検出と分類が目的であり、コードの復元・生成は行わないため、除外基準 EC3 に該当します。"}], "reasoning": "本研究は decompiled Android アプリから関数呼び出しグラフを生成し、深層グラフ畳み込みネットワークでマルウェア検出を行うことを目的としている。デコンパイルによる高水準コードの復元や可読化は目指しておらず、コード生成・再構成の意図がないため、除外基準 EC3（コード生成・再構成意図がない）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3459, "latency_ms": 113020}}
{"key": "WOS:000618528800004", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "The pipeline is based on IFCL, an intermediate firewall language equipped with a formal semantics, and it is implemented in an open source tool called FWS.", "explanation": "要旨からは機械学習や大規模言語モデルの使用は示されておらず、従って本サーベイのML/LLM が中核手法という条件を満たさないため除外と判断した。"}], "reasoning": "本文はファイアウォール設定のデコンパイルと解析に焦点を当てているが、機械学習やLLM の手法は言及されていない。デコンパイルの定義自体は満たす可能性があるものの、IC0 の「LLM/ML が中核手法として使われている」要件を欠くため、除外基準 EC1 (ex_no_ml) に該当し除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3313, "latency_ms": 101125}}
{"key": "WOS:000632639400003", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The model classifies an unknown application as benign or malicious based on the log likelihood score generated.", "explanation": "本文はデコンパイルして得た API 情報を特徴量としてマルウェア検出・分類を行うことが主目的であり、コードやソースの生成・復元は目的に含まれていないため、コード生成・再構築意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿は Android アプリをデコンパイルして API 列を抽出し、Profile HMM によるマルウェア検出・分類を行う手法を提案しています。デコンパイルは前処理であり、最終目的は高水準コードの復元ではなくマルウェア判定であるため、デコンパイル・コード生成を主目的とする基準を満たさず除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3307, "latency_ms": 109645}}
{"key": "WOS:000649389100006", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a control flow‑based feature extraction dynamic programming algorithm", "explanation": "要旨に機械学習や大規模言語モデルの使用は記載されておらず、純粋にアルゴリズム手法のみであるためML/LLMが使われていないと判断しました。"}, {"code": "ex_no_code_generation", "evidence": "method has the ability to detect malicious code", "explanation": "本研究の目的はマルウェア検出という分類であり、コードの復元・生成が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本論文は低水準コードから特徴を抽出しマルウェアを検出することを目的としており、機械学習やLLMは用いられていません。また、出力はコードそのものの復元や高水準表現ではなく、検出用の特徴ベクトルであり、デコンパイルの主目的から外れます。したがって除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3227, "latency_ms": 107888}}
{"key": "WOS:000658941200001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a new Android malware identification approach based on malicious subgraph mining", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及されておらず、単なるサブグラフマイニング手法と記載されているため、ML/LLM が中心手法であるという条件を満たさないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "function call graphs (FCGs), sensitive permissions, and application programming interfaces (APIs) are generated from the decompiled files of malware", "explanation": "生成されるのはグラフや特徴量であり、復元・可読化を目的としたコード（L1-L4）の生成ではなく、検出・分類が主目的であるためコード生成目的の条件を満たさない。"}], "reasoning": "本論文はマルウェア検出のための構造的特徴抽出手法を提案しており、ML/LLM を用いたデコンパイルやコード復元は行っていない。低水準入力は使用しているものの、目的が復元・可読化ではなく分類であり、除外基準 (EC1, EC3) に該当するため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3190, "latency_ms": 104305}}
{"key": "WOS:000672841700001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_core", "evidence": "converts low-level PL into high-level PL", "explanation": "低水準コード（binary/assembly）から高水準コードを直接生成しているので、Core Decompilation に該当します。"}, {"code": "in_core", "evidence": "attention-based neural machine translation (NMT) mechanism", "explanation": "LLM/ML（NMT）が手法の中核として用いられているため、IC0 の条件を満たします。"}], "reasoning": "本論文はバイナリやアセンブリといった低水準入力を、注意機構を備えたニューラル機械翻訳モデルで高水準言語へ変換し、可読性と機能的類似性を保つことを目的としています。ML 手法が中心であり、コード生成・復元が主目的であるため、Include の Core Decompilation (in_core) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3236, "latency_ms": 103883}}
{"key": "WOS:000685203900086", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "harnessing SMT solvers", "explanation": "本文ではMLやLLMの利用は言及されておらず、SMTソルバーのみが手法として挙げられているため、ML/LLMが中核でないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "decompiles bytecode programs into an intermediate representation and then implements the modularity checking using SMT queries", "explanation": "デコンパイルは解析用のIR生成に留まり、コードの復元や可読化といった生成目的が示されていないため、コード生成・復元が主目的ではないと判断した。"}], "reasoning": "本論文はスマートコントラクトのモジュラリティ検証を目的とした静的解析手法を提案しており、ML/LLMは使用されていない。デコンパイルは内部表現への変換に過ぎず、復元・可読化といったデコンパイルの主要目的や高水準コード生成が主たる貢献ではないため、除外基準 EC1 と EC3 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3500, "latency_ms": 112093}}
{"key": "WOS:000691101100002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "uses the deep learning network for classification and discrimination", "explanation": "本文はマルウェア検出という分類タスクが目的であり、コードの復元・再構築を行うことが主目的ではないため、コード生成・復元が目的とされるEC3に該当する"}], "reasoning": "本稿はAPKをデコンパイルして特徴を抽出し、深層学習でマルウェアか否かを分類する手法を提案している。デコンパイルは前処理に過ぎず、出力は高水準コードやASTではなく分類ラベルである。デコンパイル自体を復元・可読化の目的としないため、除外基準EC3（コード生成・復元目的でない）に該当し、excludeと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3234, "latency_ms": 105746}}
{"key": "WOS:000695854600007", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "provides the stochastic generation of large amounts of standard C code", "explanation": "論文は低水準バイナリから高水準コードを復元することを目的としておらず、主目的はCコードの大量自動生成であるため、復元・可読化目的のデコンパイル研究とはみなされません。"}, {"code": "ex_no_ml", "evidence": "a Python application that provides the stochastic generation", "explanation": "手法は確率的生成であり、LLM/ML が中心手法として示されていないため、除外基準 EC1 に該当します。"}], "reasoning": "本稿はバイナリやアセンブリを入力として高水準コードを生成するデコンパイル研究ではなく、標準Cコードを大量に自動生成するツールの紹介です。LLM/ML が主要手法として示されていない上に、復元・可読化が目的ではないため、インクルード基準を満たさず除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3389, "latency_ms": 113473}}
{"key": "WOS:000709490700009", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Finally, convolution neural network is used to classify the fused samples.", "explanation": "要旨は融合した特徴をCNNで分類することが主目的であり、コードの生成や復元は行っていないため、コード生成/再構成が目的でないことが明らかです。"}], "reasoning": "本研究はマルウェアの分類を目的としており、低水準のASMやバイト列から特徴を抽出しCNNで分類する手法を提案しています。デコンパイルによる高水準コードの生成や復元を目的としていないため、除外基準EC3（コード生成・再構成が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3051, "latency_ms": 103468}}
{"key": "WOS:000712025300005", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "malware classification method ... learning the IR Sequence ... using deep learning model for sequence learning", "explanation": "要旨はバイナリをIRに変換し、そのIRを用いてマルウェアを分類することが目的であり、コードの復元や高水準表現の生成は行っていないため、除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリリフティングで得た IR をマルウェア分類に利用する研究であり、デコンパイルによるコード復元や可読化を目的としていません。ML は使用されていますが、主目的が分類であるため除外基準 ex_no_code_generation に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3056, "latency_ms": 103874}}
{"key": "WOS:000737527800001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to improve the performance of Android malware detection ... use Random Forest to build a malware detection model", "explanation": "要旨はマルウェア検出モデルの構築と性能向上であり、コードの生成・復元を目的としていないため、decompilation のコード生成・再構築目的に該当しません。"}, {"code": "ex_no_lowlevel_input", "evidence": "features that cannot be obtained through decompilation", "explanation": "入力は低水準のバイナリやアセンブリではなく、逆コンパイルで取得できない特徴量であり、低水準入力が前提となっていません。"}], "reasoning": "本稿は Android マルウェア検出のためのクラス不均衡学習手法を提案しており、主目的は分類・検出でありコード生成や高水準表現の復元は行っていません。また、入力は低水準バイナリではなく抽象的な特徴量であるため、decompilation の定義要件を満たさないと判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3292, "latency_ms": 109649}}
{"key": "WOS:000748533600001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "reverse engineering techniques-specifically decompilation", "explanation": "抄録ではデコンパイルは言及されるものの、機械学習や大規模言語モデルの使用は示されておらず、EC1（ML/LLM未使用）に該当するため除外します。"}], "reasoning": "本稿はFlash作品の移行にデコンパイルを利用した手法を論じていますが、手法の中心に機械学習やLLMが用いられている記述がありません。従って、Decompilation SurveyのInclude Criteriaを満たさず、Exclude Criteriaの ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3007, "latency_ms": 101928}}
{"key": "WOS:000771288000001", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Many IoT devices can be disassembled for decompilation, resulting in the theft of sensitive data.", "explanation": "本稿はデコンパイル手法やLLM/MLの利用を対象としておらず、物理的な改ざん検知システムの提案であり、デコンパイルの範囲外です。"}], "reasoning": "アブストラクトはIoT機器の物理的な改ざん検知システムを提案しており、デコンパイルや機械学習・大規模言語モデルの使用に関する記述がないため、除外基準の「範囲外 (ex_out_of_scope)」に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3080, "latency_ms": 103177}}
{"key": "WOS:000790329300013", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.85, "reason_codes": [{"code": "ex_no_ml", "evidence": "employing several high-precision techniques and making them scalable", "explanation": "アブストラクトでは機械学習やLLMの利用が言及されておらず、静的解析技術のみが述べられているため、ML/LLMが手法の中核でないと判断した。"}], "reasoning": "本稿はEthereumスマートコントラクトのデコンパイラであり、低水準バイトコードを入力として高精度な静的解析手法を用いているが、機械学習や大規模言語モデルの利用が示されていない。したがって、Decompilation Surveyの採択基準で求められるML/LLM中心の手法を満たさないため除外とした。", "model": "openai/gpt-oss-120b", "tokens_used": 3289, "latency_ms": 106644}}
{"key": "WOS:000798201400013", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The Stacked-Long Short-Term Memory (S-LSTM) deep learning model is designed to predict possible clones.", "explanation": "抽象から見て、研究の主目的はクローン検出という分類タスクであり、コードの復元や生成は行わないため除外基準 EC3 に該当します。"}], "reasoning": "本論文は Android アプリのクローン検出を目的とした分類手法を提案しており、デコンパイルによるコード生成や復元は主目的ではありません。したがって、コード生成・復元を伴わないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3163, "latency_ms": 106386}}
{"key": "WOS:000804579300001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "long short term memory based electro search optimization (LSTM-ESO) is employed to detect the unknown mobile applications as benign or malicious", "explanation": "本文は LSTM を用いたマルウェア検出（分類）を目的としており、コード生成や復元は行わないため、デコンパイルの主要目的である「復元・可読化」には該当しません。"}], "reasoning": "本稿は Android アプリを Androguard で逆アセンブルし特徴を抽出した上で、ML（LSTM）を用いてマルウェアか否かを分類する研究です。目的がコードの復元や可読化ではなく分類であるため、Decompilation Survey のインクルード基準を満たさず、除外基準 EC3（コード生成・復元が主目的でない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3240, "latency_ms": 107960}}
{"key": "WOS:000838998100001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_ml", "evidence": "we used a BERT ... pretrained model for malware detection was constructed.", "explanation": "抄録では decompilation の工程は従来の逆アセンブル/逆コンパイル手法で行われ、そこに ML/LLM が用いられた記述がなく、ML が中心手法となっているのは検出モデルのみであるため、decompilation に ML が使用されていないと判断した。"}], "reasoning": "本論文はマルウェア変種データセットの構築と BERT を用いた検出手法が主目的であり、decompilation はデータ生成の前処理として従来手法で実施されている。LLM/ML が decompilation に本質的に使われていないため、インクルード基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3383, "latency_ms": 113315}}
{"key": "WOS:000849409500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "machine learning classification algorithms are used to classify the malicious and benign applications", "explanation": "アブストラクトはマルウェア検出のために分類器を用いることを目的としており、コードの復元・生成や高水準表現の出力を行う目的がないため、除外基準 EC3 に該当します。"}], "reasoning": "本稿は Android アプリを画像化しテクスチャ特徴を抽出して機械学習でマルウェアか否かを判定する手法を提案しており、デコンパイルによるコード復元や高水準表現生成は目的としていません。したがって、デコンパイル調査の対象外（コード生成・復元が主目的でない）となり除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3247, "latency_ms": 109421}}
{"key": "WOS:000849434800002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "deep neural network automatically obtains the RGB image texture features to realize the multiple classifications of the Android malware family", "explanation": "抽象からはコード生成や高水準表現の復元ではなく、マルウェアファミリの分類が目的と分かるため、コード生成/再構成意図がないと判断した。"}], "reasoning": "本論文は Android APK から DEX や XML を画像化し、ディープラーニングでマルウェアのマルチクラス分類を行うことが目的であり、デコンパイルやソースコード・擬似コードの復元を行わない。したがって、デコンパイルを目的とした LLM/ML 手法の使用がなく、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3309, "latency_ms": 106245}}
{"key": "WOS:000864735500003", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "and of the decompiled documentation of the General Archive of the Nation", "explanation": "この記述は文献の「デコンパイル」について言及しているが、機械学習やLLMの使用は示されておらず、EC1（ML/LLM未使用）に該当する。"}], "reasoning": "アブストラクトは歴史的文献の分析を対象としており、機械学習や大規模言語モデルを用いたデコンパイル手法についての記述が全くない。したがって、本サーベイの対象外であると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3060, "latency_ms": 104670}}
{"key": "WOS:000867635500021", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "introduces a Bigdata assisted energy conversion model (BD-ECM) and evaluates a decomposition approach to solve the initial problem recursively", "explanation": "本稿はエネルギー変換モデルとビッグデータによる最適化手法を扱っており、バイナリやアセンブリからのコード復元とは無関係であり、デコンパイルの範囲外です"}], "reasoning": "アブストラクトはエネルギー変換システムのモデル化とビッグデータ手法に関するもので、低水準コードやML/LLMを用いたコード復元に関する記述が全くないため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3065, "latency_ms": 103076}}
{"key": "WOS:000870301800008", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "our learned labeling model can be combined with an existing decompilation tool, Ghidra, to achieve substantially improved performance in function call recovery", "explanation": "ML により生成したラベリングモデルを既存デコンパイラ(Ghidra)に組み合わせて関数呼び出しの復元精度を向上させている点が、デコンパイラ出力の改善（enhancement）に該当するため"}, {"code": "in_core", "evidence": "supervised learning approach to the problem of recovering optimized function calls", "explanation": "低水準バイナリから関数呼び出し情報という高水準属性を直接推測しており、コアなデコンパイルタスクに該当するため"}], "reasoning": "本研究はバイナリという低レベル入力から関数呼び出し情報を機械学習で復元し、既存デコンパイラの出力を改善することを目的としている。ML 手法が中心に用いられ、復元・可読化というデコンパイル目的が明示されているため、スクリーニング基準の Include 条件を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3574, "latency_ms": 117184}}
{"key": "WOS:000873911200001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "The DGA data is first mapped to a high-dimensional space.", "explanation": "アブストラクトは入力として低水準バイナリやアセンブリではなく、変圧器のDGA（ガス分析）データを扱っているため、デコンパイルの対象となる低水準入力が存在しません。"}], "reasoning": "本稿は変圧器の故障診断を目的とし、SSA‑MDS と Random Forest で DGA データを前処理・分類する手法を提案しています。入力は低水準バイナリやアセンブリではなく高レベルの計測データであり、コードの復元・可読化を目指すデコンパイル研究の範囲外です。そのため除外基準 EC2（低水準入力なし）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3223, "latency_ms": 107885}}
{"key": "WOS:000875660200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "propose a Control-Flow Graph ... based malware classification system", "explanation": "要旨はCFGとGNNを用いたマルウェアの分類であり、コードの生成や復元を目的としていないため、コード生成/復元の意図がないと判断した"}], "reasoning": "本稿は低水準バイナリからCFGを抽出し、LLM（MiniLM）でベクトル化して分類器でマルウェア検出を行う研究であり、デコンパイルによる高水準コードの復元や可読化が目的ではない。したがって除外基準EC3（コード生成・復元意図なし）に該当し、exclude と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3348, "latency_ms": 110907}}
{"key": "WOS:000885209600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we propose a new method ... to distinguish malicious applications from benign applications.", "explanation": "要旨は権限情報とAPI呼び出しシーケンスを用いたマルウェア検出であり、コードの復元や生成は目的としていないため、コード生成/復元の意図がなく除外基準 EC3 に該当する。"}], "reasoning": "本稿はデコンパイルツールを特徴抽出に利用しているものの、主目的はマルウェアの分類・検知であり、低水準コードから高水準コードを生成することではない。したがって、デコンパイルの復元・生成を目的とした研究には該当せず、除外基準 EC3 (No Code Generation / Reconstruction Intent) に基づき除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3253, "latency_ms": 107604}}
{"key": "WOS:000900131300002", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "BiLSTM-attention neural network is used to extract ... generate more robust vulnerability patterns to detect vulnerabilities.", "explanation": "要旨から、ML はバイナリの脆弱性パターン検出（分類）に用いられ、コードの復元や高水準表現の生成が目的ではないため除外基準 EC3 に該当する。"}], "reasoning": "本研究は decompilation を脆弱性検出の前処理として利用し、主目的はバイナリの脆弱性パターン分類である。復元・可読化・高水準コード生成といった decompilation の目的が示されていないため、除外基準 EC3（コード生成・復元意図がない）に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3340, "latency_ms": 111216}}
{"key": "WOS:000935184700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Decompilers are indispensable tools in Android malware analysis and app security auditing.", "explanation": "要旨からは機械学習や大規模言語モデルを用いた手法に関する記述がなく、従来のデコンパイラの性能評価のみが述べられているため、ML/LLMが使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "we have performed ... a large‑scale study of Android decompilation failure rates", "explanation": "目的はデコンパイルの失敗率や原因の調査であり、コード生成や復元そのものを行うことが主目的ではないため、コード生成/復元を目的とした研究ではないと判断した。"}], "reasoning": "本稿は既存のAndroidデコンパイラ（Jadx など）の性能を大規模に測定・分析する実証研究であり、機械学習やLLMを手法の中心に据えていない。したがって、Decompilation Survey Screening Rules の除外基準 EC1（ML/LLM 未使用）と EC3（コード生成・復元が主目的でない）に該当し、include には該当しない。", "model": "openai/gpt-oss-120b", "tokens_used": 3220, "latency_ms": 106677}}
{"key": "WOS:000970588900012", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "We focus on the variable renaming problem using one such machine learning model, DIRE.", "explanation": "要旨は変数・関数名の復元を目的としており、変数名という高水準属性（L4）を予測することが主目的であるため、in_variable_naming が適切です。"}, {"code": "in_decompiler_enhancement", "evidence": "State-of-the-art techniques use machine learning to predict missing information like variable names.", "explanation": "既存のデコンパイラが出すコードに対し、ML が変数名を付与して可読性を向上させる手法であり、デコンパイラ出力の改善に該当します。"}], "reasoning": "本稿はバイナリからデコンパイルされたコードを入力とし、機械学習モデル（LLM/ML）を用いて変数名や関数名を自動的に付与することでコードの可読性を向上させることを目的としている。入力はデコンパイル済みの低水準表現（バイナリ由来）であり、出力は高水準属性（変数名）であるため、Decompilation Survey のインクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3882, "latency_ms": 124882}}
{"key": "WOS:000976384800001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "we propose a malware detection method ... we first decompile the Android application to generate a function call graph (FCG)", "explanation": "アブストラクトでは、デコンパイルはマルウェア検出のための特徴抽出（関数呼び出しグラフ生成）の前処理としてのみ言及されており、復元・可読化・高水準コード生成といったデコンパイルの目的は示されていないため、コード生成/復元の意図がなく除外基準EC3に該当します。"}], "reasoning": "本稿はデコンパイルをマルウェア検出のためのグラフ生成ステップとして利用しており、LLM/MLは検出モデル（GCN）に使用されているが、デコンパイル自体の復元・可読化を目的としていない。したがって、コード生成や高水準表現の復元を主目的としないため除外基準EC3に該当し、excludeと判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3114, "latency_ms": 107138}}
{"key": "WOS:000985293800001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "This paper aims to detect vulnerabilities via the Bug Injection framework and transfer learning techniques.", "explanation": "目的が脆弱性検出であり、コード生成や復元が主目的ではないため、EC3 に該当し除外します。"}], "reasoning": "本文は低水準コードを入力に取りますが、最終目的はスマートコントラクトの脆弱性検出という分類タスクであり、デコンパイルによる高水準コード生成や復元を行う研究ではありません。したがって、コード生成・復元意図がなく除外基準 EC3 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3317, "latency_ms": 109020}}
{"key": "WOS:000991628700004", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "we improve an existing decompilation tool by leveraging the characteristics of JNI programs", "explanation": "抽象では機械学習や大規模言語モデルの使用が言及されておらず、手法は従来のデコンパイラ改善に留まるため、EC1 に該当し除外されます。"}], "reasoning": "本論文はバイナリをデコンパイルして JNI プログラムを解析する手法を提案していますが、LLM や機械学習を用いる旨の記述がなく、ルールベースまたは手作業の改善にとどまっています。そのため、Include Criteria を満たさず Exclude Criteria の「No ML/LLM (ex_no_ml)」に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3111, "latency_ms": 107353}}
{"key": "WOS:000995629300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a novel privacy protection algorithm based on chunking disorder.", "explanation": "要旨に機械学習／LLMの利用は言及されておらず、従ってML/LLMが使用されていないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "Our algorithm exchanges data within a specific range of chunk size for the position...", "explanation": "入力はデータのチャンク化・暗号化であり、バイナリやアセンブリ等の低水準コード入力ではないため除外基準に該当する。"}], "reasoning": "本稿はデータプライバシー保護アルゴリズムの提案であり、機械学習やLLMを用いたコードの復元・生成とは無関係である。低水準プログラム表現を入力としたデコンパイル目的も示されていないため、除外基準 (ex_no_ml, ex_no_lowlevel_input) を適用して除外した。", "model": "openai/gpt-oss-120b", "tokens_used": 3263, "latency_ms": 112516}}
{"key": "WOS:000998081700001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "mine the syntactic information of more than 17 million syntactic constructs in Java code", "explanation": "要旨はJavaのソースコード（高水準）から構文情報を抽出・分析しており、低水準バイナリやアセンブリが入力ではないため除外基準EC2に該当する。"}, {"code": "ex_no_code_generation", "evidence": "documenting recurrent syntactic constructs, analyzing the particular constructs used by experts and beginners", "explanation": "目的は構文パターンの分析・可視化であり、コードの復元・生成（decompilation）を目指すものではないため除外基準EC3にも該当する。"}], "reasoning": "本研究はJavaソースコードを対象に機械学習で構文パターンを分析するもので、バイナリやアセンブリといった低水準入力から高水準コードを生成するデコンパイルは行っていない。したがって、Decompilation Survey の採択基準を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3292, "latency_ms": 113554}}
{"key": "WOS:000998226600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "A 1-D convolutional neural network and fully connected layers are used for further feature extraction and classification", "explanation": "本文はデコンパイルやコード復元ではなく、GCN を用いたマルウェア検出・分類が主目的であるため、コード生成・復元が意図されていないと判断した。"}], "reasoning": "本稿はデコンパイルした APK から抽出した関数呼び出しグラフを特徴量として利用し、GCN でマルウェア検出を行うことに焦点を当てている。目的は復元や可読化ではなく分類であり、LLM/ML がデコンパイル自体を支援する手法ではないため除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3455, "latency_ms": 114731}}
{"key": "WOS:001005701900019", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "hardware loop rerolling leverages clone detection and program synthesis techniques", "explanation": "要旨はクローン検出とプログラム合成を用いると述べており、機械学習や大規模言語モデルの使用は示唆されていないため、EC1 に該当し除外と判断した。"}], "reasoning": "本稿はハードウェアデコンパイルの一部としてループ再構築手法を提案しているが、ML/LLM を中心手法として使用している記述がなく、EC1（ML/LLM 未使用）に該当するため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3237, "latency_ms": 111939}}
{"key": "WOS:001027789500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "we decompiled and analysed 420 open-source applications by extending an existing tool", "explanation": "要旨では機械学習や大規模言語モデルの使用について言及されておらず、単に既存ツールを拡張してデコンパイルと静的解析を行っているため、ML/LLM が用いられていないと判断した。"}], "reasoning": "本論文はデコンパイルしたコードを用いたエネルギーパターン検出を目的としており、ML/LLM を中心手法として使用していない。したがって Exclude Criteria の EC1 (No ML/LLM) に該当し、除外とする。", "model": "openai/gpt-oss-120b", "tokens_used": 3313, "latency_ms": 108177}}
{"key": "WOS:001038327600001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "non-invasive ... does not infringe licenses and terms of use of applications", "explanation": "要旨では低水準バイナリやアセンブリを入力とせず、ライセンス違反とならない特徴取得手法を用いると明示しているため、デコンパイルの入力条件を満たさない。"}, {"code": "ex_no_code_generation", "evidence": "propose an approach to detect Android malware ... classification ... more efficient process to classify applications", "explanation": "研究の目的はマルウェア検出・分類であり、コードの復元や擬似コード生成などの出力は行わないのでコード生成・復元の目的を満たさない。"}], "reasoning": "本論文は低水準コードから高水準表現を生成することや既存デコンパイラ出力の改善を目的としておらず、むしろデコンパイルを回避した非侵襲的なマルウェア検出手法を提案している。したがって、Decompilation Surveyの採択基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3456, "latency_ms": 117817}}
{"key": "WOS:001070689400010", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose BiAn, a source code level smart contract obfuscation method", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、従来の手法とみなせるため"}, {"code": "ex_no_lowlevel_input", "evidence": "source code level smart contract obfuscation method", "explanation": "入力はソースコードレベルであり、バイナリやアセンブリといった低水準表現が使用されていないため"}], "reasoning": "本稿はスマートコントラクトのソースコードを対象とした難読化手法を提案しており、低水準表現から高水準コードを復元することを目的としていません。また、機械学習や大規模言語モデルを中心手法として用いている記述がなく、デコンパイル調査の対象外です。", "model": "openai/gpt-oss-120b", "tokens_used": 3165, "latency_ms": 113357}}
{"key": "WOS:001094893100006", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "A novel program code obfuscation approach involving the x86 mode switching is proposed...", "explanation": "要旨では機械学習や大規模言語モデルの使用は言及されておらず、純粋にオブファスケーション手法を提案しているため、ML/LLM が中心手法であるという条件を満たさない"}], "reasoning": "本稿は x86 モードスイッチングを用いたコード難読化手法を紹介し、リバースエンジニアリングツールへの影響を評価していますが、機械学習・LLM を利用したデコンパイルやコード復元に関する研究ではありません。そのため、Include 基準の ML/LLM 使用要件を満たさず、除外基準 ex_no_ml に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2909, "latency_ms": 108069}}
{"key": "WOS:001102195500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "a new method for Android ransomware classification was proposed. This method implements a Convolutional Neural Network (CNN) for malware classification", "explanation": "要旨はマルウェアの分類が目的であり、コードの復元や高水準表現の生成を行うことが明示されていないため、コード生成・再構成が主目的ではないという除外基準 EC3 に該当します。"}], "reasoning": "本論文は APK を画像化し CNN でランサムウェアを分類する手法を提案しており、デコンパイルや高水準コードの復元を目的としていません。したがって、Decompilation Survey の対象外となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3159, "latency_ms": 110935}}
{"key": "WOS:001119002600001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "These methods face two main challenges... To overcome these challenges, we propose a new method called multiple features (MulFC) based on unsupervised learning.", "explanation": "目的はマルウェアのクラスタリング・分類であり、コードの復元や高水準表現の生成は行っていないため、コード生成・復元の意図がないと判断した。"}, {"code": "ex_out_of_scope", "evidence": "we first leverage a decompiling tool to extract multiple features, including ... opcode features.", "explanation": "デコンパイルは特徴抽出の手段としてのみ用いられ、デコンパイル自体の改善や高水準コード生成が主目的ではないため、デコンパイル調査の範囲外と判断した。"}], "reasoning": "本論文はマルウェアのファミリーをクラスタリングすることを主目的としており、デコンパイルは単なる特徴抽出の手段に過ぎない。復元・可読化・高水準コード生成といったデコンパイルの目的がなく、コード生成・再構築の意図が認められないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3409, "latency_ms": 116325}}
{"key": "WOS:001136012000001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The proposed method implements a convolutional neural network for malware classification using images.", "explanation": "アブストラクトはマルウェアの分類が目的であり、コードの生成や復元を行うことは示されていないため、コード生成・再構築が目的でないという除外基準EC3に該当します。"}], "reasoning": "本論文はAndroidアプリのAPKを画像化しCNNでマルウェア分類を行う手法を提案しており、目的は分類タスクです。デコンパイルによる高水準コードの復元や生成を目指すものではなく、コード生成・再構築の意図が示されていないため除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3287, "latency_ms": 117165}}
{"key": "WOS:001166549700001", "action": "remove", "reason": "ex_out_of_scope", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_out_of_scope", "evidence": "Lipids in food components were decompiled by an analysis of the maximum common substructures.", "explanation": "「decompiled」は化学構造の解析を指しており、プログラムのバイナリから高水準コードを生成するデコンパイルとは無関係です。"}, {"code": "ex_no_ml", "evidence": "The approach to food components addressed in this study is a public database with more than 70,000 compounds, including those predicted via omics techniques.", "explanation": "要約に機械学習や大規模言語モデルの使用は示されておらず、従来の化学情報学手法のみが述べられています。"}], "reasoning": "本稿は食品化学物質の化学空間分析であり、プログラムコードの復元や逆コンパイルを目的としていません。さらに、機械学習／LLM の利用も明示されていないため、デコンパイル調査の対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3250, "latency_ms": 113049}}
{"key": "WOS:001174314700019", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "method for preprocessing ... for subsequent detection of their similarity using machine learning methods", "explanation": "目的はバイナリ断片の類似性検出であり、コードの復元・生成ではなく分類・検出が主目的であるため、コード生成/復元の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリからデコンパイルされた疑似コードを機械学習で解析し、機能的類似性を検出する手法を提案しています。復元や可読化といった高水準コード生成が目的ではなく、類似性判定が主目的であるため、デコンパイルのコア目的から外れます。そのため除外基準 EC3（コード生成・復元意図なし）に該当し、exclude と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3077, "latency_ms": 113475}}
{"key": "WOS:001191292200001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_core", "evidence": "to decompile, code and compile analogue computations... By decompiling the reservoir's internal representation and dynamics into an analytic basis of its inputs, we define a low-level neural machine code", "explanation": "低水準のニューラルマシンコード（内部表現）を入力とし、RNN（機械学習）を用いて高水準のコードやプログラムを直接生成しているため、Core Decompilation に該当する"}], "reasoning": "本文は低水準の内部表現（ニューラルマシンコード）を入力に取り、リカレントニューラルネットワークという機械学習手法でそれを高水準のコードへ変換・コンパイルすることを目的としている。目的が復元・可読化であり、LLM/ML が中心手法なので、インクルード基準を満たす。", "model": "openai/gpt-oss-120b", "tokens_used": 3382, "latency_ms": 117141}}
{"key": "WOS:001208845200025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our approach is based on automated program transformation to manipulate Java bytecode...", "explanation": "本文ではプログラム変換による保護手法を述べており、機械学習や大規模言語モデルの利用は言及されていないため、ML/LLM が用いられていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "We propose a novel approach to protect Java bytecode from malicious debugging.", "explanation": "目的はデバッグ攻撃の防止であり、バイナリやバイトコードから高水準コードを生成・復元すること（コード生成・再構築）ではないため、コード生成/復元の意図がないと判断した。"}], "reasoning": "この論文は Java バイトコードのデバッグ保護を目的とした変換手法を提案しており、機械学習やLLM を用いたデコンパイルやコード生成は行っていない。入力はバイトコードであるが、出力は保護された実行可能形態であり、復元・可読化を目的とした高水準表現の生成が主目的ではないため、除外基準 EC1 と EC3 に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3410, "latency_ms": 116116}}
{"key": "WOS:001209927600050", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.96, "reason_codes": [{"code": "ex_no_ml", "evidence": "We conduct the study by investigating 333 unique bugs from three popular Java decompilers.", "explanation": "アブストラクトでは機械学習・LLM の利用について言及されておらず、従来の手法でバグ調査を行っているため、ML/LLM が使用されていないと判断した。"}, {"code": "ex_no_code_generation", "evidence": "Based on these findings, we present JD-Tester, a differential testing framework for Java decompilers...", "explanation": "本研究の目的はデコンパイルのバグ検出・評価であり、低水準入力から高水準コードを生成すること（コード生成・復元）が主目的ではないため除外基準に該当する。"}], "reasoning": "本文は Java デコンパイラのバグ調査とテストフレームワークの提示に焦点を当てており、ML/LLM を用いたデコンパイル生成や復元手法を提案していない。したがって、Decompilation Survey の包括基準を満たさず除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3478, "latency_ms": 114949}}
{"key": "WOS:001217002000001", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_variable_naming", "evidence": "suggest descriptive variable names for decompiled code", "explanation": "要旨は SMT を用いてデコンパイル済みコードの変数名を復元することなので、変数/関数命名の回復が主目的であると判断した。"}, {"code": "in_decompiler_enhancement", "evidence": "improving original variable names ... suggestions ... viewed as improvements", "explanation": "既存のデコンパイラ出力（変数名が失われたコード）に対し、ML 手法で命名を改善しているため、デコンパイラ出力の強化に該当する。"}], "reasoning": "本論文は統計的機械翻訳（ML 手法）を用いてデコンパイルされたコードの変数名を自動提案し、復元精度を評価している。入力はデコンパイル結果という低水準表現で、目的は変数名の回復・改善であり、デコンパイル支援の周辺研究として評価基準を満たすため include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3752, "latency_ms": 123346}}
{"key": "WOS:001237837300001", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This article offers a thorough examination and organized summary of the pertinent material of smart contract security analysis.", "explanation": "要旨はスマートコントラクトのセキュリティに関する包括的な調査・要約であり、実装手法や実験結果を示す研究ではなく、レビュー論文であるため除外基準 EC4 に該当します。"}], "reasoning": "本稿はスマートコントラクトのセキュリティに関するサーベイであり、LLM/ML を用いたデコンパイル手法の提案や評価を行っていない。したがって、除外基準の「Survey/Review」に該当し、インクルード対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 2969, "latency_ms": 107063}}
{"key": "WOS:001247013900001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We carried out both a dynamic and a static analysis of decompiled Locker.CB!tr ransomware source code", "explanation": "抄録では機械学習や大規模言語モデルの使用について言及されておらず、従来の動的・静的解析手法のみが述べられているため、ML/LLM を用いた研究ではないと判断した。"}], "reasoning": "本稿はランサムウェアの通信パターンを利用した復旧手法を提案しており、デコンパイル自体は既に行われたコードの解析に留まる。手法の中心に機械学習・LLM がないため、除外基準 EC1（ex_no_ml）に該当し、インクルード対象外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3082, "latency_ms": 108906}}
{"key": "WOS:001256552500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.94, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "establishing a ... methodology for machine learning classification models... detects malware but also classifies its variants", "explanation": "要旨はバイナリからIRオペコードシーケンスを抽出し、統計的特徴でマシンラーニング分類を行うことに焦点を当てており、コードやソースの復元・生成は目的としていないため除外基準 EC3 に該当する。"}], "reasoning": "本研究はバイナリリフティングと opcode エントロピーを用いた特徴抽出で、マルウェア検出・変種分類を行うことが主目的です。デコンパイルや高水準コードの生成・再構成を目指すものではなく、コード復元に関する目的や出力がないため、除外基準 (ex_no_code_generation) に該当し除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3065, "latency_ms": 112665}}
{"key": "WOS:001263763900001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "enhances classifier performance through adversarial training", "explanation": "アブストラクトは分類器の性能向上とマルウェア変種生成を目的としており、コードの復元・生成は行わないため、デコンパイルの目的を満たさない"}], "reasoning": "本稿はAndroidマルウェアの変種生成と分類を中心にした研究であり、低水準バイナリから高水準コードを生成することが目的ではなく、分類タスクに焦点を当てている。したがって、デコンパイル（復元・可読化）に該当せず、除外基準 EC3（コード生成・復元が主目的でない）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3193, "latency_ms": 113386}}
{"key": "WOS:001320166600005", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "implemented in C++ as a part of a decompilation program", "explanation": "アブストラクトは手法がC++で実装されたグラフアルゴリズムであると述べており、機械学習・LLMの使用は言及されていないため、除外基準EC1に該当します。"}], "reasoning": "本論文はトランジスタレベル回路から論理ゲート階層へのデコンパイルを目指すが、手法は純粋なグラフアルゴリズムであり機械学習や大規模言語モデルの利用が示されていない。したがって、Decompilation Surveyの採択基準で必須とされるML/LLMの使用がなく、除外基準EC1に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2968, "latency_ms": 111219}}
{"key": "WOS:001322090400005", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "we propose a simulation execution based code extraction method", "explanation": "アブストラクトではML/LLMを用いる旨の記述がなく、シミュレーション実行に基づくコード抽出とヒューリスティック解析のみが述べられているため、機械学習手法が使用されていないと判断した。"}], "reasoning": "本稿はPLCの制御ロジックを抽出するフレームワークを提案しているが、手法はシミュレーション実行やヒューリスティックデータフロー解析といった非機械学習アプローチであり、LLM/MLが中心手法として用いられていない。したがって、除外基準 EC1（No ML/LLM）に該当し、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3124, "latency_ms": 112265}}
{"key": "WOS:001332656400001", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.86, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "refine decompilation outputs at the intermediate representation level", "explanation": "既存のデコンパイラが生成した中間表現(IR)を入力とし、LLMベースのシーケンス‑ツー‑シーケンスモデルで可読性とコンパイル可能性を向上させているため、デコンパイラ出力の改善研究に該当する。"}], "reasoning": "本論文は、LLM/ML を用いて既存デコンパイラが出力した IR を入力とし、可読性やコンパイル可能性を向上させる手法を提案している。低水準入力（バイナリから生成された IR）と高水準出力（改善された IR）を扱い、目的が復元・可読化である点が採択基準を満たす。従って Core ではなく Decompiler Enhancement に分類し、include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3491, "latency_ms": 120922}}
{"key": "WOS:001336094300001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.87, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "fingerprint reused functions, within stripped binaries, ...", "explanation": "要旨は関数の指紋付けによる類似性検出が目的であり、コードの生成や復元を行う記述がなく、復元・可読化が主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿は低レベルバイナリから関数指紋を生成し、再利用検出を目的とした研究であり、LLM/ML を用いたコード生成やデコンパイルは行っていません。そのためデコンパイルの復元・可読化という目的を満たさず、除外基準 EC3（コード生成/再構築の意図がない）に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 2959, "latency_ms": 113314}}
{"key": "WOS:001350308700001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "Static taint analysis is a widely used method to identify vulnerabilities in Android applications.", "explanation": "要旨に機械学習やLLMの利用について言及がなく、従来の静的解析手法のみが述べられているため、ML/LLMが使用されていないと判断した。"}], "reasoning": "本論文は Android アプリの静的汚染分析手法を提案しており、ML/LLM を用いたデコンパイルは主要な技術ではない。入力はバイナリを Jimple に変換するが、目的はコード復元ではなく脆弱性検出であり、除外基準 EC1 (No ML/LLM) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3196, "latency_ms": 111408}}
{"key": "WOS:001368390400002", "action": "keep", "reason": "uns_unclear_method", "details": {"decision": "uncertain", "confidence": 0.55, "reason_codes": [{"code": "uns_unclear_method", "evidence": "This article proposes the REMaQE automated framework for reverse engineering of math equations from binary executables.", "explanation": "要旨からはフレームワークが自動化されていることは分かりますが、LLMや機械学習を使用している旨の記述がなく、手法が不明です。"}], "reasoning": "入力がバイナリであり、出力が数式という高水準表現であるため、decompilation の目的は満たしています。しかし、抽象だけでは LLM/ML を中心手法として用いているか判断できず、除外基準や採択基準を満たすか判定できません。そのため、情報不足として uncertain としました。", "model": "openai/gpt-oss-120b", "tokens_used": 3276, "latency_ms": 115961}}
{"key": "WOS:001377798100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "LLM chatbots can help security analysts in their work, but point out specific limitations and security concerns related to this approach.", "explanation": "本文はLLMを分析支援・レポート作成に用いることを目的としており、バイナリやアセンブリから高水準コードを生成・復元することは行わないため、コード生成・復元の意図がなく除外基準EC3に該当します。"}], "reasoning": "本稿はLLMを用いたサイバーセキュリティ分析支援を検討しており、デコンパイル（低水準入力から高水準コードを生成）を目的としていない。そのため、コード生成・復元が主目的でないという除外基準EC3に該当し、インクルード対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3105, "latency_ms": 113665}}
{"key": "WOS:001397990500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a low complexity decompression method for commercial FPGA bitstreams", "explanation": "要旨には機械学習や大規模言語モデルの使用が言及されておらず、従ってML/LLMが手法の中核でないため除外されます。"}], "reasoning": "本研究は FPGA ビットストリームの圧縮解除手法を提案しており、デコンパイル（低水準バイナリから高水準コードへの復元）とは目的が異なります。また、要旨に機械学習やLLMの利用が示されていないため、調査対象外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3133, "latency_ms": 114997}}
{"key": "WOS:001403092200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "aims to bridge the gap ... provide a standardized similarity measurement across three code similarity detection tasks", "explanation": "アブストラクトはコードの類似性測定が主目的であり、復元や高水準コード生成を行うことは述べていないため、コード生成・復元を目的としたデコンパイルではないと判断した。"}], "reasoning": "本論文はバイナリとソースコードの類似性測定を目的としており、復元・可読化・高水準コード生成といったデコンパイルの主目的が記載されていない。したがって除外基準 EC3（コード生成・復元を目的としない）に該当し、exclude と判断する。", "model": "openai/gpt-oss-120b", "tokens_used": 3334, "latency_ms": 115523}}
{"key": "WOS:001420041900001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "VARLIFTER interprets every read or written field of a data region as at least one potential variable...", "explanation": "抄録に機械学習や大規模言語モデルの使用が言及されておらず、手法は静的解析的な解釈に基づくため、EC1 に該当し除外する"}], "reasoning": "本稿は Solidity バイトコードから変数と型を復元する手法を提案していますが、手法の記述は静的解析に基づくものであり、ML/LLM の利用が示されていません。したがって、Decompilation Survey の採択基準である「ML/LLM を中核手法として使用」要件を満たさず、除外基準 EC1 に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3412, "latency_ms": 117673}}
{"key": "WOS:001429826200001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Our approach involves decompiling .NET executables, parsing the resulting code, and extracting standard .NET method names.", "explanation": "要旨は抽出したメソッド名を用いたマルウェア検出であり、復元・コード生成・可読化が目的ではないため、コード生成・再構築の意図がないと判断した。"}], "reasoning": "本稿は .NET 実行ファイルをデコンパイルしメソッド名を抽出してマルウェア検出を行う手法を提案しているが、主目的は分類であり、デコンパイルによる高水準コードの再構成や可読化は行っていない。そのため、デコンパイルを核心目的とする本サーベイの包含基準を満たさず除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3305, "latency_ms": 117301}}
{"key": "WOS:001448323100001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "introduces a novel malware detection approach utilizing an ensemble of Convolutional Neural Networks (CNNs) for enhanced classification accuracy", "explanation": "本文の目的はマルウェアの分類・検出であり、コード生成や復元を行うことが主目的ではないため、除外基準 EC3 に該当します。"}], "reasoning": "本稿は低レベルバイナリを画像化し CNN でマルウェアを分類する手法を提案しており、デコンパイルによる高水準コード生成や復元は目的としていません。したがって、コード生成・復元を主目的としない点で除外基準 (ex_no_code_generation) に該当します。", "model": "openai/gpt-oss-120b", "tokens_used": 3171, "latency_ms": 112545}}
{"key": "WOS:001450844300001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "Finally, training and evaluating the ability to detect Android malware ... a final classification will determine the safety of the tested application", "explanation": "要旨はマルウェア検出・分類が主目的であり、デコンパイルで生成したコードは解析材料にすぎず、コード生成や復元は行っていないため"}], "reasoning": "本稿はAPKをデコンパイルして得たソースコードから特徴を抽出し、機械学習でマルウェアか否かを分類することが主目的です。デコンパイルは前処理として使用されており、LLM/ML がデコンパイル自体や高水準コード生成に用いられているわけではありません。したがって、復元・可読化を目的としたデコンパイル研究ではないため除外とします。", "model": "openai/gpt-oss-120b", "tokens_used": 3472, "latency_ms": 115835}}
{"key": "WOS:001470367300014", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "CF-GKAT is able to soundly and completely verify trace equivalence of a larger class of programs...", "explanation": "抄録に機械学習や大規模言語モデルの利用についての記述が全くなく、従来の形式手法のみを用いているため、EC1 の『ML/LLM を用いていない』に該当します。"}], "reasoning": "本稿は制御フロー変換の検証手法を形式的に提案しており、ML/LLM を用いたデコンパイル手法ではありません。したがって除外基準 EC1（ex_no_ml）に該当し、インクルードの対象外と判断します。", "model": "openai/gpt-oss-120b", "tokens_used": 3196, "latency_ms": 115410}}
{"key": "WOS:001488140900040", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.9, "reason_codes": [{"code": "ex_no_ml", "evidence": "creates a patched binary using source- and binary-level techniques", "explanation": "要旨では機械学習や大規模言語モデルの利用について言及されておらず、代わりに従来のソース・バイナリレベル手法を用いると記述されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿はバイナリ関数をソースレベルにデコンパイルし、パッチ適用後に再コンパイルする手法を提案しているが、機械学習や大規模言語モデルを中心手法として用いている記述がなく、従来の解析・修正技術に依存している。したがって、Decompilation Survey のインクルード基準（LLM/ML の使用）を満たさないと判断し、除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 3372, "latency_ms": 116270}}
{"key": "WOS:001498227900001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "the existing static methods mainly rely on taint analysis", "explanation": "アブストラクトでは機械学習や大規模言語モデルの利用が全く言及されておらず、手法は主にタイント解析とファズングに基づくため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本研究は IoT デバイス向けの新しい指向型ファズング手法を提案しており、デコンパイルコードを利用した解析は行うものの、ML/LLM を中心技術として使用していない。したがって、Decompilation Survey の採択基準である「LLM/ML が中核手法である」条件を満たさないため、除外と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3266, "latency_ms": 117322}}
{"key": "WOS:001503249300001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "Our method utilizes the Ghidra decompiler in conjunction with a custom-built transpiler to reconstruct highlevel C++ source code from binary executables.", "explanation": "要約では機械学習や大規模言語モデルの使用が全く言及されておらず、従来のデコンパイラと独自のトランスパイラだけが使用されているため、EC1の「ML/LLM を用いていない」に該当します。"}], "reasoning": "本稿はバイナリをデコンパイルして高レベルソースを生成し、グラフ分析でマッチングを行う手法を提案していますが、手法の中心に機械学習や大規模言語モデルは含まれていません。したがって、Decompilation Survey Screening Rules の除外基準 EC1 に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3265, "latency_ms": 115208}}
{"key": "WOS:001517603500001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "to accurately identify compiler versions using compiled executable files", "explanation": "目的がコンパイラバージョンの分類であり、コードの復元や生成を行うことが主目的ではないため、EC3 に該当します。"}], "reasoning": "本稿はバイナリからアセンブリへ逆コンパイルした後、特徴抽出と SVM による分類を行いコンパイラバージョンを特定することを目的としている。復元・可読化といったコード生成・再構成が目的ではなく、分類タスクであるため除外基準 EC3（コード生成・復元意図がない）に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3471, "latency_ms": 120903}}
{"key": "WOS:001539888300001", "action": "remove", "reason": "ex_no_lowlevel_input", "details": {"decision": "exclude", "confidence": 0.86, "reason_codes": [{"code": "ex_no_lowlevel_input", "evidence": "migrating legacy C and C++ code to Python", "explanation": "要旨は既存のC/C++ソースコードを対象としており、バイナリやアセンブリなどの低水準入力が明示されていないため、除外基準 EC2 に該当します。"}], "reasoning": "本論文は LLM を用いたソースコード間の翻訳（C/C++→Python）に焦点を当てており、入力が低水準表現（バイナリ・アセンブリ等）であることが示されていません。そのため、デコンパイルのコア対象外と判断し、除外しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3437, "latency_ms": 121544}}
{"key": "WOS:001551990000001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We propose a defense model integrating blockchain, zero-knowledge proofs, and smart contract (SC) obfuscation", "explanation": "アブストラクトからは機械学習や大規模言語モデルの利用が全く言及されておらず、手法はブロックチェーン・ゼロ知識証明・オブフュスケーションに限定されているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本稿は産業制御システムに対する防御モデルの提案であり、ML/LLM を用いたデコンパイル技術の生成・改善が目的ではない。抽象的に「Obfuscated SCs resist decompilation」とは述べているものの、デコンパイル自体を行う研究ではなく、逆にデコンパイルを阻止することが中心であるため、スクリーニング基準の除外項目 (No ML/LLM) に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3267, "latency_ms": 117506}}
{"key": "WOS:001556094500001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "implementing sophisticated algorithms for control-flow recovery, stack frame recovery, data type inference, decompilation etc.", "explanation": "抽象からは機械学習・LLM の利用が示されておらず、従来のアルゴリズムによる手法のみが語られているため、ML/LLM 不使用と判断した。"}], "reasoning": "本論文はバイナリからコンパイルユニットを推定する手法を提案しているが、手法の中心が機械学習や大規模言語モデルではなく、従来のアルゴリズム的アプローチと記述されている。したがって、Decompilation Survey の採択基準 (IC0) を満たさず、除外基準 EC1 に該当すると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3403, "latency_ms": 116793}}
{"key": "WOS:001560856600001", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_ml", "evidence": "using ultrasound-assisted hydrothermal cracking to produce platelet nanofibers", "explanation": "要旨に機械学習や大規模言語モデルの使用が記載されておらず、物理・化学的手法のみが述べられているため、ML/LLM が中核手法であるという条件を満たさないと判断した。"}, {"code": "ex_no_lowlevel_input", "evidence": "we developed an aramid-fiber decompilation/reconstruction process", "explanation": "「decompilation/reconstruction」は材料加工プロセスを指すだけで、バイナリやアセンブリ等の低水準コード入力は示されていないため、入力が低水準表現でないと判断した。"}], "reasoning": "本文は材料工学に関する研究であり、ソフトウェアのデコンパイル（低レベルコードから高レベルコードへの変換）とは無関係です。機械学習や大規模言語モデルは使用されておらず、入力も低水準プログラム表現ではないため、サーベイの対象外と判定しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3457, "latency_ms": 120249}}
{"key": "WOS:001561843400001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.88, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "proposes ... hybrid malware detection model", "explanation": "論文の目的はマルウェア検出であり、コードの復元や生成は主目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本稿はバイナリやオペコードを用いたマルウェア検出手法を提案しており、デコンパイルや高水準コード生成を行うことが目的ではありません。したがって、デコンパイル調査の対象外と判断し除外します。", "model": "openai/gpt-oss-120b", "tokens_used": 3240, "latency_ms": 116141}}
{"key": "WOS:001566975200005", "action": "remove", "reason": "ex_survey_or_meta", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_survey_or_meta", "evidence": "This survey provides an extensive evaluation of recent AI-based reverse engineering techniques...", "explanation": "アブストラクトがサーベイであることを明示しており、オリジナルのML/LLMを用いたデコンパイル研究ではないため除外基準EC4に該当します。"}], "reasoning": "本文はAIを用いたリバースエンジニアリング全般の調査・レビューであり、デコンパイル手法そのものの提案や実装を行っていないため、本サーベイの採択対象外です。", "model": "openai/gpt-oss-120b", "tokens_used": 3020, "latency_ms": 115502}}
{"key": "WOS:001571912000001", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "ensemble detection model combines Random Forest, Decision Tree, and Bagging classifiers", "explanation": "本文はマルウェア検出のための分類モデルを構築することが主目的であり、コードの復元や生成を行わないため、コード生成・復元の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本稿はAndroidアプリの静的特徴を抽出し、機械学習によるマルウェア検出モデルを構築することに焦点を当てている。デコンパイル自体は入力前処理として利用されているものの、低水準バイナリから高水準コードを生成・復元する目的ではないため、除外基準 ex_no_code_generation に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3281, "latency_ms": 117850}}
{"key": "WOS:001597451300043", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "high-performance and reliable tracing and traceability ... for ... source code exceptions and routine detection", "explanation": "アブストラクトはコードの復元や生成ではなく、ソースコードの検出・追跡を目的としているため、デコンパイルのコード生成目的を満たさない。"}, {"code": "ex_no_lowlevel_input", "evidence": "Addressing the detection blind spots in existing source code analysis techniques", "explanation": "入力として低水準バイナリやアセンブリではなく、ソースコード解析を対象としていることが示唆される。"}], "reasoning": "本論文はブロックチェーンを用いたICSコンポーネントの検出フレームワークを提案しており、デコンパイルによる高水準コード生成や復元を目的としていない。入力は主にソースコードであり、低水準バイナリからの変換は行わない。また、ML手法はクラスタリングによるサンプリングに留まり、デコンパイルの核心手法とは無関係であるため、除外基準 EC3 と EC2 に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3765, "latency_ms": 126511}}
{"key": "WOS:001616881300004", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.93, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "The MalSFF employs six different classifiers, with optimized hyperparameters using an automated grid-search algorithm.", "explanation": "本文はマルウェア検出・分類が主目的であり、コードやソースの復元・生成を行わないため、除外基準EC3に該当します。"}], "reasoning": "本稿はバイナリを逆コンパイルして画像化し、機械学習でマルウェアを分類することを目的としているため、復元・可読化といったデコンパイルの主要目的を持ちません。したがって、コード生成/再構成が目的でない点で除外基準 EC3 に該当し、除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3367, "latency_ms": 120128}}
{"key": "WOS:001623665300001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.88, "reason_codes": [{"code": "in_core", "evidence": "end-to-end decompilation method based on large language models (LLMs)", "explanation": "LLM が低水準コード（assembly）から直接高水準言語を生成する手法であり、復元・可読化が目的なので Core Decompilation に該当する"}, {"code": "in_type_recovery", "evidence": "The Function Call strategy infers variable types and retrieves missing variable information from binary files.", "explanation": "変数型の推論が主要なサブタスクとして記述されており、型回復研究としても該当する"}], "reasoning": "本稿は LLM を中心手法とし、バイナリ／アセンブリといった低水準入力から高水準コードを生成するエンドツーエンドのデコンパイル手法を提案しているため Core Decompilation に該当する。また、関数呼び出し戦略で型推論を行う点から Type Recovery 研究でもある。したがって include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3180, "latency_ms": 118698}}
{"key": "WOS:001631663000010", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "labels each instruction as Inlined or Not inlined and recovers the inlined-function boundaries", "explanation": "アブストラクトは命令をインラインか非インラインか分類し境界を復元すると述べており、コードや高水準表現の生成・復元が目的ではないため除外基準 EC3 に該当します。"}], "reasoning": "本研究はバイナリ命令レベルでインライン関数を検出することに焦点を当てており、出力はバイナリ予測ラベルであり高水準コードやAST等の生成を行わない。したがってデコンパイルの直接的な出力を提供しないため、除外基準 EC3（コード生成・再構築が主目的でない）に基づき除外と判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3774, "latency_ms": 127544}}
{"key": "WOS:001639031400025", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "enhances decompiler output by combining static analysis (SA) and large language models (LLM)", "explanation": "LLM を用いて既存のデコンパイラ出力を改善する手法であるため、IC2 の Decompiler Enhancement に該当します。"}, {"code": "in_type_recovery", "evidence": "precision of 90.40% ... for variable types", "explanation": "変数型の回復精度を評価しており、型回復が主要な改善項目の一つであることが示されています。"}, {"code": "in_control_structure", "evidence": "precision of 91.32% ... for function boundaries", "explanation": "関数境界（制御構造）の復元精度を報告しており、制御構造の回復が目的の一部となっています。"}], "reasoning": "本稿は Solidity バイトコードから生成されたデコンパイラ出力を、静的解析で得た依存グラフと LLM により意味的に再構成し、可読性・型情報・契約属性を向上させることを目的としている。入力は低水準のバイトコードで、LLM が中心手法として使用され、コード生成・復元が主要目的であるため、Include 基準を満たし、Decompiler Enhancement として採択します。", "model": "openai/gpt-oss-120b", "tokens_used": 3703, "latency_ms": 126318}}
{"key": "WOS:001641511700015", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "producing detailed and interpretable Android malware analysis reports", "explanation": "アブストラクトはLLMを用いてマルウェア分析レポート（自然言語テキスト）を生成することが目的であり、コードやソースの復元・生成は行っていないため、復元・生成を目的としたデコンパイルではなく除外基準EC3に該当します。"}], "reasoning": "本稿はLLMでマルウェア分析レポートを生成することに焦点を当てており、低水準コードから高水準ソースコードや擬似コードを生成する目的ではない。そのためデコンパイルの核心目的（コード復元・生成）を満たさず、除外基準EC3（コード生成・復元意図がない）に該当すると判断しました。", "model": "openai/gpt-oss-120b", "tokens_used": 3308, "latency_ms": 120978}}
{"key": "WOS:001657340000001", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.93, "reason_codes": [{"code": "in_core", "evidence": "binary decompilation model based on fine-tuned large language models designed to generate high-precision decompiled code", "explanation": "LLM を中心手法として、バイナリ（低水準入力）から直接コンパイル可能なソースコードを生成している点が Core Decompilation に該当するため"}, {"code": "in_decompiler_enhancement", "evidence": "compilation success rate, functional correctness", "explanation": "生成されたコードがコンパイル可能かつ機能的に正しいことを評価している点が、デコンパイル出力の品質向上を目的としているため"}], "reasoning": "本稿はバイナリを入力とし、LLM を用いて高品質なソースコード（L1）を直接生成する手法を提案している。デコンパイルの復元・可読化が主目的であり、ML 手法が中核にあるため Inclusion 判定となる。", "model": "openai/gpt-oss-120b", "tokens_used": 3326, "latency_ms": 120158}}
{"key": "WOS:001662944300026", "action": "remove", "reason": "ex_no_code_generation", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_code_generation", "evidence": "identify and classify cryptographic functions in source code and decompiled firmware", "explanation": "抄録は低水準バイナリから関数を検出・分類し脆弱性を検出することが目的であり、ソースコードや擬似コードを生成・復元することは示されていないため、コード生成・復元の意図がなく除外基準 EC3 に該当します。"}], "reasoning": "本論文はカスタム暗号関数の検出と脆弱性診断を目的としており、LLM/ML は分類器や属性生成に用いられていますが、低水準入力から高水準コードや擬似コードを生成するデコンパイル目的ではありません。そのため、コード生成・復元が主目的でないことから除外対象となります。", "model": "openai/gpt-oss-120b", "tokens_used": 3308, "latency_ms": 121387}}
{"key": "Wu2023", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.78, "reason_codes": [{"code": "in_core", "evidence": "even decompiling assembly code", "explanation": "アブストラクトが、LLM（ChatGPT）を用いてアセンブリ（低水準入力）からコードを生成（高水準出力）し、復元を目的としていることを示しているため、Core Decompilation に該当すると判断した。"}], "reasoning": "本稿は、ChatGPT（LLM）を低水準のアセンブリ入力に適用し、ソースコードを生成することでデコンパイルを評価している。入力が低水準表現であり、LLM が中心手法として用いられ、復元・可読化を目的としているため、Decompilation Survey の Core カテゴリに含めるべきであると判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3686, "latency_ms": 128773}}
{"key": "Wu2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.92, "reason_codes": [{"code": "ex_no_ml", "evidence": "We presented a novel framework for empirically evaluating C-based decompilers", "explanation": "アブストラクトではML/LLMの使用が言及されておらず、評価フレームワークの提示のみなので、ML/LLM が手法の中核であるという条件を満たさないため除外と判断した。"}], "reasoning": "本論文はWebAssembly バイナリからのデコンパイル結果を評価する比較研究であり、LLM/ML を用いた高水準コード生成やデコンパイラ改善を提案していない。したがって、除外基準 EC1（No ML/LLM）に該当する。", "model": "openai/gpt-oss-120b", "tokens_used": 3156, "latency_ms": 120230}}
{"key": "Xie2025", "action": "keep", "reason": "in_core", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_core", "evidence": "genetic programming-based decompiler framework for reverse-engineering high-level quantum algorithms from low-level circuit representations", "explanation": "低水準な量子回路表現（量子アセンブリ）を入力とし、遺伝的プログラミングという機械学習手法で高水準の Qiskit アルゴリズムコードを直接生成しているため、Core Decompilation に該当します。"}], "reasoning": "本研究は低水準の量子回路（量子アセンブリ）を入力とし、遺伝的プログラミングという機械学習手法を用いて高水準の Qiskit ソースコードを生成することを目的としています。目的がコードの復元・可読化であり、ML が中心手法である点から、Decompilation Survey の inclusion 基準を満たします。", "model": "openai/gpt-oss-120b", "tokens_used": 3198, "latency_ms": 120651}}
{"key": "Xu2024", "action": "keep", "reason": "in_variable_naming", "details": {"decision": "include", "confidence": 0.95, "reason_codes": [{"code": "in_variable_naming", "evidence": "recover variable names from stripped binary", "explanation": "アブストラクトはバイナリから変数名を復元することを目的としており、LLM を用いた変数/関数名の回復が主目的であるため、in_variable_naming が最も具体的なコードです"}, {"code": "in_decompiler_enhancement", "evidence": "We build a prototype, GenNm, from pre-trained generative models ... fine‑tune GenNm on decompiled functions", "explanation": "既存のデコンパイル結果（関数）を入力にし、LLM で名前付けを改善しているので、デコンパイラ出力の強化にも該当します"}], "reasoning": "本稿は低水準のバイナリ（stripped binary）を入力とし、LLM を中核手法として変数名を復元する手法を提案している。目的はデコンパイルの可読化・意味回復であり、変数名回復という具体的なタスクに焦点を当てているため、in_variable_naming を主コードとし、既存デコンパイラ出力の改善という点で in_decompiler_enhancement も補助コードとして付加した。したがって、スクリーニング基準の Include Criteria を満たすため include と判断した。", "model": "openai/gpt-oss-120b", "tokens_used": 3444, "latency_ms": 124372}}
{"key": "You2024", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "primarily relying on two convenient context managers for its core functionality", "explanation": "本文中に機械学習や大規模言語モデルを使用したことが記載されておらず、手法はコンテキストマネージャに依存しているため、ML/LLM が使われていないと判断した。"}], "reasoning": "本稿は PyTorch のバイトコードをソースコードに戻すデコンパイラツールを紹介しているが、手法として機械学習や大規模言語モデルは用いられていない。従って、Decompilation Survey の採択基準である LLM/ML を中核とした研究には該当せず、除外基準 EC1（No ML/LLM）により除外と判定した。", "model": "openai/gpt-oss-120b", "tokens_used": 3131, "latency_ms": 118820}}
{"key": "Zhang2026", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "make use of on-the-fly symbolic techniques via SAT solvers", "explanation": "要旨では機械学習・LLMの利用が言及されておらず、SAT ソルバーによるシンボリック手法のみが使用されているため、ML/LLM が中心手法であるという条件を満たさないと判断した。"}], "reasoning": "本論文は GKAT オートマトンのトレース等価性判定アルゴリズムを提案しており、低水準バイナリやアセンブリから高水準コードを生成するデコンパイルとは無関係である。また、手法は SAT ソルバーを用いたシンボリック解析であり、機械学習や大規模言語モデルは使用していないため、採択基準を満たさない。", "model": "openai/gpt-oss-120b", "tokens_used": 3077, "latency_ms": 119927}}
{"key": "Zhou2025", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "FidelityGPT, a framework that enhances decompiled code accuracy and readability by systematically detecting and correcting semantic distortions.", "explanation": "LLM（RAG）を用いて既存のデコンパイル出力を改善することが主目的であるため、Decompilation Enhancement に該当する。"}, {"code": "ex_no_ml", "evidence": "", "explanation": ""}], "reasoning": "本稿は機械コードからのデコンパイル出力を入力とし、LLM を中心にした手法でコードの歪みを検出・修正して可読性と意味的正確性を向上させる研究である。低水準入力（機械コード）と LLM/RAG の使用が明示されており、復元・可読化が目的であるため、Include 基準を満たし、Core のうち Decompiler Enhancement に分類できる。", "model": "openai/gpt-oss-120b", "tokens_used": 3417, "latency_ms": 124189}}
{"key": "Zhou2025", "action": "remove", "reason": "ex_no_ml", "details": {"decision": "exclude", "confidence": 0.95, "reason_codes": [{"code": "ex_no_ml", "evidence": "We conduct a benchmark-driven evaluation of decompilation quality across core Rust features and compiler build modes.", "explanation": "要旨に機械学習や大規模言語モデルを利用した旨が記載されておらず、従来のデコンパイラ評価のみを行っているため、ML/LLM が使用されていないと判断した。"}], "reasoning": "本文は Rust バイナリのデコンパイル品質を評価する実証研究であり、ML/LLM を用いた手法の提示がない。したがって、Decompilation Survey の採択基準で必須となる「LLM/ML が中核手法として使われている」条件を満たさないため除外する。", "model": "openai/gpt-oss-120b", "tokens_used": 2994, "latency_ms": 119281}}
{"key": "Zou2025", "action": "keep", "reason": "in_decompiler_enhancement", "details": {"decision": "include", "confidence": 0.92, "reason_codes": [{"code": "in_decompiler_enhancement", "evidence": "LLMs to refine decompiler output", "explanation": "LLM が既存のデコンパイラ出力（バイナリから生成されたコード）を入力として可読性や正確性を改善しているため、デコンパイラ強化に該当します。"}], "reasoning": "本研究は、バイナリから得られたデコンパイル結果を LLM で高度に再調整し、コード品質を向上させる手法を提案しています。LLM/ML が中心手法として用いられ、低水準入力（バイナリ）から高水準コードへの復元を目的としたデコンパイルプロセスの改善に焦点を当てているため、インクルード基準を満たします。", "model": "openai/gpt-oss-120b", "tokens_used": 3741, "latency_ms": 128406}}
