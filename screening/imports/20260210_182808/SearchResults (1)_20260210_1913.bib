@incollection{springer_10_1007_978_981_96_4566_4_11,
  title = {Automatic Software Vulnerability Detection in Binary Code},
  author = {Liu, Shigang and Li, Lin and Ban, Xinbo and Chen, Chao and Zhang, Jun and Camtepe, Seyit and Xiang, Yang},
  booktitle = {Lecture Notes in Computer Science},
  year = {2025},
  pages = {148-166},
  publisher = {Springer Nature Singapore},
  doi = {10.1007/978-981-96-4566-4\_11},
  url = {https://doi.org/10.1007/978-981-96-4566-4\_11},
  abstract = {Cybersecurity is critical in today’s digital world, where the severity of threats from software vulnerabilities grows significantly each year. Many techniques have been developed to analyze vulnerabilities in source code. However, source code is not always available (for example, most industry software is closed-source). As a result, analyzing vulnerabilities in binary code becomes necessary and more challenging. This paper presents a novel approach called BiVulD for detecting vulnerabilities at the binary level. BiVulD has three phases: generating assembly language instructions, learning good embeddings, and building a prediction model. First, we create a database of vulnerable binaries using CVE and NVD. Next, we propose using codeBERT to obtain good embeddings. Finally, we apply a bidirectional LSTM on top of codeBERT to build the predictive model. To demonstrate BiVulD’s effectiveness, we compared it with several baselines, including source code-based, binary code-based, and machine learning-based techniques on real-world projects. The experimental results show that BiVulD outperforms the baselines and can detect more vulnerabilities. For instance, BiVulD achieves at least 20\% improvement in Precision, Recall, and F-measure. We believe this work will serve as a foundation for future research in vulnerability detection using only binary code.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_032_08124_7_27,
  title = {Ali2Vul: Binary Vulnerability Dataset Expansion via Cross-Modal Alignment},
  author = {Bai, Xinyu and Wang, Yisen and Du, Jiajun and Liang, Chen and Liang, Siyuan and Jiang, Zirui},
  booktitle = {Lecture Notes in Computer Science},
  year = {2026},
  pages = {474-493},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-032-08124-7\_27},
  url = {https://doi.org/10.1007/978-3-032-08124-7\_27},
  abstract = {In the context of software supply chain security and IoT device firmware analysis, binary vulnerability detection faces dual challenges of detection efficiency and coverage due to scarce annotated binary data. Although the open-source ecosystem has accumulated vast amounts of source-level vulnerability data, direct migration to binary vulnerability detection inevitably encounters a semantic gap caused by cross-modal representation differences such as compiler optimizations and symbol stripping. To address data scarcity in binary vulnerability detection and bridge the semantic gap in cross-modal matching with source code, this paper proposes a hierarchical semantic fusion framework for binary-source alignment. Through heterogeneous modal semantic bridging and hierarchical attention mechanisms, our approach significantly enhances cross-modal matching precision and scalability between binary and source code, achieving 94.3\% accuracy. Furthermore, we introduce a vulnerability detection task-driven transfer framework that maps source-level vulnerability patterns to binary code feature space via cross-modal alignment. Leveraging dimensional expansion within the model’s knowledge space enables exponential scaling of usable data for binary vulnerability detection, thereby transcending data scarcity constraints. We collected 400 CVEs from 8 real-world vulnerable projects, achieving 80.3\% detection accuracy. This research establishes an effective technical pathway for expanding usable data resources in automated binary vulnerability detection.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_981_96_2042_5_59,
  title = {A Multi-CPU Architecture IoT Malware Detection Approach in Cyber-Physical Power System},
  author = {Zhao, Xichao and Tang, Zhuofan and Shi, Jie and Zheng, Qingrong and Zhao, Jianli and Deng, Boya and He, Yujun},
  booktitle = {Lecture Notes in Electrical Engineering},
  year = {2025},
  pages = {546-553},
  publisher = {Springer Nature Singapore},
  doi = {10.1007/978-981-96-2042-5\_59},
  url = {https://doi.org/10.1007/978-981-96-2042-5\_59},
  abstract = {With the widespread application of Internet of Things (IoT) devices and the deep integration of cyber systems with physical systems, power systems are gradually evolving towards Cyber-Physical Power System (CPPS). However, the proliferation of IoT devices has expanded the system’s attack surface, allowing malware to infiltrate and compromise CPPS operation. Therefore, it is imperative to conduct research on malware detection specifically for CPPS. Current detection methods, however, have certain limitations, such as difficulty in analyzing IoT malware across multiple CPU architectures and insufficient opcode feature extraction. To address these issues, this paper proposes a multi-CPU architecture IoT malware detection approach based on Intermediate Representation (IR). The approach consists of a binary lifting model, an IR deduplication model, and a deep learning classification model. The binary lifting model performs in-depth malware opcode analysis and outputs them as higher-level IR, facilitating malware processing across different CPU architectures. Due to significant redundancy in the IR output, an IR deduplication model is designed to optimize the IR, ensuring high-quality data input for the classification model. The deep learning classification model processes the deduplicated IR using word embedding techniques, employs a one-dimensional convolutional neural network (1D-CNN) for dimensionality reduction, and utilizes a Long Short-Term Memory (LSTM) network for malware classification. Experimental results demonstrate that the proposed IR-based multi-CPU architecture malware detection approach can more effectively identify and classify malware across different architectures, thereby enhancing detection accuracy.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_031_72322_3_4,
  title = {LEARNT: A Neural Machine Translation Framework for Accurate Binary Lifting to High-Level Representation},
  author = {Baasantogtokh, Duulga and Yoon, Yoseob and Batzorig, Munkhdelgerekh and Sahlabadi, Mahdi and Yim, Kangbin},
  booktitle = {Lecture Notes on Data Engineering and Communications Technologies},
  year = {2024},
  pages = {33-44},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-031-72322-3\_4},
  url = {https://doi.org/10.1007/978-3-031-72322-3\_4},
  abstract = {In binary analysis, performing static analyses on architecture-agnostic intermediate representation is efficient and strongly demanded. Sound and accurate Low-Level Virtual Machine Intermediate Representation (LLVM IR) lifted from binary could make the reuse of dozens of existing analysis programs of the LLVM ecosystem possible. However, current binary lifters lack the resources to improve manually developed lifting rules and develop more of them. This work aims to solve the problem of lifting low-level language to sound high-level Intermediate Representation (IR) as a formal language translation problem, enabling automatic learning of binary lifting. Therefore, we propose a neural machine translation-based binary lifting framework named LEARNT with a parallel corpus generation method leveraging a compiler. The evaluation results show that LEARNT’s average translation accuracy is 93\%, which proves that translation rules automatically learned by LEARNT are sound.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_031_20738_9_4,
  title = {Cross Architecture Function Similarity Detection with Binary Lifting and Neural Metric Learning},
  author = {Tian, Zhenzhou and Li, Chen and Qiu, Sihao},
  booktitle = {Lecture Notes on Data Engineering and Communications Technologies},
  year = {2023},
  pages = {27-34},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-031-20738-9\_4},
  url = {https://doi.org/10.1007/978-3-031-20738-9\_4},
  abstract = {Binary code similarity detection has extensive and important applications in IoT device security, yet which suffers the challenges from the differentiated underlying architectures of the diverse IoT devices. To this end, this paper presents XFSim ( Cross -architecture F unction-level binary code Sim ilarity detection), through binary lifting and neural similarity metric learning. Firstly, to make the detection method architecture agnostic, the binaries to be analyzed are lifted to an intermediate code called LLVM-IR and normalized for an uniform representation, so as to alleviate the discrepancies between the raw assemblies of different instruction set architectures (ISAs). Secondly, we utilize FastText, a widely used word embedding algorithm, that learns on the functions’ normalized intermediate codes to obtain high quality token embeddings. Then, an efficient CNN-based model is utilized to encode the semantics of each function into numerical vectors, meanwhile the siamese neural network structure is resorted to supervise the whole model training, with the goal of minimizing the contrastive loss. Finally, the similarity of two binary code snippets can measured by the cosine similarity of their encoded vectors. The experiments conducted on a public dataset show that, the strategy of lifting and normalizing the assemblies to uniform representations greatly alleviates the semantic-gaps between different ISAs, and XFSim outperforms two existing cross-architecture binary code similarity detectors.},
  content_type = {Conference paper},
}

@article{springer_10_1007_s10207_025_01148_3,
  title = {A cross-language and cross-binary type approach to binary-source software composition analysis using BM25},
  author = {Kim, Jong-Wouk and Choi, Mi-Jung},
  journal = {International Journal of Information Security},
  year = {2025},
  volume = {24},
  number = {6},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1007/s10207-025-01148-3},
  url = {https://doi.org/10.1007/s10207-025-01148-3},
  abstract = {Software composition analysis (SCA) involves analyzing open-source software (OSS) components used in software development to identify license compliance issues and security vulnerabilities. It helps developers mitigate the legal and security risks associated with OSS, ensuring safer and more reliable software. Traditional SCA methods often require users to upload their source code to an SCA server for inspection, which then generates reports on component usage. However, vendors have significant concerns about this approach because source code often includes sensitive information like proprietary algorithms, core business logic, and confidential user data. To address these challenges, various SCA techniques, such as binary-binary SCA and binary-source SCA, have been proposed, though most are limited to specific programming languages. Existing SCA frameworks primarily focus on C/C + + and Java. This paper introduces the first binary-source SCA method capable of analyzing three binary types across five programming languages (C/C + + , Objective-C, Swift, Go). Our approach utilizes BM25-based text tokens, significantly reducing computational cost while maintaining detection performance. Empirical results demonstrate that our method achieves up to 81.4\% recall in identifying reused OSS components, providing an efficient and scalable solution for secure software development. Additionally, this study highlights the limitations of the proposed method and suggests future research directions to address these challenges.},
  content_type = {Article},
}

@article{springer_10_1007_s43926_023_00045_2,
  title = {A survey on IoT \& embedded device firmware security: architecture, extraction techniques, and vulnerability analysis frameworks},
  author = {Ul Haq, Shahid and Singh, Yashwant and Sharma, Amit and Gupta, Rahul and Gupta, Dipak},
  journal = {Discover Internet of Things},
  year = {2023},
  volume = {3},
  number = {1},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1007/s43926-023-00045-2},
  url = {https://doi.org/10.1007/s43926-023-00045-2},
  abstract = {Abstract IoT and Embedded devices grow at an exponential rate, however, without adequate security mechanisms in place. One of the key challenges in the cyber world is the security of these devices. One of the main reasons that these devices are active targets for large-scale cyber-attacks is a lack of security standards and thorough testing by manufacturers. Manufacturer-specific operating systems or firmware of various architectures and characteristics are typically included with these devices. However, due to a lack of security testing and/or late patching, the underlying firmware or operating systems are vulnerable to numerous types of vulnerabilities. Reverse engineering and in-depth research of the firmware is required to detect the vulnerabilities. In this paper, we've delved into various aspects of IoT and embedded devices. This includes a comprehensive survey on the architecture of firmware, techniques for firmware extraction, and state-of-the-art vulnerability analysis frameworks for the detection of vulnerabilities using various approaches like static, dynamic, and hybrid approaches. Furthermore, we’ve scrutinized the challenges of existing vulnerability analysis frameworks and proposed a novel framework to address these issues.},
  content_type = {Article},
}

@incollection{springer_10_1007_978_3_031_94448_2_6,
  title = {Is This the Same Code? A Comprehensive Study of Decompilation Techniques for WebAssembly Binaries},
  author = {Wu, Wei-Cheng and Yan, Yutian and Egilsson, Hallgrimur David and Park, David and Chan, Steven and Hauser, Christophe and Wang, Weihang},
  booktitle = {Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
  year = {2026},
  pages = {108-130},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-031-94448-2\_6},
  url = {https://doi.org/10.1007/978-3-031-94448-2\_6},
  abstract = {WebAssembly (abbreviated WASM) is a low-level bytecode language designed for client-side execution in web browsers. As WASM continues to gain widespread adoption and its security concerns, the need for decompilation techniques that recover high-level source code from WASM binaries has grown. However, little research has been done to assess the quality of decompiled code from WASM. This paper aims to fill this gap by conducting a comprehensive comparative analysis between decompiled C code from WASM binaries and state-of-the-art native binary decompilers. To achieve this goal, we presented a novel framework for empirically evaluating C-based decompilers from various aspects, thus assessing the proficiency of WASM decompilers in generating readable and correct code when compared to native binary decompilers. Specifically, we evaluated the decompiled code’s correctness , readability , and structural similarity with the original code from current WASM decompilers. We validated the proposed metrics’ practicality in decompiler assessment and provided insightful observations regarding the characteristics and constraints of existing decompiled code. By encouraging improvements in these tools, we seek to enhance their use in critical tasks such as auditing and sandboxing third-party libraries. This, in turn, contributes to bolstering the security and reliability of software systems that rely on WASM and native binaries.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_031_06975_8_22,
  title = {AndroClonium: Bytecode-Level Code Clone Detection for Obfuscated Android Apps},
  author = {Foroughipour, Ardalan and Stakhanova, Natalia and Abazari, Farzaneh and Sistany, Bahman},
  booktitle = {IFIP Advances in Information and Communication Technology},
  year = {2022},
  pages = {379-397},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-031-06975-8\_22},
  url = {https://doi.org/10.1007/978-3-031-06975-8\_22},
  abstract = {Detecting code clones is essential for many security tasks, e.g., vulnerability detection, malware analysis, legacy software patching. In many of these security scenarios, source code is not available, leaving binary code analysis as the only option. Yet, evaluation of binary code is often exacerbated by the wide use of obfuscation. In this work, we propose an approach for obfuscation-resistant fine-grained detection of code clones in Android apps at the bytecode level. To mitigate inherent constraints of static analysis and to achieve obfuscation resistance, we partially simulate the execution of Android code, and abstract the resulting execution traces. We validate our approach’s ability to detect different types of code clones on a set of 20 injected clones and explore its resistance against obfuscation on a set of 1085 obfuscated apps.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_031_97620_9_6,
  title = {CodeGrafter: Unifying Source and Binary Graphs for Robust Vulnerability Detection},
  author = {Irtiza, Saquib and Zamani, Mahmoud and Wickramasuriya, Shamila and Hamlen, Kevin W. and Khan, Latifur},
  booktitle = {Lecture Notes in Computer Science},
  year = {2025},
  pages = {96-117},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-031-97620-9\_6},
  url = {https://doi.org/10.1007/978-3-031-97620-9\_6},
  abstract = {CodeGrafter is a novel framework for detecting security vulnerabilities in compiled C/C++ programs by integrating source- and binary-level code features into a unified Cross-Domain Code Property Graph (CDCPG). By combining the high-level semantic insights from source code with the detailed low-level information from compiled assembly, CodeGrafter uncovers vulnerabilities that are not detectable via source analysis or binary analysis alone. By combining both, it examines compiler decisions, such as dead code elimination, build-environment-dependent semantics (e.g., macros and pragmas), and compiler-generated interface code, to avoid false positives and false negatives in its analysis. For example, it can detect Points of Interests (POIs) where vulnerability severity is influenced by compilation-specific factors, such as stack layouts that place critical data near buffers. To streamline vulnerability detection, CodeGrafter represents these POIs as graphs and leverages Graph Neural Networks (GNNs) to significantly reduce manual auditing effort. Evaluations on six real-world applications demonstrate that CodeGrafter outperforms prior works that rely solely on source or binary-level representations alone, achieving an F1-score of 0.937 and a recall of 0.945 in identifying vulnerable functions.},
  content_type = {Conference paper},
}

@article{springer_10_1007_s10489_025_06417_1,
  title = {A reinforcement learning malware detection model based on heterogeneous information network path representation},
  author = {Yang, Kang and Cai, Lizhi and Wu, Jianhua and Liu, Zhenyu and Zhang, Meng},
  journal = {Applied Intelligence},
  year = {2025},
  volume = {55},
  number = {7},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1007/s10489-025-06417-1},
  url = {https://doi.org/10.1007/s10489-025-06417-1},
  abstract = {With the significant increase of Android malware, the APP privacy data leakage incidents occur frequently, which poses a great threat to user property and information security. Specifically, the new malware has the characteristics of high evolution rate and diverse variants, leading to the fact that the current malware detection methods still have three key problems: (1) Difficulty in acquiring Android sample structural features; (2) Weakly in representing malware behavior structure; (3) Poor robustness of the detection model. To address the above limitations, we propose a new malware detection framework MPRLDroid with reinforcement learning. First of all, the MPRLDroid model extracts the Android APP structural features and constructs the heterogeneous information network data based on the semantic call structure between APP, API and permission. Subsequently, the model utilizes reinforcement learning to adaptively generate a meta-path for each sample and combines it with a graph attention network to effectively represent the graph of nodes. Finally, the low-dimensional graph node vector data is brought into the downstream detection task for classification, where the performance change of the classification result is used as a reward function for reinforcement learning. The experimental results demonstrate that the MPRLDroid model, when integrated with reinforcement learning, outperforms the baseline models in terms of performance, and its detection model exhibits greater robustness compared to other models.},
  content_type = {Article},
}

@incollection{springer_10_1007_978_3_031_93299_1_2,
  title = {Implementation Strategies},
  author = {Mogensen, Torben Ægidius},
  booktitle = {Texts in Computer Science},
  year = {2026},
  pages = {29-45},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-031-93299-1\_2},
  url = {https://doi.org/10.1007/978-3-031-93299-1\_2},
  abstract = {The very first automatic computing machines, such as Babbage’s difference engine and early electronic computers, were specialised to one particular task such as calculating polynomials or multiplying matrices. Early programmable computers were programmed by connecting wires, so there was no real concept of a program.},
  content_type = {Chapter},
}

@incollection{springer_10_1007_978_3_031_45933_7_15,
  title = {Decompilation Based Deep Binary-Source Function Matching},
  author = {Wang, Xiaowei and Yuan, Zimu and Xiao, Yang and Wang, Liyan and Yao, Yican and Chen, Haiming and Huo, Wei},
  booktitle = {Lecture Notes in Computer Science},
  year = {2023},
  pages = {244-260},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-031-45933-7\_15},
  url = {https://doi.org/10.1007/978-3-031-45933-7\_15},
  abstract = {Binary and source matching is vital for vulnerability detection or program comprehension. Most existing works focus on library matching (coarse-grained) by utilizing some simple features. However, they are so coarse-grained that high false positives occur since developers tend to reuse source code library partly. These shortcomings drive us to perform fine-grained matching (i.e., binary and source function matching). At the same time, due to the enormous differences between the form of binary and source functions, function matching (fine-grained) meets huge challenges. In this work, inspired by the decompilation technique and advanced neural networks, we propose tool, a D ecompilation based deep B inary- S ource function M atching framework. Specifically, we take the triplet features from both binary pseudo-code and source code functions as input, which are extracted from code property graph and can represent both the syntactic and semantic information. In this way, the binary and source functions are represented in the same feature space so to ease the matching model to learn function similarity. For the matching model, we adopt a self-attention based siamese network with contrastive loss. Experiments on two datasets, R 0 and R 3, show that our tool achieves consistent improvements than other methods, which demonstrate the effectiveness of our self-attention based matching model, and our triplets features can well capture the two kinds of code functions. Our work improves the accuracy of binary and source code matching, which in turn enables us to better address security issues such as vulnerability detection and program comprehension.},
  content_type = {Conference paper},
}

@article{springer_10_1007_s10845_025_02695_1,
  title = {Assembly task planning framework based on knowledge graph},
  author = {Xu, Zhaobo and Zhang, Chaoran and Hou, Sheng and Han, Zhaochun and Zeng, Long and Feng, Pingfa},
  journal = {Journal of Intelligent Manufacturing},
  year = {2025},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1007/s10845-025-02695-1},
  url = {https://doi.org/10.1007/s10845-025-02695-1},
  abstract = {Assembly task planning (ATP) translates natural language described assembly tasks into executable programs, along with desired product models as input. It is a critical component of embodied intelligent assembly systems. However, current methods leveraging large language models are unable to comply with industrial standards and constraints well. We address this issue by proposing a knowledge graph (KG) based ATP framework that comprises four key modules: assembly KG, high-level task planner, low-level skill controller and reconfigurable flexible assembly system. First, the information of a product family is stored in an assembly KG. Then, a given language described assembly task is decomposed into a sequence of subtasks by the high-level task planner based on product information and inference rules in the assembly KG. After that, the low-level skill controller further transforms the assembly subtasks into skills that can be ultimately mapped to assembly programs, which can be directly executed on our highly reconfigurable flexible assembly system. Moreover, we develop a software platform to ease the assembly program generation. The proposed method is demonstrated by its application to the assembly of four valves. The results demonstrate that the programming time has been reduced from 10 to 25 min to less than 1 s. And the assembly accuracy can reach over 80\%. These show the effectiveness and potential of our KG-based ATP framework in improving efficiency and reducing manual workload in industrial assembly scenarios.},
  content_type = {Article},
}

@incollection{springer_10_1007_978_3_031_82349_7_32,
  title = {frameD: Toward Automated Identification of Embedded Frameworks in Firmware Images},
  author = {van Nielen, Jorik and Peter, Andreas and Continella, Andrea},
  booktitle = {Lecture Notes in Computer Science},
  year = {2025},
  pages = {514-533},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-031-82349-7\_32},
  url = {https://doi.org/10.1007/978-3-031-82349-7\_32},
  abstract = {In the era of the Internet of Things, firmware security analyses have become tremendously important to protect networks and guarantee safety-critical operations. Indeed, the firmware running on smart devices (which are increasingly adopted also in critical infrastructures) often contains security vulnerabilities, and delivering timely updates proved to be challenging, both from a technical perspective and due to a lack of support from device vendors. In particular, firmware images present difficulties that hinder automated analyses and patching, mostly because their code and data are opaquely intermixed and squashed together on top of embedded development frameworks. In this paper, we propose a new lightweight approach to automatically analyze firmware images and identify the embedded frameworks they are built upon. Our approach facilitates reverse engineering, reducing the scope for security analyses and assisting the vulnerability detection and patching process of embedded devices. We implement our approach in frameD , and we evaluate it on a dataset of 536 firmware images from different devices and vendors. Our system identifies embedded frameworks with an accuracy of 83\%, and we perform a case study to combine frameD with an existing patch injection framework, demonstrating to be a helpful and effective tool for security analysts and reverse engineers.},
  content_type = {Conference paper},
}

@article{springer_10_1007_s10207_024_00953_6,
  title = {Speeding-up fuzzing through directional seeds},
  author = {Koffi, Koffi Anderson and Kampourakis, Vyron and Kolias, Constantinos and Song, Jia and Ivans, Robert C.},
  journal = {International Journal of Information Security},
  year = {2025},
  volume = {24},
  number = {2},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1007/s10207-024-00953-6},
  url = {https://doi.org/10.1007/s10207-024-00953-6},
  abstract = {Abstract Fuzzing is an automated process for discovering inputs in a program that may trigger unexpected behavior. Today, fuzzing has become a standard practice for the discovery of bugs and security vulnerabilities. However, the main issue with such practices is that the exploration of the input space of programs can often be prohibitively expensive. Therefore, several alternative fuzzing strategies have been introduced during the last few years. Some fuzzing techniques rely on human expertise to provide a plausible set of initial input examples, namely, seeds. However, the process of handcrafting seeds for fuzzing purposes often becomes strenuous for humans as it requires a deeper understanding of the Program-Under-Test (PUT). Also, the use of known inputs to programs often does not trigger vulnerable program behavior or may not reach potentially vulnerable code locations. To address those issues, we propose a seed generation framework that enables Human-In-The-Loop (HITL) directed fuzzing where the human assumes a more active role in the creation of seeds that can penetrate and assess desired locations of the PUT. Our proposed framework uses Symbolic Execution (SE) to generate seeds that exercise paths to target program locations. Moreover, our framework enables the visualization of the explored execution paths in the binary of the PUT for the generated seeds. We evaluated our approach on a set of 12 carefully designed C programs with diverse characteristics that mimic real-world programs. The experimental results show the effectiveness of the proposed approach in improving the performance of standard fuzzing tools such as the American Fuzzy Lop ("Image missing"). Specifically, our solution can generate seeds that substantially enhance the performance of the fuzzer, achieving speedups ranging from \$\$1.46\\times \$\$ 1.46 × to \$\$68.53\\times \$\$ 68.53 × for branch conditions, \$\$1.39\\times \$\$ 1.39 × to \$\$254.62\\times \$\$ 254.62 × for branch depths, \$\$14,879.59\\times \$\$ 14 , 879.59 × to \$\$30,295.88\\times \$\$ 30 , 295.88 × for branch widths over traditional seeds. Additionally, the speedup increases with the number of target function ranging from \$\$12,260\\times \$\$ 12 , 260 × to \$\$22,856.07\\times \$\$ 22 , 856.07 × over traditional seeds while only requiring less than 15 seconds on average for the seed generation step.},
  content_type = {Article},
}

@article{springer_10_1007_s10207_021_00568_1,
  title = {Data space randomization for securing cyber-physical systems},
  author = {Potteiger, Bradley and Cai, Feiyang and Zhang, Zhenkai and Koutsoukos, Xenofon},
  journal = {International Journal of Information Security},
  year = {2022},
  volume = {21},
  number = {3},
  pages = {597-610},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1007/s10207-021-00568-1},
  url = {https://doi.org/10.1007/s10207-021-00568-1},
  abstract = {Non-control data attacks have become widely popular for circumventing authentication mechanisms in websites, servers, and personal computers. These attacks can be executed against cyber-physical systems (CPSs) in which not only authentication is an issue, but safety is at risk. Furthermore, any unauthorized change to safety-critical variables within the software may cause damage or even catastrophic consequences. Moving target defense techniques such as data space randomization (DSR) have become popular for protecting against memory corruption attacks such as non-control data attacks. However, current DSR implementations rely on source code transformations and do not stop critical variables from being overwritten, only that the new overwritten value will be vastly different than expected by the attacker. As such, these implementations are often ineffective for legacy CPS software in which only a binary is available. The problem addressed in this paper is how do we protect against non-control data attacks in legacy CPS software while ensuring that we can detect instances of variable integrity violations. We solve this problem by combining DSR at the binary level with variable comparison checks to ensure that we can detect and mitigate any attacker attempt to overwrite safety-critical variables. Our security approach is demonstrated utilizing an autonomous emergency braking system case study.},
  content_type = {Article},
}

@incollection{springer_10_1007_978_981_96_4880_1_10,
  title = {Optimizing Static Malware Analysis: Tool Efficacy and Performance Metrics},
  author = {Mani, Jibin Jacob and Abishek Ansel, T. M.},
  booktitle = {Lecture Notes in Networks and Systems},
  year = {2025},
  pages = {127-134},
  publisher = {Springer Nature Singapore},
  doi = {10.1007/978-981-96-4880-1\_10},
  url = {https://doi.org/10.1007/978-981-96-4880-1\_10},
  abstract = {In the field of Cybersecurity, Malware threats can turn out to be a difficult path to navigate. Malware represents real and harmful entities that can jeopardize your computer system. Malicious software, encompasses a range of programs designed to inflict damage on your PC. This term includes Viruses, Worms, Trojans, and other harmful softwares that hackers might use to deploy malicious payloads or extract sensitive information from victimized systems. These programs can severely compromise the integrity and security of Computer System. This work focuses on Static Malware Analysis, a primary methods for examining malware. Static Malware Analysis involves examining the malware without executing it, using a set of specialized tools. A comparative study of various tools were conducted, Dependency Walker had the highest detection rate (78.80\%) and accuracy rate (86.60\%), making it the most reliable instrument. The static analysis tools PiEd, Resource Hacker, PEview, and FileAlyzer had lower detection rates.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_030_34238_8_2,
  title = {Binary Analysis Overview},
  author = {Alrabaee, Saed and Debbabi, Mourad and Shirani, Paria and Wang, Lingyu and Youssef, Amr and Rahimian, Ashkan and Nouh, Lina and Mouheb, Djedjiga and Huang, He and Hanna, Aiman},
  booktitle = {Advances in Information Security},
  year = {2020},
  pages = {7-44},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-030-34238-8\_2},
  url = {https://doi.org/10.1007/978-3-030-34238-8\_2},
  abstract = {When the source code is unavailable, it is important for security applications, such as malware detection, software license infringement , vulnerability analysis , and digital forensics to be able to efficiently extract meaningful fingerprints from the binary code. Such fingerprints will enhance the effectiveness and efficiency of reverse engineering tasks as they can provide a range of insights into the program binaries. However, a great deal of important information will likely be lost during the compilation process, including variable and function names, the original control and data flow structures, comments, and layout. In this chapter, we provide a comprehensive review of existing binary code fingerprinting frameworks. As such, we systematize the study of binary code fingerprints based on the most important dimensions: the applications that motivate it, the approaches used and their implementations, the specific aspects of the fingerprinting framework, and how the results are evaluated.},
  content_type = {Chapter},
}

@incollection{springer_10_1007_978_3_030_78120_0_5,
  title = {QuickBCC: Quick and Scalable Binary Vulnerable Code Clone Detection},
  author = {Jang, Hajin and Yang, Kyeongseok and Lee, Geonwoo and Na, Yoonjong and Seideman, Jeremy D. and Luo, Shoufu and Lee, Heejo and Dietrich, Sven},
  booktitle = {IFIP Advances in Information and Communication Technology},
  year = {2021},
  pages = {66-82},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-030-78120-0\_5},
  url = {https://doi.org/10.1007/978-3-030-78120-0\_5},
  abstract = {Due to code reuse among software packages, vulnerabilities can propagate from one software package to another. Current code clone detection techniques are useful for preventing and managing such vulnerability propagation. When the source code for a software package is not available, such as when working with proprietary or custom software distributions, binary code clone detection can be used to examine software for flaws. However, existing binary code clone detectors have scalability issues, or are limited in their accurate detection of vulnerable code clones . In this paper, we introduce QuickBCC, a scalable binary code clone detection framework designed for vulnerability scanning. The framework was built on the idea of extracting semantics from vulnerable binaries both before and after security patches, and comparing them to target binaries. In order to improve performance, we created a signature based on the changes between the pre- and post-patched binaries, and implemented a filtering process when comparing the signatures to the target binaries. In addition, we leverage the smallest semantic unit, a strand , to improve accuracy and robustness against compile environments. QuickBCC is highly optimized, capable of preprocessing 5,439 target binaries within 111 min, and is able to match those binaries against 6 signatures in 23 s when running as a multi-threaded application. QuickBCC takes, on average, 3 ms to match one target binary. Comparing performance to other approaches, we found that it outperformed other approaches in terms of performance when detecting well known vulnerabilities with acceptable level of accuracy.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_031_22390_7_21,
  title = {Representing LLVM-IR in a Code Property Graph},
  author = {Küchler, Alexander and Banse, Christian},
  booktitle = {Lecture Notes in Computer Science},
  year = {2022},
  pages = {360-380},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-031-22390-7\_21},
  url = {https://doi.org/10.1007/978-3-031-22390-7\_21},
  abstract = {In the past years, a number of static application security testing tools have been proposed which use so-called code property graphs (CPGs), a graph model which keeps rich information about the source code while enabling its user to write language-agnostic analyses. However, they suffer from several shortcomings. They work mostly on source code and exclude the analysis of third-party dependencies if they are only available as compiled binaries. Furthermore, they are limited in their analysis to whether an individual programming language is supported or not. While often support for well-established languages such as C/C++ or Java is included, languages that are still heavily evolving, such as Rust, are not considered because of the constant changes in the language design. To overcome these limitations, we extend an open source implementation of a code property graph to support LLVM-IR which can be used as output by many compilers and binary lifters. In this paper, we discuss how we address challenges that arise when mapping concepts of an intermediate representation to a CPG. At the same time, we optimize the resulting graph to be minimal and close to the representation of equivalent source code. Our case-study on detecting cryptographic misuse indicates that existing analyses can be reused and that the analysis time is comparable to operating on source code. This makes the approach suitable for a security analysis of large-scale projects.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_031_94455_0_1,
  title = {Fast Firmware Fuzz with Input/Output Reposition},
  author = {Xin, Mingfeng and Deng, Liting and Wen, Hui and Fang, Dongliang and Lv, Shichao and Sun, Limin},
  booktitle = {Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
  year = {2026},
  pages = {3-27},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-031-94455-0\_1},
  url = {https://doi.org/10.1007/978-3-031-94455-0\_1},
  abstract = {Embedded devices are used ubiquitously for managing both personnel belongs and critical infrastructures. Researchers have adopted various fuzzing techniques to test firmware images of embedded devices for detecting security vulnerabilities. However, firmware images are different from traditional desktop applications, especially in the input/output system, which brings unique changes that hinder efficient testing. In this paper, we propose a novel method, input/output reposition (or I/O reposition ) to improve the performance of fuzzing firmware images. The core idea is to automatically replace the interrupt-based I/O method with polling to address two issues. First, interrupt introduces a lot of context switches, leading to heavy overhead; Second, interrupt is triggered in a low frequency and the system either starves on input or gets stuck on output. We implement Fire that utilizes probabilistic invocation and interrupt service slicing to achieve practical I/O reposition. We evaluate Fire on 30 popular and widely used firmware images. The results show that Fire brings 95.4\% higher throughput and achieves 30.4\% more code coverage. Fuzzing Fire -modified images can detect 12 known bugs with 63.6\% of the time required by fuzzing the original images. We detect three new vulnerabilities from tested firmware images and have reported to their developers.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_031_46077_7_13,
  title = {Reliable Basic Block Energy Accounting},
  author = {Lamprakos, Christos P. and Bouras, Dimitrios S. and Catthoor, Francky and Soudris, Dimitrios},
  booktitle = {Lecture Notes in Computer Science},
  year = {2023},
  pages = {193-208},
  publisher = {Springer Nature Switzerland},
  doi = {10.1007/978-3-031-46077-7\_13},
  url = {https://doi.org/10.1007/978-3-031-46077-7\_13},
  abstract = {Modeling the energy consumption of low-level code will enable (i) a better understanding of its relationship to execution time and (ii) compiler/runtime optimizations tailored for energy efficiency. But such models need reliable ground truth data to be trained on. We thus attack extracting machine-specific datasets for the energy consumption of basic blocks–a problem with surprisingly few solutions available. Given the impact of execution context on energy, we are interested in recording sequences of basic blocks coupled to corresponding energy measurements. Our design is lightweight and portable; no manual hardware/software instrumentation is required. Its main components are an energy estimation interface with sufficiently high refresh rate, access to an application’s complete execution trace, and LLVM pass-based instrumentation. We extract half a million basic block-energy mappings overall, and achieve a mean whole-program error of \\(\\sim \\) 3\% on two different machines. This paper demonstrates that commodity resources suffice to perform a very crucial task on the road to energy-optimal computing.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_981_19_5256_2_59,
  title = {Smart Contract: Is it Really Smart in Construction?},
  author = {Wu, Liupengfei and Lu, Weisheng and Zhao, Rui and Xue, Fan},
  booktitle = {Lecture Notes in Operations Research},
  year = {2022},
  pages = {751-759},
  publisher = {Springer Nature Singapore},
  doi = {10.1007/978-981-19-5256-2\_59},
  url = {https://doi.org/10.1007/978-981-19-5256-2\_59},
  abstract = {A smart contract is a protocol that can self-execute when predefined conditions are met. This new technology is considered destructive and can transfer the construction industry. In Blockchain 2.0, the combined use of blockchain and smart contracts allows users to express business logic to achieve more advanced transactions. This research aims to critically analyze the challenges, progresses, and benefits of smart contracts in construction through a systematic literature review to address whether it is smart. The findings suggested that numerous progress had been made to address the challenges of smart contracts. Besides, the benefits of smart contracts have attracted the construction industry. The research findings can open the avenue for researchers and construction practitioners to understand the impacts of the salient features of smart contracts and determine appropriate application areas.},
  content_type = {Conference paper},
}

@article{springer_10_1007_s43621_024_00689_2,
  title = {Realization of circular economy principles in manufacturing: obstacles, advancements, and routes to achieve a sustainable industry transformation},
  author = {Dennison, Milon Selvam and Kumar, M. Bhuvanesh and Jebabalan, S. Kirubanidhi},
  journal = {Discover Sustainability},
  year = {2024},
  volume = {5},
  number = {1},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1007/s43621-024-00689-2},
  url = {https://doi.org/10.1007/s43621-024-00689-2},
  abstract = {This review explores the integration of Circular Economy (CE) principles in manufacturing, focusing on its potential to transform industrial practices by promoting sustainability, economic adaptability, and social welfare. As manufacturers face the depletion of natural resources and growing environmental concerns, CE presents a regenerative model that prioritizes resource efficiency, waste reduction, and closed-loop systems. The study provides a detailed analysis of the current state of CE adoption, outlining significant barriers such as economic, technological, and regulatory and showcase innovative strategies and business models that successfully apply circular principles. Additionally, the paper emphasizes the role of supportive legislative frameworks, economic incentives, and educational initiatives in accelerating CE adoption. The review offers actionable recommendations for industry stakeholders, emphasizing the importance of collaboration, continuous learning, and robust monitoring systems to ensure a smooth transition. By uniting manufacturers, policymakers, and consumers under shared CE principles, this review advocates for a sustainable, resilient, and prosperous future for the manufacturing sector.},
  content_type = {Article},
}

@article{springer_10_1186_s42400_021_00085_7,
  title = {B2SMatcher: fine-Grained version identification of open-Source software in binary files},
  author = {Ban, Gu and Xu, Lili and Xiao, Yang and Li, Xinhua and Yuan, Zimu and Huo, Wei},
  journal = {Cybersecurity},
  year = {2021},
  volume = {4},
  number = {1},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1186/s42400-021-00085-7},
  url = {https://doi.org/10.1186/s42400-021-00085-7},
  abstract = {Abstract Codes of Open Source Software (OSS) are widely reused during software development nowadays. However, reusing some specific versions of OSS introduces 1-day vulnerabilities of which details are publicly available, which may be exploited and lead to serious security issues. Existing state-of-the-art OSS reuse detection work can not identify the specific versions of reused OSS well. The features they selected are not distinguishable enough for version detection and the matching scores are only based on similarity.This paper presents B2SMatcher, a fine-grained version identification tool for OSS in commercial off-the-shelf (COTS) software. We first discuss five kinds of version-sensitive code features that are trackable in both binary and source code. We categorize these features into program-level features and function-level features and propose a two-stage version identification approach based on the two levels of code features. B2SMatcher also identifies different types of OSS version reuse based on matching scores and matched feature instances. In order to extract source code features as accurately as possible, B2SMatcher innovatively uses machine learning methods to obtain the source files involved in the compilation and uses function abstraction and normalization methods to eliminate the comparison costs on redundant functions across versions. We have evaluated B2SMatcher using 6351 candidate OSS versions and 585 binaries. The result shows that B2SMatcher achieves a high precision up to 89.2\% and outperforms state-of-the-art tools. Finally, we show how B2SMatcher can be used to evaluate real-world software and find some security risks in practice.},
  content_type = {Article},
}

@incollection{springer_10_1007_978_3_030_95391_1_48,
  title = {OptCL: A Middleware to Optimise Performance for High Performance Domain-Specific Languages on Heterogeneous Platforms},
  author = {Xiao, Jiajian and Andelfinger, Philipp and Cai, Wentong and Eckhoff, David and Knoll, Alois},
  booktitle = {Lecture Notes in Computer Science},
  year = {2022},
  pages = {772-791},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-030-95391-1\_48},
  url = {https://doi.org/10.1007/978-3-030-95391-1\_48},
  abstract = {Programming on heterogeneous hardware architectures using OpenCL requires thorough knowledge of the hardware. Many High-Performance Domain-Specific Languages (HPDSLs) are aimed at simplifying the programming efforts by abstracting away hardware details, allowing users to program in a sequential style. However, most HPDSLs still require the users to manually map compute workloads to the best suitable hardware to achieve optimal performance. This again calls for knowledge of the underlying hardware and trial-and-error attempts. Further, very often they only consider an offloading mode where compute-intensive tasks are offloaded to accelerators. During this offloading period, CPUs remain idle, leaving parts of the available computational power untapped. In this work, we propose a tool named OptCL for existing HPDSLs to enable a heterogeneous co-execution mode when capable where CPUs and accelerators can process data simultaneously. Through a static analysis of data dependencies among compute-intensive code regions and performance predictions, the tool selects the best execution schemes out of purely CPU/accelerator execution or co-execution. We show that by enabling co-execution on dedicated and integrated CPU-GPU systems up to 13 \\(\\times \\) and 21 \\(\\times \\) speed-ups can be achieved.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_031_17510_7_21,
  title = {Building Deobfuscated Applications from Polymorphic Binaries},
  author = {Crăciun, Vlad Constantin and Mogage, Andrei-Cătălin},
  booktitle = {Lecture Notes in Computer Science},
  year = {2022},
  pages = {308-323},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-031-17510-7\_21},
  url = {https://doi.org/10.1007/978-3-031-17510-7\_21},
  abstract = {Along with the rise of the cyber threats industry, attackers have become more fluent in developing and integrating various obfuscation layers. This is mainly focused on impeding or at least slowing the analysis and the reverse engineering process, both manually and automatically, such that their threats will have more time to do damage. Our contribution comes two-fold: we propose a semi-formal description to reason with a certain class of obfuscators, while also presenting a concrete implementation proving our deobfuscation mechanisms. Our results are based on a set of case studies of both common threats and legitimate software, running on Windows operating systems. We evaluate our results comparing with PINDemonium, a tool built on top of PIN dynamic binary instrumentation tool. Our solution CFGDump attempts to brute-force and hash inter-procedural control flow graphs, opening the doors to future optimisations and possible other features.},
  content_type = {Conference paper},
}

@incollection{springer_10_1007_978_3_030_05487_8_1,
  title = {On Efficiency and Effectiveness of Linear Function Detection Approaches for Memory Carving},
  author = {Liebler, Lorenz and Baier, Harald},
  booktitle = {Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
  year = {2019},
  pages = {3-22},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-030-05487-8\_1},
  url = {https://doi.org/10.1007/978-3-030-05487-8\_1},
  abstract = {In the field of unstructured memory analysis, the context-unaware detection of function boundaries leads to meaningful insights. For instance, in the field of binary analysis, those structures yield further inference, e.g., identifying binaries known to be bad. However, recent publications discuss different strategies for the problem of function boundary detection and consider it to be a difficult problem. One of the reasons is that the detection process depends on a quantity of parameters including the used architecture, programming language and compiler parameters. Initially a typical memory carving approach transfers the paradigm of signature-based detection techniques from the mass storage analysis to memory analysis. To automate and generalise the signature matching, signature-based recognition approaches have been extended by machine learning algorithms. Recently a review of function detection approaches claims that the results are possibly biased by large portions of shared code between the used samples. In this work we reassess the application of recently discussed machine learning based function detection approaches. We analyse current approaches in the context of memory carving with respect to both their efficiency and their effectiveness. We show the capabilities of function start identification by reducing the features to vectorised mnemonics. In all this leads to a significant reduction of runtime by keeping a high value of accuracy and a good value of recall.},
  content_type = {Conference paper},
}

@article{springer_10_1007_s13753_018_0202_9,
  title = {Participatory Disaster Recovery Simulation Modeling for Community Resilience Planning},
  author = {Miles, Scott B.},
  journal = {International Journal of Disaster Risk Science},
  year = {2018},
  volume = {9},
  number = {4},
  pages = {519-529},
  publisher = {Springer Science and Business Media LLC},
  doi = {10.1007/s13753-018-0202-9},
  url = {https://doi.org/10.1007/s13753-018-0202-9},
  abstract = {A major challenge in enhancing the resilience of communities stems from current approaches used to identify needs and strategies that build the capacity of jurisdictions to mitigate loss and improve recovery. A new generation of resilience-based planning processes has emerged in the last several years that integrate goals of community well-being and identity into recovery-based performance measurement frameworks. Specific tools and refined guidance are needed to facilitate evidence-based development of recovery estimates. This article presents the participatory modeling process, a planning system designed to develop recovery-based resilience measurement frameworks for community resilience planning initiatives. Stakeholder engagement is infused throughout the participatory modeling process by integrating disaster recovery simulation modeling into community resilience planning. Within the process, participants get a unique opportunity to work together to deliberate on community concerns through facilitated participatory modeling. The participatory modeling platform combines the DESaster recovery simulation model and visual analytics interfaces. DESaster is an open source Python Library for creating discrete event simulations of disaster recovery. The simulation model was developed using a human-centered design approach whose goal is to be open, modular, and extensible. The process presented in this article is the first participatory modeling approach for analyzing recovery to aid creation of community resilience measurement frameworks.},
  content_type = {Article},
}
