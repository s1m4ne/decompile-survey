@article{10.1145/3720524,
author = {Park, Jihee and Yun, Insu and Ryu, Sukyoung},
title = {Bridging the Gap between Real-World and Formal Binary Lifting through Filtered-Simulation},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3720524},
doi = {10.1145/3720524},
abstract = {Binary lifting is a key component in binary analysis tools.        In order to guarantee the correctness of binary lifting,        researchers have proposed various formally verified lifters.        However, such formally verified lifters have too strict requirements on binary,        which do not sufficiently reflect real-world lifters. In addition, real-world lifters use heuristic-based assumptions to lift binary code, which makes it difficult to guarantee the correctness of the lifted code using formal methods. In this paper, we propose a new interpretation of the correctness of real-world binary lifting.        We formalize the process of binary lifting with heuristic-based assumptions used in real-world lifters by dividing it into a series of transformations, where each transformation represents a lift with new abstraction features.        We define the correctness of each transformation as filtered-simulation, which is a variant of bi-simulation, between programs before and after transformation.        We present three essential transformations in binary lifting and formalize them: (1) control flow graph reconstruction, (2) abstract stack reconstruction, and (3) function input/output identification.        We implement our approach for x86-64 Linux binaries, named FIBLE, and demonstrate that it can correctly lift Coreutils and CGC datasets compiled with GCC.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {112},
numpages = {29},
keywords = {Binary lifting, formal semantics}
}

@inproceedings{10.1145/3658644.3691386,
author = {Naus, Nico and Verbeek, Freek and Atla, Sagar and Ravindran, Binoy},
title = {Poster: Formally Verified Binary Lifting to P-Code},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3691386},
doi = {10.1145/3658644.3691386},
abstract = {Analysis of binary software plays a critical role in software security. Reverse engineers analyze binaries to discover vulnerabilities, patch legacy software, and detect malware. Most of the reverse engineering tools have been developed from a practical point of view, and do not provide any guarantees with their results. Recently, formally verified reverse engineering and decompilation have gained traction. These formal tools are for the most part proof-of-concept systems not yet suitable for real-world reverse-engineering tasks. In this poster, we explore the idea of formalizing part of an existing decompilation tool instead. We focus on the lifting from assembly to the IR P-Code in one of the most popular decompilers, Ghidra. This step occurs immediately after disassembly. We are developing a proof system inside the Isabelle theorem prover, to automatically prove semantical equivalence between the assembly and P-Code instructions. We leverage machine-learned x86-64 semantics, to stay as close as possible to actual CPU behavior. This approach has uncovered several shortcomings in Ghidra's P-Code and the lifting it performs. By using a theorem prover, we obtain guarantees that our system of formal semantics and lifting is internally consistent. This work brings the powerful guarantees that formal methods provide in reverse engineering research to the real world.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4973–4975},
numpages = {3},
keywords = {binary lifting, decompilation, formal verification, proof automation, reverse engineering, theorem provers},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@article{10.1145/3486860,
author = {Alrabaee, Saed and Debbabi, Mourad and Wang, Lingyu},
title = {A Survey of Binary Code Fingerprinting Approaches: Taxonomy, Methodologies, and Features},
year = {2022},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3486860},
doi = {10.1145/3486860},
abstract = {Binary code fingerprinting is crucial in many security applications. Examples include malware detection, software infringement, vulnerability analysis, and digital forensics. It is also useful for security researchers and reverse engineers since it enables high fidelity reasoning about the binary code such as revealing the functionality, authorship, libraries used, and vulnerabilities. Numerous studies have investigated binary code with the goal of extracting fingerprints that can illuminate the semantics of a target application. However, extracting fingerprints is a challenging task since a substantial amount of significant information will be lost during compilation, notably, variable and function naming, the original data and control flow structures, comments, semantic information, and the code layout. This article provides the first systematic review of existing binary code fingerprinting approaches and the contexts in which they are used. In addition, it discusses the applications that rely on binary code fingerprints, the information that can be captured during the fingerprinting process, and the approaches used and their implementations. It also addresses limitations and open questions related to the fingerprinting process and proposes future directions.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {19},
numpages = {41},
keywords = {software security, reverse engineering, Binary code analysis}
}

@inproceedings{10.1145/3342195.3387550,
author = {Altinay, Anil and Nash, Joseph and Kroes, Taddeus and Rajasekaran, Prabhu and Zhou, Dixin and Dabrowski, Adrian and Gens, David and Na, Yeoul and Volckaert, Stijn and Giuffrida, Cristiano and Bos, Herbert and Franz, Michael},
title = {BinRec: dynamic binary lifting and recompilation},
year = {2020},
isbn = {9781450368827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342195.3387550},
doi = {10.1145/3342195.3387550},
abstract = {Binary lifting and recompilation allow a wide range of install-time program transformations, such as security hardening, deobfuscation, and reoptimization. Existing binary lifting tools are based on static disassembly and thus have to rely on heuristics to disassemble binaries.In this paper, we present BinRec, a new approach to heuristic-free binary recompilation which lifts dynamic traces of a binary to a compiler-level intermediate representation (IR) and lowers the IR back to a "recovered" binary. This enables BinRec to apply rich program transformations, such as compiler-based optimization passes, on top of the recovered representation. We identify and address a number of challenges in binary lifting, including unique challenges posed by our dynamic approach. In contrast to existing frameworks, our dynamic frontend can accurately disassemble and lift binaries without heuristics, and we can successfully recover obfuscated code and all SPEC INT 2006 benchmarks including C++ applications. We evaluate BinRec in three application domains: i) binary reoptimization, ii) deobfuscation (by recovering partial program semantics from virtualization-obfuscated code), and iii) binary hardening (by applying existing compiler-level passes such as AddressSanitizer and SafeStack on binary code).},
booktitle = {Proceedings of the Fifteenth European Conference on Computer Systems},
articleno = {36},
numpages = {16},
location = {Heraklion, Greece},
series = {EuroSys '20}
}

@inproceedings{10.1145/3713081.3731728,
author = {Zhou, Li and Dacier, Marc and Konstantinou, Charalambos},
title = {ReGraph: A Tool for Binary Similarity Identification},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731728},
doi = {10.1145/3713081.3731728},
abstract = {Binary Code Similarity Detection (BCSD) is not only essential for security tasks such as vulnerability identification but also for code copying detection, yet it remains challenging due to binary stripping and diverse compilation environments. Existing methods tend to adopt increasingly complex neural networks for better accuracy performance. The computation time increases with the complexity. Even with powerful GPUs, the treatment of large-scale software becomes time-consuming. To address these issues, we present a framework called ReGraph to efficiently compare binary code functions across architectures and optimization levels. Our evaluation with public datasets highlights that ReGraph exhibits a significant speed advantage, performing 700 times faster than Natural Language Processing (NLP)-based methods while maintaining comparable accuracy results with respect to the state-of-the-art models.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {6–10},
numpages = {5},
keywords = {binary code similarity detection, code property graph, graph neural network, code lifting, binary code re-optimization},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@article{10.1162/jmlr.2003.4.7-8.1411,
author = {Waheed, Khurram and Salem, Fathi M.},
title = {Blind source recovery: a framework in the state space},
year = {2004},
issue_date = {October 1 - November 15, 2004},
publisher = {JMLR.org},
volume = {4},
number = {7–8},
issn = {1532-4435},
url = {https://doi.org/10.1162/jmlr.2003.4.7-8.1411},
doi = {10.1162/jmlr.2003.4.7-8.1411},
abstract = {Blind Source Recovery (BSR) denotes recovery of original sources/signals from environments that may include convolution, temporal variation, and even nonlinearity. It also infers the recovery of sources even in the absence of precise environment identifiability. This paper describes, in a comprehensive fashion, a generalized BSR formulation achieved by the application of stochastic optimization principles to the Kullback-Liebler divergence as a performance functional subject to the constraints of the general (i.e., nonlinear and time-varying) state space representation. This technique is used to derive update laws for nonlinear time-varying dynamical systems, which are subsequently specialized to time-invariant and linear systems. Further, the state space demixing network structures have been exploited to develop learning rules, capable of handling most filtering paradigms, which can be conveniently extended to nonlinear models. In the special cases, distinct linear state-space algorithms are presented for the minimum phase and non-minimum phase mixing environment models. Conventional (FIR/IIR) filtering models are subsequently derived from this general structure and are compared with material in the recent literature. Illustrative simulation examples are presented to demonstrate the online adaptation capabilities of the developed algorithms. Some of this reported work has also been implemented in dedicated hardware/software platforms.},
journal = {J. Mach. Learn. Res.},
month = oct,
pages = {1411–1446},
numpages = {36},
keywords = {state space representation, feedforward network, feedback network, blind source recovery, Kullback-Liebler divergence}
}

@inproceedings{10.1145/2465351.2465380,
author = {Anand, Kapil and Smithson, Matthew and Elwazeer, Khaled and Kotha, Aparna and Gruen, Jim and Giles, Nathan and Barua, Rajeev},
title = {A compiler-level intermediate representation based binary analysis and rewriting system},
year = {2013},
isbn = {9781450319942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2465351.2465380},
doi = {10.1145/2465351.2465380},
abstract = {This paper presents component techniques essential for converting executables to a high-level intermediate representation (IR) of an existing compiler. The compiler IR is then employed for three distinct applications: binary rewriting using the compiler's binary back-end, vulnerability detection using source-level symbolic execution, and source-code recovery using the compiler's C backend. Our techniques enable complex high-level transformations not possible in existing binary systems, address a major challenge of input-derived memory addresses in symbolic execution and are the first to enable recovery of a fully functional source-code.We present techniques to segment the flat address space in an executable containing undifferentiated blocks of memory. We demonstrate the inadequacy of existing variable identification methods for their promotion to symbols and present our methods for symbol promotion. We also present methods to convert the physically addressed stack in an executable (with a stack pointer) to an abstract stack (without a stack pointer). Our methods do not use symbolic, relocation, or debug information since these are usually absent in deployed executables.We have integrated our techniques with a prototype x86 binary framework called SecondWrite that uses LLVM as IR. The robustness of the framework is demonstrated by handling executables totaling more than a million lines of source-code, produced by two different compilers (gcc and Microsoft Visual Studio compiler), three languages (C, C++, and Fortran), two operating systems (Windows and Linux) and a real world program (Apache server).},
booktitle = {Proceedings of the 8th ACM European Conference on Computer Systems},
pages = {295–308},
numpages = {14},
location = {Prague, Czech Republic},
series = {EuroSys '13}
}

@article{10.5555/945365.964312,
author = {Waheed, Khurram and Salem, Fathi M.},
title = {Blind source recovery: a framework in the state space},
year = {2003},
issue_date = {12/1/2003},
publisher = {JMLR.org},
volume = {4},
number = {null},
issn = {1532-4435},
abstract = {Blind Source Recovery (BSR) denotes recovery of original sources/signals from environments that may include convolution, temporal variation, and even nonlinearity. It also infers the recovery of sources even in the absence of precise environment identifiability. This paper describes, in a comprehensive fashion, a generalized BSR formulation achieved by the application of stochastic optimization principles to the Kullback-Liebler divergence as a performance functional subject to the constraints of the general (i.e., nonlinear and time-varying) state space representation. This technique is used to derive update laws for nonlinear time-varying dynamical systems, which are subsequently specialized to time-invariant and linear systems. Further, the state space demixing network structures have been exploited to develop learning rules, capable of handling most filtering paradigms, which can be conveniently extended to nonlinear models. In the special cases, distinct linear state-space algorithms are presented for the minimum phase and non-minimum phase mixing environment models. Conventional (FIR/IIR) filtering models are subsequently derived from this general structure and are compared with material in the recent literature. Illustrative simulation examples are presented to demonstrate the online adaptation capabilities of the developed algorithms. Some of this reported work has also been implemented in dedicated hardware/software platforms.},
journal = {J. Mach. Learn. Res.},
month = dec,
pages = {1411–1446},
numpages = {36}
}

@inproceedings{10.1145/3519939.3523702,
author = {Verbeek, Freek and Bockenek, Joshua and Fu, Zhoulai and Ravindran, Binoy},
title = {Formally verified lifting of C-compiled x86-64 binaries},
year = {2022},
isbn = {9781450392655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3519939.3523702},
doi = {10.1145/3519939.3523702},
abstract = {Lifting binaries to a higher-level representation is an essential step for decompilation, binary verification, patching and security analysis. In this paper, we present the first approach to provably overapproximative x86-64 binary lifting. A stripped binary is verified for certain sanity properties such as return address integrity and calling convention adherence. Establishing these properties allows the binary to be lifted to a representation that contains an overapproximation of all possible execution paths of the binary. The lifted representation contains disassembled instructions, reconstructed control flow, invariants and proof obligations that are sufficient to prove the sanity properties as well as correctness of the lifted representation. We apply this approach to Linux Foundation and Intel’s Xen Hypervisor covering about 400K instructions. This demonstrates our approach is the first approach to provably overapproximative binary lifting scalable to commercial off-the-shelf systems. The lifted representation is exportable to the Isabelle/HOL theorem prover, allowing formal verification of its correctness. If our technique succeeds and the proofs obligations are proven true, then – under the generated assumptions – the lifted representation is correct.},
booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {934–949},
numpages = {16},
keywords = {Formal Verification, Disassembly, Binary Analysis},
location = {San Diego, CA, USA},
series = {PLDI 2022}
}

@inproceedings{10.1145/3597503.3639100,
author = {Jiang, Ling and An, Junwen and Huang, Huihui and Tang, Qiyi and Nie, Sen and Wu, Shi and Zhang, Yuqun},
title = {BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639100},
doi = {10.1145/3597503.3639100},
abstract = {While third-party libraries (TPLs) are extensively reused to enhance productivity during software development, they can also introduce potential security risks such as vulnerability propagation. Software composition analysis (SCA), proposed to identify reused TPLs for reducing such risks, has become an essential procedure within modern DevSecOps. As one of the mainstream SCA techniques, binary-to-source SCA identifies the third-party source projects contained in binary files via binary source code matching, which is a major challenge in reverse engineering since binary and source code exhibit substantial disparities after compilation. The existing binary-to-source SCA techniques leverage basic syntactic features that suffer from redundancy and lack robustness in the large-scale TPL dataset, leading to inevitable false positives and compromised recall. To mitigate these limitations, we introduce BinaryAI, a novel binary-to-source SCA technique with two-phase binary source code matching to capture both syntactic and semantic code features. First, BinaryAI trains a transformer-based model to produce function-level embeddings and obtain similar source functions for each binary function accordingly. Then by applying the link-time locality to facilitate function matching, BinaryAI detects the reused TPLs based on the ratio of matched source functions. Our experimental results demonstrate the superior performance of BinaryAI in terms of binary source code matching and the downstream SCA task. Specifically, our embedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving 22.54% recall@1 and 0.34 MRR compared with 10.75% and 0.17 respectively. Additionally, BinaryAI outperforms all existing binary-to-source SCA tools in TPL detection, increasing the precision from 73.36% to 85.84% and recall from 59.81% to 64.98% compared with the well-recognized commercial SCA product Black Duck.https://www.binaryai.net},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {224},
numpages = {13},
keywords = {software composition analysis, static binary analysis},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3474369.3486865,
author = {Deshpande, Chinmay and Gens, David and Franz, Michael},
title = {StackBERT: Machine Learning Assisted Static Stack Frame Size Recovery on Stripped and Optimized Binaries},
year = {2021},
isbn = {9781450386579},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474369.3486865},
doi = {10.1145/3474369.3486865},
abstract = {The call stack represents one of the core abstractions that compiler-generated programs leverage to organize binary execution at runtime. For many use cases reasoning about stack accesses of binary functions is crucial: security-sensitive applications may require patching even after deployment, and binary instrumentation, rewriting, and lifting all necessitate detailed knowledge about the function frame layout of the affected program. As no comprehensive solution to the stack symbolization problem exists to date, existing approaches have to resort to workarounds like emulated stack environments, resulting in increased runtime overheads.In this paper we present StackBERT, a framework to statically reason about and reliably recover stack frame information of binary functions in stripped and highly optimized programs. The core idea behind our approach is to formulate binary analysis as a self-supervised learning problem by automatically generating ground truth data from a large corpus of open-source programs. We train a state-of-the-art Transformer model with self-attention and finetune for stack frame size prediction. We show that our finetuned model yields highly accurate estimates of a binary function's stack size from its function body alone across different instruction-set architectures, compiler toolchains, and optimization levels. We successfully verify the static estimates against runtime data through dynamic executions of standard benchmarks and additional studies, demonstrating that StackBERT's predictions generalize to 93.44% of stripped and highly optimized test binaries not seen during training. We envision these results to be useful for improving binary rewriting and lifting approaches in the future.},
booktitle = {Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security},
pages = {85–95},
numpages = {11},
keywords = {stack symbolization, recompilation, machine learning, binary lifting},
location = {Virtual Event, Republic of Korea},
series = {AISec '21}
}

@inbook{10.1145/3676536.3676745,
author = {Mai, Jing and Zhang, Zuodong and Lin, Yibo and Wang, Runsheng and Huang, Ru},
title = {MORPH: More Robust ASIC Placement for Hybrid Region Constraint Management},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676745},
abstract = {Modern ASIC placement tools encompass three categories of region constraints: default regions, fence regions, and guide regions. Region constraints pose significant challenges to existing placement algorithms, compromising the versatility and robustness required for diverse placement workloads. In this work, we propose MORPH, a more robust ASIC placer designed for hybrid region constraints. We integrate hybrid region constraints into a unified multi-electrostatic formulation that features a shared electrostatics model and a binary-lifting-based region pruning algorithm. We develop a more robust nonlinear placement framework that includes second-order information and a hybrid-region-aware legalization algorithm to address convergence issues. Experiments on the ISPD 2015 benchmark suite demonstrate 5.6-14.3% HPWL improvement and 10--24% overflow reduction compared to state-of-the-art region-aware placers. Further experiments on the ISPD 2015 benchmark suite and its variants show that the proposed techniques can achieve over 30% HPWL improvement and up to a twofold reduction in overflow with more stable convergence.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {49},
numpages = {9}
}

@inproceedings{10.1145/3494110.3528244,
author = {Shafiei, Ali and Rimmer, Vera and Tsingenopoulos, Ilias and Desmet, Lieven and Joosen, Wouter},
title = {Position Paper: On Advancing Adversarial Malware Generation Using Dynamic Features},
year = {2022},
isbn = {9781450391795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494110.3528244},
doi = {10.1145/3494110.3528244},
abstract = {Along the evolution of malware detection systems, adversaries develop sophisticated evasion techniques that render malicious samples undetectable. Especially for ML-based detection systems, an effective approach is to craft adversarial malware to evade detection. In this position paper, we conduct a critical review of existing adversarial attacks against malware detection, and conclude that current research focuses mainly on evasion techniques against static analysis; generating adversarial Windows samples to evade dynamic analysis remains largely unexplored. In the context of black-box attack scenarios, we investigate an adversary's potential to carry out practical transformations in order to influence behavioral features observed by ML systems and security products. Moreover, we investigate the range of dynamic behavior transformations and identify critical properties and associated challenges that relate to feasibility, automation, technical costs and detection risks. Through this discussion, we propose solutions to important challenges and present promising paths for future research on evasive malware under dynamic analysis.},
booktitle = {Proceedings of the 1st Workshop on Robust Malware Analysis},
pages = {15–20},
numpages = {6},
keywords = {malware detection, evasion, dynamic analysis, adversarial attack},
location = {Nagasaki, Japan},
series = {WoRMA '22}
}

@inproceedings{10.1145/3589250.3596147,
author = {Lee, Sangrok and Lee, Jieun and Ko, Jaeyong and Shim, Jaewoo},
title = {Crosys: Cross Architectural Dynamic Analysis},
year = {2023},
isbn = {9798400701702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589250.3596147},
doi = {10.1145/3589250.3596147},
abstract = {Though there was a surge in the production of IoT devices, IoT malware analysis has remained a problem wanting for a clever solution. However, unlike PC and mobile, whose running environment is relatively standardized, IoT malware is rooted in Linux binary so that it can be built for various CPUs and with multiple libraries. For that, developing an effective dynamic analysis tool can be a challenging task.    In this paper, we present Crosys, a method for dynamic analysis of multi-architectural binaries in a single analysis host through intermediate language interpretation and binary rewriting. We explain how we elaborate binary lifting to assure both accuracy and stability. Then we propose cross-architectural dynamic analysis enabled by our work. In the end, we evaluated the stability of rewritten binary and the efficiency of dynamic analysis using technology.},
booktitle = {Proceedings of the 12th ACM SIGPLAN International Workshop on the State Of the Art in Program Analysis},
pages = {55–62},
numpages = {8},
keywords = {malware, dynamic analysis, cross architecture, binary rewriting},
location = {Orlando, FL, USA},
series = {SOAP 2023}
}

@inproceedings{10.1145/3691620.3695012,
author = {Zhan, Qi and Hu, Xing and Xia, Xin and Li, Shanping},
title = {REACT: IR-Level Patch Presence Test for Binary},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695012},
doi = {10.1145/3691620.3695012},
abstract = {Patch presence test is critical in software security to ensure that binary files have been patched for known vulnerabilities. It is challenging due to the semantic gap between the source code and the binary, and the small and subtle nature of patches. In this paper, we propose React, the first patch presence test approach on IR-level. Based on the IR code compiled from the source code and the IR code lifted from the binary, we first extract four types of feature (return value, condition, function call, and memory store) by executing the program symbolically. Then, we refine the features from the source code and rank them. Finally, we match the features to determine the presence of a patch with an SMT solver to check the equivalence of features at the semantic level.To evaluate our approach, we compare it with state-of-the-art approaches, BinXray and PS3, on a dataset containing binaries compiled from different compilers and optimization levels. Our experimental results show that React achieves scores of 0.88, 0.98, and 0.93, in terms of precision, recall, and F1 score, respectively. React outperforms the baselines by 39% and 12% in terms of the F1 score, while the testing speed of our approach is 2x faster than BinXray and 100x faster than PS3. Furthermore, we conduct an ablation study to evaluate the effectiveness of each component in React, which shows that SMT solver and refinement can contribute to 16% and 10% improvement in terms of the F1 score, respectively.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {381–392},
numpages = {12},
keywords = {patch presence test, security, program analysis},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3519939.3523719,
author = {Rocha, Rodrigo C. O. and Sprokholt, Dennis and Fink, Martin and Gouicem, Redha and Spink, Tom and Chakraborty, Soham and Bhatotia, Pramod},
title = {Lasagne: a static binary translator for weak memory model architectures},
year = {2022},
isbn = {9781450392655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3519939.3523719},
doi = {10.1145/3519939.3523719},
abstract = {The emergence of new architectures create a recurring challenge to ensure that existing programs still work on them. Manually porting legacy code is often impractical. Static binary translation (SBT) is a process where a program’s binary is automatically translated from one architecture to another, while preserving their original semantics. However, these SBT tools have limited support to various advanced architectural features. Importantly, they are currently unable to translate concurrent binaries. The main challenge arises from the mismatches of the memory consistency model specified by the different architectures, especially when porting existing binaries to a weak memory model architecture. In this paper, we propose Lasagne, an end-to-end static binary translator with precise translation rules between x86 and Arm concurrency semantics. First, we propose a concurrency model for Lasagne’s intermediate representation (IR) and formally proved mappings between the IR and the two architectures. The memory ordering is preserved by introducing fences in the translated code. Finally, we propose optimizations focused on raising the level of abstraction of memory address calculations and reducing the number of fences. Our evaluation shows that Lasagne reduces the number of fences by up to about 65%, with an average reduction of 45.5%, significantly reducing their runtime overhead.},
booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {888–902},
numpages = {15},
keywords = {Memory Model, Compiler, Binary Translation},
location = {San Diego, CA, USA},
series = {PLDI 2022}
}

@article{10.1145/3158117,
author = {Melo, Leandro T. C. and Ribeiro, Rodrigo G. and de Ara\'{u}jo, Marcus R. and Pereira, Fernando Magno Quint\~{a}o},
title = {Inference of static semantics for incomplete C programs},
year = {2017},
issue_date = {January 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {POPL},
url = {https://doi.org/10.1145/3158117},
doi = {10.1145/3158117},
abstract = {Incomplete source code naturally emerges in software development: during the design phase, while evolving, testing and analyzing programs. Therefore, the ability to understand partial programs is a valuable asset. However, this problem is still unsolved in the C programming language. Difficulties stem from the fact that parsing C requires, not only syntax, but also semantic information. Furthermore, inferring types so that they respect C's type system is a challenging task. In this paper we present a technique that lets us solve these problems. We provide a unification-based type inference capable of dealing with C intricacies. The ideas we present let us reconstruct partial C programs into complete well-typed ones. Such program reconstruction has several applications: enabling static analysis tools in scenarios where software components may be absent; improving static analysis tools that do not rely on build-specifications; allowing stub-generation and testing tools to work on snippets; and assisting programmers on the extraction of reusable data-structures out of the program parts that use them. Our evaluation is performed on source code from a variety of C libraries such as GNU's Coreutils, GNULib, GNOME's GLib, and GDSL; on implementations from Sedgewick's books; and on snippets from popular open-source projects like CPython, FreeBSD, and Git.},
journal = {Proc. ACM Program. Lang.},
month = dec,
articleno = {29},
numpages = {28},
keywords = {Type Inference, Partial Programs, Parsing, C Language}
}

@inproceedings{10.1145/3556384.3556404,
author = {Li, Changli},
title = {A Unifying Framework for Blind Source Separation Algorithms Based on Generalized Eigen-value Decomposition},
year = {2022},
isbn = {9781450396912},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3556384.3556404},
doi = {10.1145/3556384.3556404},
abstract = {In this paper, we present a unifying framework for linear blind source separation (BSS) via generalized eigen-value decomposition (GEVD). The derived algorithms via GEVD for BSS turn the underlying optimization problem into a GEVD problem, thus they can be easily implemented. There are two classes of algorithms via GEVD for BSS. The first class of algorithm directly accomplishes the GEVD of a matrix pencil which is composed of observed signals from sensors in a practical system. The second class of algorithm constructs some cost function with a form of generalized Rayleigh quotient (GRQ), and its corresponding separation vector can be easily obtained by GEVD. However, algorithms of this type lack reasonable explanation. In this paper, we focus on proposing a unifying framework for BSS via GEVD. Besides, it is pointed out that their separability relies on source signals’ non-property: non-Gaussianity (statistical non-property), non-stationarity (time non-property), or non-whiteness (frequency non-property). Hence, the non-property is the essential characteristic of all GEVD-based algorithms for BSS. Under the proposed unifying framework, we prove that any generalized eigenvector of the GEVD problem is the same as the de-mixing vector which can successfully separate one of the original source signals. Finally, simulation experiments are made and theoretical explanation for our unifying framework is given.},
booktitle = {Proceedings of the 2022 5th International Conference on Signal Processing and Machine Learning},
pages = {124–131},
numpages = {8},
location = {Dalian, China},
series = {SPML '22}
}

@inproceedings{10.1145/2745754.2745770,
author = {Grahne, G\"{o}sta and Moallemi, Ali and Onet, Adrian},
title = {Recovering Exchanged Data},
year = {2015},
isbn = {9781450327572},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2745754.2745770},
doi = {10.1145/2745754.2745770},
abstract = {The inversion of data exchange mappings is one of the thorniest issues in data exchange. In this paper we study inverse data exchange from a novel perspective. Previous work has dealt with the static problem of finding a target-to-source mapping that captures the "inverse" of a source-to-target data exchange mapping. As we will show this approach has some drawbacks when it come actually applying the inverse mapping in order to recover a source instance from a materialized target instance. More specifically (1): As is well known, the inverse mappings have to be expressed in a much more powerful language than the mappings they invert. (2): There are simple cases where a source instance computed by the inverse mapping misses sound information that one may easily obtain when the particular target instance is available. (3): In some cases the inverse mapping can introduce unsound information in the recovered source instance.To overcome these drawbacks we focus on the dynamic problem of recovering the source instance using the source-to-target mapping as well as a given target instance. Similarly to the problem of finding "good" target instances in forward data exchange, we look for "good" source instances to restore, i.e. to materialize. For this we introduce a new semantics to capture instance based recovery. We then show that given a target instance and a source-to-target mapping expressed as set of tuple generating dependencies, there are chase-based algorithms to compute a representative finite set of source instances that can be used to get certain answers to any union of conjunctive source queries. We also show that the instance based source recovery problem unfortunately is coNP-complete. We therefore present a polynomial time algorithm that computes a "small" set of source instances that can be used to get sound certain answers to any union of conjunctive source queries. This algorithm is then extended to extract more sound information for the case when only conjunctive source queries are allowed.},
booktitle = {Proceedings of the 34th ACM SIGMOD-SIGACT-SIGAI  Symposium on Principles of Database Systems},
pages = {105–116},
numpages = {12},
keywords = {incomplete databases, date exchange, data repair, complexity, chase},
location = {Melbourne, Victoria, Australia},
series = {PODS '15}
}

