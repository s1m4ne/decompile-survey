@INPROCEEDINGS{8109451,
  author={Kostelanský, Jozef and Dedera, Ľubomír},
  booktitle={2017 Communication and Information Technologies (KIT)}, 
  title={An evaluation of output from current Java bytecode decompilers: Is it Android which is responsible for such quality boost?}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Countless various malware families provide huge variety of functionalities which allow them to do many malicious activities. This conditions led to development of many different analysis methods. In this paper, we focused on reverse engineering, which is elementary part of static analysis. We evaluate current Java bytecode decompilers. We evaluate the output from current Java bytecode decompilers in this paper using test samples and metrics from previous surveys in 2003 and in 2009. Quality boost is really significant between actual results and the results based on research from 2009, in contrast with only slight improvement between researches in 2003 and 2009. Even though we were witnesses of rapid quality boost, still any of the decompilers pass all the tests acceptably. We also give reasons why outdated decompilers from previous research perform almost same.},
  keywords={Java;Malware;Casting;Androids;Humanoid robots;Measurement;java;reverse engineering;bytecode;decompilation},
  doi={10.23919/KIT.2017.8109451},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8054016,
  author={Lv, Xuefeng and Xie, Yaobin and Zhu, Xiaodong and Ren, Lu},
  booktitle={2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, 
  title={A technique for bytecode decompilation of PLC program}, 
  year={2017},
  volume={},
  number={},
  pages={252-257},
  abstract={Program logical controllers (PLCs) are the kernel equipment of industrial control system (ICS) as they directly monitor and control industrial processes. Recently, ICS is suffering from various cyber threats, which may lead to significant consequences due to its inherent characteristics. In IT system, decompilation is a useful method to detect intrusion or to discovery vulnerabilities, however, it has yet not been developed in ICS. In this work, we present a technique to decompile the bytecode of PLC program. By introducing the instruction template and operand template, we propose a decompiling framework, which is validated by 11 PLC programs. In disassembling experiments, the present framework can cover all instructions with disassembling accuracy reaching 100%, this fully shows that our framework is able to effectively decompile the bytecode of PLC programs.},
  keywords={Integrated circuits;Computer languages;Instruction sets;Algorithm design and analysis;Encoding;Libraries;Industrial control;programmable logical controller;bytecode;decompilation;mapping rules},
  doi={10.1109/IAEAC.2017.8054016},
  ISSN={},
  month={March},}@INPROCEEDINGS{11208400,
  author={Duţu, Teodor-Ştefan and Deaconescu, Adrian-Răzvan and Peca, Ludmila},
  booktitle={2025 24th RoEduNet Conference: Networking in Education and Research (RoEduNet)}, 
  title={Improving iOS Sandbox Profile Decompilation Accuracy}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Mobile devices have become ubiquitous, with iOS being the second most popular mobile operating system on the market [1]. One method iOS uses to ensure the security of its apps is through sandboxing. This mechanism is implemented as a set of rules compiled into binary files that lie inside the OS firmware and which are not made public by Apple. Thus, security engineers require third-party tools to decompile and then visualize the contents of the profiles mentioned above. This paper presents a validation framework for iOS sandbox profile decompilers, specifically targeting the SandBlaster tool. Our approach represents sandbox profiles as dependency graphs and compares decompiled profiles with reference implementations compiled from Sandbox Profile Language (SBPL) representations using SandScout. We evaluated our framework in iOS versions 7–10, analyzing both individual profiles and bundled profile collections. The results demonstrate 100% precision and recall for iOS 7–8 profiles, 90-100% for iOS 9, and 75-100% for iOS 10. We also optimised a performance bottleneck in SandBlaster's node matching algorithm, reducing decompilation time from over 7 hours to under 5 minutes.},
  keywords={Visualization;Accuracy;Operating systems;Education;Mobile communication;Security;Smart phones;Microprogramming;iOS;Sandboxing},
  doi={10.1109/RoEduNet68395.2025.11208400},
  ISSN={2247-5443},
  month={Sep.},}@INPROCEEDINGS{9425937,
  author={Mauthe, Noah and Kargén, Ulf and Shahmehri, Nahid},
  booktitle={2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={A Large-Scale Empirical Study of Android App Decompilation}, 
  year={2021},
  volume={},
  number={},
  pages={400-410},
  abstract={Decompilers are indispensable tools in Android malware analysis and app security auditing. Numerous academic works also employ an Android decompiler as the first step in a program analysis pipeline. In such settings, decompilation is frequently regarded as a "solved" problem, in that it is simply expected that source code can be accurately recovered from an app. While a large proportion of methods in an app can typically be decompiled successfully, it is common that at least some methods fail to decompile. In order to better understand the practical applicability of techniques in which decompilation is used as part of an automated analysis, it is important to know the actual expected failure rate of Android decompilation. To this end, we have performed what is, to the best of our knowledge, the first large-scale study of Android decompilation failure rates. We have used three sets of apps, consisting of, respectively, 3,018 open-source apps, 13,601 apps from a recent crawl of Google Play, and a collection of 24,553 malware samples. In addition to the state-of-the-art Dalvik bytecode decompiler jadx, we used three popular Java decompilers. While jadx achieves an impressively low failure rate of only 0.02% failed methods per app on average, we found that it manages to recover source code for all methods in only 21% of the Google Play apps.We have also sought to better understand the degree to which in-the-wild obfuscation techniques can prevent decompilation. Our empirical evaluation, complemented with an indepth manual analysis of a number of apps, indicate that code obfuscation is quite rarely encountered, even in malicious apps. Moreover, decompilation failures mostly appear to be caused by technical limitations in decompilers, rather than by deliberate attempts to thwart source-code recovery by obfuscation. This is an encouraging finding, as it indicates that near-perfect Android decompilation is, at least in theory, achievable, with implementation-level improvements to decompilation tools.},
  keywords={Java;Conferences;Pipelines;Process control;Manuals;Tools;Malware;Android;mobile apps;decompilation;obfuscation;reverse engineering;malware},
  doi={10.1109/SANER50967.2021.00044},
  ISSN={1534-5351},
  month={March},}@INPROCEEDINGS{9631736,
  author={Pavel, Sharikov and Andrey, Krasov and Artem, Gelfand and Ernest, Birikh},
  booktitle={2021 13th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)}, 
  title={A Technique for Detecting the Substitution of a Java-Module of an Information System Prone to Pharming with Using a Hidden Embedding of a Digital Watermark Resistant to Decompilation}, 
  year={2021},
  volume={},
  number={},
  pages={219-223},
  abstract={The relevance of the problem under study is due to the rapid development of the java programming language, a large number of commercial applications written in this programming language. The purpose of the article is to develop a methodology that allows you to determine the java-module of the information system, which does not contain a hidden digital watermark. It is necessary that the digital watermark is not damaged during the decompilation of the entire system in order to replace the java module, and that the class files and the entire information system function unchanged. Thus, at first, a digital watermark is hidden in all java-modules of the information system. Next, we check the resistance of the digital watermark to decompilation attacks with block substitution. The materials of the article can be useful in the implementation of hidden embedding of a digital watermark in the class files of a large java module.},
  keywords={Resistance;Java;Computer languages;Codes;Watermarking;Writing;Virtual machining;bytecode;java-module;java;digital watermark;decompilation attack;decompilation;java module substitution;intruder model},
  doi={10.1109/ICUMT54235.2021.9631736},
  ISSN={2157-023X},
  month={Oct},}@INBOOK{10649756,
  author={Domas, Stephanie and Domas, Christopher},
  booktitle={x86 Software Reverse-Engineering, Cracking, and Counter-Measures}, 
  title={Decompilation and Architecture}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={Summary <p>This chapter explores the steps necessary to get started reverse engineering an application. Decompilation is crucial to transforming an application from machine code to something that can be read and understood by humans. For many programming languages, full decompilation is impossible. These languages build code directly to machine code, and some information, such as variable names, is lost in the process. JIT compilation also makes reverse engineering these applications much easier. Unlike true machine code programs, JIT&#x2010;compiled programs can often be converted to source code. All high&#x2010;level languages are eventually converted into a series of bits called machine code. Assembly code is designed to be a human&#x2010;readable version of machine code. A microarchitecture describes how a particular ISA is implemented on a processor. Reduced instruction set computing architectures define a small number of simpler instructions.</p>},
  keywords={Codes;Computer architecture;Source coding;Reverse engineering;Java;Computer languages;Computers},
  doi={10.1002/9781394277131.ch1},
  ISSN={},
  publisher={Wiley},
  isbn={9781394199907},
  url={https://ieeexplore.ieee.org/document/10649756},}@INPROCEEDINGS{10123564,
  author={Liu, Xia and Hua, Baojian and Wang, Yang and Pan, Zhizhong},
  booktitle={2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={An Empirical Study of Smart Contract Decompilers}, 
  year={2023},
  volume={},
  number={},
  pages={1-12},
  abstract={Smart contract decompilers, converting smart contract bytecode into smart contract source code, have been used extensively in many scenarios such as binary code analysis, reverse engineering, and security studies. However, existing studies, as well as industrial engineering practices, all assumed that smart contract decompilers are reliable and trustworthy, to generate correct and semantically equivalent source code from binaries. Unfortunately, whether such an assumption truly holds in practice is still unknown.In this paper, we conduct, to the best of our knowledge, the first and most comprehensive large-scale empirical study of smart contract decompilers, to gain an understanding of the reliability, limitations, and remaining research challenges of state-of-the-art smart contract decompilation tools. We first designed and implemented a software prototype SOLINSIGHT, then used it to study 5 state-of-the-art smart contract decompilers. We obtained important findings and insights from empirical results, such as: 1) we proposed 3 root causes leading to decompiler failures; 2) we revealed 2 reasons hurting performance; 3) we identified 3 root causes affecting decompilation effectiveness; 4) we proposed a measurement metric for completeness; and 5) we investigated the resilience of contract decompilers against program transformations. We suggest that: 1) decompiler builders should enhance decompilers in terms of effectiveness, performance, and completeness; and 2) security researchers should select appropriate decompilers based on the suggestions in this study. We believe these findings and suggestions will help decompiler builders, contract developers, and security researchers, by providing better guidelines for contract decompiler studies.},
  keywords={Measurement;Source coding;Smart contracts;Reverse engineering;Prototypes;Reliability engineering;Software;Empirical study;Smart contracts;Decompilation},
  doi={10.1109/SANER56733.2023.00011},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{9464996,
  author={Broukhis, Leonid A.},
  booktitle={2020 Fifth International Conference “History of Computing in the Russia, former Soviet Union and Council for Mutual Economic Assistance countries” (SORUCOM)}, 
  title={Notes on Simulating the BESM-6 and Decompiling Pascal Programs}, 
  year={2020},
  volume={},
  number={},
  pages={67-71},
  abstract={The article describes the author's source of interest in the BESM-6 computer, its software, and the history of development of simulators of the BESM-6 architecture, and provides comments and observations regarding decompilation of a Pascal compiler for the BESM-6 and of the strategy game Kalah.},
  keywords={Program processors;Software algorithms;Software;History;Software measurement;Task analysis;Optimization;BESM-6;simulation;DISPAK;Dubna monitor system;ALGOL-60;FORTRAN;Pascal},
  doi={10.1109/SORUCOM51654.2020.9464996},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8668959,
  author={Yoo, Dongkyun and Shin, Yeonghun and Kim, SungJin and Kim, HyunJin and Kwon, SungMoon and Shon, Taeshik},
  booktitle={2019 International Conference on Platform Technology and Service (PlatCon)}, 
  title={Digital Forensic Artifact Collection Technique using Application Decompilation}, 
  year={2019},
  volume={},
  number={},
  pages={1-3},
  abstract={Nowadays, many applications tend to collect user profile, such as location, usage trace and so on, even if it is not malicious. This information can be important clues in the criminal investigation. So, the technique is needed which extract artifacts from applications using decompilation. We describe a method for selecting and analyzing forensic artifacts from the Android application with a share of over 80% of mobile devices. Based on the static analysis method, we propose a method for automatically collecting forensic artifact. The effectiveness of the proposed idea is proved by simulation.},
  keywords={Smart phones;Java;Static analysis;Tools;Servers;Digital forensics;Reverse Engineering;APK Decompilation},
  doi={10.1109/PlatCon.2019.8668959},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8330222,
  author={Katz, Deborah S. and Ruchti, Jason and Schulte, Eric},
  booktitle={2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Using recurrent neural networks for decompilation}, 
  year={2018},
  volume={},
  number={},
  pages={346-356},
  abstract={Decompilation, recovering source code from binary, is useful in many situations where it is necessary to analyze or understand software for which source code is not available. Source code is much easier for humans to read than binary code, and there are many tools available to analyze source code. Existing decompilation techniques often generate source code that is difficult for humans to understand because the generated code often does not use the coding idioms that programmers use. Differences from human-written code also reduce the effectiveness of analysis tools on the decompiled source code. To address the problem of differences between decompiled code and human-written code, we present a novel technique for decompiling binary code snippets using a model based on Recurrent Neural Networks. The model learns properties and patterns that occur in source code and uses them to produce decompilation output. We train and evaluate our technique on snippets of binary machine code compiled from C source code. The general approach we outline in this paper is not language-specific and requires little or no domain knowledge of a language and its properties or how a compiler operates, making the approach easily extensible to new languages and constructs. Furthermore, the technique can be extended and applied in situations to which traditional decompilers are not targeted, such as for decompilation of isolated binary snippets; fast, on-demand decompilation; domain-specific learned decompilation; optimizing for readability of decompilation; and recovering control flow constructs, comments, and variable or function names. We show that the translations produced by this technique are often accurate or close and can provide a useful picture of the snippet's behavior.},
  keywords={Recurrent neural networks;Tools;Training;Binary codes;Natural languages;Decoding;Data models;decompilation;recurrent neural networks;translation;deep learning},
  doi={10.1109/SANER.2018.8330222},
  ISSN={},
  month={March},}@INPROCEEDINGS{7880502,
  author={Ragkhitwetsagul, Chaiyong and Krinke, Jens},
  booktitle={2017 IEEE 11th International Workshop on Software Clones (IWSC)}, 
  title={Using compilation/decompilation to enhance clone detection}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={We study effects of compilation and decompilation to code clone detection in Java. Compilation/decompilation canonicalise syntactic changes made to source code and can be used as source code normalisation. We used NiCad to detect clones before and after decompilation in three open source software systems, JUnit, JFreeChart, and Tomcat. We filtered and compared the clones in the original and decompiled clone set and found that 1,201 clone pairs (78.7%) are common between the two sets while 326 pairs (21.3%) are only in one of the sets. A manual investigation identified 325 out of the 326 pairs as true clones. The 252 original-only clone pairs contain a single false positive while the 74 decompiled-only clone pairs are all true positives. Many clones in the original source code that are detected only after decompilation are type-3 clones that are dicult to detect due to added or deleted statements, keywords, package names; flipped if-else statements; or changed loops. We suggest to use decompilation as normalisation to compliment clone detection. By combining clones found before and after decompilation, one can achieve higher recall without losing precision.},
  keywords={Cloning;Java;Detectors;Software systems;Manuals;Open source software},
  doi={10.1109/IWSC.2017.7880502},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{8930870,
  author={Harrand, Nicolas and Soto-Valero, César and Monperrus, Martin and Baudry, Benoit},
  booktitle={2019 19th International Working Conference on Source Code Analysis and Manipulation (SCAM)}, 
  title={The Strengths and Behavioral Quirks of Java Bytecode Decompilers}, 
  year={2019},
  volume={},
  number={},
  pages={92-102},
  abstract={During compilation from Java source code to bytecode, some information is irreversibly lost. In other words, compilation and decompilation of Java code is not symmetric. Consequently, the decompilation process, which aims at producing source code from bytecode, must establish some strategies to reconstruct the information that has been lost. Modern Java decompilers tend to use distinct strategies to achieve proper decompilation. In this work, we hypothesize that the diverse ways in which bytecode can be decompiled has a direct impact on the quality of the source code produced by decompilers. We study the effectiveness of eight Java decompilers with respect to three quality indicators: syntactic correctness, syntactic distortion and semantic equivalence modulo inputs. This study relies on a benchmark set of 14 real-world open-source software projects to be decompiled (2041 classes in total). Our results show that no single modern decompiler is able to correctly handle the variety of bytecode structures coming from real-world programs. Even the highest ranking decompiler in this study produces syntactically correct output for 84% of classes of our dataset and semantically equivalent code output for 78% of classes.},
  keywords={Java;Syntactics;Semantics;Distortion;Uniform resource locators;Measurement;Program processors;Java bytecode;decompilation;reverse engineering;source code analysis},
  doi={10.1109/SCAM.2019.00019},
  ISSN={2470-6892},
  month={Sep.},}@INPROCEEDINGS{11023256,
  author={Wiedemeier, Josh and Tarbet, Elliot and Zheng, Max and Ko, Sangsoo and Ouyang, Jessica and Cha, Sang Kil and Jee, Kangkook},
  booktitle={2025 IEEE Symposium on Security and Privacy (SP)}, 
  title={PyLingual: Toward Perfect Decompilation of Evolving High-Level Languages}, 
  year={2025},
  volume={},
  number={},
  pages={2976-2994},
  abstract={Python is one of the most popular programming languages among both industry developers and malware authors. Despite demand for Python decompilers, community efforts to maintain automatic Python decompilation tools have been hindered by Python's aggressive language improvements and unstable bytecode specification. Every year, language features are added, code generation undergoes significant changes, and opcodes are added, deleted, and modified. Our research aims to integrate Natural Language Processing (NLP) techniques with classical Programming Language (PL) theory to create a Python decompiler that accomodates evolving language features and changes to the bytecode specification with minimal human maintenance effort. PyLINGUAL plugs in data-driven NLP components to a version-agnostic core to automatically absorb superficial bytecode and compiler changes, while leveraging programmatic components for abstract control flow reconstruction. To establish trust in the decompilation results, we introduce a stringent correctness measure based on “perfect decompilation”, a statically verifiable refinement of semantic equivalence. We demonstrate the efficacy of our approach with extensive real-world datasets of benign and malicious Python source code and their corresponding compiled PYC binaries. Our research makes three major contributions: (1) we present PyLINGUAL, a scalable, data-driven decompilation framework with state-of-the-art support for Python versions 3.6 through 3.12, improving the perfect decompilation rate by an average of 45% over the best results of existing decompiler across four datasets; (2) we provide a Python decompiler evaluation framework that verifies decompilation results with perfect decompilation; and (3) we launch PyLINGUAL as a public online service.},
  keywords={Codes;Translation;Program processors;Source coding;Semantics;Reverse engineering;Syntactics;Natural language processing;Security;Python;python;decompiler;nlp;reverse engineering},
  doi={10.1109/SP61157.2025.00052},
  ISSN={2375-1207},
  month={May},}@INPROCEEDINGS{8811905,
  author={Grech, Neville and Brent, Lexi and Scholz, Bernhard and Smaragdakis, Yannis},
  booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)}, 
  title={Gigahorse: Thorough, Declarative Decompilation of Smart Contracts}, 
  year={2019},
  volume={},
  number={},
  pages={1176-1186},
  abstract={The rise of smart contracts - autonomous applications running on blockchains - has led to a growing number of threats, necessitating sophisticated program analysis. However, smart contracts, which transact valuable tokens and cryptocurrencies, are compiled to very low-level bytecode. This bytecode is the ultimate semantics and means of enforcement of the contract. We present the Gigahorse toolchain. At its core is a reverse compiler (i.e., a decompiler) that decompiles smart contracts from Ethereum Virtual Machine (EVM) bytecode into a highlevel 3-address code representation. The new intermediate representation of smart contracts makes implicit data- and control-flow dependencies of the EVM bytecode explicit. Decompilation obviates the need for a contract's source and allows the analysis of both new and deployed contracts. Gigahorse advances the state of the art on several fronts. It gives the highest analysis precision and completeness among decompilers for Ethereum smart contracts - e.g., Gigahorse can decompile over 99.98% of deployed contracts, compared to 88% for the recently-published Vandal decompiler and under 50% for the state-of-the-practice Porosity decompiler. Importantly, Gigahorse offers a full-featured toolchain for further analyses (and a “batteries included” approach, with multiple clients already implemented), together with the highest performance and scalability. Key to these improvements is Gigahorse's use of a declarative, logic-based specification, which allows high-level insights to inform low-level decompilation.},
  keywords={Smart contracts;Blockchain;Virtual machining;Task analysis;Java;Security;Ethereum;Blockchain;Decompilation;Program Analysis;Security},
  doi={10.1109/ICSE.2019.00120},
  ISSN={1558-1225},
  month={May},}@INPROCEEDINGS{10179314,
  author={Han, HyungSeok and Kyea, JeongOh and Jin, Yonghwi and Kang, Jinoh and Pak, Brian and Yun, Insu},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)}, 
  title={QueryX: Symbolic Query on Decompiled Code for Finding Bugs in COTS Binaries}, 
  year={2023},
  volume={},
  number={},
  pages={3279-3295},
  abstract={Extensible static checking tools, such as Sys and CodeQL, have successfully discovered bugs in source code. These tools allow analysts to write application-specific rules, referred to as queries. These queries can leverage the domain knowledge of analysts, thereby making the analysis more accurate and scalable. However, the majority of these tools are inapplicable to binary-only analysis. One exception, joern, translates a binary code into decompiled code and feeds the decompiled code into an ordinary C code analyzer. However, this approach is not sufficiently precise for symbolic analysis, as it overlooks the unique characteristics of decompiled code. While binary analysis platforms, such as angr, support symbolic analysis, analysts must understand their intermediate representations (IRs) although they are mostly working with decompiled code.In this paper, we propose a precise and scalable symbolic analysis called fearless symbolic analysis that uses intuitive queries for binary code and implement this in QueryX. To make the query intuitive, QueryX enables analysts to write queries on top of decompiled code instead of IRs. In particular, QueryX supports callbacks on decompiled code, using which analysts can control symbolic analysis to discover bugs in the code. For precise analysis, we lift decompiled code into our IR named DNR and perform symbolic analysis on DNR while considering the characteristics of the decompiled code. Notably, DNR is only used internally such that it allows analysts to write queries regardless of using DNR. For scalability, QueryX automatically reduces control-flow graphs using callbacks and ordering dependencies between callbacks that are specified in the queries. We applied QueryX to the Windows kernel, the Windows system service, and an automotive binary. As a result, we found 15 unique bugs including 10 CVEs and earned $180,000 from the Microsoft bug bounty program.},
  keywords={Privacy;Codes;Scalability;Source coding;Computer bugs;Binary codes;Security},
  doi={10.1109/SP46215.2023.10179314},
  ISSN={2375-1207},
  month={May},}@INPROCEEDINGS{10179370,
  author={Ahad, Ali and Jung, Chijung and Askar, Ammar and Kim, Doowon and Kim, Taesoo and Kwon, Yonghwi},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)}, 
  title={Pyfet: Forensically Equivalent Transformation for Python Binary Decompilation}, 
  year={2023},
  volume={},
  number={},
  pages={3296-3313},
  abstract={Decompilation is a crucial capability in forensic analysis, facilitating analysis of unknown binaries. The recent rise of Python malware has brought attention to Python decompilers that aim to obtain source code representation from a Python binary. However, Python decompilers fail to handle various binaries, limiting their capabilities in forensic analysis.This paper proposes a novel solution that transforms a decompilation error-inducing Python binary into a decompilable binary. Our key intuition is that we can resolve the decompilation errors by transforming error-inducing code blocks in the input binary into another form. The core of our approach is the concept of Forensically Equivalent Transformation (FET) which allows non-semantic preserving transformation in the context of forensic analysis. We carefully define the FETs to minimize their undesirable consequences while fixing various error-inducing instructions that are difficult to solve when preserving the exact semantics. We evaluate the prototype of our approach with 17,117 real-world Python malware samples causing decompilation errors in five popular decompilers. It successfully identifies and fixes 77,022 errors. Our approach also handles anti-analysis techniques, including opcode remapping, and helps migrate Python 3.9 binaries to 3.8 binaries.},
  keywords={Privacy;Limiting;Forensics;Source coding;Semantics;Field effect transistors;Prototypes;Reverse-Engineering;Decompilation;Binary-Transformation;Python-Malware},
  doi={10.1109/SP46215.2023.10179370},
  ISSN={2375-1207},
  month={May},}@ARTICLE{10967090,
  author={Sateanpattanakul, Siwadol and Jetpipattanapong, Duangpen and Mathulaprangsan, Seksan},
  journal={Journal of Mobile Multimedia}, 
  title={Java Bytecode Control Flow Classification: Framework for Guiding Java Decompilation}, 
  year={2022},
  volume={18},
  number={2},
  pages={179-202},
  abstract={Decompilation is the main process of software development, which is very important when a program tries to retrieve lost source codes. Although decompiling Java bytecode is easier than bytecode, many Java decompilers cannot recover originally lost sources, especially the selection statement, i.e., if statement. This deficiency affects directly decompilation performance. In this paper, we propose the methodology for guiding Java decompiler to deal with the aforementioned problem. In the framework, Java bytecode is transformed into two kinds of features called frame feature and latent semantic feature. The former is extracted directly from the bytecode. The latter is achieved by two-step transforming the Java bytecode to bigram and then term frequency-inverse document frequency (TFIDF). After that, both of them are fed to the genetic algorithm to reduce their dimensions. The proposed feature is achieved by converting the selected TFIDF to a latent semantic feature and concatenating it with the selected frame feature. Finally, KNN is used to classify the proposed feature. The experimental results show that the decompilation accuracy is 93.68 percent, which is obviously better than Java Decompiler.},
  keywords={Java;Accuracy;Source coding;Semantics;Nearest neighbor methods;Feature extraction;Genetic algorithms;Software development management;Indexing;Decompilation;feature selection;latent semantic indexing;genetic algorithm},
  doi={10.13052/jmm1550-4646.1822},
  ISSN={1550-4654},
  month={March},}@INPROCEEDINGS{10986108,
  author={Sharikov, Pavel and Krasov, Andrey and Chechulin, Andrey},
  booktitle={2025 International Russian Smart Industry Conference (SmartIndustryCon)}, 
  title={Methodology for Embedding a Digital Watermark in Java Application Class Files Resistant to Decompilation Attacks Aimed at Its Destruction}, 
  year={2025},
  volume={},
  number={},
  pages={906-911},
  abstract={This paper examines the development of a methodology for embedding a digital watermark in class files by replacing bytecode opcodes and adding certain Java programming language constructs that hinder decompilation. The possible actions of an intruder are considered, along with the methods by which an attacker might obtain a class file or a Java application. An analysis of existing decompilers is conducted, with examples of programming language constructs that lead to decompilation errors or incorrect decompilation results. The principle of the methodology is demonstrated, and experiments are conducted to confirm that after embedding the digital watermark using the developed approach, it remains resilient to decompilation attacks aimed at its removal. The compiled class file containing the modified bytecode is analyzed. It is proven that the logic of the Java application remains unchanged after editing the bytecode of the class file and recompiling it. Certain constructs and code design patterns are examined, demonstrating that specific constructs in the source code increases the likelihood of incorrect decompilation of Java application class files, the inability to recompile the decompiled code.},
  keywords={Resistance;Java;Computer languages;Codes;Source coding;Watermarking;Software;Logic;Usability;Resilience;Java;bytecode;digital watermark;decompilation attack;class file;obfuscation},
  doi={10.1109/SmartIndustryCon65166.2025.10986108},
  ISSN={},
  month={March},}@INPROCEEDINGS{8952404,
  author={Lacomis, Jeremy and Yin, Pengcheng and Schwartz, Edward and Allamanis, Miltiadis and Le Goues, Claire and Neubig, Graham and Vasilescu, Bogdan},
  booktitle={2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={DIRE: A Neural Approach to Decompiled Identifier Naming}, 
  year={2019},
  volume={},
  number={},
  pages={628-639},
  abstract={The decompiler is one of the most common tools for examining binaries without corresponding source code. It transforms binaries into high-level code, reversing the compilation process. Decompilers can reconstruct much of the information that is lost during the compilation process (e.g., structure and type information). Unfortunately, they do not reconstruct semantically meaningful variable names, which are known to increase code understandability. We propose the Decompiled Identifier Renaming Engine (DIRE), a novel probabilistic technique for variable name recovery that uses both lexical and structural information recovered by the decompiler. We also present a technique for generating corpora suitable for training and evaluating models of decompiled code renaming, which we use to create a corpus of 164,632 unique x86-64 binaries generated from C projects mined from GitHub. Our results show that on this corpus DIRE can predict variable names identical to the names in the original source code up to 74.3% of the time.},
  keywords={Tools;Recurrent neural networks;Reverse engineering;Training;Software;Analytical models;Decompilation;Deep learning},
  doi={10.1109/ASE.2019.00064},
  ISSN={2643-1572},
  month={Nov},}@INPROCEEDINGS{10123452,
  author={Al-Kaswan, Ali and Ahmed, Toufique and Izadi, Maliheh and Sawant, Anand Ashok and Devanbu, Premkumar and van Deursen, Arie},
  booktitle={2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Extending Source Code Pre-Trained Language Models to Summarise Decompiled Binaries}, 
  year={2023},
  volume={},
  number={},
  pages={260-271},
  abstract={Binary reverse engineering is used to understand and analyse programs for which the source code is unavailable. Decompilers can help, transforming opaque binaries into a more readable source code-like representation. Still, reverse engineering is difficult and costly, involving considering effort in labelling code with helpful summaries. While the automated summarisation of decompiled code can help reverse engineers understand and analyse binaries, current work mainly focuses on summarising source code, and no suitable dataset exists for this task. In this work, we extend large pre-trained language models of source code to summarise de-compiled binary functions. Further-more, we investigate the impact of input and data properties on the performance of such models. Our approach consists of two main components; the data and the model. We first build CAPYBARA, a dataset of 214K decompiled function-documentation pairs across various compiler optimisations. We extend CAPYBARA further by removing identifiers, and deduplicating the data. Next, we fine-tune the CodeT5 base model with CAPYBARA to create BinT5. BinT5 achieves the state-of-the-art BLEU-4 score of 60.83, 58.82 and, 44.21 for summarising source, decompiled, and obfuscated decompiled code, respectively. This indicates that these models can be extended to decompiled binaries successfully. Finally, we found that the performance of BinT5 is not heavily dependent on the dataset size and compiler optimisation level. We recommend future research to further investigate transferring knowledge when working with less expressive input formats such as stripped binaries.},
  keywords={Source coding;Reverse engineering;Binary codes;Transformers;Data models;Software;Labeling;Task analysis;Optimization;Synthetic data;Decompilation;Binary;Reverse Engineering;Summarization;Deep Learning;Pre-trained Language Models;CodeT5;Transformers},
  doi={10.1109/SANER56733.2023.00033},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{9589721,
  author={Alsabbagh, Wael and Langendörfer, Peter},
  booktitle={IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={A Control Injection Attack against S7 PLCs -Manipulating the Decompiled Code}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper, we discuss an approach which allows an attacker to modify the control logic program that runs in S7 PLCs in its high-level decompiled format. Our full attack-chain compromises the security measures of PLCs, retrieves the machine bytecode of the target device, and employs a decompiler to convert the stolen compiled bytecode (low-level) to its decompiled version (high-level) e.g. Ladder Diagram LAD. As the LAD code exposes the structure and semantics of the control logic, our attack also manipulates the LAD code based on the attacker’s understanding to the physical process causing abnormal behaviors of the system that we target. Finally, it converts the infected LAD code to its executable version i.e. machine bytecode that can run on the PLC using a compiler before pushing the malicious code back to the PLC. For a real scenario, we implemented our full attack-chain on a small industrial setting using real S7-300 PLCs, and built the database (for our decompiler and compiler) using 108 different control logic programs of varying complexity, ranging from simple programs consisting of a few instructions to more complex ones including multi functions, sub-functions and data blocks. We tested and evaluated the accuracy of our decompiler and compiler on 5 random programs written for real industrial applications. Our experimental results showed that an external adversary is able to infect S7 PLCs successfully. We eventually suggest some potential mitigation approaches to secure systems against such a threat.},
  keywords={Industrial electronics;Electric potential;Codes;Program processors;Semantics;Programmable logic devices;Process control;Programmable Logic Controllers (PLCs);Control Injection Attack;Decompiler;Compiler;Ladder Diagram},
  doi={10.1109/IECON48115.2021.9589721},
  ISSN={2577-1647},
  month={Oct},}@ARTICLE{11207559,
  author={Liao, Zeqin and Nan, Yuhong and Gao, Zixu and Liang, Henglong and Hao, Sicheng and Ren, Peifan and Zheng, Zibin},
  journal={IEEE Transactions on Software Engineering}, 
  title={Augmenting Smart Contract Decompiler Output Through Fine-Grained Dependency Analysis and LLM-Facilitated Semantic Recovery}, 
  year={2025},
  volume={51},
  number={12},
  pages={3574-3590},
  abstract={Decompiler is a specialized type of reverse engineering tool extensively employed in program analysis tasks, particularly in program comprehension and vulnerability detection. However, current Solidity smart contract decompilers face significant limitations in reconstructing the original source code. In particular, the bottleneck of SOTA decompilers lies in inaccurate function identification, incorrect variable type recovery, and missing contract attributes. These deficiencies hinder downstream tasks and understanding of the program logic. To address these challenges, we propose SmartHalo, a new framework that enhances decompiler output by combining static analysis (SA) and large language models (LLM). SmartHalo leverages the complementary strengths of SA’s accuracy in control and data flow analysis and LLM’s capability in semantic prediction. More specifically, SmartHalo constructs a new data structure - Dependency Graph (DG), to extract semantic dependencies via static analysis. Then, it takes DG to create prompts for LLM optimization. Finally, the correctness of LLM outputs is validated through symbolic execution and formal verification. Evaluation on a dataset consisting of 465 randomly selected smart contract functions shows that SmartHalo significantly improves the quality of the decompiled code, compared to SOTA decompilers (e.g., Gigahorse). Notably, integrating GPT-4o mini with SmartHalo further enhances its performance, achieving a precision of 91.32% and a recall of 87.38% for function boundaries, a precision of 90.40% and a recall of 88.82% for variable types, and a precision of 80.66% and a recall of 91.78% for contract attributes.},
  keywords={Smart contracts;Codes;Optimization;Source coding;Static analysis;Large language models;Accuracy;Training;Semantics;Annotations;Smart contract;decompilation;static analysis;large language model},
  doi={10.1109/TSE.2025.3623325},
  ISSN={1939-3520},
  month={Dec},}@INPROCEEDINGS{10764949,
  author={She, Xinyu and Zhao, Yanjie and Wang, Haoyu},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={WaDec: Decompiling WebAssembly Using Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={481-492},
  abstract={WebAssembly (abbreviated Wasm) has emerged as a cornerstone of web development, offering a compact binary format that allows high-performance applications to run at near-native speeds in web browsers. Despite its advantages, Wasm’s binary nature presents significant challenges for developers and researchers, particularly regarding readability when debugging or analyzing web applications. Therefore, effective decompilation becomes crucial. Unfortunately, traditional decompilers often struggle with producing readable outputs. While some large language model (LLM)-based decompilers have shown good compatibility with general binary files, they still face specific challenges when dealing with Wasm.In this paper, we introduce a novel approach, WaDec, which is the first use of a fine-tuned LLM to interpret and decompile Wasm binary code into a higher-level, more comprehensible source code representation. The LLM was meticulously fine-tuned using a specialized dataset of wat-c code snippets, employing self-supervised learning techniques. This enables WaDec to effectively decompile not only complete wat functions but also finer-grained wat code snippets. Our experiments demonstrate that WaDec markedly outperforms current state-of-the-art tools, offering substantial improvements across several metrics. It achieves a code inflation rate of only 3.34%, a dramatic 97% reduction compared to the state-of-the-art’s 116.94%. Unlike the output of baselines that cannot be directly compiled or executed, WaDec maintains a recompilability rate of 52.11%, a re-execution rate of 43.55%, and an output consistency of 27.15%. Additionally, it significantly exceeds state-of-the-art performance in AST edit distance similarity by 185%, cyclomatic complexity by 8%, and cosine similarity by 41%, achieving an average code similarity above 50%. In summary, WaDec enhances understanding of the code’s structure and execution flow, facilitating automated code analysis, optimization, and security auditing.},
  keywords={Training;Measurement;Codes;Large language models;Source coding;Self-supervised learning;Security;Optimization;Faces;Software engineering;wasm;readability;binary;webassembly;llm;large language model;decompilation;finetune},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{11334528,
  author={Liu, Jiayang and Zhao, Yanjie and Xia, Pengcheng and Wang, Haoyu},
  booktitle={2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={APKARMOR: Low-Cost Lightweight Anti-Decompilation Techniques for Android Apps}, 
  year={2025},
  volume={},
  number={},
  pages={3180-3191},
  abstract={Android app security is a critical concern for the software industry, with companies investing significantly in protecting their intellectual property from reverse engineering attacks. While commercial protection tools exist to prevent decompilation and unauthorized code access, they pose substantial challenges for businesses: high licensing costs ranging from thousands to tens of thousands of dollars annually, significant performance overhead that impacts user experience and app ratings, and increased app size that affects download rates. These limitations particularly burden small to medium-sized enterprises and independent developers, creating an urgent industry need for cost-effective protection solutions.To address these challenges, we propose a novel file format-based anti-decompilation strategy that systematically exploits structural vulnerabilities in APK files. Building upon this strategy, we have developed APKARMOR, a lightweight and cost-effective anti-decompilation framework that exploits inherent vulnerabilities in popular reverse engineering tools. Through systematic analysis, we first identified critical weaknesses in common decompilation tools’ parsing mechanisms and structural assumptions. Based on these findings, we developed seven mutation-based protection strategies that deliberately trigger these vulnerabilities by introducing specific structural anomalies into APK files and the AndroidManifest.xml. These methods include Countermeasures against Dirty Code and Corrupted Payloads (CACoP), Pseudo-Encryption (PE), Using Unknown Compression Method (UUCM), Unavailable Magic Value (UMA), Modify the Offset Field in stringChunk (MOFS), and Dirty Bytecode Replacement of "Android" (DRA). We evaluated our exploitation strategies through extensive experiments on 100 randomly selected Android apps, testing against the latest versions of three widely used decompilation tools: JADX (v1.5.1), APKTool (v2.11.0), and Androguard (v4.1.2). Our results demonstrate that PE and DRA achieved complete protection by successfully exploiting vulnerabilities present in all tested tools. MOFS, UUCM, and UNV effectively exploited weaknesses in APKTool and Androguard’s parsing mechanisms.},
  keywords={Industries;Codes;Systematics;Reverse engineering;User experience;Software;Security;Protection;Testing;Software engineering},
  doi={10.1109/ASE63991.2025.00262},
  ISSN={2643-1572},
  month={Nov},}@ARTICLE{10035436,
  author={Park, Jihee and Lee, Sungho and Hong, Jaemin and Ryu, Sukyoung},
  journal={IEEE Transactions on Software Engineering}, 
  title={Static Analysis of JNI Programs via Binary Decompilation}, 
  year={2023},
  volume={49},
  number={5},
  pages={3089-3105},
  abstract={JNI programs are widely used thanks to the combined benefits of C and Java programs. However, because understanding the interaction behaviors between two different programming languages is challenging, JNI program development is difficult to get right and vulnerable to security attacks. Thus, researchers have proposed static analysis of JNI program source code to detect bugs and security vulnerabilities in JNI programs. Unfortunately, such source code analysis is not applicable to compiled JNI programs that are not open-sourced or open-source JNI programs containing third-party binary libraries. While JN-SAF, the state-of-the-art analyzer for compiled JNI programs, can analyze binary code, it has several limitations due to its symbolic execution and summary-based bottom-up analysis. In this paper, we propose a novel approach to statically analyze compiled JNI programs without their source code using binary decompilation. Unlike JN-SAF that analyzes binaries directly, our approach decompiles binaries and analyzes JNI programs with the decompiled binaries using an existing JNI program analyzer for source code. To decompile binaries to compilable C source code with precise JNI-interoperation-related types, we improve an existing decompilation tool by leveraging the characteristics of JNI programs. Our evaluation shows that the approach is precise as almost the same as the state-of-the-art JNI program analyzer for source code, and more precise than JN-SAF.},
  keywords={Java;Codes;Source coding;Static analysis;Libraries;Computer architecture;Security;Java native interface;binary decompilation;static analysis},
  doi={10.1109/TSE.2023.3241639},
  ISSN={1939-3520},
  month={May},}@INPROCEEDINGS{11068876,
  author={Yang, Yuwei and Grandel, Skyler and Lacomis, Jeremy and Schwartz, Edward and Vasilescu, Bogdan and Le Goues, Claire and Leach, Kevin},
  booktitle={2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)}, 
  title={A Human Study of Automatically Generated Decompiler Annotations}, 
  year={2025},
  volume={},
  number={},
  pages={129-142},
  abstract={Reverse engineering is a crucial technique in software security, enabling professionals to analyze malware, identify vulnerabilities, and patch legacy software without access to source code. Although decompilers attempt to reconstruct high-level code from binaries, essential information, such as variable names and types, is often dissimilar from the original version, hindering readability and comprehension.Recent advancements have employed AI to enhance decompiler output by recovering original variable names and types. Traditional evaluation of recovery techniques relies on measuring similarity between original and recovered names, assuming that higher similarity enhances readability. However, studies suggest that these "intrinsic" metrics may not accurately predict "extrinsic" outcomes like user comprehension or task performance, revealing a gap in understanding readability and cognitive load in reverse engineering.This paper presents an extrinsic evaluation of machine-generated variable and type names, focusing on their impact on reverse engineers’ comprehension of decompiled code. We conducted a user study with 40 participants—including students and professionals—to assess code comprehension both with and without AI-generated variable and type name assistance. Our findings indicate a lack of correlation between traditional machine learning metrics and actual comprehension gains, highlighting limitations in current evaluation techniques. Despite this, participants showed a preference for AI-augmented decompiler outputs. These insights contribute to understanding the effectiveness of automatic recovery techniques in enhancing reverse engineering tasks and underscore the need for comprehensive, user-centered evaluation frameworks.},
  keywords={Measurement;Codes;Correlation;Source coding;Reverse engineering;Focusing;Machine learning;Cognitive load;Malware;Security;Decompilation;Binary Reverse Engineering;Human Study},
  doi={10.1109/DSN64029.2025.00026},
  ISSN={2158-3927},
  month={June},}@INPROCEEDINGS{10795101,
  author={Zhang, Runze and Cao, Ying and Liang, Ruigang and Hu, Peiwei and Chen, Kai},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Optimizing Decompiler Output by Eliminating Redundant Data Flow in Self-Recursive Inlining}, 
  year={2024},
  volume={},
  number={},
  pages={38-49},
  abstract={Decompilation, which aims to lift a binary to a high-level language such as C, is one of the most common approaches software security analysts use for analyzing binary code. Recovering decompiled code with high readability is essential, as humans must understand the code's functionality correctly. However, some compilation optimization strategies will introduce obfuscation into the binary code, thereby reducing the readability of decompiled code. Among them, the function inlining related optimization strategies combine functions, causing the original function's code volume and complexity to multiply. Especially with self-recursive inlining optimization, it transforms initially simple functions into ones with significantly increased code volume and complex logic, greatly hindering the understanding of security engineers. In this paper, we present Erase, the first approach to reverse the self-recursive inlining optimization technique. We compare Erase with state-of-the-art decompilers Ghidra and Hex-Rays to evaluate ERASE's improvement for the functions affected by self-recursive inlining. Experimental results show that Erase's output is 78.4% and 88.9% more compact (fewer lines of code) than Ghidra and Hex-Rays, respectively. Moreover, reverse engineers spend 88.5% less time analyzing ERASE's output than analyzing Ghidra and 90.4% less time than analyzing Hex-Rays, and the accuracy of analyzing Erase's output is 2.75 times higher than both Ghidra and Hex-Rays.},
  keywords={Software maintenance;Accuracy;Systematics;Binary codes;Transforms;Complexity theory;Security;Logic;High level languages;Optimization;Reverse Engineering;Decompilation;Compiler Optimization;Self-Recursive Inlining;Program Analysis},
  doi={10.1109/ICSME58944.2024.00015},
  ISSN={2576-3148},
  month={Oct},}@ARTICLE{11367734,
  author={Liu, Li and Sun, Fanghui and Wang, Shen and Jiang, Xunzhi},
  journal={IEEE Internet of Things Journal}, 
  title={DECodeT5: A Lightweight and Efficient Neural Decompiler with Assembly Semantic Assistance}, 
  year={2026},
  volume={},
  number={},
  pages={1-1},
  abstract={Decompilation plays a critical role in firmware analysis and reverse engineering by enabling the recovery of high-level source code from binary executables. However, existing neural decompilation models often face challenges due to the semantic gap between assembly code and high-level languages, and they typically require large-scale models that impose significant computational demands. In this paper, we propose DECodeT5, a lightweight and efficient neural decompilation method for the C language. DECodeT5 builds upon the CodeT5 code generation model by integrating a pre-trained assembly encoder in place of its original embedding layer. This modification allows for more effective semantic learning from assembly code, improving the model’s ability to capture the intricacies of assembly-to-source code mapping. The architecture of DECodeT5 not only accelerates convergence during end-to-end decompilation tasks but also supports rapid adaptation across different compilers and instruction set architectures (ISAs) by swapping out the encoder module as needed. Our experimental evaluation on the HumanEval and Exebench benchmarks reveals that DECodeT5 significantly improves semantic recovery accuracy, outperforming Ghidra by over 83% and LLM4Decompile by more than 43% in terms of execution recovery. Furthermore, DECodeT5 maintains a compact model size of only 360M parameters, providing inference speeds that are twice as fast as LLM4Decompile. These results underscore DECodeT5’s suitability for deployment in resource-constrained environments and its flexibility in adapting to real-world reverse engineering scenarios, offering a practical solution for modern firmware analysis and security tasks.},
  keywords={Codes;Semantics;Assembly;Source coding;Optimization;Instruction sets;Computer architecture;Adaptation models;Microprogramming;Internet of Things;Decompile;reverse engineering;firmware security;deep neural network},
  doi={10.1109/JIOT.2026.3659328},
  ISSN={2327-4662},
  month={},}@INPROCEEDINGS{10444788,
  author={Armengol-Estapé, Jordi and Woodruff, Jackson and Cummins, Chris and O'Boyle, Michael F.P.},
  booktitle={2024 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)}, 
  title={SLaDe: A Portable Small Language Model Decompiler for Optimized Assembly}, 
  year={2024},
  volume={},
  number={},
  pages={67-80},
  abstract={Decompilation is a well-studied area with numerous high-quality tools available. These are frequently used for security tasks and to port legacy code. However, they regularly generate difficult-to-read programs and require a large amount of engineering effort to support new programming languages and ISAs. Recent interest in neural approaches has produced portable tools that generate readable code. Nevertheless, to-date such techniques are usually restricted to synthetic programs without optimization, and no models have evaluated their portability. Furthermore, while the code generated may be more readable, it is usually incorrect. This paper presents SLaDe, a Small Language model Decompiler based on a sequence-to-sequence Transformer trained over real-world code and augmented with a type inference engine. We utilize a novel tokenizer, dropout-free regularization, and type inference to generate programs that are more readable and accurate than standard analytic and recent neural approaches. Unlike standard approaches, SLaDe can infer out-of-context types and unlike neural approaches, it generates correct code. We evaluate SLaDe on over 4,000 ExeBench functions on two ISAs and at two optimization levels. SLaDe is up to 6× more accurate than Ghidra, a state-of-the-art, industrial-strength decompiler and up to 4× more accurate than the large language model ChatGPT and generates significantly more readable code than both.},
  keywords={Codes;Transformers;Security;Task analysis;Optimization;Standards;Engines;decompilation;neural decompilation;Transformer;language models;type inference},
  doi={10.1109/CGO57630.2024.10444788},
  ISSN={2643-2838},
  month={March},}@INPROCEEDINGS{10646727,
  author={Pal, Kuntal Kumar and Bajaj, Ati Priya and Banerjee, Pratyay and Dutcher, Audrey and Nakamura, Mutsumi and Basque, Zion Leonahenahe and Gupta, Himanshu and Sawant, Saurabh Arjun and Anantheswaran, Ujjwala and Shoshitaishvili, Yan and Doupé, Adam and Baral, Chitta and Wang, Ruoyu},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)}, 
  title={"Len or index or count, anything but v1": Predicting Variable Names in Decompilation Output with Transfer Learning}, 
  year={2024},
  volume={},
  number={},
  pages={4069-4087},
  abstract={Binary reverse engineering is an arduous and tedious task performed by skilled and expensive human analysts. Information about the source code is irrevocably lost in the compilation process. While modern decompilers attempt to generate C-style source code from a binary, they cannot recover lost variable names. Prior works have explored machine learning techniques for predicting variable names in decompiled code. However, the state-of-the-art systems, DIRE and DIRTY, generalize poorly to functions in the testing set that are not included in the training set—31.8% for DIRE on DIRTY’s data set and 36.9% for DIRTY on DIRTY’s data set.In this paper, we present VarBERT, a Bidirectional Encoder Representations from Transformers (BERT) to predict meaningful variable names in decompilation output. An advantage of VarBERT is that we can pre-train on human source code and then fine-tune the model to the task of predicting variable names. We also create a new data set VarCorpus, which significantly expands the size and variety of the data set. Our evaluation of VarBERT on VarCorpus, demonstrates a significant improvement in predicting the developer’s original variable names for O2 optimized binaries achieving accuracies of 54.43% for IDA and 54.49% for Ghidra. VarBERT is strictly better than state-of-the-art techniques: On a subset of VarCorpus, VarBERT could predict the developer’s original variable names 50.70% of the time, while DIRE and DIRTY predicted original variable names 35.94% and 38.00% of the time, respectively.},
  keywords={Training;Privacy;Codes;Source coding;Transfer learning;Reverse engineering;Transformers;Program and binary analysis;Machine learning and computer security;Decompilation},
  doi={10.1109/SP54263.2024.00152},
  ISSN={2375-1207},
  month={May},}@INPROCEEDINGS{8973072,
  author={Jaffe, Alan and Lacomis, Jeremy and Schwartz, Edward J. and Le Goues, Claire and Vasilescu, Bogdan},
  booktitle={2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC)}, 
  title={Meaningful Variable Names for Decompiled Code: A Machine Translation Approach}, 
  year={2018},
  volume={},
  number={},
  pages={20-30},
  abstract={When code is compiled, information is lost, including some of the structure of the original source code as well as local identifier names. Existing decompilers can reconstruct much of the original source code, but typically use meaningless placeholder variables for identifier names. Using variable names which are more natural in the given context can make the code much easier to interpret, despite the fact that variable names have no effect on the execution of the program. In theory, it is impossible to recover the original identifier names since that information has been lost. However, most code is natural: it is highly repetitive and predictable based on the context. In this paper we propose a technique that assigns variables meaningful names by taking advantage of this naturalness property. We consider decompiler output to be a noisy distortion of the original source code, where the original source code is transformed into the decompiler output. Using this noisy channel model, we apply standard statistical machine translation approaches to choose natural identifiers, combining a translation model trained on a parallel corpus with a language model trained on unmodified C code. We generate a large parallel corpus from 1.2 TB of C source code obtained from GitHub. Under the most conservative assumptions, our technique is still able to recover the original variable names up to 16.2% of the time, which represents a lower bound for performance.},
  keywords={Lower bound;Codes;Translation;Source coding;Distortion;Noise measurement;Machine translation;Channel models;Standards;Software development management;Decompilation;Understandability;Statistical Machine Translation;Renaming Identifiers},
  doi={},
  ISSN={2643-7171},
  month={May},}@ARTICLE{10740475,
  author={Reiter, Pemma and Tay, Hui Jun and Weimer, Westley and Doupé, Adam and Wang, Ruoyu and Forrest, Stephanie},
  journal={IEEE Transactions on Dependable and Secure Computing}, 
  title={Automatically Mitigating Vulnerabilities in Binary Programs via Partially Recompilable Decompilation}, 
  year={2025},
  volume={22},
  number={3},
  pages={2270-2282},
  abstract={Vulnerabilities are challenging to locate and repair, especially when source code is unavailable and binary patching is required. Manual methods are time-consuming, require significant expertise, and do not scale to the rate at which new vulnerabilities are discovered. Automated methods are an attractive alternative, and we propose Partially Recompilable Decompilation (PRD) to help automate the process. PRD lifts suspect binary functions to source, available for analysis, revision, or review, and creates a patched binary using source- and binary-level techniques. Although decompilation and recompilation do not typically succeed on an entire binary, our approach does because it is limited to a few functions, such as those identified by our binary fault localization. We evaluate the assumptions underlying our approach and find that, without any grammar or compilation restrictions, up to 79% of individual functions are successfully decompiled and recompiled. In comparison, only 1.7% of the full C-binaries succeed. When recompilation succeeds, PRD produces test-equivalent binaries 93.0% of the time. We evaluate PRD in two contexts: a fully automated process incorporating source-level Automated Program Repair (APR) methods; and human-edited source-level repairs. When evaluated on DARPA Cyber Grand Challenge (CGC) binaries, we find that PRD-enabled APR tools, operating only on binaries, perform as well as, and sometimes better than full-source tools, collectively mitigating 85 of the 148 scenarios, a success rate consistent with the same tools operating with access to the entire source code. PRD achieves similar success rates as the winning CGC entries, sometimes finding higher-quality mitigations than those produced by top CGC teams. For generality, the evaluation includes two independently developed APR tools and C++, Rode0day, and real-world binaries.},
  keywords={Maintenance engineering;Source coding;Codes;Location awareness;Software;Computer bugs;Prototypes;Measurement;Grammar;C++ languages;Software engineering;software maintenance},
  doi={10.1109/TDSC.2024.3482413},
  ISSN={1941-0018},
  month={May},}@INPROCEEDINGS{11334294,
  author={Sun, Xinyu and Tang, Fugen and Zhang, Yu and Shen, Han and Song, Chengru and Zhang, Di},
  booktitle={2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Enhancing LLM to Decompile Optimized PTX to Readable CUDA for Tensor Programs}, 
  year={2025},
  volume={},
  number={},
  pages={2235-2247},
  abstract={The growing demand for high-performance tensor programs on GPUs, especially for large language models (LLMs), necessitates advanced compilation and optimization techniques. However, the critical task of analyzing optimized, low-level PTX code for performance tuning or understanding poses significant challenges. While LLMs hold promise for PTX-to-CUDA de-compilation to improve code intelligibility, their effectiveness is severely limited by the scarcity of aligned training data and the inherent complexity of highly optimized, unrolled PTX code.In this work, we explore methodologies to significantly enhance LLM capabilities for accurate and readable PTX-to-CUDA decompilation and present PtxDec, a decompilation prototype implementing our approach. To overcome the critical barrier of data scarcity, we develop a compiler-based data augmentation framework coupled with rigorous post-processing, enabling the creation of a large-scale, high-quality dataset of 400K aligned CUDA-PTX kernel pairs for effective LLM training. Furthermore, to empower LLMs to handle the complexity of optimized PTX, we introduce Rolled-PTX—an intermediate representation generated through heuristic loop rerolling during preprocessing. Rolled-PTX condenses unrolled patterns, drastically simplifying the input structure presented to the LLM and aligning it better with higher-level loop constructs.Comprehensive evaluation demonstrates that PtxDec achieves substantial performance gains: our approach yields a 2.3×–3.1× improvement in functional accuracy over baseline methods, alongside significant enhancements in generated code readability and scheduling consistency with the original optimized kernels. Ablation studies further validate the contribution of each proposed component to the overall performance.To the best of our knowledge, this is the first work tackling PTX-to-CUDA decompilation, specifically focusing on and demonstrating effective strategies for augmenting LLMs to overcome the key challenges in this domain.},
  keywords={Codes;Tensors;Accuracy;Graphics processing units;Training data;Data augmentation;Complexity theory;Kernel;Optimization;Tuning;LLM;Decompilation;Deep learning compiler;GPU Programming},
  doi={10.1109/ASE63991.2025.00185},
  ISSN={2643-1572},
  month={Nov},}@ARTICLE{10531777,
  author={Sang, Chao and Wu, Jun and Li, Jianhua and Guizani, Mohsen},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={From Control Application to Control Logic: PLC Decompile Framework for Industrial Control System}, 
  year={2024},
  volume={19},
  number={},
  pages={8685-8700},
  abstract={Industrial Control System (ICS) depends on the underlying Programmable Logical Controllers (PLCs) to run. As such, the security of the internal control logic of the PLCs is the top concern of ICS. Reversing analysis and forensic work against PLC require extracting control logic from the control application running inside PLC, which is still an unresolved problem. To address the challenge, we propose a PLC decompile framework named CLEVER, which can analyze the control application and extract the control logic. First, we propose a simulation execution based code extraction method, which is utilized to filter the control logic related data. Then, to normalize the control application decompile process, an intermediate representation (IR) is designed, which can simplify the analysis process and enhance the extensibility of CLEVER. Finally, a heuristic data flow analysis algorithm is proposed to find variable dependency, and a sequential parsing method is utilized to reconstruct the source code from the control application. To evaluate our work, real world PLC hardware and programming software are used for the experiment. We use 22 real-world, 58 hand-written, and 150 auto-generated control applications to demonstrate the usability, correctness, and operational efficiency of CLEVER.},
  keywords={Codes;Software;Registers;Data mining;Assembly;Process control;Feature extraction;Reverse engineering;program analysis;network forensics;industrial control system;PLC},
  doi={10.1109/TIFS.2024.3402117},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{11334626,
  author={Li, Gangyang and Shang, Xiuwei and Cheng, Shaoyin and Zhang, Junqi and Hu, Li and Zhu, Xu and Zhang, Weiming and Yu, Nenghai},
  booktitle={2025 40th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={PseudoFix: Refactoring Distorted Structures in Decompiled C Pseudocode}, 
  year={2025},
  volume={},
  number={},
  pages={841-853},
  abstract={Decompilation can convert binary programs into clear C-style pseudocode, which is of great value in a wide range of security applications. Existing research primarily focuses on recovering symbolic information in pseudocode, such as function names, variable names, and data types, but neglecting structural information. We observe that even when symbolic information is fully preserved, severe and complex structure distortions remain in the pseudocode, greatly impairing code readability and comprehension. In this work, we first systematically investigate structure distortions in decompiled pseudocode, revealing their variation patterns through quantitative analysis. Using open coding, we derive a taxonomy comprising six top-level categories of structure distortions. Building upon this taxonomy, we propose PseudoFix, a novel framework that combines large language models (LLMs) with retrieval-based in-context learning. PseudoFix employs semantic retrieval to select the most relevant few-shot examples that provide structure distortion knowledge, and combines this with the well-structured coding patterns learned by LLMs from vast source code repositories, to efficiently refactor distorted pseudocode. Comprehensive evaluations demonstrate that PseudoFix significantly improves pseudocode readability, achieving up to a 34% reduction in Halstead Complexity Effort and a 105% increase in BLEU-4 score. Notably, it significantly outperforms state-of-the-art approaches in both temporary variable elimination and goto statement removal tasks. Additionally, human evaluations yield consistently positive feedback from users across readability, consistency, and reasonability.},
  keywords={Systematics;Statistical analysis;Large language models;Source coding;Taxonomy;Semantics;Software algorithms;Distortion;Security;Software engineering;Decompilation;Refactor Structure Distortion;Taxonomy;In-context Learning;Large Language Models},
  doi={10.1109/ASE63991.2025.00075},
  ISSN={2643-1572},
  month={Nov},}@INPROCEEDINGS{9282790,
  author={Korenčik, Lukáš and Ročkai, Petr and Lauko, Henrich and Barnat, Jiří},
  booktitle={2020 IEEE 20th International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={On Symbolic Execution of Decompiled Programs}, 
  year={2020},
  volume={},
  number={},
  pages={265-272},
  abstract={In this paper, we present a combination of existing and new tools that together make it possible to apply formal verification methods to programs in the form of ×86_64 machine code. Our approach first uses a decompilation tool (remill) to extract low-level intermediate representation (LLVM) from the machine code. This step consists of instruction translation (i.e. recovery of operation semantics), control flow extraction and address identification.The main contribution of this paper is the second step, which builds on data flow analysis and refinement of indirect (i.e. data-dependent) control flow. This step makes the processed bitcode much more amenable to formal analysis.To demonstrate the viability of our approach, we have compiled a set of benchmark programs into native executables and analysed them using two LLVM-based tools: DIVINE, a software model checker and KLEE, a symbolic execution engine. We have compared the outcomes to direct analysis of the same programs.},
  keywords={Semantics;Software quality;Tools;Software reliability;Security;Engines;Formal verification;decompilation;llvm;symbolic execution;program analysis;binary analysis},
  doi={10.1109/QRS51102.2020.00044},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11050729,
  author={Magin, Florian and Patat, Gwendal and Scherf, Fabian},
  booktitle={2025 IEEE/ACM 1st International Workshop on Advancing Static Analysis for Researchers and Industry Practitioners in Software Engineering (STATIC)}, 
  title={Heros in Action: Analyzing Objective-C Binaries through Decompilation and IFDS}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper demonstrates static taint analysis on Objective-C binaries through the integration of the Ghidra framework with the Heros IFDS solver, achieving an inter-procedural, field-sensitive and flow-sensitive analysis. Our contributions include two plugins: one extending Ghidra Objective-C capabilities to improve decompilation accuracy, and another integrating the Heros framework for inter-procedural taint analysis on Ghidra Intermediate Representation (IR).To assess our approach, we introduce a new benchmark suite tailored to Objective-C, covering diverse dataflow challenges and promoting further community-driven research. By leveraging existing frameworks, this work demonstrates how established static analysis techniques can be adapted to binary targets, laying a groundwork for advancements in Objective-C binary analysis.},
  keywords={Industries;Accuracy;Conferences;Static analysis;Benchmark testing;Software engineering;Heros;IFDS;Objective-C;Decompilation},
  doi={10.1109/STATIC66697.2025.00005},
  ISSN={},
  month={April},}@INPROCEEDINGS{10515515,
  author={Izrailov, Konstantin},
  booktitle={2024 International Russian Smart Industry Conference (SmartIndustryCon)}, 
  title={GREMC: Genetic Reverse-Engineering of Machine Code to Search Vulnerabilities in Software for Industry 4.0. Predicting the Size of the Decompiling Source Code}, 
  year={2024},
  volume={},
  number={},
  pages={622-628},
  abstract={The article is devoted to the problem of security of cyber-physical systems as part of production according to the Industry 4.0 concept. For this purpose, the author's approach of “Genetic Reverse Engineering of Machine Code” (GREMC) is proposed. The essence of this approach lies in the use of artificial intelligence in the field of genetic algorithms to restore the source code of software executed in the form of machine code on cyber-physical devices for Industry 4.0. The resulting code can then be analysed for vulnerabilities by an expert. One issue that arises during genetic reverse engineering is predicting the size of the source code based on its machine representation (i.e., in an object or executable file). The article is devoted to solving this problem for functions in the C programming language. To do this, a method for obtaining a relationship between the sizes of the source and machine code of individual functions is described, which consists of steps such as loading a dataset with C-functions, isolating the function code in it, preprocessing them, compiling them into machine code, calculating the required sizes, building dependencies between each source code size and the corresponding machine code sizes, generating the final table and determining the dependency formula. An experiment is carried out using a software prototype that implements the method; ExeBench with 83 thousand C-functions is taken as a dataset. Justifications are given regarding the appearance of abnormal machine code sizes and their impact on the dependence formula.},
  keywords={Codes;Source coding;Reverse engineering;Prototypes;Production;Genetics;Software;machine code;source code;reverse-engineering;decompilation;size dependence},
  doi={10.1109/SmartIndustryCon61328.2024.10515515},
  ISSN={},
  month={March},}@INPROCEEDINGS{10174218,
  author={Cao, Kevin and Leach, Kevin},
  booktitle={2023 IEEE/ACM 31st International Conference on Program Comprehension (ICPC)}, 
  title={Revisiting Deep Learning for Variable Type Recovery}, 
  year={2023},
  volume={},
  number={},
  pages={275-279},
  abstract={Compiled binary executables are often the only available artifact in reverse engineering, malware analysis, and software systems maintenance. Unfortunately, the lack of semantic information like variable types makes comprehending binaries difficult. In efforts to improve the comprehensibility of binaries, researchers have recently used machine learning techniques to predict semantic information contained in the original source code. Chen et al. implemented DIRTY, a Transformer-based Encoder-Decoder architecture capable of augmenting decompiled code with variable names and types by leveraging decompiler output tokens and variable size information. Chen et al. were able to demonstrate a substantial increase in name and type extraction accuracy on Hex-Rays decompiler outputs compared to existing static analysis and AI-based techniques. We extend the original DIRTY results by re-training the DIRTY model on a dataset produced by the open-source Ghidra decompiler. Although Chen et al. concluded that Ghidra was not a suitable decompiler candidate due to its difficulty in parsing and incorporating DWARF symbols during analysis, we demonstrate that straightforward parsing of variable data generated by Ghidra results in similar retyping performance. We hope this work inspires further interest and adoption of the Ghidra decompiler for use in research projects.},
  keywords={Training;Source coding;Semantics;Reverse engineering;Symbols;Computer architecture;Static analysis;Ghidra;Hex-Rays;Machine Learning;Transformers},
  doi={10.1109/ICPC58990.2023.00042},
  ISSN={2643-7171},
  month={May},}@ARTICLE{9520296,
  author={Ahmed, Toufique and Devanbu, Premkumar and Sawant, Anand Ashok},
  journal={IEEE Transactions on Software Engineering}, 
  title={Learning to Find Usages of Library Functions in Optimized Binaries}, 
  year={2022},
  volume={48},
  number={10},
  pages={3862-3876},
  abstract={Much software, whether beneficent or malevolent, is distributed only as binaries, sans source code. Absent source code, understanding binaries’ behavior can be quite challenging, especially when compiled under higher levels of compiler optimization. These optimizations can transform comprehensible, “natural” source constructions into something entirely unrecognizable. Reverse engineering binaries, especially those suspected of being malevolent or guilty of intellectual property theft, are important and time-consuming tasks. There is a great deal of interest in tools to “decompile” binaries back into more natural source code to aid reverse engineering. Decompilation involves several desirable steps, including recreating source-language constructions, variable names, and perhaps even comments. One central step in creating binaries is optimizing function calls, using steps such as inlining. Recovering these (possibly inlined) function calls from optimized binaries is an essential task that most state-of-the-art decompiler tools try to do but do not perform very well. In this paper, we evaluate a supervised learning approach to the problem of recovering optimized function calls. We leverage open-source software and develop an automated labeling scheme to generate a reasonably large dataset of binaries labeled with actual function usages. We augment this large but limited labeled dataset with a pre-training step, which learns the decompiled code statistics from a much larger unlabeled dataset. Thus augmented, our learned labeling model can be combined with an existing decompilation tool, Ghidra, to achieve substantially improved performance in function call recovery, especially at higher levels of optimization.},
  keywords={Libraries;Tools;Optimization;Databases;Reverse engineering;Training;Malware;Reverse engineering;software modeling;deep learning},
  doi={10.1109/TSE.2021.3106572},
  ISSN={1939-3520},
  month={Oct},}@INPROCEEDINGS{9833799,
  author={Liu, Zhibo and Yuan, Yuanyuan and Wang, Shuai and Bao, Yuyan},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)}, 
  title={SoK: Demystifying Binary Lifters Through the Lens of Downstream Applications}, 
  year={2022},
  volume={},
  number={},
  pages={1100-1119},
  abstract={Binary lifters convert executables into an intermediate representation (IR) of a compiler framework. The recovered IR code is generally deemed “analysis friendly,” bridging low-level code analysis with well-established compiler infrastructures. With years of development, binary lifters are becoming increasingly popular for use in various security, systems, and software (re)-engineering applications. Recent studies have also reported highly promising results that suggest binary lifters can generate LLVM IR code with correct functionality, even for complex cases.This paper conducts an in-depth study of binary lifters from an orthogonal and highly demanding perspective. We demystify the “expressiveness” of binary lifters, and reveal how well the lifted LLVM IR code can support critical downstream applications in security analysis scenarios. To do so, we generate two pieces of LLVM IR code by compiling C/C++ programs or by lifting the corresponding executables. We then feed these two pieces of LLVM IR code to three keystone downstream applications (pointer analysis, discriminability analysis, and decompilation) and determine whether inconsistent analysis results are generated. We study four popular static and dynamic LLVM IR lifters that were developed by the industry or academia from a total of 252,063 executables generated by various compilers and optimizations and on different architectures. Our findings show that modern binary lifters afford IR code that is highly suitable for discriminability analysis and decompilation, and suggest that such binary lifters can be applied in common similarity- or code comprehension-based security analysis (e.g., binary diffing). However, the lifted IR code appears unsuited to rigorous static analysis (e.g., pointer analysis). To obtain a more comprehensive view of the utility of binary lifters, we also compare the performance of lifter-enabled approaches with that of binary-only tools in three security tasks, i.e., sanitization, binary diffing, and C decompilation. We summarize our findings and make suggestions for the correct use and further enhancement of binary lifters. We also explored practical ways to enhance the accuracy of pointer analysis using lifted IR code, by using and augmenting Debin, a tool for predicting debug information.},
  keywords={Industries;Privacy;Codes;Static analysis;Software;Security;Feeds;reverse-engineering;software-security},
  doi={10.1109/SP46214.2022.9833799},
  ISSN={2375-1207},
  month={May},}@INPROCEEDINGS{8987703,
  author={Slawinski, Michael and Wortman, Andy},
  booktitle={2019 4th International Conference on System Reliability and Safety (ICSRS)}, 
  title={Applications of Graph Integration to Function Comparison and Malware Classification}, 
  year={2019},
  volume={},
  number={},
  pages={16-24},
  abstract={We classify .NET files as either benign or malicious by examining directed graphs derived from the set of functions comprising the given file. Each graph is viewed probabilistically as a Markov chain where each node represents a code block of the corresponding function, and by computing the PageRank vector (Perron vector with transport), a probability measure can be defined over the nodes of the given graph. Each graph is vectorized by computing Lebesgue antiderivatives of hand-engineered functions defined on the vertex set of the given graph against the PageRank measure. Files are subsequently vectorized by aggregating the set of vectors corresponding to the set of graphs resulting from decompiling the given file. The result is a fast, intuitive, and easy-to-compute glass-box vectorization scheme, which can be leveraged for training a standalone classifier or to augment an existing feature space. We refer to this vectorization technique as PageRank Measure Integration Vectorization (PMIV). We demonstrate the efficacy of PMIV by training a vanilla random forest on 2.5 million samples of decompiled. NET, evenly split between benign and malicious, from our in-house corpus and compare this model to a baseline model which leverages a text-only feature space. The median time needed for decompilation and scoring was 24ms. 11Code available at https://github.com/gtownrocks/grafuple},
  keywords={Training;Robust control;Taxonomy;Aerospace electronics;Syntactics;Vectors;Malware;Safety;Reliability;Glass box;graph integration;pagerank;machine learning;classification;malware;NET;decompilation;abstract syntax tree},
  doi={10.1109/ICSRS48664.2019.8987703},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10773695,
  author={Smith, Ian and Bertolaccini, Francesco and Tan, William and Brown, Michael D.},
  booktitle={MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM)}, 
  title={IRENE: A Toolchain for High-level Micropatching through Recompilable Sub-function Regions}, 
  year={2024},
  volume={},
  number={},
  pages={1064-1069},
  abstract={Devices with long life-cycles extend the duration of a software product’s exposure. Vulnerabilities in the device’s software may be discovered after the toolchain for building software for that device has been deprecated, the source-code for the program that is running on the device is unavailable, or both. Current solutions for patching these latent vulnerabilities are insufficient, either requiring deep technical expertise and manual effort or producing a large set of changes to the target binary. The large number of changes in the target program makes validating the patch difficult.We present IRENE, a decompiler that produces recompilable decompilation for patching. IRENE decompiles sub-function regions of a binary program to separate recompilable regions of code. The IRENE compiler replaces the original binary region with recompiled assembly, representing the user’s patch. IRENE allows developers to compose patches by modifying a high-level representation of the target program, but produces targeted micropatches. We evaluate the size of IRENE produced micropatches against patches produced both by recompilation and manual assembly patching in a case study. This evaluation shows a patch size reduction of 4x compared with recompilation and a 21x size reduction when compared with recompiling the patch with a newer toolchain version.},
  keywords={Military communication;Codes;Buildings;Manuals;Software;Assembly;binary patching;recompilation;binary rewriting;binary analysis},
  doi={10.1109/MILCOM61039.2024.10773695},
  ISSN={2155-7586},
  month={Oct},}@INPROCEEDINGS{10581196,
  author={Ahmad Ali Qureshi, Muhammad and Munawar Gill, Arsham and Sadaf, Memoona},
  booktitle={2024 International Conference on Engineering & Computing Technologies (ICECT)}, 
  title={APK Insight: Revolutionizing Forensic Analysis with a User-Friendly Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research paper introduces a novel forensic tool named ‘A2forensicsKit’, developed for non-technical users to proficiently analyze and decompile Android Application Package (APK) files [7]. With the increasing prevalence of mobile applications, the need for accessible forensic solutions has become imperative. Our tool focuses on simplifying the complex process of APK analysis, enabling investigators, law enforcement, and other non-technical users to extract valuable insights from mobile applications. The tool employs an intuitive user interface, providing a seamless experience for users with limited technical expertise. Through a combination of automated processes and user-friendly features, our tool allows for the swift identification of malicious code, potential vulnerabilities, and unauthorized activities within APK files. Its effectiveness lies in its ability to bridge the gap between intricate forensic procedures and the diverse user base involved in digital investigations. Key functionalities include static analysis and decompilationof APK files, all seamlessly integrated into a unified platform. The tool's efficiency is underscored by its capacity to generate comprehensive reports, helping investigators in presenting findings in a clear and understandable manner. In conclusion, our research presents a user-friendly forensic tool that empowers non-technical users to conduct thorough analysis and decompilation of APK files. By addressing the accessibility gap in digital forensics, this tool contributes to enhancing the efficiency and inclusivity of mobile application investigations.},
  keywords={Training;Technological innovation;Law enforcement;Operating systems;Digital forensics;Transforms;Static analysis;Digital Forensics;APK Analysis;Mobile Application Security;Cybersecurity;Android Application Package;Forensic Tools},
  doi={10.1109/ICECT61618.2024.10581196},
  ISSN={},
  month={May},}@INPROCEEDINGS{11185876,
  author={Enders, Steffen and Behner, Eva-Maria C. and Padilla, Elmar},
  booktitle={2025 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={A Jump-Table-Agnostic Switch Recovery on ASTs}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Recovering high-level control-flow structures is a crucial part of modern reverse engineering, especially in fields like binary analysis. Here, analysts often use decompilers to convert functions of binary programs into a more humanreadable C -like representation. Among these control-flow structures, switch statements have unique significance because of their ability to represent complex decision-making and branching behavior in a concise and readable manner. Consequently, the successful recovery of switch statements during decompilation can greatly enhance the readability of the resulting output, making it a highly desired goal in the field of reverse engineering. In this paper, we present a new technique for identifying abstract syntax tree components that can be transformed into semantically equivalent switches, thus improving code readability. In contrast to other approaches, we do not rely on jump tables that have or have not been emitted during compilation. Instead, we identify clusters of comparisons involving the same expression but with varying constant values within the abstract syntax tree to be transformed into switch constructs. Because this approach is inherently linked to the semantic definition of a switch statements, it only generates meaningful switches by design. We evaluated our approach on the coreutils-9.3 dataset and compared it to the leading decompilers Ghidra and Hex-Rays, both of which attempt to recover switch statements as well. Our evaluation results indicate that our approach outperforms both Ghidra and Hex-Rays by successfully recovering more than twice as many switch constructs in the given dataset.},
  keywords={Software maintenance;Source coding;Semantics;Reverse engineering;Decision making;Switches;Transforms;Syntactics;Control systems;Complexity theory;switch recovery;decompilation;reverse engineering;binary analysis;jump tables;control-flow structuring},
  doi={10.1109/ICSME64153.2025.00028},
  ISSN={2576-3148},
  month={Sep.},}@INPROCEEDINGS{11352404,
  author={Zhao, Shiwu and Zheng, Ningjun and Li, Haoyu and Feng, Ruizhi and Chen, Xingchen and Tan, Ru and Liu, Qixu},
  booktitle={2025 28th International Symposium on Research in Attacks, Intrusions and Defenses (RAID)}, 
  title={DEPHP: A Source Code Recovery Method for PHP Bytecode with Improved Structural Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={77-91},
  abstract={Over the past decade, PHP has consistently been one of the most popular server-side programming languages among developers for web development. To protect intellectual property, various PHP source code obfuscation and encryption methods have been developed, which has led to difficulties in performing security analysis on PHP source code. Previous work has demonstrated the feasibility of recovering source code by extracting bytecode from PHP during dynamic execution. However, there is still a lack of a universal decompilation method for this kind of bytecode, tailored to PHP’s unique syntax. Thus, we propose a systematic decompilation framework for PHP bytecode. First, we design a unified intermediate representation that eliminates the differences between bytecodes from different PHP versions. Then, we introduce a structural analysis algorithm specifically for PHP syntax, improving upon existing methods to better accommodate PHP’s unique syntax. We use over 3 million lines of PHP code as a dataset and compiled it into PHP bytecode. After decompiling it with our method, we successfully recovered 92% of the classes and 85% of the methods. Furthermore, from the encrypted dataset containing 37 SQL injection and 31 XSS vulnerability patterns, we fully restored the original vulnerability patterns and reconstructed the exploitation chains. Furthermore, we identified a series of vulnerabilities in real-world projects and were assigned 6 new CVE IDs1, demonstrating the correctness of our method and its ability to assist in static analysis for vulnerability discovery.1CVE-2025-45046, CVE-2025-45047, CVE-2025-45048, CVE-2025-45049, CVE-2025-45050, CVE-2025-45052},
  keywords={Codes;Systematics;Source coding;Trees (botanical);Process control;Static analysis;Intellectual property;Syntactics;SQL injection;Protection;decompilation;structural analysis;code protection;PHP bytecode;vulnerability detection},
  doi={10.1109/RAID67961.2025.00032},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9282282,
  author={Li, Xiaoqi and Chen, Ting and Luo, Xiapu and Zhang, Tao and Yu, Le and Xu, Zhou},
  booktitle={2020 IEEE 20th International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={STAN: Towards Describing Bytecodes of Smart Contract}, 
  year={2020},
  volume={},
  number={},
  pages={273-284},
  abstract={More than eight million smart contracts have been deployed into Ethereum, which is the most popular blockchain that supports smart contract. However, less than 1% of deployed smart contracts are open-source, and it is difficult for users to understand the functionality and internal mechanism of those closed-source contracts. Although a few decompilers for smart contracts have been recently proposed, it is still not easy for users to grasp the semantic information of the contract, not to mention the potential misleading due to decompilation errors. In this paper, we propose the first system named Stan to generate descriptions for the bytecodes of smart contracts to help users comprehend them. In particular, for each interface in a smart contract, Stan can generate four categories of descriptions, including functionality description, usage description, behavior description, and payment description, by leveraging symbolic execution and NLP (Natural Language Processing) techniques. Extensive experiments show that Stan can generate adequate, accurate and readable descriptions for contract’s bytecodes, which have practical value for users.},
  keywords={Smart contracts;Semantics;Software quality;Tools;Natural language processing;Software reliability;Security;Smart contract;Ethereum;Program comprehension},
  doi={10.1109/QRS51102.2020.00045},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8406593,
  author={Bodei, Chiara and Degano, Pierpaolo and Galletta, Letterio and Focardi, Riccardo and Tempesta, Mauro and Veronese, Lorenzo},
  booktitle={2018 IEEE European Symposium on Security and Privacy (EuroS&P)}, 
  title={Language-Independent Synthesis of Firewall Policies}, 
  year={2018},
  volume={},
  number={},
  pages={92-106},
  abstract={Configuring and maintaining a firewall configuration is notoriously hard. Policies are written in low-level, platform-specific languages where firewall rules are inspected and enforced along non trivial control flow paths. Further difficulties arise from Network Address Translation (NAT), since filters must be implemented with addresses translations in mind. In this work, we study the problem of decompiling a real firewall configuration into an abstract specification. This abstract version throws the low-level details away by exposing the meaning of the configuration, i.e., the allowed connections with possible address translations. The generated specification makes it easier for system administrators to check if: (i) the intended security policy is actually implemented; (ii) two configurations are equivalent; (iii) updates have the desired effect on the firewall behavior. The peculiarity of our approach is that is independent of the specific target firewall system and language. This independence is obtained through a generic intermediate language that provides the typical features of real configuration languages and that separates the specification of the rulesets, determining the destiny of packets, from the specification of the platform-dependent steps needed to elaborate packets. We present a tool that decompiles real firewall configurations from different systems into this intermediate language and uses the Z3 solver to synthesize the abstract specification that succinctly represents the firewall behavior and the NAT. Tests on real configurations show that the tool is effective: it synthesizes complex policies in a matter of minutes and, and it answers to specific queries in just a few seconds. The tool can also point out policy differences before and after configuration updates in a simple, tabular form.},
  keywords={Tools;Firewalls (computing);Proposals;Network address translation;Standards;Operating systems;Network Security;Firewall configuration;Policy Synthesis},
  doi={10.1109/EuroSP.2018.00015},
  ISSN={},
  month={April},}@INPROCEEDINGS{9850326,
  author={Zubair, Nauman and Ayub, Adeen and Yoo, Hyunguk and Ahmed, Irfan},
  booktitle={2022 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={Control Logic Obfuscation Attack in Industrial Control Systems}, 
  year={2022},
  volume={},
  number={},
  pages={227-232},
  abstract={Industrial control systems (ICS) are essential for safe and efficient operations of critical infrastructures such as power grids, pipelines, and water treatment facilities. Attackers target ICS, mainly programmable logic controllers (PLC), to sabotage underlying infrastructure. A PLC controls a physical process through connected sensors and actuators. It runs a control-logic program that specifies monitoring and controlling a physical process and is a common target of cyberattacks. A vendor-provided proprietary engineering software is typically used to investigate the infected control logic. This paper shows that an attacker can use control-logic obfuscation as an anti-forensics technique to hinder the investigations and incident response. The control-logic obfuscation subverts the engineering software’s decompilation function; therefore, we call it a denial-of-decompilation attack. The attack exploits a fundamental design principle of creating compiled control logic in engineering software, thereby affecting the engineering software of multiple vendors in the industry.},
  keywords={Integrated circuits;Programmable logic devices;Pipelines;Process control;Control systems;Software;Power grids;Control-logic attacks;digital forensics;industrial control system (ICS);programmable logic controller (PLC)},
  doi={10.1109/CSR54599.2022.9850326},
  ISSN={},
  month={July},}@INPROCEEDINGS{8936022,
  author={Semenov, Serhii and Davydov, Viacheslav and Voloshyn, Denys},
  booktitle={2019 XXIX International Scientific Symposium "Metrology and Metrology Assurance" (MMA)}, 
  title={Obfuscated Code Quality Measurement}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={Nowadays, number of cyber-attacks aimed at software increases. Thus, improving the quality of software security services becomes acute. Confidentiality is one of the basic security services. It is provided, including through the use of obfuscation mechanism. Code quality measurement Methods has been investigated. Particular attention is paid to methods aimed at decompiled code, where standard metrics do not take in account. The method of decompiled code static analysis has been improved. This method takes into account the features of the compile procedure for languages with intermediate code.},
  keywords={Codes;Atmospheric measurements;Static analysis;Metrology;Particle measurements;Software;Security;Standards;Cyberattack;obfuscation;security service;code quality;immediate code},
  doi={10.1109/MMA.2019.8936022},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9647781,
  author={Enders, Steffen and Rybalka, Mariia and Padilla, Elmar},
  booktitle={2021 18th International Conference on Privacy, Security and Trust (PST)}, 
  title={PIdARCI: Using Assembly Instruction Patterns to Identify, Annotate, and Revert Compiler Idioms}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Analysis of binary code is a building block of computer security. Especially in malware or firmware analysis where source code oftentimes is not available, techniques like decompilation are utilized to Figure out the functionality of binaries. During the optimization phase in modern compilers, human-readable expressions are often transformed into instruction sequences (compiler idioms or idioms) that may be more efficient in terms of speed or size than the direct translation. However, these transformations are often considerably worse in terms of readability for the analyst. Such compiler specific sequences are not only significantly longer than the apparent translation of the original high-level language operation but also have no trivial correlation to the original expression’s semantics. Modern decompilers address this issue by reverting idioms using static, manually crafted rules. In this paper, we introduce a novel approach to find and annotate arithmetic idioms with their corresponding high-level language expressions to significantly simplify manual analysis. In contrast to previous approaches, our method does not require manual work to create the patterns for matching idioms and significantly less manual labour to derive the transformation rules to calculate the original constants. In our evaluation, we compared the results of PIdARCI against the current academic and commercial state-of-the-art Ghidra, RetDec, and Hex Rays / IDA Pro. We show that PIdARCI matches more than 99% of all considered idioms, exceeding the matching rate of the other approaches.},
  keywords={Matched filters;Databases;Semantics;Manuals;Malware;High level languages;Pattern matching},
  doi={10.1109/PST52912.2021.9647781},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8210757,
  author={de la Torre-Díez, Isabel and Trinchet, Bruno Olivar and Rodrigues, Joel J.P.C. and López-Coronado, Miguel},
  booktitle={2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom)}, 
  title={Security analysis of a mHealth app in Android: Problems and solutions}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, medicine has seen how technology was going day by day more present to become necessary. At the same time, security became a critical aspect, since private patient medical data are handled. In this field in which gather mobile technologies with medicine, security has great importance. Therefore, it is essential to conduct security audits to mobile applications which deal with private information and confidential patient data. The main objective of this paper is to carry out an audit of security of an mHealth Android application. Taking HeartKeeper application to self-manage cardiac patients, a series of tests and modifications are conducted to check its strengths and weaknesses. The methodology consists in attempting to decompile the application HeartKeeper. Applying to the source code techniques of reverse engineering, we will try to perform an analysis that allows us to carry out the security check of the Android application HeartKeeper. It can be applied to audit security on any other Android application. In this way, it provides developers a tool that allows them to check the security of any Android app. Among these vulnerabilities found, the most relevant is that which allows us to inject code to steal some private information. This information should only be accessible from the application itself and only once the user is authenticated. As solutions, we propose different protections. These are: protection against decompilation, against code analysis, and against modified applications. It is very important to carry out a comprehensive review of the mobile applications' strength, since they are increasingly present in our lives and they manage sensitive and protected data. It is highly recommended to install applications from trusty sources, as they are the official app stores like Google Play Store in Android and iOS App Store.},
  keywords={Androids;Humanoid robots;Medical services;Malware;Conferences;Android;app;audit;mhealth;security},
  doi={10.1109/HealthCom.2017.8210757},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10320193,
  author={Chen, Guoqiang and Gao, Han and Zhang, Jie and He, Yanru and Cheng, Shaoyin and Zhang, Weiming},
  booktitle={2023 20th Annual International Conference on Privacy, Security and Trust (PST)}, 
  title={Investigating Neural-based Function Name Reassignment from the Perspective of Binary Code Representation}, 
  year={2023},
  volume={},
  number={},
  pages={1-11},
  abstract={Building a model to reassign descriptive names for binary functions is considerable assistance for reverse engineering. Existing methods proposed for this issue are based on the low-level representation of binary code (e.g., assembly code), and especially the recent approaches employed neural-based models on instruction sequences. However, their performance is still unsatisfactory. Meanwhile, modern decompilers provide lifted representations of binary code, and their effectiveness has not been adequately studied. This paper further explores the issue of function name reassignment from the perspective of binary code representation. Specifically, we present a general and flexible NEural-based function name Reassignment framework NER, which leverages a decompiler to obtain a specific representation and applies the corresponding serialization strategy on it. NER then uses an alternative neural network to make predictions. Three levels of representation are investigated, including assembly code, Intermediate Representation (IR), and pseudo-code. We observe the binary code representations are significant for the final performance. It demonstrates that the pseudo-code is the most effective one. Based on these findings, we leverage the framework to implement a reassignment model NER-pc, which has 25% and 10% F1 score improvements against the state-of-the-art methods. Besides, more experiments are conducted to verify the design of NER and the effectiveness of NER-pc.},
  keywords={Privacy;Reverse engineering;Neural networks;Buildings;Binary codes;Predictive models;Security;Binary analysis;Reverse engineering;Function name prediction;Binary code representation;Neural networks},
  doi={10.1109/PST58708.2023.10320193},
  ISSN={2643-4202},
  month={Aug},}@INPROCEEDINGS{10043270,
  author={Yu, Qifan and Zhang, Pengcheng and Dong, Hai and Xiao, Yan and Ji, Shunhui},
  booktitle={2022 29th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Bytecode Obfuscation for Smart Contracts}, 
  year={2022},
  volume={},
  number={},
  pages={566-567},
  abstract={Ethereum smart contracts face serious security problems, which not only cause huge economic losses, but also destroy the Ethereum credit system. To solve this problem, code obfuscation techniques are applied to smart contracts to improve their complexity and security. However, the current source code obfuscation methods have insufficient anti-decompilation ability. Therefore, we propose a novel bytecode obfuscation approach called BOSC based on four kinds of bytecode obfuscation techniques, which is directed at solidity. The experimental results show that, after the bytecode obfuscation, the failure rate of decompilation tools is over 99% and only a small amount of gas is consumed.},
  keywords={Economics;Codes;Source coding;Smart contracts;Complexity theory;Security;Faces;Ethereum;Smart Contract;Bytecode Obfusca-tion},
  doi={10.1109/APSEC57359.2022.00083},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{10197775,
  author={Lee, Young and McDonald, Arlen and Yang, Jeong},
  booktitle={2023 IEEE/ACIS 21st International Conference on Software Engineering Research, Management and Applications (SERA)}, 
  title={Identifying Code Tampering Using A Bytecode Comparison Analysis Tool}, 
  year={2023},
  volume={},
  number={},
  pages={69-76},
  abstract={The issues related to SolarWinds attacks point out a large concern with modern software development projects in that there are fundamental flaws with existing security infrastructure. The purpose of this research is to investigate to what extent can the SootDiff analysis tool, a bytecode comparison tool, be used to determine if an application has been tampered with by comparing a known good version with a version that is unknown. The compiled and decompiled bytecodes as Jimple representations were compared to analyze the unique differences in identifying code tempering. The results showed that the scope of the variable is important in whether the change was detected. Variables with a scope that was entirely contained within one method could have their names changed without triggering a warning, but global variables to objects could not. The parameter variable and the local variable behave differently. Since the parameter is in the publicly available part of the method Java treats it the same way as it does the global variable. The local variable is strictly private to the method and not made available to the outside. Such findings can support the analysis tool which is useful for identifying potential breaches to detect meaningful changes in code even if it is decompiled.},
  keywords={Java;Codes;Supply chains;Software;Security;Software engineering;SolarWinds;SootDiff;Java;Jimple;bytecode;software supply chain;software supply chain security},
  doi={10.1109/SERA57763.2023.10197775},
  ISSN={2770-8209},
  month={May},}@INPROCEEDINGS{11129273,
  author={Behner, Eva-Maria C. and Enders, Steffen and Padilla, Elmar},
  booktitle={2025 IEEE 10th European Symposium on Security and Privacy (EuroS&P)}, 
  title={SoK: No Goto, No Cry? The Fairy Tale of Flawless Control-Flow Structuring}, 
  year={2025},
  volume={},
  number={},
  pages={411-431},
  abstract={Decompilers play a crucial role in the detailed analysis of malware or firmware, particularly because control-flow structuring allows the recovery of high-level code that is more readable to human analysts. Despite the ongoing debate over their usage of gotos to work around constraints during control-flow structuring, pattern-matching approaches remain prevalent among both commercial and open-source decompilers. With the emergence of pattern-independent restructuring techniques, various attempts have been made to overcome readability limitations, especially concerning the use of gotos. However, despite these advances, recent approaches often fail to thoroughly address several inherent challenges of control-flow structuring, thereby affecting output quality or practicality.In this paper, we systematize the intrinsic challenges of control-flow structuring that every approach must address. In addition, we review existing methods, comparing them, while highlighting both their advantages and limitations with respect to these challenges. Specifically, we emphasize the practicability issues of current pattern-independent restructuring techniques and discuss whether and how future methods might overcome them. Finally, we explore the theoretical potential to mitigate some of these challenges by suggesting methodology ideas for various aspects of control-flow structuring. Overall, this paper enables other researchers to make informed decisions when developing or enhancing control-flow structuring methods, thereby preventing negative side-effects arising from the interdependence of challenges.},
  keywords={Codes;Reviews;Reverse engineering;Static analysis;Malware;Microprogramming;decompilation;control-flow recovery;control-flow structuring;reverse engineering;static analysis},
  doi={10.1109/EuroSP63326.2025.00032},
  ISSN={2995-1356},
  month={June},}@ARTICLE{11052248,
  author={Peng, Xiangzhen and Ma, Tianyu and Zheng, Chengliang and Shen, Zhidong and Cui, Xiaohui},
  journal={IEEE Internet of Things Journal}, 
  title={BCTD-ICS: A Blockchain-Aided Framework for Trusted Detection of Industrial Control System Components}, 
  year={2025},
  volume={12},
  number={18},
  pages={37552-37570},
  abstract={The cybersecurity threats targeting industrial control systems (ICSs) are evolving with increasing sophistication. Addressing the detection blind spots in existing source code analysis techniques, this study reveals a dual security paradox arising from code sensitivity: privacy leakage risks caused by decompilation techniques and integrity verification deficiencies in reverse engineering. This article investigates three critical challenges: 1) what are the component flow process and detection elements of ICS component source code? 2) how can high-performance and reliable tracing and traceability be provided for ICS component source code exceptions and routine detection? and 3) how can privacy enhancement and trusted detection of ICS component source code with high sensitivity be achieved? This article proposes a blockchain-integrated trusted detection framework for ICS (BCTD-ICS), delivering groundbreaking solutions: 1) establishing a lifecycle circulation model that systematically maps component types, stakeholders, and detection parameters; 2) developing a tripartite collaborative architecture [blockchain- identification resolution zero-knowledge proofs (ZKPs)], featuring a traceability mechanism with trusted identification codes (resolution efficiency: 40 ms/105 queries) to eliminate decompilation-induced privacy risks; and 3) creating an industrial-oriented privacy enhancement system utilizing DBSCAN clustering for intelligent sampling (26% compression rate on BCN3D Moveo) and optimizing ZK-SNARK protocols through Shamir’s secret sharing, establishing a backdoor-resistant distributed parameter generation system (time delay increment < 100 ms). Experimentally verified, our solution enables ICS component code detection supply-chain-wise without sensitive data leakage in real-world industries. This work establishes a novel trusted detection paradigm for ICS, advancing detection efficiency and credibility under strict privacy preservation requirements, meeting Industry 4.0 security demands.},
  keywords={Blockchains;Source coding;Security;Codes;Privacy;Supply chains;Protocols;Object recognition;Telecommunication traffic;Internet of Things;Artificial intelligence technology;blockchain;identification resolution technology;industrial control systems (ICSs);source code detection;zero-knowledge proofs (ZKPs)},
  doi={10.1109/JIOT.2025.3583304},
  ISSN={2327-4662},
  month={Sep.},}@INPROCEEDINGS{9445905,
  author={Lu, Ziang and Shao, Zhipeng},
  booktitle={2021 International Conference on Communications, Information System and Computer Engineering (CISCE)}, 
  title={A Research on ELF File Protection Schemes of IOT Application in Electric Power Industry}, 
  year={2021},
  volume={},
  number={},
  pages={105-108},
  abstract={As more and more IOT Applications implemented in electric power industry, source code leaking gradually becomes an important topic for discussion. Some researches have proved that IOT APP could be cracked down and source code (C/C++, JAVA, etc) is likely to be decompiled by attackers with expert skills. And this trend is going to be irreversible with a variety of auto-cracking tools published, which means that the cost of time and cracking technique are unprecedentedly decreased. To avoid source code leaking, some ways of protecting native code in ELF file such as code obfuscation or ELF shell (special in Android) were provided and then applied widely. But these schemes can not meanwhile completely satisfy the performance and secure rate in Linux platform. This paper originally proposes a scheme that protects native code from being decompiled and stolen in situation where ELF file is called by JAVA in Linux. The SM4 encryption algorithm and look-up table are creatively used to achieve the goals of apparently elevating the security within a limited performance price. At the posterior of the paper, a control experiment between one famous open source project and this scheme is introduced to supply the data supporting.},
  keywords={Technical requirements;Java;Ground penetrating radar;Linux;Geophysical measurement techniques;Tools;Table lookup;component;ELF(SO) file protection;look-up table;SM4;native code;IOT application},
  doi={10.1109/CISCE52179.2021.9445905},
  ISSN={},
  month={May},}@INPROCEEDINGS{11081372,
  author={R, Siva Surya and R, Varuneshan and C, Heltin Genitha},
  booktitle={2025 3rd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS)}, 
  title={Designing a Static Malware Analysis Framework for Detecting Malicious Malware Code with Ghidra}, 
  year={2025},
  volume={},
  number={},
  pages={1696-1701},
  abstract={Malware analysis is an integral part of cybersecurity, however traditional signature-based detection techniques are inadequate for advanced obfuscation techniques. This paper proposes a static malware analysis framework for identifying malicious code, using Ghidra. The proposed malware analysis framework decompiles malware samples automatically in order to extract features, while reviewing control flow, scanning opcodes, or extracting embedded strings. Additionally, the system uses integrated tools such as VirusTotal API and PEview to validate or classify signatures and analyze file structure. An experimental evaluation of the proposed framework showed an 89% success rate of malware detection that outperformed the performance of traditional signature based methods (72%) and had a lower false-positive rate (7%) than heuristic based methods (15%) under specific conditions. Results suggest that the proposed framework is effective towards the identification of obfuscated malware while being reliable. Unlike earlier traditional techniques, the system user-friendly utilizes Ghidra's improved, advanced capabilities of decompilation and scripts to offer more precision and automation. The solution provides improvement in cybersecurity with an effective, scalable, and automated, static approach to malware analysis.},
  keywords={Automation;Codes;Computer viruses;Machine learning;Inspection;Feature extraction;Dynamic scheduling;Malware;Reliability;Computer security;Static Malware Analysis;Ghidra;Opcode Inspection;Heuristic Detection;VirusTotal API;PEview;Cybersecurity},
  doi={10.1109/ICSSAS66150.2025.11081372},
  ISSN={},
  month={June},}@INPROCEEDINGS{9259834,
  author={TAHTACI, Burak and CANBAY, Beyzanur},
  booktitle={2020 Innovations in Intelligent Systems and Applications Conference (ASYU)}, 
  title={Android Malware Detection Using Machine Learning}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={The usage of mobile devices is increasing exponentially. There were lots of critical applications such as banking to health applications are available on mobile devices through mobile applications. This penetration and spread of mobile applications brings some threats. Malicious software(Malware) is one of these dangers. Malware has the potential to cause damage to various scales such as theft of sensitive data, identity and credit card. To reduce the effects of these threats, antiviruses have been developed and malware analysis teams have been established, but human effort may be insufficient in the rapidly growing malware market. For this reason, automated malware scanning solutions should be developed by making use of machine learning algorithms. In this study, machine learning models were created by using the n-gram features of the smali files, which are the decompiled Android packages. The trained models are combined with different feature extraction and feature selection methods and as a result their performances are reported.},
  keywords={Malware;Machine learning;Covariance matrices;Internet;Forestry;Feature extraction;Support vector machines;Malware Detection;Mobile Malwares;Static Code Analysis;Machine Learning;Artificial Neural Neworks;Random Forest},
  doi={10.1109/ASYU50717.2020.9259834},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9331988,
  author={Aminuddin, Afrig},
  booktitle={2020 3rd International Conference on Information and Communications Technology (ICOIACT)}, 
  title={Android Assets Protection Using RSA and AES Cryptography to Prevent App Piracy}, 
  year={2020},
  volume={},
  number={},
  pages={461-465},
  abstract={Android is the major operating system for mobile devices. The presence of the Google Play Store creates an ecosystem between the app developers and users. As the ecosystem grows, some pirated apps start to show up. This is possible due to the nature of the Android Application that easily can be extracted and decompiled to reveal the source code and the assets file. This research proposed a methodology to protect the application assets from piracy using the cryptographic algorithm. The assets are encrypted during the compile-time using the Gradle build system provided by the Android Studio. While the decryption is performed in the Android device during the application run-time. The proposed algorithm is the pair of asymmetric algorithm called RSA and the symmetric algorithm called AES. This research shows that RSA-AES gives the best security in protecting the assets of Android applications. Besides, the performance of the algorithm is evaluated based on the speed of the encryption and decryption that reach 106.82 MB/s and 44.42 MB/s respectively.},
  keywords={Performance evaluation;Operating systems;Ecosystems;Public key;Mobile handsets;Internet;Cryptography;Android;Cryptography;Encryption;Decryption},
  doi={10.1109/ICOIACT50329.2020.9331988},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8299877,
  author={Dalai, Asish Kumar and Das, Shakya Sundar and Jena, Sanjay Kumar},
  booktitle={2017 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)}, 
  title={A code obfuscation technique to prevent reverse engineering}, 
  year={2017},
  volume={},
  number={},
  pages={828-832},
  abstract={Reverse engineering is the process of decompiling and disassembling the executables to recover the source code/assembly code embedded within it. While reverse engineering is the process of examining the code, in offensive context the attackers can re-engineer the code which leads to software piracy. Software anti-tamper technology like obfuscation is used to deter both reverse engineering and re-engineering of proprietary software and software-powered systems. Code obfuscation, as a part of software protection, got commercial interest from both vendors and as well as from the clients. Vendors want to keep their proprietary code as secret and customers needs software upon which they can trust. In this article, a code obfuscation technique has been proposed to complicate the process of reverse engineering. The basic idea is to conceal the proprietary code section by using preventive design obfuscation and insertion of self-modifying code at the binary level. The combination of design level obfuscation and the insertion of self-modifying code converts the code into a semantically equivalent one that makes it difficult to reverse engineer. The technique is evaluated using different sorting algorithms. The experimental results quantify the degree of obfuscation, stealth of the code, and effects on execution time and code size.},
  keywords={Reverse engineering;Software;Static analysis;Servers;Tools;Resists;Conferences;Software Security;Code Obfuscation;Reverse Engineering},
  doi={10.1109/WiSPNET.2017.8299877},
  ISSN={},
  month={March},}@INPROCEEDINGS{9948365,
  author={Han, Wenjie and Pang, Jianmin and Zhou, Xin and Zhu, Di},
  booktitle={2022 5th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)}, 
  title={Binary vulnerability mining technology based on neural network feature fusion}, 
  year={2022},
  volume={},
  number={},
  pages={257-261},
  abstract={The high complexity of software and the diversity of security vulnerabilities have brought severe challenges to the research of software security vulnerabilities Traditional vulnerability mining methods are inefficient and have problems such as high false positives and high false negatives, which can not meet the growing needs of software security. To solve the above problems, this paper proposes a binary vulnerability mining technology based on neural network feature fusion. Firstly, this method constructs binary vulnerability data sets containing multiple vulnerability types, then decompile them to the pcode intermediate language level, and then extracts relevant feature vectors from binary vulnerability data sets according to Bert fine tuning model and bilstm model respectively. In order to fully obtain the semantic information of vulnerabilities, this method standardized the two, fused them, and carried out relevant experiments. The experimental results show that the accuracy of vulnerability detection on SARD data set is 96.92%, which is higher than other binary vulnerability detection methods based on neural network.},
  keywords={Computers;Neural networks;Semantics;Feature extraction;Software;Data models;Data mining;Vulnerability mining;Decompilation Technology;Deep learning;Neural network},
  doi={10.1109/AEMCSE55572.2022.00058},
  ISSN={},
  month={April},}@INPROCEEDINGS{10123584,
  author={Xiao, Xuangan and Wang, Yizhuo and Hu, Yikun and Gu, Dawu},
  booktitle={2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={xVMP: An LLVM-based Code Virtualization Obfuscator}, 
  year={2023},
  volume={},
  number={},
  pages={738-742},
  abstract={Obfuscation techniques are widely used to protect the digital copyright and intellectual property rights of software. Among them, code virtualization is one of the most powerful obfuscation techniques, which hides both the control flow and the data flow of the code, thereby preventing code from being decompiled. However, existing code virtualization solutions are not well-resistant to de-obfuscation techniques (e.g., symbolic execution and frequency analysis), and only target limited program languages and architectures, which are challenging to integrate into the process of software development and maintenance.In this paper, We propose an LLVM-based code virtualization tool, namely xVMP to fulfill a scalable and virtualized instruction-hardened obfuscation. To mask the effects of multiple program languages and architectures, xVMP incorporates the obfuscation process of code virtualization into the compilation, and generates virtualized code based on LLVM intermediate representation (IR). After virtualization, it embeds the interpreter of virtualized code into the IR and compiles to an executable. To enhance the security, xVMP encrypts virtualized instructions in each basic block and decrypts them at runtime to enhance the security of obfuscation. In addition, it supports specified function obfuscation. xVMP identifies the function annotations marked by the developer in the source code to locate the function to protect. We implement the prototype of xVMP, and evaluate it with a microbenchmark and three real-world programs. The experimental results show that xVMP can be more difficult to crack than the state-of-the-art obfuscators, and it can support more source code types and architectures, and can be applied to real-world software. Source Code: https://github.com/GANGE666/xVMP.},
  keywords={Codes;Runtime;Annotations;Source coding;Prototypes;Computer architecture;Intellectual property;Code Virtualization;Obfuscation;Reverse Engineering},
  doi={10.1109/SANER56733.2023.00082},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{9141591,
  author={Maalla, Allam},
  booktitle={2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)}, 
  title={Improves the Operation and Maintenance Technology of DC Transmission Based on the Algorithm of VBE}, 
  year={2020},
  volume={},
  number={},
  pages={1813-1817},
  abstract={At present, VBE is widely used in DC transmission research, and its performance directly affects the actual operation process of DC transmission systems. This research improves the operation and maintenance technology of field personnel and the reliability of DC transmission by studying the program of the VBE system and analyzing its weak links. Our research is to simulate the operating conditions of the VBE system and use the platform to test the VBE to ensure that it is in good working condition. Therefore, research decompiles the VBE system, builds a test platform, sorts out its weak links, and proposes anti-accident measures for research. Both in the theoretical method research and engineering application prospects are in the domestic leading position.},
  keywords={Valves;Monitoring;Threshold voltage;Optical receivers;Cooling;Optical fibers;DC Transmission;Converter Valve;VBE;Single-Ship CPU},
  doi={10.1109/ITOEC49072.2020.9141591},
  ISSN={},
  month={June},}@INPROCEEDINGS{9718856,
  author={Zhu, Di and Pang, Jianmin and Zhou, Xin and Han, Wenjie},
  booktitle={2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)}, 
  title={Similarity Measure for Smart Contract Bytecode Based on CFG Feature Extraction}, 
  year={2021},
  volume={},
  number={},
  pages={558-562},
  abstract={As the mainstream of smart contract research, most Ethereum smart contracts do not open their source code, and the bytecode of smart contracts has attracted the attention of researchers. Based on the similarity measurement of smart contract bytecode, a series of tasks such as vulnerability mining, contract upgrading and malicious contract detection can be carried out. This paper proposes a method to measure the similarity of smart contract bytecode. Firstly, the key opcode combination of smart contract is summarized. When traversing the CFG(control flow graph) constructed by decompilation of smart contract bytecode, the opcodes in the basic block are pattern matched, and the features between the basic blocks are extracted according to the in-out degree, so as to enhance the similarity measurement effect of contract semantics in vector space. The experimental results show that the proposed method is greatly improved compared with the baseline.},
  keywords={Information science;Smart contracts;Semantics;Euclidean distance;Feature extraction;Extraterrestrial measurements;Flow graphs;bytecode similarity;basic block;CFG;feature extraction},
  doi={10.1109/CISAI54367.2021.00113},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9631860,
  author={Wahaz, Rizaldi and Harmana, Rakha Nadhifa and Amiruddin, Amiruddin and Suryadinata, Ardya},
  booktitle={2021 6th International Workshop on Big Data and Information Security (IWBIS)}, 
  title={Is WhatsApp Plus Malicious? A Review Using Static Analysis}, 
  year={2021},
  volume={},
  number={},
  pages={91-96},
  abstract={For cybersecurity activists, reviewing whether an application, including modified applications, is malicious or not is a challenging job. WhatsApp Plus is a messenger application modified from the official WhatsApp application. Comparing the source code of the WhatsApp Plus with the official WhatsApp is one way to review its security or malice. Considering that WhatsApp is very popular and has many users, the results of this investigation are very useful for users to avoid malicious applications. In this study, we have conducted an exploration of the source code of the WhatsApp and WhatsApp Plus applications to find out whether or not WhatsApp Plus has been inserted with malware, spyware, or other malicious code. The exploration used the static analysis method, where the source code of the two applications were decompiled, compared, and analyzed. The de-compilation is done using the MobSF tool and the comparison using the extension of Visual Studio Code called Compare Folders. The differences in the source code found are then analyzed for possible behavior to determine whether it can cause harm, for example stealing user credentials. Although no malicious code was found on WhatsApp Plus, in our study, users must stay alert since they remain vigilant in installing and using WhatsApp Plus because the developer may add malicious code to the next version update.},
  keywords={Deep learning;Freeware;Visualization;Codes;Databases;Information security;Static analysis;Malicious;Source code;Static Analysis;WhatsApp;WhatsApp Plus},
  doi={10.1109/IWBIS53353.2021.9631860},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8109245,
  author={Lee, Sung-Hoon and Kim, Seung-Hyun and Kim, SooHyung and Jin, Seung-Hun},
  booktitle={2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Appwrapping Providing Fine-Grained Security Policy Enforcement Per Method Unit in Android}, 
  year={2017},
  volume={},
  number={},
  pages={36-39},
  abstract={Enterprise mobility management (EMM) solution is widely used to securely protect confidential information stored on an individual's smartphone, while increasing the efficiency because of BYOD policy. The application wrapping (Appwrapping) technology is one way to be applied EMM solutions, by modifying binary applications without the original source code. In the past, Appwrapping was performed to control permissions or APIs to protect privacy on Android. This method is applied collectively to the whole section, not a specific section of the app, so it is difficult to control the section (flow) desired by the user or the manager. In addition, system overhead can occur because the control is applied to the whole section of the app. In this paper, we propose a method to insert an additional security policy code at a certain interval position in the intermediate code of a binary app, so that it can be controlled at a specific interval rather than the whole interval of the app. The proposed method extracts and saves the security policy intermediate code and the related file in advance and then adds the security policy code to the specific method on the intermediate code of the specific activity acquired by decompiling the target app. Finally, the additional security policy code is modified to avoid errors caused by the additional code. We create an automation tool for performance verification, experiment with five commercial office apps, and confirm that the apps work properly with the added EMM security functions.},
  keywords={Privacy;Androids;Humanoid robots;Libraries;Usability;Information security;Appwrapping;EMM;mobile security},
  doi={10.1109/ISSREW.2017.25},
  ISSN={},
  month={Oct},}@ARTICLE{9514711,
  author={Nghi Phu, Tran and Dai Tho, Nguyen and Huy Hoang, Le and Ngoc Toan, Nguyen and Ngoc Binh, Nguyen},
  journal={The Computer Journal}, 
  title={An Efficient Algorithm to Extract Control Flow-Based Features for IoT Malware Detection}, 
  year={2019},
  volume={64},
  number={1},
  pages={599-609},
  abstract={Control flow-based feature extraction method has the ability to detect malicious code with higher accuracy than traditional text-based methods. Unfortunately, this method has been encountered with the NP-hard problem, which is infeasible for the large-sized and high-complexity programs. To tackle this, we propose a control flow-based feature extraction dynamic programming algorithm for fast extraction of control flow-based features with polynomial time O($N^{2}$), where N is the number of basic blocks in decompiled executable codes. From the experimental results, it is demonstrated that the proposed algorithm is more efficient and effective in detecting malware than the existing ones. Applying our algorithm to an Internet of Things dataset gives better results on three measures: Accuracy = 99.05%, False Positive Rate = 1.31% and False Negative Rate = 0.66%.},
  keywords={IoT malware detection;control flow-based features;dynamic programming;CFD;embedded malware},
  doi={10.1093/comjnl/bxaa087},
  ISSN={1460-2067},
  month={Nov},}@INPROCEEDINGS{10857519,
  author={Yama, Yuto and Uda, Ryuya},
  booktitle={2025 19th International Conference on Ubiquitous Information Management and Communication (IMCOM)}, 
  title={Machine Learning Approach to Malware Classification Using Byte N-Grams on IoT Devices}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Malware for IoT devices has become popular in recent years. Many detection methods have been proposed to detect the malware, mainly using machine learning, but they are not designed to work on IoT devices and are often implemented using Python. Running a Python program requires the installation of a package, which is impractical given the memory and storage size of IoT devices. In addition, methods that require decompilation, static and dynamic analysis of test samples are difficult to run on IoT devices. Therefore, in this research, we propose a method implemented in C/C++ so that malware detection using byte n-grams and machine learning can be run on IoT devices, and then resource consumption can be measured. Byte n-gram methods are good approaches to detect malware without knowing the execution environment. Moreover, the Top-L approach to information gain can be effectively applied to reduce storage and memory consumption. As a result of the evaluation, when using an SVM model with Top-50000 that maintains effective classification accuracy, the memory consumption was 71.91MB and the storage consumption was 1.3GB, which can be implemented in IoT devices.},
  keywords={Support vector machines;Radio frequency;Accuracy;Memory management;Virtual environments;Machine learning;Malware;Information management;Internet of Things;Python;malware detection;IoT;machine learning},
  doi={10.1109/IMCOM64595.2025.10857519},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9115191,
  author={Feng, Li and Tao, Chen and Bin, Wang and Jianye, Zhang and Song, Qing},
  booktitle={2020 Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC)}, 
  title={Research on Information Security Technology of Mobile Application in Electric Power Industry}, 
  year={2020},
  volume={},
  number={},
  pages={51-54},
  abstract={With the continuous popularization of smart terminals, Android and IOS systems are the most mainstream mobile operating systems in the market, and their application types and application numbers are constantly increasing. As an open system, the security issues of Android application emerge in endlessly, such as the reverse decompilation of installation package, malicious code injection, application piracy, interface hijacking, SMS hijacking and input monitoring. These security issues will also appear on mobile applications in the power industry, which will not only result in the embezzlement of applied knowledge copyrights but also lead to serious leakage of users' information and even economic losses. It may even result in the remote malicious control of key facilities, which will cause serious social issues. Under the background of the development of smart grid information construction, also with the application and promotion of power services in mobile terminals, information security protection for mobile terminal applications and interactions with the internal system of the power grid has also become an important research direction. While analyzing the risks faced by mobile applications, this article also enumerates and analyzes the necessary measures for risk resolution.},
  keywords={power industry;mobile application;information security;security reinforcement},
  doi={10.1109/IPEC49694.2020.9115191},
  ISSN={},
  month={April},}@INPROCEEDINGS{9421647,
  author={Han, Wenjie and Pang, Jianmin and Zhou, Xin and Zhu, Di},
  booktitle={2020 5th International Conference on Mechanical, Control and Computer Engineering (ICMCCE)}, 
  title={Binary software vulnerability detection method based on attention mechanism}, 
  year={2020},
  volume={},
  number={},
  pages={1462-1466},
  abstract={Aiming at the stack overflow vulnerability in binary software, this paper proposes a binary vulnerability detection method based on the attention mechanism. First, this paper analyze the basic characteristics of stack overflow vulnerabilities, and perform data preprocessing on the decompiled files to make the neural network better adapt to the characteristics of stack overflow vulnerabilities, then formulate instruction specifications at the assembly language level, and finally input the data into the fusion attention mechanism Learning in the neural network. This paper compares and analyzes three kinds of neural networks on the CWE121 data set. The experimental results show that after neural network training, the detection method based on the attention mechanism can be effective and accurately discover whether the target area has stack overflow vulnerabilities, thereby greatly improving the detection efficiency.},
  keywords={Training;Computational modeling;Neural networks;Force;Data preprocessing;Software;Data models;Binary;software vulnerability;attention;machine learning},
  doi={10.1109/ICMCCE51767.2020.00320},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10077138,
  author={Lv, Di and Zhao, Liang and Chen, Bin},
  booktitle={2022 International Conference on Industrial IoT, Big Data and Supply Chain (IIoTBDSC)}, 
  title={Research Based on LLVM Code Obfuscation Technology}, 
  year={2022},
  volume={},
  number={},
  pages={163-167},
  abstract={Computer programs are executed continuously in a certain relatively fixed order of instructions. Replacing these instructions with another more complex order or with different instructions with the same meaning without changing the result of the program will change the logic of the original instructions without affecting the result of the operation, which is the core principle of code obfuscation. In the compilation process, before the compiler compiles the code into the target machine code, it will transform the code into a kind of intermediate code, and then generate the target code after Control Flow Flattening and string encryption obfuscation of the intermediate code, which will make the decompilation work more difficult, thus realizing a code obfuscation system, and through some test cases, the effectiveness and feasibility of the system is demonstrated.},
  keywords={Codes;Source coding;Operating systems;Supply chains;Reverse engineering;Process control;Transforms;code obfuscation;code safety;Control Flow Flattening obfuscation;String encryption;encryption process},
  doi={10.1109/IIoTBDSC57192.2022.00039},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9117398,
  author={Kim, Yeoneo and Kim, Jinseob and Liu, Xiao and Cheon, Junseok and Woo, Gyun},
  booktitle={2019 8th International Conference on Innovation, Communication and Engineering (ICICE)}, 
  title={PILDroid: A System for Detecting the Leakage of Privacy Information using the JNI}, 
  year={2019},
  volume={},
  number={},
  pages={153-156},
  abstract={We live in a period of explosive growth of smart device applications. Specifically, the growth rate of Android applications is amazing. And these Android applications often use JNI (Java native interface). However, research on the leakage of private information using JNI is lacking. In this paper, we propose a system for detecting the leakage of private information using JNI. Our system named PILDroid adopts tainted analysis based on static method. PILDroid can perform the analysis more easily and effectively than the assembly-based analysis systems because it decompiles a JNI into LLVM IR instead of assembly language. And this paper demonstrates an experiment to verify the precision and performance. For the test data, we selected five Android applications: three of which are well known malware, two of which are malware made by us. And experiment results, PILDroid determined that there has a leak of privacy information flow from five malware.},
  keywords={Android;taint analysis;static analysis;privacy leakage},
  doi={10.1109/ICICE49024.2019.9117398},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7889345,
  author={Popić, Srđan and Velikić, Ivan and Teslić, Nikola},
  booktitle={2017 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={Retrieving the useful information from the binary files compiled by C compiler}, 
  year={2017},
  volume={},
  number={},
  pages={338-339},
  abstract={In order to reuse a software component or verify it, the information about compiler, that is used for compilation of the component, is very significant. Due to unknown build flags and compiler information, third party components usually cannot be reused. When it comes to the matter of software components developed in C language, the only place to look for this information is in compiled binary file. Since there are no standards for C language that bind compiler to leave any information about itself in binary file, the information is not expected to be found. However, the information can be found in most of the binary files. This paper investigates what is the possibility of retrieving the information about compiler name and version based on the content of the binary code, without decompiling the binary code. The information retrieving opens up new possibilities for reusing the components and verifying the software requirements as well.},
  keywords={Software;Testing;Conferences;Feature extraction;Binary codes;Training;Consumer electronics},
  doi={10.1109/ICCE.2017.7889345},
  ISSN={2158-4001},
  month={Jan},}@INPROCEEDINGS{9638928,
  author={Fang, Zhan and Liu, Jun and Huang, Ribian and Chen, Peng and Li, Xin and Chen, Xiao},
  booktitle={2021 4th International Conference on Robotics, Control and Automation Engineering (RCAE)}, 
  title={Research on Multi-model Android Malicious Application Detection Based on Feature Fusion}, 
  year={2021},
  volume={},
  number={},
  pages={147-151},
  abstract={With the widespread use of the Android operating system, the number of applications on the platform is increasing, and malicious applications are also emerging. How to effectively identify android malware applications to prevent and protect the security of the mobile terminal is a crucial issue. This paper uses the feature fusion method and directly call the library function to extract the permissions and API features of the APK file, then decompile the APK file to obtain the opcode features and merge the three features with multiple features to generate a feature vector. Finally it use a multi-model neural network HYDRA to learn fusion feature vector, so that it can identify and detect malware. The work also compare it with other single-feature machine learning algorithms to verify its effect. Experimental results show that the accuracy of the multi-model neural network detection method based on feature fusion reaches 98.92%, which is better than other single-model feature methods.},
  keywords={Machine learning algorithms;Automation;Operating systems;Neural networks;Feature extraction;Malware;Libraries;android malicious applications;decompile;feature fusion;neural network},
  doi={10.1109/RCAE53607.2021.9638928},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10594168,
  author={Wu, Liang},
  booktitle={2024 IEEE 4th International Conference on Electronic Technology, Communication and Information (ICETCI)}, 
  title={A Malicious Code Detection Strategy Based on Feature Fusion}, 
  year={2024},
  volume={},
  number={},
  pages={1502-1506},
  abstract={Due to its weak characteristics, the general malware software detection technology has the weakness of inaccurate detection and inefficiency. Therefore, a malicious application or software detection mechanism is designed based on feature fusion. The detection mechanism based on OPC X-gram and malicious applications or software is improved, and the malicious applications or software detection mechanism based on OPC X-gram with multi-X value combination can mine the expressive logic sequence of malicious applications or software and improve the detection ability of malicious application or software. The potential feature representation mechanism of OPC X-gram is designed, and the decompiling component is used to get the source of the procedure to be tested. Then the source parts to be analyzed is extracted. Combined with the OPC X-gram sequences with multiple X values, the recognizable sequences are screened out by using the content feature recognition method, and the malicious application or software classification training is carried out on the OPC X-gram logic sequences with different X values by using KNN and RF classification algorithms, and finally the OPC X-gram will be used. The inferring sequence will be f made up by logic analysis again. By the experiment analysis, the proposed multi-X value OPC X-gram approach is better than the bin-file X-gram sequence logic and the single-X value OPC X-gram in terms of the accuracy of the potential threat application or software classification.},
  keywords={Training;Radio frequency;Accuracy;Nearest neighbor methods;Feature extraction;Software;Malware;Decompiling;Code detection;Training;Feature extraction},
  doi={10.1109/ICETCI61221.2024.10594168},
  ISSN={},
  month={May},}@INPROCEEDINGS{8859456,
  author={Huang, Song and Yang, Sen and Hui, Zhanwei and Yao, Yongming and Chen, Lele and Liu, Jialuo and Chen, Qiang},
  booktitle={2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)}, 
  title={Runtime-Environment Testing Method for Android Applications}, 
  year={2019},
  volume={},
  number={},
  pages={534-535},
  abstract={One of the key problems in app testing is to improve the test coverage of apps. However, current testing techniques, whether in code coverage or activity coverage, are not satisfactory. To address this limitation, we present an algorithm for generating test runtime-environment-set to exercise mobile apps. Our approach is based on code analysis to systematically test the targeted code of the Android apps. It analyzes the decompiled code that identifies the code related to Android SDK version, generating the corresponding test cases with the runtime-environment set. We also implement our approach on Android, and validate the method with the existing widely used strategies. An empirical study of the practical usefulness of the technique has been presented on 6 widely-used industrial apps. 18 unique crashes have been found, and the method coverage has been increased by far 9.8% to 130.4% on those apps.},
  keywords={Testing;Smart phones;Runtime environment;Tools;Google;Computer crashes;Mobile testing, code analysis, android version, runtime environment set generation},
  doi={10.1109/QRS-C.2019.00111},
  ISSN={},
  month={July},}@INPROCEEDINGS{11205440,
  author={Adamec, Matej and Turčaník, Michal},
  booktitle={2025 Communication and Information Technologies (KIT)}, 
  title={Malware Detection with LLM}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The increasing sophistication of malware poses critical challenges to traditional detection techniques, particularly in the face of polymorphic and evasive threats. Recent advances in Natural Language Processing (NLP), specifically through the deployment of large language models (LLMs), offer promising capabilities for addressing these challenges. This study evaluates the effectiveness of three LLMs-GPT-2, T5, and CodeBERT-in detecting malware from decompiled.c code derived from Portable Executable (PE) files. The models were tested on a balanced dataset containing real-world malware and benign samples, preprocessed using a custom tokenization and classification pipeline. Experimental results indicate that GPT-2 and T5 achieved strong performance. The study confirms the viability of transformerbased LLMs for source-code-based malware detection, particularly GPT-2 and T5, and emphasizes the importance of model selection and dataset quality. Future work will focus on refining these architectures using larger, more diverse training sets and incorporating class-weighted loss functions to further improve detection balance and reduce false positives.},
  keywords={Training;Codes;Large language models;Refining;Pipelines;Transformers;Malware;Tokenization;Information and communication technology;Faces;LLM;Malware Detection;GPT 2;T5;CodeBERT},
  doi={10.1109/KIT67756.2025.11205440},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8572021,
  author={Corcalciuc, Horia V.},
  booktitle={2018 Conference Grid, Cloud & High Performance Computing in Science (ROLCG)}, 
  title={Low-Level Control-Flow Manipulation Techniques}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={Contrary to interacting with software remotely at runtime, commercial software may be altered by an attacker that is able to to change the meaning of the program at will by decompiling and recompiling the program. An attacker is able to coerce control-flow, manipulate predicates in order to lead the program into a favourable state. The aim of this paper is to present a strictly limited set of low-level attack patterns and to draw a parallel to exploits carried out against system software that cannot be tampered with.},
  keywords={Runtime;Software packages;Software protection;Physics;Unified modeling language;Taxonomy;security;software protection;predicate logic;control flow;UML},
  doi={10.1109/ROLCG.2018.8572021},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8005920,
  author={Hong, Zhao and Nan, Guo},
  booktitle={2017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)}, 
  title={Java Source Code Protection Based on JNI and AES Algorithm}, 
  year={2017},
  volume={1},
  number={},
  pages={846-849},
  abstract={In the Java web security field, the encryption and decryption code of the traditional Java source code protection scheme, which is based on custom class loader encryption, can be easily decompiled. This effect results in the leakage of the source code and the low efficiency of encryption and decryption. This study proposes a scheme based on the Java Native Interface (JNI) and the Advanced Encryption Standard (AES) to protect the Java source code. The proposed scheme adopts the JNI for calling the encryption and decryption's codes implemented by C/C ++, and the encryption and decryption's codes adopt an improved AES encryption algorithm. This scheme greatly improves both the encryption and decryption of the implementation efficiency and the security of the source code.},
  keywords={Encryption;Java;Algorithm design and analysis;Standards;Electronic mail;Advanced Encryption Standard (AES);Data Encryption Standard (DES);Java Native Interface (JNI);Java;encryption},
  doi={10.1109/CSE-EUC.2017.169},
  ISSN={},
  month={July},}@INPROCEEDINGS{10965404,
  author={Li, Kun and Liu, Yanyan and Wang, Xuchen and Li, Guopeng and Ma, Ziyue},
  booktitle={2023 International Conference on Information Processing and Network Provisioning (ICIPNP)}, 
  title={Research on Recognition of Android Counterfeit Application Based on Siamese Network}, 
  year={2023},
  volume={},
  number={},
  pages={218-222},
  abstract={In recent years, with the popularity of mobile phones and mobile Internet, the download volume and application rate of third-party applications for smart phones, namely APP, have increased rapidly, and criminals have taken advantage of users' trust in well-known apps to produce similar interfaces and functions, induce users to download and install, steal users' personal information, property or spread malware, not only causing losses to users, but also disrupting normal market order. In order to identify counterfeit APP more quickly and effectively, this paper proposes a counterfeit APP recognition model based on twin network. The model first decompiles and extracts the name, package name, icon, and signature information of the APP, then filters out suspected counterfeit applications by calculating the editing distance of the name, and finally calculates the icon similarity based on the twin network model to determine whether the application is counterfeit. In this paper, datasets containing multiple types of phishing applications are used for experiments, and the effects of VGG16, ResNet50, and ViT algorithms on the recognition results are compared as the basic feature extraction networks. The results show that the accuracy of the ViT-based twin network architecture reaches 85.12%, which can effectively identify counterfeit applications.},
  keywords={Training;Knowledge engineering;Accuracy;Phishing;Network architecture;Feature extraction;Probability distribution;Malware;Smart phones;Residual neural networks;Counterfeit APP;deep learning;Twin networks},
  doi={10.1109/ICIPNP62754.2023.00052},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11139736,
  author={Bhattacharjee, Srijita and Patil, Param and Patil, Vishal and Nage, Pranav},
  booktitle={2025 7th International Conference on Energy, Power and Environment (ICEPE)}, 
  title={Hybrid Multi-Stage Framework for Advanced Malware Detection: Enhancing Accuracy & Resilience}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Malware detection is one of the parts of the modern cybersecurity system that requires precision and scalability against the ever-evolving threats. This paper will present a multi-staged hybrid framework for malware detection that combines static analysis, machine learning, and rule-based approaches. The files are processed through a sequence of stages: hash-based matching, machine learning classification, YARA rule evaluation, and decompiled code analysis. This further helps in accuracy and reduces the false prediction. The last decision will aggregate the outputs of all the stages using weighted scoring and achieving the final overall accuracy as 94.8% with a dataset of 8,932 samples. A layered approach ensures that a comprehensive analysis is provided along with a strong, scalable solution for malware detection. Our findings indicate that the multiplexing of various methods for detection may significantly boost the accuracy of detection along with minimizing the shortcomings inherent in each technique.},
  keywords={Multiplexing;Accuracy;Codes;Databases;Scalability;Machine learning;Static analysis;Feature extraction;Malware;Resilience;Malware detection;AI-driven analysis;YARA rules;Radare2;behavioral analysis;feature extraction;multi staged;enhancing malware detection;signature based;machine learning based;de-compilation for malware analysis},
  doi={10.1109/ICEPE65965.2025.11139736},
  ISSN={2832-8973},
  month={May},}@ARTICLE{10858047,
  author={Ji, Weixing and Huo, Yuanhong and Wang, Yizhuo and Gao, Yujin and Shi, Feng},
  journal={Chinese Journal of Electronics}, 
  title={Control Structure Analysis and Recovery of Embedded Binaries}, 
  year={2017},
  volume={26},
  number={6},
  pages={1118-1124},
  abstract={Existing decompilers use rule-based algorithms to transform unstructured Control flow graph (CFG) into equivalent high-level programming language constructs with “goto” statements. One problem of such approaches is that they generate a large number of “goto”s in the output code, which reduce the readability and hinder the understanding of input binaries. A global search algorithm is proposed based on structural analysis. This algorithm restructures a CFG and generates fewer number of “goto” statements than the rule-based algorithm does. We also present a Genetic algorithm (GA) for the global search approach to locate near optimal solutions for large CFGs. Evaluation results on a set of real CFGs show that the genetic algorithm-based heuristic for global search is capable of finding high-quality solutions.},
  keywords={Computer languages;Codes;Transforms;Flow graphs;Genetic algorithms;Decompiling;Control flow graph restructuring;Structural analysis;Genetic algorithm (GA)},
  doi={10.1049/cje.2017.09.003},
  ISSN={2075-5597},
  month={November},}@INBOOK{10649762,
  author={Domas, Stephanie and Domas, Christopher},
  booktitle={x86 Software Reverse-Engineering, Cracking, and Counter-Measures}, 
  title={Advanced Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={245-249},
  abstract={Summary <p>This chapter describes at a high level some advanced techniques and tools on the cutting edge of reverse engineering. Timeless debugging is also known as reverse debugging. Binary instrumentation is when security professionals inject code to watch or modify a process as it executes. This can be useful for finding memory leaks, tracing key checks, performing anti&#x2010;anti&#x2010;debugging, etc. Normally, for reversing and cracking, it's necessary to learn and write tools for each new architecture. The idea of intermediate representations is to translate all assembly code for all architectures to the same language. The idea of decompiling is to recover original source code from advanced automated analysis of assembly code. Automatic structure recovery involves automatically finding patterns and links in memory to make inferences about the data types used. Visualization can be used to deepen the understanding of file structure and execution. Theorem provers use mathematics to analyze code, including reduction, deobfuscation, boundaries, inputs, etc.</p>},
  keywords={Debugging;Codes;Instruments;Software;Engines;Data visualization;Computer architecture},
  doi={10.1002/9781394277131.ch16},
  ISSN={},
  publisher={Wiley},
  isbn={9781394199907},
  url={https://ieeexplore.ieee.org/document/10649762},}@INPROCEEDINGS{9410081,
  author={Chen, Lu and Ma, Yuanyuan and Shao, Zhipeng and Chen, Mu},
  booktitle={2021 13th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA)}, 
  title={Mobile application reinforcement method based on control flow and data flow confusion}, 
  year={2021},
  volume={},
  number={},
  pages={345-348},
  abstract={At present, mobile applications are developing rapidly, and the methods of attacking mobile applications by reverse engineering to obtain the core logic of the program are becoming more and more intense. In the face of malicious tampering, permission bypassing or obtaining core intellectual property rights through reverse engineering of mobile application, this paper proposes a mobile application reinforcement method based on control flow and data flow confusion, and factors affecting the accuracy and complexity of program analysis extracted for mobile applications, analyze its own characteristics and the relationship between them, detailed analysis of the implementation principle and code of the variable target compiler, in the syntax analysis and semantic analysis stage, the corresponding code obfuscation algorithm is implemented. Through obfuscation, the compiled program is strengthened at the three levels of grammar, control flow, and data flow. Experiments show that even if the source code of mobile application reinforced by this method is obtained through decompilation, the internal logic of the application cannot be known, and the next attack cannot be initiated.},
  keywords={Java;Program processors;Mechatronics;Reverse engineering;Semantics;Intellectual property;Syntactics;control flow;data flow;security reinforcement;mobile application},
  doi={10.1109/ICMTMA52658.2021.00080},
  ISSN={2157-1481},
  month={Jan},}@INPROCEEDINGS{8965960,
  author={Yu, Qing and Ma, Kuolang and Wang, Zuohua},
  booktitle={2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, 
  title={Android Malicious Code Detection Based on Secondary Pruning Optimization}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={In this paper, we propose a detection algorithm for Android malicious code based on integrated multi-feature. By decompiling and processing APK files, the multi-class behavior features of Android application are extracted, and the classification is achieved through an integrated learning framework based on quadratic pruning optimization. The prototype system automatically detects the malicious code of the Android platform and analyzes the validity of the algorithm through experimental verification.},
  keywords={Classification algorithms;Malware;Feature extraction;Optimization;Predictive models;Security;Android;Multi-feature;Optimization;Pruning},
  doi={10.1109/CISP-BMEI48845.2019.8965960},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11241815,
  author={Johri, Siddharth and Bose, Adyot and Jha, Shaaswat K and Kakkar, Misha and Mehrotra, Deepti},
  booktitle={2025 12th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, 
  title={AMADel: Android Malware Analysis Using Deep Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Malware Detection is a nuanced activity that often requires human intervention and complex sandboxing methodology to detect complex and obfuscated malware. Human intervention is not practical for a large sample size of untested applications. Android, being the most used and heavily built-upon mobile operating system, is no stranger to having malware embedded in its packaged applications. This paper proposes an innovative ensemble deep learning model designed to classify Android applications as benign or malicious, known as AMADel. AMADeL includes three Convolutional Neural Networks (CNNs) models ensembled together, which were trained on images generated using DEX bytecode obtained by decompiling APKs using Androguard. The APK files were sourced from the AndroZoo dataset. The dataset was prepared and used to train various models. The standalone CNNs gave the highest accuracy of 86.14%. Pre-trained models, such as ResNet50 and VGG16, achieved accuracies of 81.19% and 82.18%, respectively. However, the proposed AMADel attained an accuracy of over 90%.},
  keywords={Deep learning;Accuracy;Operating systems;Neural networks;Market research;Malware;Reliability;Convolutional neural networks;Optimization;Residual neural networks;Android;Malware Detection;Deep Learning;Convolution Neural Networks;DEX bytecode;ResNet50;VGG19},
  doi={10.1109/ICRITO66076.2025.11241815},
  ISSN={2769-2884},
  month={Sep.},}@INPROCEEDINGS{10937558,
  author={Krishnaswamy, Nitin and Mandadi, Sanjana and Nelson, Micah and Slater, Timothy and Liu, Benson},
  booktitle={2024 IEEE MIT Undergraduate Research Technology Conference (URTC)}, 
  title={MBASED: Practical Simplifications of Mixed Boolean-Arithmetic Obfuscation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Mixed Boolean-Arithmetic (MBA) obfuscation is a technique that complicates boolean expressions by combining arithmetic and boolean operations. It obstructs the process of reverse engineering by making code more difficult to analyze. This paper presents the Binary Ninja plugin, MBASED (Mixed Boolean-Arithmetic Simplification Engine for Deobfuscation), which performs MBA deobfuscation on C programs. It utilizes novel simplification methods that take ideas from compiler construction and simplification performed on parse trees. MBASED is the first practical implementation of MBA deobfuscation in an industry-grade decompiler. Its extensible framework allows users to incorporate their own simplification passes.},
  keywords={Codes;Reverse engineering;Malware;Libraries;Security;Engines;Arithmetic;security;reverse engineering;deobfuscation;decompiler;Mixed Boolean-Arithmetic},
  doi={10.1109/URTC65039.2024.10937558},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10625666,
  author={Zhao, Shu-Han and Li, Yong-Zhen and Wang, Zhen-Zhen and Jin, Zhe-Xue},
  booktitle={2024 4th International Conference on Information Communication and Software Engineering (ICICSE)}, 
  title={Research on Security Protection Mechanism of Android APP}, 
  year={2024},
  volume={},
  number={},
  pages={35-38},
  abstract={Based on the idea of a digital signature, an Android program protection scheme is proposed. First, check whether there is a security file when the program starts, download it from the server if there is no security file, and perform subsequent verification if there is; Secondly, the gatekeeper mechanism is used to determine whether the installation address of the software is from the specified server by asking, and if it is, the subsequent verification is made, and if it is not, the program is directly exited; Then, the signature authentication is performed based on the server, and the hash value in the security file is compared with the decrypted hash value. If the hash value is consistent, the file is not tampered with; Finally, the integrity of the file is verified, and the installation is allowed if every value in the security file is verified. The application protection method can identify the installation files from unknown sources and prevent the installation. The whole process adopts the method of JNI call, the application core code is placed in the Java layer, the digital signature mechanism and integrity verification are placed in the Native layer, and the Java layer is packaged into the.so library, the Java layer calls the.so library through the JNI, which can effectively prevent decompilation.},
  keywords={Java;Operating systems;Logic gates;Libraries;Malware;Security;Servers;Security file;“Gatekeeper mechanism”;Server-based digital signature;Integrity verification;JNI technology},
  doi={10.1109/ICICSE61805.2024.10625666},
  ISSN={},
  month={May},}@ARTICLE{8443103,
  author={Chu, Gordon and Apthorpe, Noah and Feamster, Nick},
  journal={IEEE Internet of Things Journal}, 
  title={Security and Privacy Analyses of Internet of Things Children’s Toys}, 
  year={2019},
  volume={6},
  number={1},
  pages={978-985},
  abstract={This paper investigates the security and privacy of Internet-connected children's smart toys through case studies of three commercially available products. We conduct network and application vulnerability analyses of each toy using static and dynamic analysis techniques, including application binary decompilation and network monitoring. We discover several publicly undisclosed vulnerabilities that violate the Children's Online Privacy Protection Rule as well as the toys' individual privacy policies. These vulnerabilities, especially security flaws in network communications with first-party servers, are indicative of a disconnect between many Internet of Things toy developers and security and privacy best practices despite increased attention to Internet-connected toy hacking risks.},
  keywords={Toy manufacturing industry;Privacy;Servers;Mobile applications;Internet of Things;Authentication;Data security;Internet of Things (IoT);privacy},
  doi={10.1109/JIOT.2018.2866423},
  ISSN={2327-4662},
  month={Feb},}@INPROCEEDINGS{8327566,
  author={Bragagnolo, Santiago and Rocha, Henrique and Denker, Marcus and Ducasse, Stephane},
  booktitle={2018 International Workshop on Blockchain Oriented Software Engineering (IWBOSE)}, 
  title={SmartInspect: solidity smart contract inspector}, 
  year={2018},
  volume={},
  number={},
  pages={9-18},
  abstract={Solidity is a language used for smart contracts on the Ethereum blockchain. Smart contracts are embedded procedures stored with the data they act upon. Debugging smart contracts is a really difficult task since once deployed, the code cannot be reexecuted and inspecting a simple attribute is not easily possible because data is encoded. In this paper, we address the lack of inspectability of a deployed contract by analyzing contract state using decompilation techniques driven by the contract structure definition. Our solution, SmartInspect, also uses a mirror-based architecture to represent locally object responsible for the interpretation of the contract state. SmartInspect allows contract developers to better visualize and understand the contract stored state without needing to redeploy, nor develop any ad-hoc code.},
  keywords={Contracts;Tools;Inspection;Debugging;Indexes;Blockchain;Inspecting;Solidity;Smart Contracts},
  doi={10.1109/IWBOSE.2018.8327566},
  ISSN={},
  month={March},}@INPROCEEDINGS{8728471,
  author={Akarsh, S. and Simran, K. and Poornachandran, Prabaharan and Menon, Vijay Krishna and Soman, K.P.},
  booktitle={2019 5th International Conference on Advanced Computing & Communication Systems (ICACCS)}, 
  title={Deep Learning Framework and Visualization for Malware Classification}, 
  year={2019},
  volume={},
  number={},
  pages={1059-1063},
  abstract={In this paper we propose a deep learning framework for classification of malware. There has been an enormous increase in the volume of malware generated lately which represents a genuine security danger to organizations and people. So as to battle the expansion of malwares, new strategies are needed to quickly identify and classify malware. Malimg dataset, a publicly available benchmark data set was used for the experimentation. The architecture used in this work is a hybrid cost-sensitive network of one-dimensional Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) network which obtained an accuracy of 94.4%, an increase in performance compared to work done by [1] which got 84.9%. Hyper parameter tuning is done on deep learning architecture to set the parameters. A learning rate of 0.01 was taken for all experiments. Train-test split of 70-30% was done during experimentation. This facilitates to find how well the models perform on imbalanced data sets. Usual methods like disassembly, decompiling, de-obfuscation or execution of the binary need not be done in this proposed method. The source code and the trained models are made publicly available for further research.},
  keywords={Malware;Feature extraction;Deep learning;Computer architecture;Logic gates;Convolution;Malware;image processing;machine learning;deep learning;cost-sensitive learning},
  doi={10.1109/ICACCS.2019.8728471},
  ISSN={2575-7288},
  month={March},}@INPROCEEDINGS{9519451,
  author={Zhang, Zhuo and Ye, Yapeng and You, Wei and Tao, Guanhong and Lee, Wen-chuan and Kwon, Yonghwi and Aafer, Yousra and Zhang, Xiangyu},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)}, 
  title={OSPREY: Recovery of Variable and Data Structure via Probabilistic Analysis for Stripped Binary}, 
  year={2021},
  volume={},
  number={},
  pages={813-832},
  abstract={Recovering variables and data structure information from stripped binary is a prominent challenge in binary program analysis. While various state-of-the-art techniques are effective in specific settings, such effectiveness may not generalize. This is mainly because the problem is inherently uncertain due to the information loss in compilation. Most existing techniques are deterministic and lack a systematic way of handling such uncertainty. We propose a novel probabilistic technique for variable and structure recovery. Random variables are introduced to denote the likelihood of an abstract memory location having various types and structural properties such as being a field of some data structure. These random variables are connected through probabilistic constraints derived through program analysis. Solving these constraints produces the posterior probabilities of the random variables, which essentially denote the recovery results. Our experiments show that our technique substantially outperforms a number of state-of-the-art systems, including IDA, Ghidra, Angr, and Howard. Our case studies demonstrate the recovered information improves binary code hardening and binary decompilation.},
  keywords={Privacy;Uncertainty;Systematics;Binary codes;Probabilistic logic;Data structures;Random variables;Binary-Analysis;Reverse-Engineering;Type-Inference;Probabilistic-Analysis},
  doi={10.1109/SP40001.2021.00051},
  ISSN={2375-1207},
  month={May},}@ARTICLE{9921221,
  author={Gao, Yun and Hasegawa, Hirokazu and Yamaguchi, Yukiko and Shimada, Hajime},
  journal={IEEE Access}, 
  title={Malware Detection by Control-Flow Graph Level Representation Learning With Graph Isomorphism Network}, 
  year={2022},
  volume={10},
  number={},
  pages={111830-111841},
  abstract={With society’s increasing reliance on computer systems and network technology, the threat of malicious software grows more and more serious. In the field of information security, malware detection has been a key problem that academia and industry are committed to solving. Machine learning is an effective method for processing large-scale data, such as the Gradient Boosting Decision Tree (GBDT) and deep neural network technology. Although these types of detection methods can deal with cyber threats, most feature extraction methods are based on the statistical information features of portable executable (PE) files and thus lack the decompiled code and execution flow structure of the PE samples. Therefore, we propose a Control-Flow Graph (CFG)- and Graph Isomorphism Network (GIN)-based malware classification system. The feature vectors of CFG basic blocks are generated using the large-scale pre-trained language model MiniLM, which is beneficial for the GIN to further learn and compress the CFG-based representation, and classified with multi-layer perceptron. In addition, we evaluated the effectiveness of the representation under different dimensions and classifiers. To evaluate our method, we set up a CFG-based malware detection graph dataset from a PE file of the Blue Hexagon Open Dataset for Malware Analysis (BODMAS), which we call the Malware Geometric Binary Dataset (MGD-BINARY) and collected the experimental results of CFG representation in different dimensions and classifier settings. The evaluation results show that our proposal has proved an Accuracy metric of 0.99160 and achieved 0.99148 Area Under the Curve (AUC) results.},
  keywords={Malware;Feature extraction;Codes;Data mining;Analytical models;Machine learning;Natural language processing;Graphics;Malware detection;machine learning;static analysis;graph classification},
  doi={10.1109/ACCESS.2022.3215267},
  ISSN={2169-3536},
  month={},}@ARTICLE{10186242,
  author={Costa, Leonardo da and Moia, Vitor},
  journal={IEEE Access}, 
  title={A Lightweight and Multi-Stage Approach for Android Malware Detection Using Non-Invasive Machine Learning Techniques}, 
  year={2023},
  volume={11},
  number={},
  pages={73127-73144},
  abstract={Android has been a constant target of cybercriminals that try to attack one of the most used operating systems, commonly using malicious applications (denominated malware) that, once installed on a device, can harm users in several ways. Existing malware detection solutions are usually invasive as they obtain classification features by performing reverse engineering, decompilation, or disassembly of the analyzed application, which infringes licenses and terms of use of applications. In addition, these solutions often employ a single machine learning (ML) model to detect various types of malware, resulting in several false alarms. In this context, we propose an approach to detect Android malware consisting of a set of specific-type detectors in which each one performs a multi-stage analysis, based on rules and ML techniques, in different phases of the application cycle (before and after its installation). Our approach also differs from state-of-the-art solutions by being non-invasive, since it leverages a process to obtain application’s features that does not infringe licenses and terms of use of applications. In addition, according to experiments performed on a real Android smartphone, our proposal presents the following additional advantages over state-of-the-art solutions: a more efficient process to classify applications that is three times faster and requires ten times less CPU usage in some cases (saving device energy); and a better detection performance, with higher balanced accuracy, nine times less false positive cases, and ten times less false negative cases.},
  keywords={Malware;Feature extraction;Smart phones;Operating systems;Proposals;Detectors;Behavioral sciences;Androids;Noninvasive treatment;Android;machine learning;malware detection;multi-stage analysis;non-invasive feature extraction},
  doi={10.1109/ACCESS.2023.3296606},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9453483,
  author={Alsabbagh, Wael and Langendörfer, Peter},
  booktitle={2021 22nd IEEE International Conference on Industrial Technology (ICIT)}, 
  title={A Stealth Program Injection Attack against S7-300 PLCs}, 
  year={2021},
  volume={1},
  number={},
  pages={986-993},
  abstract={Industrial control systems (ICSs) consist of programmable logic controllers (PLCs) which communicate with an engineering station on one side, and control a certain physical process on the other side. Siemens PLCs, particularly S7-300 controllers, are widely used in industrial systems, and modern critical infrastructures heavily rely on them. But unfortunately, security features are largely absent in such devices or ignored/disabled because security is often at odds with operations. As a consequence of the already reported vulnerabilities, it is possible to leverage PLCs and perhaps even the corporate IT network. In this paper we show that S7-300 PLCs are vulnerable and demonstrate that exploiting the execution process of the logic program running in a PLC is feasible. We discuss a replay attack that compromises the password protected PLCs, then we show how to retrieve the Bytecode from the target and decompile the Bytecode to STL source code. Afterwards we present how to conduct a typical injection attack showing that even a very tiny modification in the code is sufficient to harm the target system. Finally we combine the replay attack with the injection approach to achieve a stronger attack – the stealth program injection attack – which can hide the previous modification by engaging a fake PLC, impersonating the real infected device. For real scenarios, we implemented all our attacks on a real industrial setting using S7-300 PLC. We eventually suggest mitigation approaches to secure systems against such threats.},
  keywords={Conferences;Programmable logic devices;Process control;Critical infrastructure;Security;Password;S7-300 PLCs;Injection Attack;Stealthy Attack;Replay Attack;Fake PLC},
  doi={10.1109/ICIT46573.2021.9453483},
  ISSN={},
  month={March},}@INPROCEEDINGS{8600052,
  author={Zhao, Lichao and Li, Dan and Zheng, Guangcong and Shi, Wenbo},
  booktitle={2018 IEEE 18th International Conference on Communication Technology (ICCT)}, 
  title={Deep Neural Network Based on Android Mobile Malware Detection System Using Opcode Sequences}, 
  year={2018},
  volume={},
  number={},
  pages={1141-1147},
  abstract={Malware detection is more challenging due to the increase in android malicious programs and the current problems of android malicious detection. This paper proposes an android mobile malware detection system based on deep neural network, a novel malware detection method which uses optimized deep Convolutional Neural Network to learn from opcode sequences. In the proposed detection system, the optimized Convolutional Neural Network is trained multiple times by the raw operation code sequence extracted from the decompiled android file, so that the feature information can be effectively learned and the malicious program can be detected more accurately. More critically, the k-max pooling method with better results was adopted in the pooling operation phase, and which improves the detection effect of the proposed method. The experimental results show that the detection system achieved the accuracy of 99%, which is 2%-11 % higher than the accuracy of the machine learning detection algorithms when using the same dataset. It also ensures that the indicators such as Fl-score, Recall and Precision are maintained above 97%.},
  keywords={Feature extraction;Malware;Convolutional neural networks;Matrix converters;Data mining;Smart phones;malware detection;opcode;k-max pooling;Convolutional Neural Network},
  doi={10.1109/ICCT.2018.8600052},
  ISSN={2576-7828},
  month={Oct},}@INPROCEEDINGS{8029506,
  author={Tang, Junwei and Li, Ruixuan and Han, Hongmu and Zhang, Heng and Gu, Xiwu},
  booktitle={2017 IEEE Trustcom/BigDataSE/ICESS}, 
  title={Detecting Permission Over-claim of Android Applications with Static and Semantic Analysis Approach}, 
  year={2017},
  volume={},
  number={},
  pages={706-713},
  abstract={Android access control granularity based on its permission mechanism is relatively coarse, which cannot effectively protect the user privacy. Many Android applications do not strictly abide by the principle of least privilege (PLP). Both benign and malicious apps may request more permissions than those they really use. We rethink previous permission over-claim problem of Android applications, and extend it to three kinds of problems: Explicit Permission Over-claim, Implicit Permission Over-claim and Ad Library Permission Over-claim. The latter two problems are new that have not been raised by any previous work. Static analysis is to decompile the applications to generate intermediate code and then analyze the usage of permissions. Our static analysis on 10710 applications shows that 76.08% of them may have Explicit Permission Over-claim problem, among those there are 424 applications that have sensitive permissions, which are only used in the advertisement library's code of the applications rather than developer's own code. They have Ad Library Permission Over-claim problem. The main idea of our semantic analysis is to calculate the semantic similarity between apps' descriptions and function phrases. If the similarity exceeds a certain threshold, the app is considered relevant to the corresponding function. We compare the results of the semantic analysis with those of manual reading of 102 Android application descriptions. The F-measures of the three chosen functions are 80.82%, 70.48% and 89.62%, respectively. The evaluation results show our method can efficiently detect the above three kinds of permission over claim problems which indicates that our method would be helpful for normal users to have a clear understanding of permission usage of Android applications.},
  keywords={Androids;Humanoid robots;Libraries;Semantics;Smart phones;Security;Privacy;Mobile security;Android system;permission overclaim problem;static analysis;semantic analysis},
  doi={10.1109/Trustcom/BigDataSE/ICESS.2017.303},
  ISSN={2324-9013},
  month={Aug},}@INPROCEEDINGS{8080433,
  author={Kostka, Bartosz and Kwiecieli, Jaroslaw and Kowalski, Jakub and Rychlikowski, Pawel},
  booktitle={2017 IEEE Conference on Computational Intelligence and Games (CIG)}, 
  title={Text-based adventures of the golovin AI agent}, 
  year={2017},
  volume={},
  number={},
  pages={181-188},
  abstract={The domain of text-based adventure games has been recently established as a new challenge of creating the agent that is both able to understand natural language, and acts intelligently in text-described environments. In this paper, we present our approach to tackle the problem. Our agent, named Golovin, takes advantage of the limited game domain. We use genre-related corpora (including fantasy books and decompiled games) to create language models suitable to this domain. Moreover, we embed mechanisms that allow us to specify, and separately handle, important tasks as fighting opponents, managing inventory, and navigating on the game map. We validated usefulness of these mechanisms, measuring agent's performance on the set of 50 interactive fiction games. Finally, we show that our agent plays on a level comparable to the winner of the last year Text-Based Adventure AI Competition.},
  keywords={Games;Artificial intelligence;Natural language processing;Conferences;Engines},
  doi={10.1109/CIG.2017.8080433},
  ISSN={2325-4289},
  month={Aug},}
