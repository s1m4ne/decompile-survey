以下は「**スコープ設計**」と「**スクリーニング基準**」だけを固めるための、（一般的なSLR/サーベイの作法を踏まえつつ）**デコンパイル領域に合わせた“査読で突っ込まれにくい”案**です。
あなたの懸念（出力/粒度の揺れ、LLM単独だと件数不足、型回復・変数名復元などの取りこぼし、スコープの美しさとの衝突）を、**定義と二層構造**で吸収する設計にしています。

---

## 一般的なサーベイ/SLRがスコープとスクリーニングでやっていること（要点）

* **明示的な inclusion/exclusion を置く**（何を含め、何を除くかを事前に文章化）
  SLRガイドラインでも「明示的な包含/除外基準が必要」とされます。([legacyfileshare.elsevier.com][1])

* **PRISMA 的に “識別→スクリーニング→採択” を可視化**（件数、除外理由を追えるようにする）
  PRISMA 2020 のフロー図は、同定・除外・採択と除外理由を整理して示すためのテンプレです。([PRISMA statement][2])

* **件数不足・取りこぼし対策として “検索は広め、採択は基準で絞る”**
  例えばLLM4SEの大規模SLRでは、LLMに直結しないML/DLキーワードも含めて検索を広げ、後段の段階で絞っています（「取りこぼし回避のため」）。【20:1†2308.10620v6.pdf†L25-L33】

* **arXiv等のプレプリントを“条件付きで入れる”運用も一般的**（新興分野では特に）
  同SLRは、分野が新しいため 2023–2024 の arXiv を保持しつつ、**品質評価で足切り**しています。【20:0†2308.10620v6.pdf†L29-L34】

* **スノーボーリング（前方/後方ら追加収集するガイドラインが整備されています。([wohlin.eu][3])
  またソフトウェア工学では systematic mapping（広く俯瞰し分類スキームを作る）という形式も定番です。([ACM Digital Library][4])で締める**」「**新興分野はプレプリントも品質評価で扱う**」を、デコンパイル×LLMにそのまま移植すると、あなたの課題（件数不足・ニッチ取りこぼし）に効きます。

---

## スコープ設計案（推奨：二層スコープ＋“出力レベル”で揺れを吸収）

### 1) まず “デコンパイル” を操作的に定義する（査読で揉めない軸）

**本サーベイのデコンパイル（operational definition）**を、次のように置くのが安定です：

> **低水準表現（バイナリ/機械語/アセンブリ/バイトコード/バイナリ由来IR）から、より高水準のプログラム表現（ソース/擬似コード/AST/高水準IR/型や識別子などの高水準属性）を再構成する研究**
> かつ、その目的が **ソース復元・可読化・高水準意味の回復** にあるもの。

ここで重要なのは、**“最終出力＝コンパイル可能C/C++” を定義に含めない**ことです。
代わりに「出力レベル」をタグとして扱うと、綺麗さと件数の両方を守れます。

---

### 2) “出力レベル”でスコープを二層化する（あなたの懸念を全部回収）

あなたの悩みは、結局「最終出力が揺れる」ことに起因します。そこで、**スコープ自体は二層**、**論文分類は出力レベル**で揃えるのが、最も査読耐性が高いです。

#### 推奨スコープ：Core / Peripheral（二層）

**Core（主対象）**：

* LLM（＋必要なら非LLMのニューラル/MLも含む）が、
  **関数単位またはプログラム単位**で
  **高水準表現を生成**する研究（生成物は下の L1–L3 のいずれか）

**Peripheral（周辺だが“デコンパイルに直結する要素”として採択）**：

* 最終コード全体は出さないが、**デコンパイル品質を決定づける回復要素**を推定する研究
  例：型回復、変数名/関数名回復、シグネチャ・呼出規約、データ構造回復、制御構造化（if/while再構成）、等
* ただし「何でもあり」にしないため、後述の **Peripheral採択条件（3条件）**を課す

#### 出力レベル（分類タグ）

* **L1: コンパイル可能なソース（またはそれに近い）**
  例：C/C++/Rust/Go/Java 等で “コンパイル成功” を評価している、またはコンパイル可能性を明示
* **L2: 擬似コード/構造化コード（非コンパイルでも可）**
  例：decompiler-like pseudocode、structured code、自然言語でなくコード様
* **L3: AST / 高水準IR / 構文木・高水準命令列**
  例：AST、LLVM IRの高水準側、正規化IR、など
* **L4: 高水準属性のみ（型・識別子・シグネチャ・制御構造など）**
  ※これを Peripheral で扱う（＝L4だけでCoreに入れない）と、綺麗さを保てます

> これで「最終出力をソースコードに限定する綺麗さ」と「型回復/変数名などニッチを拾う」を両立できます。
> **“最終出力に限定する”のではなく、“最終出力に近いほどCoreで厚く扱う”**に変換します。

---

### 3) 粒度の揺れは “単位タグ” で吸収し、スコープは切りすぎない

粒度はスコープで切ると事故りやすいので、**採択は広め**にして、分類で吸収が安全です。

**単位タグ（分類）**

* G1: 命令/基本ブロック
* G2: 関数
* G3: モジュール/ファイル
* G4: プログラム全体

推奨は **G2以上をCoreの中心**にしつつ、
G1でも **“最終的にG2/G3へ合成されることが論文で明示”**なら Peripheral で拾う余地を残す、です。

---

### 4) 「LLM単独だと件数不足」への、スコープ側の解決策（おすすめ）

**“LLMを使ったデコンパイル”**に固執して件数不足になる場合、次のどちらか（または両方）をスコープ文で宣言すると、自然に広がり、しかも筋が通ります。

#### 解決策A：LLMに限定せず「データ駆動（Neural/ML）デコンパイル」とし、LLMは主役として深掘り

* Scope文：
  「本サーベイはデータ駆動（特にニューラル/LLM）によるデコンパイルを対象とし、LLM研究を中心に体系化する」
* メリット：古典的ニューラルdecompilation/translationも入って件数が増える
* デメリット：広がりすぎる → Core/Peripheralと出力レベルで制御可能

#### 解決策B：LLMを “decompilerの後処理” として扱う研究も Core に入れる

* 例：既存デコンパイラの擬似コードを入力に、LLMで可読化・型付け・変数名復元・コンパイル可能化
* これはあなたの目的（LLMでデコンパイルを良くする）に直結するので、Coreに入れてよい

※一般のSLRでも、取りこぼし回避で検索語を広げる運用は普通に行われています。【20:0†2308.10620v6.pdf†L21-L27】【20:1†2308.10620v6.pdf†L25-L33】

---

### 5) Peripheral（周辺）を“無限に広げない”ための採択条件（3条件）

周辺を入れるときに、査読で突っ込まれる典型は「それデコンパイル？」問題です。これを防ぐため、Peripheralは以下の **3条件を同時に満たす場合のみ採択**と定義しておくと強いです：

1. **入力が低水準表現**（バイナリ/機械語/アセンブリ/バイトコード/バイナリ由来IR）
2. **出力が高水準復元に直接寄与する要素**（L4のどれか：型・識別子・シグネチャ・制御構造・デーneering のため”**という目的が明示されている

   * 目的が “バイナリ類似度/マルウェア分類/脆弱性検出” だけなら除外（後述）

これで、型回復や変数名復元は拾いつつ、バイナリ分類系の大量流入を防げます。

---

## スクリーニング基準案（PRISMA/SLRの作法＋デコンパイル仕様）

一般のSLRでは、包含/除外基準を置き、段階的に絞り、必要に応じて品質評価をします。([legacyfileshare.elsevier.com][1])
LLM4SEのSLRでも、包含/除外基準を明示し【20:1†2308.10620v6.pdf†L6-L23】、品質評価項目（QAC）を設けています【20:0†2308.10620v6.pdf†L3-L17】。

あなたの用途向けに、**そのまま使える形**で提示します。

---

### A. 収集・選定フロー（査読で説明しやすい形）

1. **自動フィルタ**：年、言語、重複、フルテキスト可否（bib情報だけで落とせるもの）
2. **Title/Abstract/Keyword スクリーニング**：IC/ECで一次判定
3. **Full-text スクリーニング**：境界事例を含め厳密判定
4. **品質評価（任意だが強い）**：再現性や評価の有無などで“主張できる論文”を残す
5. **スノーボーリング**：前方/後方で追加候補→同じIC/ECで再選定 ([wohlin.eu][3])

PRISMAフロー図にこの数字を載せると盤石です([PRISMA statement][2])

---

### B. In）**：

* 低水準表現を入力に含むこと：
  **native binary / machine code / assembly / bytecode /（バイナリ由来の）低水準IR**

**IC2（目的）**：

* 目的が次のいずれかであること：

  * source code recovery / reverse compilation / decompilation / program reconstruction
  * 既存デコンパイラ出力の改善（可読化、型付け、識別子復元、構造化、コンパイル可能化 等）

**IC3（出力）**：

* 出力が **L1–L3**（Core）または **L4（Peripheral条件を満たす場合）**

**IC4（手法）**：

* **LLM、またはニューラル/ML（NLP含むが“低水準→高水準復元”に使っていること）**

  * 「LLMを少し言及しただけ」は除外（ECで落とす）

**IC5（単位）**：

* 最低でも **関数単位（G2）以上**を主対象に扱う

  * ただし、命令/ブロック（G1）でも **関数合成や高水準化に直結**していれば Peripheral で検討可

**IC6（公開形態）**：

* フルテキスト入手可能
* 査読付き会議/ジャーナルを基本

  * ただし新興分野のため arXiv 等プレプリントも **品質評価つきで採択可**（一般例あり）【20:0†2308.10620v6.pdf†L29-L34】

**IC7（期間）**：

* 例：2017年以降（Transformer以降に寄せる理屈が立つ）【20:1†2308.10620v6.pdf†L35-L39】

  * ただし「ニューラルdecompilationも含める」なら、開始年を前倒しし、LLMパートを2017以降に分ける設計も可能

---

### C. Exclusion Criteria（EC）案（デコンパイルで揉めやすい点を先回り）

**EC1（目的違い）**：

* 主目的が **分類/検索/検知**で、復元（reconstruction）をしない

  * 例：binary similarity、malware family classification、vulnerability detection だけ

**EC2（入力違い）**：

* 入力がソースコードのみ（低水準入力がない）

  * 例：ソース→ソース翻訳、コード要約、テスト生成（バイナリ起点でない）

**EC3（“デコンパイルと言いつつ”出力が復元でない）**：

* 出力が **評価指標の予測**や **埋め込み（embedding）**のみ：
* LLM/MLを「将来やる」「触れただけ」で、具体的手法がない

  * LLM4SEのSL。【20:0†2308.10620v6.pdf†L40-L43】

**EC5（出版形態）**：

* チュートリアル、パネル、編集記事、ポスター、ツールデモ中心で技術詳細がない

  * ただしデコンパイルは短いが重要な論文もあり得るので、**“ページ数”で機械的に落とすのは慎重に**
  * もし足切りするなら「extended abstract級（例：4ページ未満）」など弱め推奨
    （LLM4SE SLRは <8ページを除外していますが【20:1†2308.10620v6.pdf†L12-L18】、分野特性に合わせて調整する余地があります）

**EC6（言語）**：

* 非英語を除外（現実的な再現性のため）

  * ただし、日本語論文（国内会議）を入れる方針なら、最初から明記してOK
  * 参考：LLM4SE SLRは非英語を除外しています。【20:1†2308.10620v6.pdf†L20-L22】

**EC7（重複）**：

* 同一研究の arXiv→会議→ジャーナルなど重複は、最も完全な版を採択

  * 参考：重複除外は一般的な除外基準の一つです。【20:1†2308.10620v6.pdf†L13-L16】
    sment）を“軽量に”入れると査読耐性が上がる
    あなたのテーマは新しく、プレプリントも混ざりやすいので、**品質評価を入れると強い**です（「入れる/入れない」ではなく、「主張の強さを調整」できる）。

LLM4SEの例ではQAC（品質評価項目）を設計しています。【20:0†2308.10620v6.pdf†L3-L17】
これをデコンパイル向けに軽量化した例：

* **Q1**：低水準→**Q2**：モデル/プロンプト/学習の詳細が再現可能な粒度で書かれているか
* **Q3**：データセット生成条件（ISA、最適化、コンパイラ等）が明示されているか
* **Q4**：評価があるか（定量 or 定性でもよいが、根拠があるか）
* **Q- **Q6**：限界・脅威（threats）が議論されているか

> ここでのコツ：**“採択/不採択”ではなく、“Coreで厚く扱うか/Peripheralで位置たの懸念がどう解消されるか（設計の効き方）

* **出力が揺れる問題**：
  「採択条件」では縛りすぎず、**L1–L4の出力レベル分類**で吸収。
  “コンパイル可能”は **ICにせずタグ（L1）**にする → 件数不足を防ぐ。

* **粒度が揺れる問題**：
  “関数/全体”に寄せたいなら、**G2以。

* **LLM単独だと件数不足**：
  Scope文で「データ駆動（Neural/ML）も含む、ただしLLM中心に深掘り」と宣言すれば筋が通る。
  一般のSLRでも取りこぼし回避で検索を広げる運用は普通です。【20:1†2308.10620v6.pdf†L25-L33】

* **型回復・変数名復元などニッチ取りこぼし**：
  Peripheralを**3条件**で定義して拾えるようにする（“何でも入る”にはならない）。

* **“最終出力はソースコード”の綺麗さとの衝突**：
  CoreをL1–L3に置き、L4はPeripheralで「デコンパイル要素技術」として章立てすれば、むしろ論旨が綺麗になります（デコンパイルを“パイプライン”として描ける）。

---

## 最終的に論文中にそのまま貼れる「スコープ文」テンプレ（推奨）

最後に、査読で刺されにくい形の短文テンプレを置きます（必要に応じて調整して使えます）。

> 本サーベイは、**低水準プログラム表現（バイナリ、機械語、アセンブリ、バイトコード、またはそれらから導出された低水準IR）から高水準表現を再構成するデータ駆動手法**を対象とする。特に、**LLMを用いた関数単位またはプログラム単位の高水準生成（ソース、擬似コード、AST/高水準IR）**を主対象（Core）とし、加えてデコンパイルに直接寄与する**要素技術（型回復、識別子復元、シグネチャ推定、制御構造化等）**を周辺対象（Periph、出力レベルとして分類し比較する。

---

必要なら次のステップとして、**あなたの既存検索クエリを「Core用」「Peripheral用」に分割した検索式**（取りこぼし最小化＋ノイズ抑制）も、ここで固めたスコープ/基準に完全整合する形で提案できます。

[1]: https://legacyfileshare.elsevier.com/promis_misc/525444systematicreviewsguide.pdf?utm_source=chatgpt.com "Guidelines for performing Systematic Literature Reviews in ..."
[2]: https://www.prisma-statement.org/prisma-2020-flow-diagram?utm_source=chatgpt.com "PRISMA 2020 flow diagram"
[3]: https://www.wohlin.eu/ease14.pdf?utm_source=chatgpt.com "Guidelines for Snowballing in Systematic Literature Studies"
[4]: https://dl.acm.org/doi/10.5555/2227115.2227123?utm_source=chatgpt.com "Systematic mapping studies in software engineering"
