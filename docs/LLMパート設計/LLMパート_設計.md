以下は、**現状プロジェクトで「実際にやっていること」**（進捗スライド）を正として、**サーベイ論文全体（歴史＋LLM/ML）**の設計を **1つの設計書**としてまとめたものです。
書式は「歴史パート設計_1.md」の雰囲気（導入→全体像→構成→方法）に寄せつつ、LLM/MLパートの仕様を統合しています。

**参照（一次）**：進捗スライド（2026-01-16 / 01-23 / 02-06）  
**スクリーニングルール（v8）**：
**形式の参照（歴史設計テンプレ）**：

---

# デコンパイル×LLM/ML サーベイ論文 設計書（2026-02-12版）

## 0. 目的（この論文で“何を確定させるか”）

本サーベイの狙いは、**「低水準→高水準の再構成」**としてのデコンパイル研究を、

1. **歴史（研究と実務の節目、評価観点の変化）** と
2. **データ駆動（ML/LLM）手法（何がどこまで改善したか）**
   の **二本立て**で整理し、**タスクの異質性（出力・粒度・評価の揺れ）を吸収した比較枠組み**を提供すること。

* **歴史パート**：網羅SLRを目指しすぎず、査読耐性の高い「根拠付きの歴史的合成（timeline＋課題軸）」を作る
* **LLM/MLパート**：PRISMA的な透明性を持つ収集・選定を行い、v8ルールに沿って分類・比較する

---

## 1. 研究質問（RQs：論文の背骨）

> ※“二本立て”を自然に正当化できるよう、歴史とML/LLMを **同じ評価軸・ボトルネック軸**に接続する形にする。

### RQ-H（歴史側）

* **RQ-H1**：デコンパイル技術は、どのボトルネック（構造化、型、命名、意味保存…）を軸にどう発展したか？
* **RQ-H2**：評価（再コンパイル可能性、fidelity、人手評価、ベンチマーク）が、いつ・どう整備され、何が比較可能になったか？

### RQ-ML（LLM/ML側）

* **RQ-M1**：LLM/MLは、デコンパイル・パイプラインのどの段（出力レベルL1–L4）に適用され、何を改善したか？
* **RQ-M2**：性能向上は「モデル規模」なのか「表現（IR/CFG/擬似コード等）」なのか「解析との統合」なのか？（寄与の分解）
* **RQ-M3**：一般化（ISA/最適化/コンパイラ/難読化/言語）と再現性（データ生成、評価手順、アーティファクト公開）の観点で、何が弱点として残るか？

---

## 2. スコープと定義（査読で揉める所を先に固定）

### 2.1 操作的定義（Operational Definition）

本サーベイにおける「デコンパイル」＝
**低水準表現（binary / machine code / assembly / bytecode / 由来IR）から、より高水準のプログラム表現（ソース/擬似コード/AST/高水準IR/高水準属性）を再構成**し、
目的が **ソース復元・可読化・高水準意味回復（逆解析支援）** にある研究。
（この定義は v8 ルールを採用）

### 2.2 二層スコープ（Core / Peripheral）

v8に合わせて、**スコープを二層**にする（“論文数確保のため広めに取る”方針を明文化） 

* **Core（主対象）**

  * L1–L3 を生成/再構成する研究
  * 既存デコンパイラ出力を LLM/ML で改善する研究（可読化・型付け・命名・構造化・コンパイル可能化 等）
* **Peripheral（周辺対象）**

  * L4（属性のみ）でも、デコンパイル品質を決める要素技術として扱う
  * ただし **Peripheral採択は v8 の3条件（低水準入力・復元に寄与・目的明示）を満たす場合のみ** 

### 2.3 出力レベル（L1–L4）＝“揺れ吸収”の中核

* **L1**：コンパイル可能（またはそれに近い）ソース
* **L2**：擬似コード/構造化コード（非コンパイル可）
* **L3**：AST/高水準IR
* **L4**：型・識別子・シグネチャ・制御構造など（属性）

> 重要：**「L1必須」にしない**。L1–L4をタグとして保持し、比較・議論の単位にする（論文数不足を避ける）。 

### 2.4 粒度タグ（G1–G4）

* **G1**：命令/基本ブロック
* **G2**：関数
* **G3**：モジュール/ファイル
* **G4**：プログラム全体

> Coreの中心は **G2以上**。G1は“最終的に高水準化へ寄与が明示”される場合のみPeripheral候補。

---

## 3. 全体構成（章立て：歴史＋LLM/MLを“同格”で配置）

### Part 0：導入と方法

1. Introduction（課題、二本立ての必要性、貢献、RQs）
2. Scope & Definitions（Operational definition / L1–L4 / Core-Peripheral / G1–G4）
3. Methodology（コーパス構築：検索・重複排除・スクリーニング・抽出項目・PRISMA）

### Part I：歴史パート（Evidence-backed history）

4. Chronological history（Era分割＋“どのボトルネックが主役だったか”）
5. Technical taxonomy（デコンパイル・パイプライン別に整理：構造化/型/命名/意味保存…）
6. Evaluation & benchmarks history（何が比較可能になったか、指標の変遷）

### Part II：データ駆動（ML/LLM）パート（Systematic taxonomy）

7. Taxonomy of ML/LLM approaches（入力表現×出力レベル×統合戦略）
8. Evaluation & reproducibility（データ生成、一般化、指標、アーティファクト）
9. Synthesis（歴史で確立したボトルネックに対して、ML/LLMがどこまで解いたか）

### 締め

10. Open problems & future directions
11. Threats to validity
12. Conclusion
    Appendix：検索式、PRISMA、採択論文一覧、抽出フォーム、v8ルーブリック

---

## 4. 文献収集戦略（現状の“実施内容”を固定）

### 4.1 使用DB（現状：4つで進める）

* **IEEE Xplore / ACM DL / Web of Science / arXiv**  
* Springerはクエリ制約の都合で現状は不採用（スライド通りの意思決定）

### 4.2 検索期間

* **2017年〜カットオフ日（現状運用に合わせる）** 

  * 初期は2018〜だったが、Transformer直後の取りこぼし回避で見直した流れを記録しておく  

### 4.3 クエリ方針（2本立て）

* **Query A（コア）**：`decompil*`（用語揺れを最小化しつつ網羅）
* **Query B（補完）**：decompil*を使わない論文を拾うための AND 構成（タスク×対象×手法）

  * ただし「lifting」はノイズが大きかったため見直し（スライドの反省を反映）

> 付録に、DBごとの“完全な検索式”と検索日・ヒット件数ログを載せる（再現性の核）。

---

## 5. スクリーニング（v8ルールをそのまま採用）

### 5.1 選定フロー（PRISMAに対応）

1. Identification：DB検索で候補収集（検索ログ保存）
2. Deduplication：重複排除（DOI/タイトル/著者/年）
3. Title/Abstract Screening：**v8で include / exclude / uncertain** 
4. Full-text Screening：境界事例を本文で確定
5. Included：最終コーパス確定
6. Snowballing：前方/後方引用追跡（必要に応じて最終段階で）

### 5.2 v8の判定原則（超重要）

* **ECに当たれば即 exclude**
* ECで落ちないならIC判定で include
* 情報不足は **推測で落とさず uncertain**（後で本文確認）

### 5.3 reason code（v8）

* include側（主コード例）：

  * `in_core` / `in_decompiler_enhancement` / `in_type_recovery` / `in_variable_naming` / `in_control_structure`
* exclude側：

  * `ex_no_ml` / `ex_no_lowlevel_input` / `ex_no_code_generation` / `ex_survey_or_meta` / `ex_out_of_scope`
* uncertain側：

  * `uns_unclear_method` / `uns_unclear_input` / `uns_unclear_output` / `uns_need_fulltext`
    （詳細はv8に準拠）

---

## 6. データ抽出（LLM/MLパートの“仕様”＝ここが論文の品質を決める）

### 6.1 抽出項目（最低限：比較のための必須セット）

* **書誌**：venue、年、査読/プレプリント、URL/DOI、版（arXiv/会議/ジャーナル）
* **タスク定義**：目的（復元/可読化/意味回復）と対象（Core/Peripheral）
* **入力**：binary / asm / bytecode / decompiler output / derived IR
* **出力**：L1–L4（必須タグ）
* **粒度**：G1–G4（必須タグ）
* **手法**：

  * モデル種別（LLM/Transformer/その他ML）
  * 学習（finetune / pretrain / in-context / retrieval / tool-augmented）
  * 解析統合（静的解析、CFG/SSA、型伝播、制約、コンパイル/テストによる検証等）
* **データ**：データ生成条件（ISA、最適化、コンパイラ、難読化、言語）、公開有無
* **評価**：指標（compile率、AST一致、BLEU系、型精度、命名精度、fidelity、人手評価、ベンチ名）
* **再現性**：コード/モデル/データ/プロンプト公開、実験条件の明示
* **限界**：Threats、一般化の弱点（ISA/最適化/難読化/スケール）

### 6.2 記録フォーマット（実装向け）

スクリーニングアプリ（既に作成している前提）で扱えるよう、**JSONL（1論文=1行）**を推奨。
v8の判定結果（decision / reason codes / evidence）もそのまま格納する。

---

## 7. LLM/MLパートのタクソノミー（論文の“整理棚”）

### 7.1 入力表現で分ける（現実に効く軸）

* **I1**：生バイナリ（bytes）／命令列（最小前処理）
* **I2**：アセンブリ（disassembly）＋補助情報（CFG等）
* **I3**：低水準IR（SSA/CFG/typed IR など）
* **I4**：既存デコンパイラ出力（擬似コード/IR）＝Enhancement系の主戦場

### 7.2 目的（出力レベル）で分ける（L1–L4）

* **S1（L1）**：コンパイル可能ソース復元
* **S2（L2）**：擬似コード/構造化復元（読みやすさ）
* **S3（L3）**：AST/高水準IR（構文・意味の中間表現）
* **S4（L4）**：型/命名/シグネチャ/制御構造（要素技術：Peripheral中心）

### 7.3 統合戦略で分ける（“LLM単体”からの脱却）

* **M1**：純生成（seq2seq / LLM prompting）
* **M2**：解析併用（CFG/SSA/型伝播/制約などを特徴・ガイドに使う）
* **M3**：ツール併用（既存デコンパイラ→LLMで改善、または検証器でループ）
* **M4**：検証ループ（compile/test/diff等で候補を選別・修正）

> これで「スコープを広げたらデコンパイルじゃなくなるのでは？」という懸念は、**Core/Peripheral＋L1–L4＋統合戦略**として論理的に制御できる。 

---

## 8. 歴史パート設計（現状方針の固定）

進捗の意思決定に合わせ、**歴史パートは“SLR検索に含めず”別建てで収集**する。

* まず **10–15本**を「年代×分野が偏らない」ように収集
* 引用追跡・追加探索で **20–30本**へ拡張（均等性を保つ）
* 書き方は「timeline＋ボトルネック軸＋評価史」で、形式は歴史設計テンプレを踏襲 

---

## 9. 再現性パッケージ（査読で一番効く“添付物”）

付録/リポジトリとして最低限これを揃える：

* `search_log/`：DB別の検索式・検索日・件数
* `dedup/`：重複排除ルール
* `screening/`：v8判定（decision / reason_codes / evidence）
* `prisma/`：PRISMAフローの数値
* `corpus.bib`：最終採択BibTeX
* `extraction/`：抽出結果JSONL/CSV、抽出フォーム
* （可能なら）スクリーニングアプリのリリース手順

---

## 10. 現状ステータス（“今どこまでやったか”を設計書に反映）

* 収集：4DBで収集→重複排除の運用（初期 712→655 等の履歴あり）
* 機械スクリーニング：title/abstractでの一次絞り込みを実施（例：655→53→40）
* 検索見直し：期間を2017へ、ノイズ語の見直し、現状 540→57 のように再実行 
* 歴史パート：SLR対象外として別収集に切替、20–30本計画 

---

必要なら次に、**この設計書をそのまま「論文本文の Methodology 節」に落とし込んだ文章**（学術文体）と、**付録用の“v8ルール（短縮版）”**（1ページ相当）まで一気に整形します。
