# 回答1

以下は「**歴史（黎明期〜現在への流れ）を“サーベイの中で同等の重要度で扱っている / 扱える書き方”**」の参考になりやすい論文を、**書き方の型**が分かるように意図的に選んだリストです。デコンパイルに近い分野（バイナリ解析・逆解析・復元系）を厚めにしつつ、**他分野でも歴史の書き方がうまいサーベイ**を混ぜています。

---

## 1) デコンパイルに近い「逆解析・バイナリ解析」系で、歴史の扱いが参考になるサーベイ

### (A) 研究史を“タイムライン化”してから分類（＝歴史と体系化を両立）

**Type Inference on Executables**（Caballero & Lin）

* 何が参考になるか：**「どのように“歴史パートを作るか”の作業手順自体」を論文中で開示**していて、査読耐性が高い書き方です。

  * 例：1998年以降の文献探索、Google Scholar検索、参照文献追跡（スノーボール）などの選定方針を説明し、**出版年順に並べて“timeline”を構成**しています。さらに「この分野は学会が分散している」など、歴史パートでありがちな論点も整理してくれます。 
* デコンパイルへの転用：あなたの“歴史パート”を、単なる年代記ではなく **「年表＋（その時代ごとの）技術論点」**として書くときの雛形になります（例：構造化、型回復、識別子回復、IR、ML/LLM…）。

### (B) 「スコープ・起源・進化」をサーベイ本文の要件として宣言している

**A Survey of Binary Code Similarity**（Ul Haq & Caballero）

* 何が参考になるか：アブストで **「過去20年の発展」「起源と進化（evolution）も議論する」**と明言し、さらに **61本を系統立てて整理**するタイプです。歴史が“前置き”ではなく、サーベイの核（体系化の軸）になっています。 ([arXiv][1])
* デコンパイルへの転用：デコンパイル史も「構造復元」「データ構造/型」「最適化差分」「評価ベンチマーク」などで“系統化”できるので、この論文の **「起源→進化→現在の分類」**の流れが刺さります。

### (C) 40年スパンの“成熟領域”を、歴史の厚みを保ったままサーベイ

**A Survey of Symbolic Execution Techniques**（Baldoni et al.）

* 何が参考になるか：象徴実行が **「過去4 decadesで多数のツールに育った」**という歴史的スケール感を、抽象→課題→解法へ自然に接続しています。歴史が“導入の飾り”ではなく「なぜ課題が残るか」の説明に効いています。 ([arXiv][2])
* デコンパイルへの転用：デコンパイルも「長期にわたるツール実装の蓄積」があるので、**“何が解決された／されていないか”を歴史で説明する**構成の参考になります。

### (D) タイトルからして「Past–Present–Future」型（歴史を同格にしやすい）

**Past, Present, and Future of SLAM**（Cadena et al.）

* 何が参考になるか：**過去30年の進歩**を明示し、現在のデファクト定式化→関連研究→新領域→オープン課題へ繋ぎます。歴史＝過去、サーベイ＝現在、議論＝未来、が最初から設計されているタイプです。 ([arXiv][3])
* デコンパイルへの転用：あなたがやりたい「歴史パートを同等の重要度で扱う」は、**この“Past/Present/Future”三分割が最も実装しやすい**です（歴史がページ数的にも構造的にも正当化される）。

### (E) “ツールの発展史”を、分類（taxonomy）と一緒に書くタイプ

**A Survey of Reverse Engineering Tools for the 32-Bit Microsoft Windows Environment**（Canzanese et al.）

* 何が参考になるか：逆解析プロセスを説明したうえで、ツールをカテゴリ化し、**「長年にわたりツールの“arsenal”が発展してきた」**という時間軸を含んだ整理をしています。 
* デコンパイルへの転用：デコンパイル史を「理論史」だけでなく、**現場ツール観点（デコンパイラ出力、周辺補助、デバッグ連携等）**で書くときの参考になります。

---

## 2) CS一般で「歴史セクションをちゃんと“章”として作っている」良い雛形

### (F) 典型的な「Brief History」節を、サーベイ本文の骨格として宣言

**A Survey on Transfer Learning**（Pan & Yang）

* 何が参考になるか：論文構成の説明で **「historyを簡潔にサーベイし、定義・分類へ進む」**と明言し、実際に **“2.1 A Brief History …”**が独立節として入っています。 ([cse.ust.hk][4])
* デコンパイルへの転用：あなたの論文でも「定義→（簡潔な）歴史→分類スキーム」の順にすると、歴史が“同格の柱”になります。

### (G) Background節の中に「brief history」を置き、そこから“代表的タイムライン”へ

**A Comprehensive Survey on Graph Neural Networks**（Wu et al.）

* 何が参考になるか：Backgroundの中で **“A brief history …”**として初期研究（1997など）を明示し、そこから系列（RecGNN/ConvGNN…）に繋げ、**代表研究のタイムライン（Table参照）**も示す流れです。 
* デコンパイルへの転用：「初期の形式的手法→構造化/データフロー→型/構造体→ニューラル→LLM」みたいに、**“歴史＝分類の根拠”**にすると非常に強いです。

---

## 3) 「歴史が主役」の“歴史サーベイ”そのもの（歴史パートの文章トーンを学べる）

### (H) 歴史だけで一本書き切るCSUR流（引用・年代・分類のバランスが上手い）

**A Brief History of Just-In-Time**（Aycock）

* 何が参考になるか：JITが **1960年代から存在**することを押さえた上で、**1960–2000の40年を“survey”する**と宣言し、さらに「Genesis（起源）」など節立てして**時系列で整理**します。 
* デコンパイルへの転用：あなたが「歴史パートを同等に」したいなら、歴史章をこのくらい“独立した論文のように”書く発想（章内で定義→時代区分→代表技術の分類）を真似しやすいです。

---

## 4) 他分野（CS外）でも「歴史→現在→展望」をきれいに接続しているレビュー

### (I) “Past/Present/Future”を材料・技術進化の物語として書く

**A brief review: Past, present and future of lithium ion batteries**（Schipper & Aurbach）

* 何が参考になるか：アブストで **1970–1980年代の研究から現代技術へ**という歴史起点を明示し、その後に材料発展と次世代（future）へ繋げる構成です。 ([スプリンガー][5])

### (J) 「ここでbrief historyをやる」と宣言してから“ツールキット”を体系化

**The CRISPR tool kit for genome editing and beyond**（Adli）

* 何が参考になるか：アブストで **「遺伝子編集ツールのbrief historyを示し、その後にツール群を説明し、最後にfuture」**と設計を宣言しています。歴史が“免罪符”ではなく、体系化への入口です。 ([Nature][6])

---

## 5) おまけ：デコンパイル史を書くときに「一次資料」として引用しやすい古典・近縁論文（※サーベイではない）

サーベイ“の歴史章”は、サーベイ論文だけでなく、**その時代の一次資料**を少数混ぜると説得力が上がることが多いです（「当時こう定義されていた」「当時は困難で“あまり試みられない”と書かれていた」など）。

* **Decompilation**（Bowen & Breuer, 1993の章）

  * デコンパイラ/逆コンパイラの定義や、「難しく、あまり試みられない」といった当時の見方がまとまっていて、歴史章の“引用点”にしやすいです。 ([ResearchGate][7])
* **Augmenting Decompiler Output with Learned Variable Names and Types**（Chen et al., DIRTY）

  * 近年の文脈として「デコンパイラはbinary→高級言語へ」「コメント・変数名・型などは失われる」など、現代的な位置づけを短く引用しやすい導入があります。 

---

## これらのサーベイから抽出できる「歴史パートの書き方の型」（デコンパイル向けに特に有効）

最後に、上の論文群を“書き方”として見ると、歴史の置き方はだいたい次の3パターンに収束します：

1. **Brief History → 定義 → 分類（taxonomy）**

   * 例：Transfer Learning / GNN ([cse.ust.hk][4])
   * デコンパイル向き：歴史を「用語の揺れ（decompiler / reverse compilation / lifting / structuring など）」を収束させる装置にできる。

2. **Timeline（年表）を作ってから、分類表に落とす**

   * 例：Type inference on executables（出版年順に並べてtimeline化） 
   * デコンパイル向き：論文数が多くても、「年表＋代表論文」方式なら網羅性と可読性のバランスが取れる。

3. **Past / Present / Future の三分割**

   * 例：SLAM、Li-ion、CRISPR ([rpg.ifi.uzh.ch][8])
   * デコンパイル向き：「歴史を同等の重要度」にしたいなら最も強力。章立ての時点で“ページ配分が正当化”される。

---

必要なら次に、上の“型”を使って **「デコンパイル史（例：80s/90s〜現代〜LLM時代）をどう時代区分するか」**、さらに **各時代で“何を代表論文として最小集合（例：各時代5〜10本）にするか”**まで、具体的なテンプレ（見出し案・図表案・引用の置き方）に落として提案できます。

[1]: https://arxiv.org/abs/1909.11424 "[1909.11424] A Survey of Binary Code Similarity"
[2]: https://arxiv.org/abs/1610.00502 "[1610.00502] A Survey of Symbolic Execution Techniques"
[3]: https://arxiv.org/abs/1606.05830 "[1606.05830] Past, Present, and Future of Simultaneous Localization And Mapping: Towards the Robust-Perception Age"
[4]: https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf "untitled"
[5]: https://link.springer.com/article/10.1134/S1023193516120120 "A brief review: Past, present and future of lithium ion batteries | Russian Journal of Electrochemistry | Springer Nature Link"
[6]: https://www.nature.com/articles/s41467-018-04252-2 "The CRISPR tool kit for genome editing and beyond | Nature Communications"
[7]: https://www.researchgate.net/publication/221477534_Decompilation "(PDF) Decompilation"
[8]: https://rpg.ifi.uzh.ch/docs/TRO16_cadena.pdf "untitled"



# 回答2
デコンパイル史を「同じぐらいの重要度」で扱うなら、まず **“歴史の骨格（何がいつ起きたか）”** と **“歴史を書く軸（何を主語に並べるか）”** を分けて考えるのが筋がいいです。デコンパイルは **用途（移植/保守/セキュリティ）** と **技術課題（CFG回復・型推論・構造化…）** が何度も交差するので、ただ年代順に並べると「出来事リスト」になりがちです。

## デコンパイル史の“骨格”として押さえておくべき流れ（超要約）

* **1960年代**：最初期のデコンパイルは「移植・変換（世代の違う計算機へ移す）」の文脈が強い。Cifuentes の整理では **D‑Neliac decompiler（1960）** が言及され、NEL（Navy Electronics Laboratory）で機械語から Neliac を生成した事例が紹介されます。 ([Phatcode][1])
* **1970–80年代**：形式化・パターンマッチ中心の流れから、徐々に **制御/データフロー** を用いて「高水準らしさ」を上げようとする流れが育つ（研究としては散発的で、入力がアセンブリ寄りのものも混ざる）。この時代の蓄積は、後の「構造化」「イディオム認識」の発想につながる、という位置づけがしやすいです。 
* **1990年代（大きな転換点）**：デコンパイラを **フロントエンド（機械依存）→ 中間表現の解析（機械/言語独立）→ バックエンド（言語依存）** として設計・説明する枠組みが明確化されます（Cifuentes の枠組みはまさにこれ）。 ([Phatcode][1])
* **2000年代**：SSA などのコンパイラ理論・最適化の考え方が、式回復・型解析・間接分岐解析など、デコンパイルの主要コンポーネント実装に強く効く、という整理がしやすくなります（Van Emmerik の本全体がこの“コンポーネント実装史”として読めます）。 
* **2007前後〜**：産業ツールが「C風擬似コード」を現場標準にし、コミュニティの知識共有（プラグイン、API、機能DB等）が加速。例として Hex‑Rays Decompiler 1.0 のリリース日（2007‑09‑17）が公式に年表化されています。 ([hex-rays.com][2])
* **2017–2019〜（オープン化・プラットフォーム化）**：RetDec が OSS 化（2017‑12‑13 公表）し、Ghidra が 2019 RSA で一般公開（NSAが「2019 RSAで公開した」と明記）。このあたりから「研究→実装→共有」が回りやすくなる。 ([blog.avast.com][3])
* **近年**：現代的な説明として「CFG回復 → 型推論 → 制御構造化」という **3フェーズ** で語る整理が（少なくともセキュリティ研究コミュニティでは）自然に使われます。 

この骨格を踏まえた上で、「歴史を書く方法」を3つ比較します。

---

## 書き方 1：年代区分（Era-based）で“正史”として語る

### どう書くか（章立て例）

* 1. 起源（1960s）：移植・翻訳のためのデコンパイル
* 2. 研究としての模索（1970–80s）：構造化・抽象化の試行
* 3. 枠組みの確立（1990s）：逆コンパイルとしての設計原理
* 4. 実装理論の強化（2000s）：SSA/解析の体系化
* 5. 産業化（2007–）：C風擬似コードの定着とツール連携
* 6. OSS化と民主化（2017–）：RetDec/Ghidra等
* 7. データ駆動化（2020s–）：ML/LLM・評価指標の進化

### 強み

* 読者が最も迷いにくい。「いつ何が起きたか」が一発で分かる。
* ツール史・コミュニティ史（商用・OSS・公開の節目）を入れやすい。 ([hex-rays.com][2])

### 弱み（デコンパイル特有の落とし穴）

* 技術課題が交差するので、**同じ話（例：構造化、型、シンボル）が何度も出てくる**
* “歴史パートを同じ重要度で厚くする”ほど **年表の羅列** になりやすい（査読で「結局 taxonomy は？」と言われやすい）

### 向いているとき

* 読者が広い（RE初心者も含む）／論文の主眼が「LLM等の新潮流」ではなく「分野の通史」寄り。

---

## 書き方 2：デコンパイル・パイプライン（問題/コンポーネント）別の“発展史”として語る（おすすめ）

### どう書くか（章立て例）

最初に **1ページの小年表**（書き方1の圧縮版）を置き、本文は以下で厚くする：

* A. **コード発見とCFG回復**（コード/データ分離、関数境界、間接分岐…）
* B. **中間表現とデータフロー**（式回復、SSA、伝播、簡約…）
* C. **型推論・データ構造回復**（型・プロトタイプ・呼出規約…）
* D. **制御構造化と“脱最適化”**（if/while/switch、goto問題、イディオム…）
* E. **記号・名前・可読化**（シンボル、ライブラリ認識、命名、コメント…）
* F. **評価の歴史**（「一致」から「可読性/近さ」へ、ベンチマーク/メトリクス）

ここで“現代パイプライン”の見取り図として

* Cifuentes の **front-end / language&machine independent module / back-end**  ([Phatcode][1])
* Basque らの **CFG回復→型推論→構造化** 
  のどちらか（または両方）を「概念図」として採用すると、歴史と現代の接続が自然になります。

### 強み

* **あなたのサーベイ本文（最先端の整理）と“同じ軸”で歴史を書ける**
  → 歴史が「前置き」ではなく、技術分類の根拠として機能する。
* 網羅が難しい年代（1960–80s）も、**各コンポーネントの“起点となる代表例”** に絞って語れる。
* 2000年代以降の「解析の体系化」「産業ツール化」「OSSプラットフォーム化」が、各コンポーネントにどう影響したかを書きやすい。 

### 弱み

* 年代の流れが見えなくなる危険（ただし冒頭の“小年表”でほぼ解消できる）
* セクション間の重複をゼロにはできない（例：型推論と可読化は絡む）

### 向いているとき

* **歴史パートを“同じ重要度”で厚くしても、査読で「意味がある厚さ」に見せたい**
* あなたのように Core/Peripheral（出力レベルや要素技術）で整理していく設計と相性が最高。

---

## 書き方 3：ツール／エコシステム（現場の知識体系）中心に語る

### どう書くか（章立て例）

* 1. 研究プロトタイプの時代（〜1990s）：設計原理が蓄積
* 2. プラットフォーム化（2000s–）：解析基盤＋API＋プラグイン
* 3. 産業標準の確立（2007–）：擬似コード出力の普及（例：Hex‑Rays） ([hex-rays.com][2])
* 4. OSSでの民主化（2017–2019）：RetDec OSS化、Ghidra公開 ([blog.avast.com][3])
* 5. “ツールが生む研究課題”（評価、差分、近さ、ユーザ体験）

### 強み

* 実務者・読者の体験と一致しやすく、読みやすい
* “歴史パート”が単なる論文紹介ではなく、「なぜ今こうなっているか」の説明になる

### 弱み

* 査読で「学術的貢献の追跡になっていない」「製品史に寄っている」と見なされるリスク
* 商用ツールは中身がブラックボックスになりがちで、技術的比較が難しい（書ける範囲が偏る）

### 向いているとき

* 読者に実務者が多い（セキュリティ/RE寄り会議）
* “実際に使われた影響”を中心に語りたい

---

## 結論：デコンパイル史は「書き方2（パイプライン/問題別）」を主軸にするのが一番“筋がいい”

理由はシンプルで、デコンパイルは昔から一貫して **「情報が落ちた低水準表現から、高水準の構造を回復する」** という **解析パイプラインの設計問題** で、分野の成熟は「年代」よりも **“どのコンポーネントがどこまで解けるようになったか”** で説明した方が、学術的にフェアで、あなたのサーベイ全体の骨組みにも直結するからです。 ([Phatcode][1])

さらに、歴史パートを厚くするときの最大の敵は「網羅しようとして破綻する」ことですが、パイプライン別にすると、

* 1960–80s：各コンポーネントの“最初期の発想”を **代表例だけ** 置く（例：最初期デコンパイルの存在、パターンマッチの発想） ([Phatcode][1])
* 1990s：枠組み確立（Cifuentesのモジュール化）を **アンカー** にする ([Phatcode][1])
* 2000s–：SSA等で“コンポーネント実装が回る”へ（Van Emmerikをアンカー） 
* 2017–：OSS化/プラットフォーム化が“評価・共有・再現性”を押し上げた、という **横断的要因** として扱う ([nsa.gov][4])

という書き分けができ、**歴史を厚くしても破綻しにくい**です。

---

## “書き方2”を採用する場合の、すぐ使える実装テンプレ

1. **冒頭1ページ：圧縮年表（Turning pointsだけ）**

* 1960：D‑Neliac（最初期） ([Phatcode][1])
* 1994：逆コンパイルとしての設計枠組み（モジュール化） ([Phatcode][1])
* 2007：商用擬似コード出力の定着（例：Hex‑Rays 1.0） ([hex-rays.com][2])
* 2017–2019：OSS/公開（RetDec、Ghidra） ([blog.avast.com][3])
* 現代：CFG回復→型推論→構造化、という語り口 

2. **本文：コンポーネント別“発展史”**（A〜F）
   各節の冒頭を必ず同じ型にする：

* この課題はなぜ難しいか（コンパイルで失われる情報は何か）
* 初期（〜90s）はどう割り切ったか
* 体系化（2000s〜）で何が変わったか
* ツール/OSS化が何を加速したか
* 近年（ML/LLM）がどこに刺さっているか

3. **節末に“現在地サマリ”の小表**
   例：そのコンポーネントについて

* 入力（バイナリ/IR/擬似コード）
* 出力（型/AST/構造化C…）
* 評価（正しさ/近さ/可読性）
* 未解決（最適化、未到達コード、間接分岐、型の曖昧性…）
  を固定フォーマットで置く。これで「歴史＝羅列」にならず、技術サーベイとして締まります。

---

必要なら、次に **「デコンパイル史（1960s〜）を、上のA〜Fに割り振った“引用すべきアンカー文献リスト（各節5本程度）”」** をこちらで叩き台として作れます。そうすると、歴史パートを厚くしても参照数が爆発しにくく、しかも“筋の通った選定”として説明可能になります。

[1]: https://www.phatcode.net/downloads.php?action=get&file=decompilation_thesis.pdf&id=228 "Reverse Compilation Techniques"
[2]: https://hex-rays.com/blog/ida-celebrating-30-years-of-binary-analysis-innovation "IDA: celebrating 30 years of binary analysis innovation – Hex Rays"
[3]: https://blog.avast.com/avast-open-sources-its-machine-code-decompiler "Avast open-sources its machine-code decompiler"
[4]: https://www.nsa.gov/Press-Room/News-Highlights/Article/Article/3319971/four-years-later-the-impacts-of-ghidras-public-release/ "
	Four Years Later: The Impacts of Ghidra's Public Release > National Security Agency/Central Security Service > Article
"


# 回答3
以下は、あなたが選んだ **「書き方 2：デコンパイル・パイプライン（問題/コンポーネント）別の“発展史”として語る」**を、**デコンパイルの歴史（古典〜現代・学術〜実務）に即して**、しかも **サーベイとして筋が良く・査読で守りやすい形**に落とし込むための深掘り案です。
（“少し調査”として、各コンポーネントの転換点になった論文・代表的実装・最近の評価枠組みも一緒に並べます）

---

## 1. 「パイプライン別の発展史」がデコンパイルで強い理由

デコンパイルは、歴史的にも実装的にも **単一の発明ではなく“複数の難問の積み重ね”**です。だから「年表」だけで語ると、

* 重要度の違う出来事が同列に並ぶ（読者が迷う）
* 途中で枝分かれ（商用デコンパイラ・学術・バイナリ解析基盤・ML）が増えすぎて破綻
* “今の研究がどのボトルネックを解いているのか”が見えにくい

になりがちです。

一方、**パイプライン（= 典型的な処理段）**に分けると、歴史が「課題→解法→限界→次の課題」になって、**現代のニューラル/LLM系（多くが特定コンポーネント改善）とも自然に接続**できます。

さらに、実務ツールもパイプラインを前提に設計されています（例：**Hex-Rays は microcode というILを中心に複数段で精緻化**し、**Ghidra も p-code を中心に解析を組む**）。([i.blackhat.com][1])

---

## 2. 書き方2の“最小の型”テンプレ（査読で説明しやすい）

### 2.1 冒頭に置く「パイプライン図（共通語彙）」が最重要

歴史パートの最初に、**あなたのサーベイが想定するデコンパイル・パイプライン**を図で固定します。
（図を固定すると、以降は「この箱の進化史」として迷子になりません）

例（ネイティブバイナリ想定）：

1. **Decoding / Disassembly**（命令デコード、コード/データ判別、関数境界）
2. **Lifting to IR**（機械語→中間表現）
3. **CFG & Structuring**（CFG回復、if/while/switch等の構造化）
4. **Dataflow / SSA / Simplification**（値追跡、式簡約）
5. **Memory / Variables / Calling convention**（スタック変数、引数、呼出規約）
6. **Type recovery**（型・構造体の推定）
7. **Symbols / Names**（関数名・変数名・意味のある識別子）
8. **Codegen / Presentation**（擬似コード/AST/ソース出力、読みやすさ）
9. **Evaluation**（正しさ・可読性・作業効率の測り方）

この“箱”を章立てに使い、**各箱ごとに発展史を書く**のが書き方2です。

---

## 3. 「発展史」を各コンポーネントで同じ型で書く

各コンポーネント節を、毎回この型に揃えると歴史が読みやすく、サーベイとしても締まります。

* **(A) 何が失われている／何が難しいか**（コンパイルで情報が落ちる、最適化で形が壊れる、など）
* **(B) 古典的アプローチ**（静的解析・コンパイラ理論ベース、代表論文/ツール）
* **(C) “転換点”**（この箱の常識が変わった出来事：SSA化、IR設計、構造化法、学習導入など）
* **(D) 現代の主流**（実務実装や研究のメインストリーム）
* **(E) 典型的な失敗パターン（fidelity issues）**
* **(F) 次の研究余地**（ここにLLM/学習系がどこまで刺さるかも整理）

この型にすると、「歴史」が単なる過去紹介でなく、**“なぜ今ここが研究されてるのか”の説明**になります。

---

## 4. ここから“少し調査”：コンポーネント別に、転換点を置ける資料例

以下は、あなたが歴史パートを書くときに「核（anchor）」になりやすいものを、パイプラインごとに並べた例です。
（全部を網羅する必要はなく、**各箱あたり 5〜10本**を“ランドマーク”として採用→スノーボールで補うのが筋が良いです）

---

### 4.1 全体観の出発点（「デコンパイル＝コンパイラ理論の逆向き適用」）

* **Cifuentes の博士論文（1994）**：逆コンパイル/デコンパイルを、最適化理論やコンパイラ技術を逆用して体系化した古典。歴史パートの“原点”として強いです。([yurichev.com][2])

この1本があると、以降の各コンポーネント史が「ここから枝分かれして洗練された」と説明できます。

---

### 4.2 CFG構造化（if/while/switchへ戻す）＝“発展史が最も書きやすい箱”

ここは「研究の筋」が通っていて、歴史節の主柱に向きます。

* **Cifuentes: Structuring Algorithm for Decompilation**：非構造CFGを“構造化”するアルゴリズムを正面から扱う。古典の核。([cs.tufts.edu][3])
* **Phoenix（2013）**：x86を高水準ILへ、さらにCへ、という段構えの構造化・変換を提示（“構造化を中心に据えた実験”として置ける）。([users.ece.cmu.edu][4])
* **Yakdan et al. (2015) “No More Gotos”**：パターン依存を薄めた構造化を扱い、以降の研究の参照点になりやすい（この論文自体が古典研究の整理もしている）。([NDSS Symposium][5])
* **Basque et al. (2024)**：構造化を “interval analysis / structural analysis” の系譜として整理しつつ、より現代の課題に寄せている（最新のまとめ役として便利）。([USENIX][6])

> 書き方2では、この箱を「第1のメインストーリー」にすると、歴史パートが一気に締まります。
> なぜなら **“非構造→構造”**は読者が直感的に理解でき、他の箱（型・変数・命名）とも強く結びつくからです。

---

### 4.3 IR（中間表現）中心主義の確立：実務ツールが“箱を分けた”歴史

歴史としては「CPU命令そのままでは無理→IRが中核になる」が大きな転換点です。

* **Hex-Rays：microcode（IL）**
  「なぜILが必要か」を decompiler internals として明確に述べ、複数段の精緻化（maturity）で扱う流儀が見える。([i.blackhat.com][1])
* **Ghidra：SLEIGH（仕様言語）と p-code**
  アーキ依存部分を SLEIGH 記述として切り出し、解析は p-code を中心に回す設計思想が資料として明文化されている。([Ghidra][7])
* **RetDec：LLVM IRベースの2段階**
  “まず機械語→LLVM IR、次にIR→高水準”という分割の考え方を説明する資料がある。([2018.pass-the-salt.org][8])
* **Binary Ninja：BNIL（LLIL/MLIL/HLIL）**
  ILを複数レイヤに分ける（低〜高）設計が公式ドキュメントに明記されている。([docs.binary.ninja][9])

この箱の発展史は、「デコンパイル研究＝(解析したい性質)に合わせてIRを設計・選択する歴史」として書くと筋が通ります。
さらに “IRの正しさ” を検査する研究（= lifter testing）もストーリーに入れられます。([softsec.kaist.ac.kr][10])

---

### 4.4 型回復（Type recovery）：古典→原理→学習→ベンチマークの系譜が作れる

「型」はデコンパイルで最も重要かつ最も落ちる情報の一つで、研究の積み上がりも分厚いです。

* **TIE (NDSS 2011)**：型推定を“原理立てた推論問題”として押し出した代表格。歴史の節目にしやすい。([NDSS Symposium][11])
* **Debin (CCS 2018)**：stripped binary からデバッグ情報（名前や型など）を予測、という方向の代表。([ACM Digital Library][12])
* **DIRTY (USENIX 2022)**：デコンパイラ出力に学習で“変数名と型”を付加する方向を強く示す。([edmcman.github.io][13])
* **TYGR (USENIX Security 2024)**：データフローを符号化して型を推論する学習系の代表例。([USENIX][14])
* **Type inference benchmarking (2025)**：複数デコンパイラで型推定を比較する、という“評価の箱”に接続できる。([ACM Digital Library][15])

ここは書き方2で「第2のメインストーリー」に向きます。
なぜなら、型は **(i)構造化、(ii)変数回復、(iii)命名、(iv)出力品質**すべてに波及するからです。

---

### 4.5 関数境界・デコード（フロントエンド）：歴史は短く書いても効く

この箱は古典から現在までの“問題の形”が比較的変わらない一方、学習導入が節目になります。

* **Shin et al. (USENIX Security 2015)**：NNで関数認識を扱う例として置ける。([USENIX][16])
* **RetDec の decoding（recursive traversal等）**：実装上の要点（どの順で辿るか等）が資料化されている。([2018.pass-the-salt.org][8])

書き方としては、ここは長くなりやすいので
**「古典的二分法（線形スイープ vs 再帰下降）→学習の導入→今も残る難点（間接分岐/ジャンプテーブル等）」**
くらいの“短い発展史”にして、紙幅を構造化・型・命名に回すのがバランス良いです。

---

### 4.6 命名（関数名・変数名）：近年の“生成”が歴史の新章になる

命名は、古典的にはヒューリスティック・辞書・シンボル復元が中心でしたが、近年は生成的アプローチが増えています。

* **Debin (2018)**：名前の回復（デバッグ情報予測）方向の代表例。([files.sri.inf.ethz.ch][17])
* **DIRTY (2022)**：デコンパイラ出力を“人間に読む”方向へ押し出した代表。([edmcman.github.io][13])
* **SYMGEN (NDSS 2025)**：stripped binary の関数名推定を“生成”として扱う新しめの代表。([NDSS Symposium][18])
* **Generative modelでの命名回復（NDSS 2025系）**：命名を生成で扱う潮流の補助線にできる。([cs.purdue.edu][19])

ここは **「可読性（human-centric）」**という評価箱に繋げやすいので、歴史としては比較的新しいのに重要度を上げられます。

---

### 4.7 評価（Evaluation）の“歴史”：最近になって独立トピック化してきた

歴史パートを同じ重要度で扱うなら、「評価史」を最後に置くと締まります。理由は、**“何が良いデコンパイルか”が時代とともに変わる**からです。

* **DecompileBench (2025)**：実運用ワークフローを意識した評価枠組みとして置ける。([arXiv][20])
* **Decompiler fidelity issues taxonomy (2024)**：何がズレやすいか（fidelity）を整理する流れに使える。([USENIX][21])

> 書き方2では「評価」も1コンポーネントとして扱うと、歴史が“研究の積み上げ”として終われます（単なるツール列挙で終わらない）。

---

## 5. 書き方2での「歴史パートの論文数」が爆発しない設計

歴史は網羅すると無限に増えます。なので書き方2では、歴史パート自体を **“ランドマーク方式”**で宣言するのが筋が良いです。

### 推奨：ランドマーク方式（Anchor + Snowball、各箱で打ち切り）

各コンポーネント（箱）につき：

* **Anchorを3〜5本**選ぶ

  * 最初期の代表（古典）
  * 大きな転換点（例：SSA/構造化/原理的型推論/IL中心化）
  * 現代の代表（学習/LLM含む）
  * 可能なら最新のベンチマーク/整理論文
* Anchorから **前方/後方スノーボール**で追加

  * ただし「新しい概念が増えなくなったら止める（飽和）」で打ち切る

この方式だと、歴史パート全体はだいたい

* **箱 8〜10個 × (5〜8本/箱) = 40〜80本**

くらいに収まり、しかも「重要度が同じ」扱いにできます（= 各箱に同じ枠を与えるため）。

---

## 6. 実際の文章に落とすとこうなる（1箱ぶんのミニ例）

たとえば **CFG構造化**の節は、以下のような“発展史の筋”になります。

* (A) **なぜ必要か**：機械語CFGは goto 的で、HLLの if/while と整合しない
* (B) **古典**：構造化アルゴリズムで reducible/unstructured graph を扱う枠組みが提示される（Cifuentes）。([cs.tufts.edu][3])
* (C) **転換点**：意味保存変換や、よりパターン非依存な構造化（Phoenix、No More Gotos）で“どこまで goto を消せるか”が議論される。([users.ece.cmu.edu][4])
* (D) **最近**：interval/structural analysis の整理を踏まえ、コンパイラ事情（最適化・例外等）を強く意識した研究が出る。([USENIX][6])
* (E) **失敗パターン**：irreducible CFG、例外、間接分岐、オブfuscation
* (F) **次**：構造化の評価指標（人間作業に効くのか）や、命名・型推定との共同最適化へ

…という具合に、「歴史」を書いているのに、そのまま現代研究の論点整理にもなります。

---

## 7. 書き方2をさらに強くする“仕掛け”3つ

### 仕掛け1：各箱に「代表ツール実装」を1つだけ添える

論文だけだと読者の実感が湧きにくいので、各箱に

* Hex-Rays（microcode）([hex-rays.com][22])
* Ghidra（p-code / SLEIGH）([Ghidra][7])
* RetDec（LLVM IR二段）([2018.pass-the-salt.org][8])
* Binary Ninja（LLIL/MLIL/HLIL）([docs.binary.ninja][9])

のような“設計思想が読める資料”を、**入れすぎない範囲で**置くと歴史の説得力が上がります。

（Ghidraは2019年に公開、という事実も公式に押さえられます）([nsa.gov][23])

---

### 仕掛け2：「評価史」を最後に置いて“歴史＝研究の成熟”で締める

DecompileBenchのような枠組みや、fidelity issuesの分類を最後に置くと、歴史パートが「最近の論文羅列」ではなく **成熟の物語**になります。([arXiv][20])

---

### 仕掛け3：LLM/学習系は“箱に埋める”（別章に隔離しない）

学習・LLMを別章に閉じ込めると、歴史と分断します。書き方2では、

* 型の箱 → TIE → Debin/DIRTY/TYGR
* 構造化の箱 → 古典構造化 → No More Gotos → 最近の整理
* 命名の箱 → Debin/DIRTY → SYMGEN など

のように、**各箱の発展史の最終章として自然に配置**します。

なお、LLM系を含むサーベイ設計の作法（プレプリントの扱い、品質評価など）は、LLM4SEのSLRのような既存SLRの書きぶりも参考になります。

---

## 次にできること（あなた向けに“すぐ使える”作業形にする）

必要なら、ここまでの方針を **あなたのサーベイの目次（歴史パートを同格に置いた章立て）**として、

* 「箱（コンポーネント）」の確定版
* 各箱の **Anchor候補（5本）**の確定
* 各箱の **小見出し（A〜Fテンプレ）**を埋めたアウトライン
* どの箱にどれくらい紙幅を割くか（均等配分 or 重み付き配分）

まで、1回でドラフトに落とします。

もしあなたのサーベイの主軸が **「LLMでデコンパイルを改善」**なら、上の箱のうち
**(CFG構造化)・(型)・(命名)・(評価)** を“太い4本柱”にして、他を短めの補助線にする配分が一番きれいに決まります。

[1]: https://i.blackhat.com/us-18/Thu-August-9/us-18-Guilfanov-Decompiler-Internals-Microcode-wp.pdf?utm_source=chatgpt.com "Decompiler internals: microcode"
[2]: https://yurichev.com/mirrors/DCC_decompilation_thesis.pdf?utm_source=chatgpt.com "Reverse Compilation Techniques by Cristina Cifuentes"
[3]: https://www.cs.tufts.edu/comp/150FP/archive/cristina-cifuentes/structuring-algorithm.pdf?utm_source=chatgpt.com "A Structuring Algorithm for Decompilation"
[4]: https://users.ece.cmu.edu/~dbrumley/pdf/Schwartz%20et%20al._2013_Native%20x86%20Decompilation%20using%20Semantics-Preserving%20Structural%20Analysis%20and%20Iterative%20Control-Flow%20Structuring.pdf?utm_source=chatgpt.com "Native x86 Decompilation using Semantics-Preserving ..."
[5]: https://www.ndss-symposium.org/wp-content/uploads/2017/09/11_4_2.pdf?utm_source=chatgpt.com "No More Gotos: Decompilation Using Pattern-Independent ..."
[6]: https://www.usenix.org/system/files/usenixsecurity24-basque.pdf?utm_source=chatgpt.com "A Compiler-Aware Structuring Algorithm for Binary"
[7]: https://ghidra.re/ghidra_docs/languages/html/sleigh.html?utm_source=chatgpt.com "SLEIGH"
[8]: https://2018.pass-the-salt.org/files/talks/04-retdec.pdf?utm_source=chatgpt.com "RetDec: An Open-Source Machine-Code Decompiler"
[9]: https://docs.binary.ninja/dev/bnil-overview.html?utm_source=chatgpt.com "BNIL Guide: Overview - Binary Ninja User Documentation"
[10]: https://softsec.kaist.ac.kr/~soomink/paper/kim-ase17.pdf?utm_source=chatgpt.com "Testing Intermediate Representations for Binary Analysis"
[11]: https://www.ndss-symposium.org/ndss2011/tie-principled-reverse-engineering-of-types-in-binary-programs/?utm_source=chatgpt.com "Principled Reverse Engineering of Types in Binary Programs"
[12]: https://dl.acm.org/doi/10.1145/3243734.3243866?utm_source=chatgpt.com "Debin: Predicting Debug Information in Stripped Binaries"
[13]: https://edmcman.github.io/papers/usenix22.pdf?utm_source=chatgpt.com "Augmenting Decompiler Output with Learned Variable ..."
[14]: https://www.usenix.org/system/files/usenixsecurity24-zhu-chang.pdf?utm_source=chatgpt.com "TyGr: Type Inference on Stripped Binaries using Graph ..."
[15]: https://dl.acm.org/doi/10.1145/3733822.3764675?utm_source=chatgpt.com "Benchmarking Binary Type Inference Techniques in ..."
[16]: https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-shin.pdf?utm_source=chatgpt.com "Recognizing Functions in Binaries with Neural Networks"
[17]: https://files.sri.inf.ethz.ch/website/papers/ccs18-debin.pdf?utm_source=chatgpt.com "Debin: Predicting Debug Information in Stripped Binaries"
[18]: https://www.ndss-symposium.org/wp-content/uploads/2025-797-paper.pdf?utm_source=chatgpt.com "Inferring Function Names in Stripped Binaries via Domain ..."
[19]: https://www.cs.purdue.edu/homes/lintan/publications/gennm-ndss25.pdf?utm_source=chatgpt.com "Unleashing the Power of Generative Model in Recovering ..."
[20]: https://arxiv.org/html/2505.11340v1?utm_source=chatgpt.com "A Comprehensive Benchmark for Evaluating Decompilers ..."
[21]: https://www.usenix.org/system/files/usenixsecurity24-dramko.pdf?utm_source=chatgpt.com "A Taxonomy of C Decompiler Fidelity Issues"
[22]: https://hex-rays.com/blog/spying-on-decompiler-internals-the-hex-rays-microcode-viewer?utm_source=chatgpt.com "Spying on Decompiler Internals: The Hex-Rays Microcode ..."
[23]: https://www.nsa.gov/Press-Room/News-Highlights/Article/Article/3319971/four-years-later-the-impacts-of-ghidras-public-release/?utm_source=chatgpt.com "Four Years Later: The Impacts of Ghidra's Public Release"
