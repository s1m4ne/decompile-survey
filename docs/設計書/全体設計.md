了解。さっきの「1/3（全体方針）」を、**検索〜絞り込み〜管理〜執筆**の“ステップ順”で読みやすく書き直します（内容は同じで、構造だけ整理します）。
※まだ **2/3, 3/3** は出しません（あなたの指定通り、今回は1つ目だけ）。

---

# 1/3 全体方針：統合コーパスで「歴史」と「LLM」を扱う（手順ベース）

## ステップ0：基本方針（この文書で確定している前提）

* **統合コーパス（1コーパス）で進める**
  歴史・非ML古典・ML/LLM研究を、同じ母集団として集めて管理する。
* **LLMは網羅性重視**（可能な限り全件を拾う）
* **歴史は収集は同じ粒度で拾うが、記述は代表選定でまとめる**（全件を細かく解説しない）
* **統合コーパスのスクリーニングは「LLM必須」にしない**（非LLM古典も拾えるようにする）
* スクリーニング基準は **スコープベースのIC/EC**（ステップ3.2で確定済み。パイプライン非依存）

---

## ステップ1：検索（収集の入口）

### 1.1 方針（確定）

* **引用追跡（前方・後方）を必須**にする
  DB検索だけで落ちやすい古典・分野横断（PL/SE/SEC）を補う。
* **ミニQGSを必須**にする
  用語揺れ・DB偏りを補正するため、最初に少数の代表（seed/QGS）を持つ。

### 1.2 使用DBセット（確定）

* **主要DB（4つ）**：ACM Digital Library / IEEE Xplore / Web of Science / arXiv
* **補助DB（2つ）**：NDSS / USENIX（個別に検索する。まだ未実施だが方針として決定）

### 1.3 検索クエリ（確定）

2系統のクエリで title / abstract を検索する。**期間制限は設けない（全年代対象）**。歴史の古典から最新のLLM研究まで、統合コーパスとして同一の検索で収集する。

#### Q1: メインクエリ（decompil* 直接同義語）

```
decompil* OR "reverse compilation" OR "reverse compiler"
```

* `decompil*` で decompilation, decompiler, decompiling 等をカバー
* `"reverse compilation"` は古典（Cifuentes 博士論文タイトル等）で使われる直接同義語
* `"reverse compiler"` も同様
* これらはバイナリ文脈以外ではほぼ使われないため、AND 条件なしで精度が保てる

#### Q2: 補完クエリ（decompil* を使わない表現 × バイナリ文脈）

```
(
  "source code recovery" OR "source recovery"
  OR "binary-to-source" OR "binary to source"
  OR "binary lifting" OR "instruction lifting"
  OR "lifting to IR" OR "lifting to LLVM"
  OR "assembly-to-C" OR "assembly to C"
  OR "program reconstruction"
)
AND
(
  "binary code" OR "machine code" OR "assembly code"
  OR executable OR disassembly OR disassembler
  OR bytecode OR "binary analysis" OR "stripped binary"
)
```

* 第1項: デコンパイルと同じことを指すが `decompil*` を使わない表現群
* 第2項: バイナリ文脈に限定するための AND
* ML/LLM 層は設けない（手法種別による制限なし、スクリーニング基準と整合）

#### Q1 と Q2 の関係

| | Q1 | Q2 |
|---|---|---|
| 役割 | `decompil*` を明示的に使う論文 | `decompil*` を使わずにデコンパイルをしている論文 |
| AND条件 | なし（語自体が十分にspecific） | あり（復元表現 × バイナリ文脈） |
| 期待ヒット | 主力（500件台） | 補完（数十〜100件台） |

* Q1 ∩ Q2 の重複はステップ2の重複排除で吸収
* QGS の seed 論文で Q1 にも Q2 にも引っかからない論文が見つかった場合、語彙を追加する

### 1.4 QGS（Quasi-Gold Standard）による検索検証（確定）

検索クエリの感度（sensitivity）を検証するため、**QGS（Quasi-Gold Standard）を構築し、検索文字列のカバー率を測定する**。
方法論は Zhang et al. (2011) のプロトコルに従い、Napoleão et al. (2024) の多様性に関する知見を反映する。

#### 方法論的根拠

* **Zhang, H., Babar, M.A., & Tell, P. (2011).** "Identifying relevant studies in software engineering." *Information and Software Technology*, 53(6), 625–637.
  https://doi.org/10.1016/j.infsof.2010.12.010
  — QGS の概念を定式化し、quasi-sensitivity による検索文字列の評価手順を提案した原典。閾値 70〜80% を推奨。

* **Napoleão, B.M., Felizardo, K.R., de Souza, É.F., & Vijaykumar, N.L. (2024).** "How good are my search strings? Reflections on using an existing review as a quasi-gold standard." *e-Informatica Software Engineering Journal*, 18(1), 240103.
  https://arxiv.org/abs/2402.11041
  — QGS のサイズだけでなく**多様性**が代表性に重要であること、既存サーベイの参照文献を QGS として利用する際の品質課題を整理。

#### QGS 構築手順

**Step 1: seed の母集団を作る**

既存サーベイ **3 本以上**の Reference 節から、デコンパイル関連の論文を抽出する。seedの出典を既存の二次研究に限定することで、選定の恣意性を排除する（Zhang et al. の方法 (c): "papers included in related secondary studies"）。

**単一サーベイへの依存を避けるため、複数の独立したソースから三角測量（triangulation）する。**
Napoleão et al. (2024) は「QGS の品質はソースとなるサーベイの品質に依存する」と指摘しており、この問題に対して以下の対策を取る。

##### ソースサーベイの選定基準

以下のすべてを満たすサーベイをソースとして使用する：
* **査読つきトップ会議またはジャーナル**に掲載されている
* **参照文献数が 30 本以上**ある（薄い概説は除外）
* **異なる著者グループ**による（同一ラボの複数サーベイでは独立性が不十分）

##### ソースサーベイの候補（トピックの偏りを相互補完する組み合わせ）

| ソースサーベイ | トピック偏り | 役割 |
|--------------|------------|------|
| Basque et al. (2024) | CFG構造化中心、最新 | 現代研究の網羅 |
| Caballero & Lin | 型推論/データフロー中心 | 型・変数回復の網羅 |
| 広めのバイナリ解析サーベイ（例: Ul Haq & Caballero, Binary Code Similarity 等） | 周辺領域含む | 境界領域の補完 |

→ 各サーベイのトピック偏りが**相互に補完**され、特定の箱（パイプライン段）に偏った QGS になることを防ぐ。

##### seed の出典数記録

各 seed 論文が何本のソースサーベイに引用されているかを記録し、信頼度の指標とする：

| 出典数 | 解釈 |
|--------|------|
| 2 本以上 | 信頼度高（複数の独立した研究者が重要と判断） |
| 1 本のみ | 含めるが、QGS 品質の注記に記録 |

##### 非サーベイの客観指標による補完

サーベイの品質問題を完全にバイパスするため、以下の客観指標も seed 選定に活用する：
* **被引用数**: Semantic Scholar / Google Scholar の被引用数上位論文
* **venue**: トップ 4 会議（IEEE S&P, USENIX Security, NDSS, CCS）採録のデコンパイル論文

→ サーベイに引用されていなくても、被引用数やvenue の権威で「入るべき論文」を補完できる

**Step 2: seed を層別に分割する**

Napoleão et al. の「多様性が重要」の知見に基づき、年代・トピックの偏りを避ける。

| 層 | 期間 | 例 | 目的 |
|----|------|-----|------|
| 古典層 | 〜1999 | Cifuentes (1994), Bowen & Breuer (1993), 初期構造化論文 | DB検索の構造的限界を測定 |
| 中間層 | 2000〜2016 | TIE (2011), Phoenix (2013), No More Gotos (2015) | Q1/Q2 のカバー率の主たる検証 |
| 現代層 | 2017〜 | DIRTY (2022), LLM4Decompile, Basque (2024) | 最新文献のカバー率検証 |

**Step 3: Q1/Q2 に流して quasi-sensitivity を計算する**

```
quasi-sensitivity = ヒットした seed 数 / seed 総数
```

* **受け入れ閾値: 80%**（Zhang et al. 推奨の 70〜80% の上限を採用）
* 層別の sensitivity も報告する（古典層のDB限界を正直に開示する）

**Step 4: 漏れ分析と対応**

漏れた seed について原因を分類し、対応を決定する：

| 漏れ原因 | 対応 |
|---------|------|
| DB にインデックスされていない（古典、博士論文等） | スノーボール（引用追跡）で補完。PRISMA フローの「その他の方法で特定」に計上 |
| 用語が異なる（title/abstract に Q1/Q2 のいずれのタームも含まない） | Q1/Q2 への語彙追加を検討 |
| Keywords のみでヒット（Springer 等で title/abstract に該当語なし） | DB 固有の問題として記録。スノーボールで補完 |

#### QGS の規模

* **目標: 15〜30 本**（古典 5〜10、中間 5〜10、現代 5〜10）
* seed リストは補足資料（Appendix / replication package）として公開し、再現可能性を担保する

#### 古典文献と SLR の整合性に関する方針

1960〜80 年代の古典文献は学術 DB への収録が不完全であり、DB 検索のみでは構造的に網羅できない。本サーベイではこれを隠さず、Method 節で以下のように報告する：

* DB 検索の感度を層別に報告し、古典層の限界を明示する
* 古典文献の補完は**引用追跡（前方・後方スノーボール）**で行い、PRISMA フロー図の「その他の方法で特定」として計上する
* IC/EC 基準は全年代で統一適用するため、SLR としての方法論的一貫性は保たれる
* 歴史パートの記述は代表選定（全件網羅を主張しない）であり、narrative review 的要素を含むことを明記する

### 1.5 未決（検索実施時に決める）

* QGS の seed 論文の**具体的な選定結果**と検証結果（Q1/Q2 のカバー率）
* 検索の停止条件、ログ粒度
* 補助 DB（NDSS / USENIX）の具体的な検索手順
* ※既存の検索ログ（screening/imports/）は LLM パート単体を想定した試行であり、参照用として保持

---

## ステップ2：統合（重複排除・コーパス化）

### 2.1 方針（確定）

* 複数ソースから集めた結果を **1つの統合コーパスに集約**して管理する。
* 同一論文が「歴史の節目」かつ「LLM対象」になり得るため、統合後は **複数ラベル（タグ）で管理する**（二重カウントではなく“同一レコードの複数タグ”）。

### 2.2 重複排除ルール（確定）

* **3段階で実施する**：
  1. **DOI照合**：DOIが一致するレコードを統合（最優先）
  2. **タイトル正規化照合**：DOIがない／異なる場合、タイトルを正規化して一致判定
  3. **著者名照合**：上記で漏れた重複を著者名ベースで確認・捕捉

### 2.3 タグ体系（確定）

* パイプライン基準で3軸の分類タグを定義（ステップ3.3参照）:
  * パイプライン段タグ（P1〜P9, P0-e2e）← 歴史パートの「箱」と直結
  * 手法タグ（M-rule〜M-na）← LLMパートの抽出に使用
  * 貢献種別タグ（C-method〜C-survey）
* 同一論文に複数タグ付与可能（二重カウントではなく複数ラベル管理）

---

## ステップ3：スクリーニング（含む/除外の判断）

### 3.1 方針（確定）

* 統合コーパスのスクリーニングは **「LLM必須」にしない**
  → 非LLMの古典も拾えることを優先。
* スクリーニング基準は **スコープベースのIC/ECを採用**（ステップ3.2参照）
  → v2までのML/DL必須条件を撤廃し、デコンパイルのスコープに基づいて判定する。
  → パイプライン（P1–P9）はスクリーニング後の分類タグとしてのみ使用。

### 3.2 スクリーニング基準

#### スコープ

本サーベイはデコンパイルを対象とする。すなわち、コンパイル済みソフトウェアバイナリから高水準のソースコード表現を再構成する研究、およびその再構成を構成する要素技術とデコンパイラ出力の評価を含む。

> **設計意図**: スクリーニング基準はパイプライン（P1–P9）に依存しない。パイプラインはスクリーニング後の分類タグとして使用するが、採否判定そのものには用いない。これにより、自ら定義した分類枠組みが検索・スクリーニングの結果を規定する循環（self-fulfilling taxonomy）を回避する。

#### 採択条件（Inclusion Criteria — すべて満たす）

| | 条件 |
|---|---|
| **IC1** | デコンパイルまたはその構成要素技術（逆アセンブル、IR変換、制御構造回復、型回復、シンボル回復等）を、ソフトウェアバイナリを対象として扱っている。 |
| **IC2** | 手法の提案、評価枠組みの提案、ツール・基盤の設計、実証的調査、または体系的な分類・整理のいずれかで技術的貢献を行っている。 |
| **IC3** | 全文がアクセス可能であり、英語で記述されている。 |

> **IC1の補足**: 「構成要素技術」の列挙は例示であり限定列挙ではない。デコンパイルの過程で失われた情報（制御構造、型、シンボル等）の回復に寄与する技術であれば該当する。「ソフトウェアバイナリを対象として」は、入力がネイティブバイナリ（ELF, PE, Mach-O等）またはバイトコード（JVM, .NET等）であることを意味し、ソースコードやハードウェア記述のみを対象とする研究を除外する。
>
> **IC2の補足**: 技術的貢献の種別は、スクリーニング後の分類タグ（C-method / C-eval / C-infra / C-empirical / C-survey）に対応する。IC2は「貢献がある」ことを求めるのみで、貢献の種別によって採否を分けない。

#### 除外条件（Exclusion Criteria — いずれか該当で除外）

| | 条件 | 典型例 |
|---|---|---|
| **EC1** | デコンパイラ出力を下流タスクの入力として利用するのみで、デコンパイル自体の改善には貢献しない。 | デコンパイル結果を用いた脆弱性検出、マルウェア分類、バイナリコード類似度検索。 |
| **EC2** | ソフトウェアバイナリのデコンパイルとは本質的に異なる対象を扱っている。 | 量子回路の逆変換、ハードウェア記述言語の合成逆変換、3Dモデルの分解、「decompilation」の比喩的用法。 |
| **EC3** | 技術的内容が不十分である。 | ポスター、1–2頁のデモ論文、エディトリアル。ただし博士論文・テクニカルレポートは内容が十分であれば採択する。 |
| **EC4** | 同一研究のより完全なバージョンが存在する。 | 会議版と論文誌版がある場合、最も完全なもののみ採択。 |

> **EC1の境界判定**: 論文がデコンパイラ出力を利用しつつ、デコンパイル精度の向上にもフィードバックしている場合（例：脆弱性検出の過程で型推論を改善する手法を提案）はIC1–IC2を満たし採択対象となる。判断基準は「デコンパイル自体の改善に技術的貢献があるか」。
>
> **EC2の境界判定**: バイトコード（JVM, .NET, Dalvik等）のデコンパイルはIC1を満たす。WebAssemblyのデコンパイルも同様。一方、ソースコード間の変換（トランスパイル）はデコンパイルではなくEC2に該当する。

#### 補足

- コンパイラ理論（SSA構築等）のようにバイナリを対象としない文献はIC1を満たさずコーパス外とするが、サーベイ本文中で背景として引用することは可能。
- 手法の種類（ルールベース、形式的、統計的、ニューラル、LLM、ハイブリッド）による制限はない。手法種別はスクリーニング後の分類タグとして記録する。

### 3.3 分類タグ（採択後に付与、3軸）

* **軸1: パイプライン段**（P1-decode〜P9-eval, P0-e2e）
* **軸2: 手法**（M-rule / M-formal / M-stat / M-neural / M-llm / M-hybrid / M-na）
* **軸3: 貢献種別**（C-method / C-eval / C-infra / C-empirical / C-survey）

### 3.4 スクリーニングの信頼性担保（確定）

PRISMA #8（Study selection）への対応として、スクリーニングプロセスの信頼性を以下の方法で担保する。

#### レビュアー体制

* **単一レビュアー**（筆者）が全件をスクリーニングする
* 単一レビュアーであることは Method 節の **Limitations** に明記する

#### AIスクリーニングの精度検証

screening アプリの AI スクリーニング機能を活用するが、その精度を検証する：

1. AI スクリーニング完了後、**ランダムサンプル N 件**（目安: 50〜100件、または全体の10%のうち大きい方）を手動で再判定する
2. AI 判定と手動判定の**一致率（agreement rate）**を算出する
3. 一致率と不一致パターン（false positive / false negative の傾向）を Method 節で報告する
4. AI が uncertain と判定した論文は**全件手動で判定**する

#### 不一致時の解決

* 単一レビュアーのため reviewer 間不一致は発生しない
* AI と手動の不一致は、**手動判定を優先**する（AI は補助ツールとして位置づけ）
* 境界事例（IC1/EC1の判断が難しい論文）は別途リスト化し、判断根拠を記録する

### 3.5 PRISMA フロー図の数値記録（確定）

PRISMA 2020 フロー図に必要な数値を、各段階で記録する。

#### 記録する数値

```
[Identification]
  DB検索によるヒット数（DB別・クエリ別の内訳）
  その他の方法による特定数（スノーボール、手動追加）
    ↓
[重複排除]
  重複排除で除外された数
  スクリーニング対象数
    ↓
[Screening]
  title/abstract スクリーニングで除外された数（除外理由別: EC1/EC2/EC3/EC4）
  全文確認対象数
    ↓
[全文確認]
  全文確認で除外された数（除外理由別）
  全文取得不可で除外された数
    ↓
[Included]
  最終採択数
```

#### DB別・クエリ別の内訳記録

| DB | Q1 ヒット数 | Q2 ヒット数 | 検索日 |
|----|-----------|-----------|--------|
| ACM Digital Library | — | — | — |
| IEEE Xplore | — | — | — |
| Web of Science | — | — | — |
| arXiv | 125 | 11 | 2026-02-18 |
| Springer | 1,313 | 74 | 2026-02-18 |
| NDSS (S2) | — | — | — |
| USENIX (S2) | — | — | — |

→ 検索完了時に埋める。この表が PRISMA フロー図の「Identification」セクションの根拠となる。

### 3.6 旧未決事項の解決状況

* ~~v8をどう一般化するか~~ → スコープベースのIC/ECに転換し解決
* ~~統合スコープの境界（disassembly/liftingのみ等）~~ → IC1の「構成要素技術」として採択対象に含めることで解決
* ~~パイプライン依存の循環問題~~ → スクリーニング基準からパイプラインを分離し、分類タグとしてのみ使用することで解決

---

## ステップ3.5：データ抽出（採択論文からの情報収集）

### 3.5.1 方針（確定）

採択された各論文から、分類タグ（3軸）に加えて**データ抽出フォーム**に基づいて情報を収集する。
抽出結果は replication package として公開する（PRISMA #25 Data availability）。

### 3.5.2 データ抽出フォーム（確定）

#### 基本メタデータ（全論文共通）

| 抽出項目 | 説明 |
|---------|------|
| 著者 | 全著者名 |
| 年 | 出版年 |
| Venue | 会議名 / ジャーナル名 |
| DOI | — |
| 論文種別 | 会議論文 / ジャーナル / プレプリント / 博士論文 / テクニカルレポート |

#### 分類タグ（3軸、ステップ3.3で定義済み）

| 抽出項目 | 値 |
|---------|-----|
| パイプライン段 | P1〜P9, P0-e2e（複数可） |
| 手法 | M-rule / M-formal / M-stat / M-neural / M-llm / M-hybrid / M-na（複数可） |
| 貢献種別 | C-method / C-eval / C-infra / C-empirical / C-survey（複数可） |

#### 技術的属性

| 抽出項目 | 説明 | 値の例 |
|---------|------|--------|
| 対象バイナリ種別 | 入力の形式 | native (ELF/PE/Mach-O) / bytecode (JVM/.NET/Dalvik) / WebAssembly / firmware / 複数 |
| 対象アーキテクチャ | ISA | x86 / x86-64 / ARM / MIPS / RISC-V / JVM / 複数 / アーキ非依存 |
| 入力レベル | 手法への入力 | raw binary / disassembly / IR / decompiler output |
| 出力レベル | 手法の出力 | C / AST / IR / type annotation / variable name / control structure / その他 |

#### 評価関連

| 抽出項目 | 説明 | 値の例 |
|---------|------|--------|
| 評価指標 | 使用された評価指標 | correctness / BLEU / edit distance / readability / compilation rate / その他 |
| データセット / ベンチマーク | 使用されたデータセット名 | coreutils / SPEC / BinaryCorp / AnghaBench / 自作 / その他 |
| 比較対象 | 既存手法との比較有無 | あり（手法名） / なし |
| コード公開 | 実装・ツールの公開有無 | あり（URL） / なし |

### 3.5.3 抽出の実施方法

* 全文を確認し、上記フォームに基づいて情報を抽出する
* 情報が明示されていない項目は「記載なし」と記録する
* 抽出結果は CSV 形式で管理し、replication package に含める

### 3.5.4 公開方法

| 公開場所 | 内容 |
|---------|------|
| 論文本文 | サマリー表（年代分布、パイプライン段×手法のクロス集計、venue分布等） |
| 補足資料（Appendix / replication package） | 全論文の抽出データ一覧（CSV） |

→ GitHub リポジトリまたは Zenodo にて公開し、DOI を付与する

---

## ステップ4：まとめ方（歴史とLLMでの扱い分け）

### 4.1 LLMパートの扱い（確定）

* **LLM関連は原則すべて扱う**（網羅性重視で分類・整理する）

### 4.2 歴史パートの扱い（確定）

* 収集段階では統合コーパスの一部として **同じ粒度で拾う**
* 記述段階では **代表（節目）を選んで説明**する（全件を個別解説しない）

### 4.3 未決

* 「代表」の決め方（選定基準・採択数）
* ~~歴史の分類軸（例：8コンポーネント）をどこまで本文で使うか~~ → パイプライン9段をそのまま分類軸・歴史パートの「箱」として使用する方針で確定

---

## ステップ5：検討事項として保持（いまは決めない）

* **史実台帳（Tier運用）を採用するか**
  （ツール史・公開年など“史実”の根拠管理方法。現時点では検討事項。）

---

次は **2/3：歴史パートの詳細方針（同じくステップ順）** を出します。
