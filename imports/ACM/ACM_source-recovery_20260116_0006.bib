@article{10.1145/3729373,
author = {Su, Xing and Liang, Hanzhong and Wu, Hao and Niu, Ben and Xu, Fengyuan and Zhong, Sheng},
title = {DiSCo: Towards Decompiling EVM Bytecode to Source Code using Large Language Models},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {FSE},
url = {https://doi.org/10.1145/3729373},
doi = {10.1145/3729373},
abstract = {Understanding the Ethereum smart contract bytecode is essential for ensuring cryptoeconomics security. However, existing decompilers primarily convert bytecode into pseudocode, which is not easily comprehensible for general users, potentially leading to misunderstanding of contract behavior and increased vulnerability to scams or exploits. In this paper, we propose DiSCo, the first LLMs-based EVM decompilation pipeline, which aims to enable LLMs to understand the opaque bytecode and lift it into smart contract code. DiSCo introduces three core technologies. First, a logic-invariant intermediate representation is proposed to reproject the low-level bytecode into high-level abstracted units. The second technique involves semantic enhancement based on a novel type-aware graph model to infer stripped variables during compilation, enhancing the lifting effect. The third technology is a flexible method incorporating code specifications to construct LLM-comprehensible prompts for source code generation. Extensive experiments illustrate that our generated code guarantees a high compilability rate at 75%, with differential fuzzing pass rate averaging at 50%. Manual validation results further indicate that the generated solidity contracts significantly outperforms baseline methods in tasks such as code comprehension and attack reproduction.},
journal = {Proc. ACM Softw. Eng.},
month = jun,
articleno = {FSE103},
numpages = {24},
keywords = {Decompilation, EVM bytecode, Large Language Models, Smart Contract, Source Code Generation}
}

@inproceedings{10.1145/3711896.3737229,
author = {Zhao, Tong and Liu, Yozen and Kolodner, Matthew and Montemayor, Kyle and Ghazizadeh, Elham and Batra, Ankit and Fan, Zihao and Gao, Xiaobin and Guo, Xuan and Ren, Jiwen and Park, Serim and Yu, Peicheng and Yu, Jun and Vij, Shubham and Shah, Neil},
title = {GiGL: Large-Scale Graph Neural Networks at Snapchat},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737229},
doi = {10.1145/3711896.3737229},
abstract = {Recent advances in graph machine learning (ML) with the introduction of Graph Neural Networks (GNNs) have led to a widespread interest in applying these approaches to business applications at scale. GNNs enable differentiable end-to-end (E2E) learning of model parameters given graph structure which enables optimization towards popular node, edge (link) and graph-level tasks. While the research innovation in new GNN layers and training strategies has been rapid, industrial adoption and utility of GNNs has lagged considerably due to the unique scale challenges that large-scale graph ML problems create. In this work, we share our approach to training, inference, and utilization of GNNs at Snapchat. To this end, we present GiGL (Gigantic Graph Learning), an open-source library to enable large-scale distributed graph ML to the benefit of researchers, ML engineers, and practitioners. We use GiGL internally at Snapchat to manage the heavy lifting of GNN workflows, including graph data preprocessing from relational DBs, subgraph sampling, distributed training, inference, and orchestration. GiGL is designed to interface cleanly with open-source GNN modeling libraries prominent in academia like PyTorch Geometric (PyG), while handling scaling and productionization challenges that make it easier for internal practitioners to focus on modeling. GiGL is used in multiple production settings, and has powered over 35 launches across multiple business domains in the last 2 years in the contexts of friend recommendation, content recommendation and advertising. This work details high-level design and tools the library provides, scaling properties, case studies in diverse business settings with large-scale graphs up to hundreds of millions of nodes, tens of billions of edges, and hundreds of node and edge features, and several key lessons learned in employing graph ML at scale on large social data. GiGL is open-sourced at https://github.com/Snapchat/GiGL.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {5225–5236},
numpages = {12},
keywords = {distributed machine learning, graph machine learning, graph neural networks, large scale machine learning},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@article{10.1145/3658135,
author = {Han, Yushan and Chen, Yizhou and Ong, Carmichael and Chen, Jingyu and Hicks, Jennifer and Teran, Joseph},
title = {A Neural Network Model for Efficient Musculoskeletal-Driven Skin Deformation},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3658135},
doi = {10.1145/3658135},
abstract = {We present a comprehensive neural network to model the deformation of human soft tissues including muscle, tendon, fat and skin. Our approach provides kinematic and active correctives to linear blend skinning [Magnenat-Thalmann et al. 1989] that enhance the realism of soft tissue deformation at modest computational cost. Our network accounts for deformations induced by changes in the underlying skeletal joint state as well as the active contractile state of relevant muscles. Training is done to approximate quasistatic equilibria produced from physics-based simulation of hyperelastic soft tissues in close contact. We use a layered approach to equilibrium data generation where deformation of muscle is computed first, followed by an inner skin/fascia layer, and lastly a fat layer between the fascia and outer skin. We show that a simple network model which decouples the dependence on skeletal kinematics and muscle activation state can produce compelling behaviors with modest training data burden. Active contraction of muscles is estimated using inverse dynamics where muscle moment arms are accurately predicted using the neural network to model kinematic musculotendon geometry. Results demonstrate the ability to accurately replicate compelling musculoskeletal and skin deformation behaviors over a representative range of motions, including the effects of added weights in body building motions.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {118},
numpages = {12},
keywords = {human body simulation, muscle simulation, biomechanical model}
}

@inproceedings{10.1145/3589334.3645352,
author = {Hu, Sihao and Huang, Tiansheng and Chow, Ka-Ho and Wei, Wenqi and Wu, Yanzhao and Liu, Ling},
title = {ZipZap: Efficient Training of Language Models for Large-Scale Fraud Detection on Blockchain},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645352},
doi = {10.1145/3589334.3645352},
abstract = {Language models (LMs) have demonstrated superior performance in detecting fraudulent activities on Blockchains. Nonetheless, the sheer volume of Blockchain data results in excessive memory and computational costs when training LMs from scratch, limiting their capabilities to large-scale applications. In this paper, we present ZipZap, a framework tailored to achieve both parameter and computational efficiency when training LMs on large-scale transaction data. First, with the frequency-aware compression, an LM can be compressed down to a mere 7.5% of its initial size with an imperceptible performance dip. This technique correlates the embedding dimension of an address with its occurrence frequency in the dataset, motivated by the observation that embeddings of low-frequency addresses are insufficiently trained and thus negating the need for a uniformly large dimension for knowledge representation. Second, ZipZap accelerates the speed through the asymmetric training paradigm: It performs transaction dropping and cross-layer parameter-sharing to expedite the pre-training process, while revert to the standard training paradigm for fine-tuning to strike a balance between efficiency and efficacy, motivated by the observation that the optimization goals of pre-training and fine-tuning are inconsistent. Evaluations on real-world, large-scale datasets demonstrate that ZipZap delivers notable parameter and computational efficiency improvements for training LMs. Our implementation is available at: https://github.com/git-disl/ZipZap.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2807–2816},
numpages = {10},
keywords = {blockchain, computational efficient, ethereum, language models, parameter-efficient},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3732945.3732958,
author = {Li, Fei and Zhang, Xu and Peng, Ruping and Zhou, Yihan and Wei, Yulan and Zhang, Qingzhu},
title = {Control Method of Cam Jacking Transfer Machine based on BP Neural Network},
year = {2025},
isbn = {9798400715204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3732945.3732958},
doi = {10.1145/3732945.3732958},
abstract = {The cam jacking transfer machine achieves stable transmission and vertical diversion of items simultaneously through the rotation of the cam. In this operation process, rapidly determining the object's position and controlling the cam's rotation are critical steps. In this paper, a control method based on a BP neural network is designed for the cam jacking transfer machine, and simulations are conducted. The simulation results indicate that the BP neural network model can accurately determine the positional state of the items and effectively capture the complex nonlinear relationships between the input features and the items states during the training process, enabling efficient and accurate transmission and vertical diversion of the items.},
booktitle = {Proceedings of the 2025 4th International Conference on Intelligent Systems, Communications and Computer Networks},
pages = {91–96},
numpages = {6},
keywords = {BP Neural Network, Cam Jacking, Transfer Machine, Vertical Shunts},
location = {
},
series = {ISCCN '25}
}

@inproceedings{10.1145/3762249.3762267,
author = {Wang, Jia and Shafie, Nur Aima and Kasim, Eley Suzana},
title = {Research on the Construction of Supply Chain Financial Credit Risk Management Model Based on Machine Learning},
year = {2025},
isbn = {9798400713491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3762249.3762267},
doi = {10.1145/3762249.3762267},
abstract = {With the diversification of global trade and the complexity of supply chain network, supply chain finance, as a new financial service model, is facing a high degree of credit risk while promoting the coordinated development of industrial chain. However, the traditional credit risk management methods mostly rely on limited data information and a single evaluation mechanism, which is difficult to adapt to the rapidly changing market environment. In view of this situation, this paper will comprehensively analyze the application feasibility of machine learning technology in this field, and propose a brand-new supply chain financial credit risk management model to improve the level of supply chain financial credit risk management. Practice has proved that the whole model is based on support vector machine (SVM), and the LightGBM machine learning algorithm is integrated into it through ensemble learning, so as to achieve the purpose of improving the complexity of the model, thus improving the accuracy and execution efficiency of the risk prediction model and providing strong technical support for the steady development of supply chain finance.},
booktitle = {Proceedings of the 2025 2nd International Conference on Digital Economy, Blockchain and Artificial Intelligence},
pages = {101–105},
numpages = {5},
keywords = {credit risk management model, ensemble learning, machine learning, supply chain finance},
location = {
},
series = {DEBAI '25}
}

@article{10.1145/3603618,
author = {Zheng, Ce and Wu, Wenhan and Chen, Chen and Yang, Taojiannan and Zhu, Sijie and Shen, Ju and Kehtarnavaz, Nasser and Shah, Mubarak},
title = {Deep Learning-based Human Pose Estimation: A Survey},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3603618},
doi = {10.1145/3603618},
abstract = {Human pose estimation aims to locate the human body parts and build human body representation (e.g., body skeleton) from input data such as images and videos. It has drawn increasing attention during the past decade and has been utilized in a wide range of applications including human-computer interaction, motion analysis, augmented reality, and virtual reality. Although the recently developed deep learning-based solutions have achieved high performance in human pose estimation, there still remain challenges due to insufficient training data, depth ambiguities, and occlusion. The goal of this survey article is to provide a comprehensive review of recent deep learning-based solutions for both 2D and 3D pose estimation via a systematic analysis and comparison of these solutions based on their input data and inference procedures. More than 260 research papers since 2014 are covered in this survey. Furthermore, 2D and 3D human pose estimation datasets and evaluation metrics are included. Quantitative performance comparisons of the reviewed methods on popular datasets are summarized and discussed. Finally, the challenges involved, applications, and future research directions are concluded. A regularly updated project page is provided: .},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {11},
numpages = {37},
keywords = {pose estimation metrics, pose estimation datasets, deep learning-based pose estimation, 2D and 3D pose estimation, Survey of human pose estimation}
}

@inproceedings{10.1145/3644116.3644195,
author = {Wang, Qihang and Yang, Hao and Zhang, Jun and Jiang, Tianyun and Tian, Peng and Yu, Kang and Dai, Zhiwei and Wu, Shuang and Gao, Junhong and Yu, Xiaochun and Zhang, Haiying and Wang, Yunfeng},
title = {Research on Acupuncture Technique Recognition Technology Based on Deep Learning Algorithms},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644195},
doi = {10.1145/3644116.3644195},
abstract = {Combining deep learning-based methods and key posture sensor data can improve the accuracy of automatically identifying basic acupuncture techniques. This study aims to propose a novel deep learning-based method to identify the time characteristics of the physical parameters of acupuncture techniques, including twisting-supplementing (TS), twisting-draining (TD), level-supplementing level-draining (LSLD), lifting-inserting-supplementing (LIS), and lifting-inserting-draining (LID) methods. During the acupuncture process, six-axis posture sensors collect parameters such as lifting and inserting speed, twisting frequency, and angular rotation rate, and analyze the mapping relationship between physical parameters and different techniques. By using multi-dimensional signal control decision algorithms, the performance of our method is enhanced, addressing the issue of poor recognition based on single-dimensional signals. Experimental results demonstrate that our method achieves high accuracy in identifying five techniques. Our proposed method can effectively identify acupuncture techniques, making it useful for the evaluation and teaching of acupuncture techniques, facilitating the inheritance of traditional Chinese acupuncture techniques.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {481–487},
numpages = {7},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@inbook{10.1145/3773365.3773576,
author = {Li, Xiang},
title = {Construction of Carbon Emission Prediction Model in Materialization Stage of Construction Engineering Based on BIM and Machine Learning},
year = {2025},
isbn = {9798400718748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3773365.3773576},
abstract = {Under the background of “dual carbon goals”, the materialization stage of construction engineering, as the key link of carbon emission management in the whole life cycle, is directly related to the low-carbon transformation of construction industry. However, in the practical application stage, the traditional carbon emission prediction method mainly relies on the bill of quantities multiplied by static carbon emission factors, which has some problems such as difficult data acquisition, low prediction accuracy and poor project adaptability, and can not meet the actual needs of the construction industry. In this regard, this paper will deeply study the application feasibility of machine learning technology in this field, and build a brand-new carbon emission prediction model in the materialization stage of building engineering by combining the building information model (BIM) technology, aiming at improving the accuracy of prediction results and strengthening the adaptability to multiple complex scenarios. Experiments show that on the one hand, the overall model establishes the relationship between BIM model and carbon emission factors to solve the problem of data acquisition; on the other hand, the model uses extreme gradient lifting algorithm (XGBoost) to analyze the relationship between the materialization stage of mining and carbon emission, so as to realize the accurate prediction of carbon emission in the materialization stage of construction projects, and then provide decision support for carbon emission management of construction projects.},
booktitle = {Proceedings of the 2025 8th International Conference on Computer Information Science and Artificial Intelligence},
pages = {1337–1342},
numpages = {6}
}

@inproceedings{10.1145/3745676.3745703,
author = {Sun, Yuming and Yuan, Xiaofang},
title = {An investigation and prediction of work-related Musculoskeletal disorders based on machine learning among coal miners in Western China},
year = {2025},
isbn = {9798400715150},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3745676.3745703},
doi = {10.1145/3745676.3745703},
abstract = {Objective: Studies form industrialized show that work-related musculoskeletal disorders (WMSDs) occur commonly in workers. This study aimed to investigate the prevalence of WMSDs and associated risk factors among coal miners in Western China. Moreover, it constructs a model based on the analysis to predict the possible level of musculoskeletal damage in miners.Methods: A cross-sectional survey was conducted with 2297 coal miners from 6 selected coal mines in western China. Work-related musculoskeletal disorders (using the Nordic musculature questionnaire) and research factors were recorded. Analysis of variance is used to identify the difference between work type groups. Correlation analysis is used to quantify associations between research factors and WMSDs. XGboost is applied for predicting the possible level of musculoskeletal damage in miners based on survey data. By comparing it to any other methods, it shows better performance on forecast.Results: There was 80.4% participation rate (1846 valid samples). Variance analysis shows that there were differences among the different work type groups on lower back, knees and shoulders. The correlation analysis shows that neck, shoulders, lower back, thighs, knees and ankles pain are positively correlated with ages and working age. Only upper back and ankles pain are negatively correlated with income level. Every body sites are positively correlated with injury time. Shoulders, lower back, hands, knees and ankles pain are negatively correlated with education. The XGboost method is excellent at learning patterns from the information in questionnaire data to enable prediction of the degree of musculoskeletal damage in miners (with 80.8% accuracy).Conclusions: It finds that the relationship between WMSDs and occupational factors in research. This study provides more information related to WMSDs in coal miners. The model provides a reference for predicting and controlling the prevalence of WMSDs among coal miners.},
booktitle = {Proceedings of the 2025 2nd International Conference on Innovation Management and Information System},
pages = {179–186},
numpages = {8},
keywords = {Coal miners, Machine learning, Western China, Work-related Musculoskeletal disorders (WMSDs)},
location = {
},
series = {ICIIS '25}
}

@inproceedings{10.1145/3544109.3544996,
author = {Qiu, Hehua},
title = {Path Planning Algorithm of English Retrieval based on Associative Memory Neural Network},
year = {2022},
isbn = {9781450395786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544109.3544996},
doi = {10.1145/3544109.3544996},
abstract = {English collocation retrieval is to extract the phrases or idioms combined with various grammatical relations from the corpus, which is used to systematically analyze and study the collocations of words. In the absence of such corpus retrieval tools, English teachers mainly use the traditional method of definition and description to identify and analyze synonyms. In order to further enrich the English vocabulary of English learners, combined with the related algorithms of similarity, this paper proposes an English retrieval path planning algorithm based on associative memory neural network. The algorithm implements a search mechanism that uses the adjacency list data structure and restricts the search area to reasonably limit the search area of the algorithm. The BP algorithm based on the associative memory neural network model greatly reduces the network training times of the sample variable system. The system effectively reduces the network training time of the sample variable system, and provides the algorithm basis for the BP algorithm to be applied to occasions with high real-time requirements. Combined with the practical application of the path planning algorithm in the English retrieval system, through the hierarchical scheduling of tasks of different importance, a satisfactory decision result is obtained. The algorithm has the advantages of small search space and fast solution speed. Simulation results verify the effectiveness of the algorithm.},
booktitle = {Proceedings of the 3rd Asia-Pacific Conference on Image Processing, Electronics and Computers},
pages = {1049–1054},
numpages = {6},
location = {Dalian, China},
series = {IPEC '22}
}

@article{10.1145/3524497,
author = {Liu, Wu and Bao, Qian and Sun, Yu and Mei, Tao},
title = {Recent Advances of Monocular 2D and 3D Human Pose Estimation: A Deep Learning Perspective},
year = {2022},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3524497},
doi = {10.1145/3524497},
abstract = {Estimation of the human pose from a monocular camera has been an emerging research topic in the computer vision community with many applications. Recently, benefiting from the deep learning technologies, a significant amount of research efforts have advanced the monocular human pose estimation both in 2D and 3D areas. Although there have been some works to summarize different approaches, it still remains challenging for researchers to have an in-depth view of how these approaches work from 2D to 3D. In this article, we provide a comprehensive and holistic 2D-to-3D perspective to tackle this problem. First, we comprehensively summarize the 2D and 3D representations of human body. Then, we summarize the mainstream and milestone approaches for these human body presentations since the year 2014 under unified frameworks. Especially, we provide insightful analyses for the intrinsic connections and methods evolution from 2D to 3D pose estimation. Furthermore, we analyze the solutions for challenging cases, such as the lack of data, the inherent ambiguity between 2D and 3D, and the complex multi-person scenarios. Next, we summarize the benchmarks, evaluation metrics, and the quantitative performance of popular approaches. Finally, we discuss the challenges and give deep thinking of promising directions for future research. We believe this survey will provide the readers (researchers, engineers, developers, etc.) with a deep and insightful understanding of monocular human pose estimation.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {80},
numpages = {41},
keywords = {monocular images, 2D and 3D pose, deep learning, Human pose estimation}
}

@inproceedings{10.1145/3442536.3442549,
author = {Wei, Yuan and Zhang, Wei and Gu, Feng},
title = {Towards Diagnosis of Carpal Tunnel Syndrome Using Machine Learning},
year = {2021},
isbn = {9781450388832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442536.3442549},
doi = {10.1145/3442536.3442549},
abstract = {Carpal Tunnel Syndrome (CTS) is the most common peripheral neuropathy affecting the hand function. Although the most complains from patients with CTS are fine motor control failures in daily manual activities, parameters of hand functional control have not been considered neither in current diagnostic nor evaluation process. In addition, CTS has been identified as an occupational disease. Over 50% of reported CTS cases are work related. However, early screening protocols of CTS at a preliminary stage are absent, and thus unable to prevent further complications, especially for high-risk populations who can advance their CTS stage on daily work basis. In the current protocol, we aim to identify important parameters of hand functional control that are indicative of CTS clinical occurrence and severity stages. Based on designed experiments during hand grasping, we performed machine learning classifiers to detect, filter and subtract important biomarkers or groups of biomarkers that dominantly classify the CTS hand and its severity. The identified biomarkers not only provide a high potential of a paradigm shift in CTS management, but also are able to shed light on hand functional evaluations associated with this neuropathy. In this paper, we adopt one of machine learning approaches, random forests, to the raw experimental hand function gripping data to identify the most important biomarkers for CTS. The experimental results show the effectiveness of the proposed work.},
booktitle = {Proceedings of the 2020 3rd Artificial Intelligence and Cloud Computing Conference},
pages = {76–82},
numpages = {7},
keywords = {Small-sized data sample, Random forests, Grasping control, Classification, Carpal tunnel syndrome},
location = {Kyoto, Japan},
series = {AICCC '20}
}

@inproceedings{10.1145/3597503.3639100,
author = {Jiang, Ling and An, Junwen and Huang, Huihui and Tang, Qiyi and Nie, Sen and Wu, Shi and Zhang, Yuqun},
title = {BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639100},
doi = {10.1145/3597503.3639100},
abstract = {While third-party libraries (TPLs) are extensively reused to enhance productivity during software development, they can also introduce potential security risks such as vulnerability propagation. Software composition analysis (SCA), proposed to identify reused TPLs for reducing such risks, has become an essential procedure within modern DevSecOps. As one of the mainstream SCA techniques, binary-to-source SCA identifies the third-party source projects contained in binary files via binary source code matching, which is a major challenge in reverse engineering since binary and source code exhibit substantial disparities after compilation. The existing binary-to-source SCA techniques leverage basic syntactic features that suffer from redundancy and lack robustness in the large-scale TPL dataset, leading to inevitable false positives and compromised recall. To mitigate these limitations, we introduce BinaryAI, a novel binary-to-source SCA technique with two-phase binary source code matching to capture both syntactic and semantic code features. First, BinaryAI trains a transformer-based model to produce function-level embeddings and obtain similar source functions for each binary function accordingly. Then by applying the link-time locality to facilitate function matching, BinaryAI detects the reused TPLs based on the ratio of matched source functions. Our experimental results demonstrate the superior performance of BinaryAI in terms of binary source code matching and the downstream SCA task. Specifically, our embedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving 22.54% recall@1 and 0.34 MRR compared with 10.75% and 0.17 respectively. Additionally, BinaryAI outperforms all existing binary-to-source SCA tools in TPL detection, increasing the precision from 73.36% to 85.84% and recall from 59.81% to 64.98% compared with the well-recognized commercial SCA product Black Duck.https://www.binaryai.net},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {224},
numpages = {13},
keywords = {software composition analysis, static binary analysis},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3508398.3511503,
author = {Asvadishirehjini, Aref and Kantarcioglu, Murat and Malin, Bradley},
title = {GINN: Fast GPU-TEE Based Integrity for Neural Network Training},
year = {2022},
isbn = {9781450392204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3508398.3511503},
doi = {10.1145/3508398.3511503},
abstract = {Machine learning models based on Deep Neural Networks (DNNs) are increasingly deployed in a wide variety of applications, ranging from self-driving cars to COVID-19 diagnosis. To support the computational power necessary to train a DNN, cloud environments with dedicated Graphical Processing Unit (GPU) hardware support have emerged as critical infrastructure. However, there are many integrity challenges associated with outsourcing the computation to use GPU power, due to its inherent lack of safeguards to ensure computational integrity. Various approaches have been developed to address these challenges, building on trusted execution environments (TEE). Yet, no existing approach scales up to support realistic integrity-preserving DNN model training for heavy workloads (e.g., deep architectures and millions of training examples) without sustaining a significant performance hit. To mitigate the running time difference between pure TEE (i.e., full integrity) and pure GPU (i.e., no integrity) , we combine random verification of selected computation steps with systematic adjustments of DNN hyperparameters (e.g., a narrow gradient clipping range), which limits the attacker's ability to shift the model parameters arbitrarily. Experimental analysis shows that the new approach can achieve a 2X to 20X performance improvement over a pure TEE-based solution while guaranteeing an extremely high probability of integrity (e.g., 0.999) with respect to state-of-the-art DNN backdoor attacks.},
booktitle = {Proceedings of the Twelfth ACM Conference on Data and Application Security and Privacy},
pages = {4–15},
numpages = {12},
keywords = {trusted exexution environments, intel sgx, integrity preserving deep learning training, deep learning},
location = {Baltimore, MD, USA},
series = {CODASPY '22}
}

@inproceedings{10.1145/3611643.3616343,
author = {Zhao, Kunsong and Li, Zihao and Li, Jianfeng and Ye, He and Luo, Xiapu and Chen, Ting},
title = {DeepInfer: Deep Type Inference from Smart Contract Bytecode},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616343},
doi = {10.1145/3611643.3616343},
abstract = {Smart contracts play an increasingly important role in Ethereum platform. It provides various functions implementing numerous services, whose bytecode runs on Ethereum Virtual Machine. To use services by invoking corresponding functions, the callers need to know the function signatures. Moreover, such signatures provide crucial information for many downstream applications, e.g., identifying smart contracts, fuzzing, detecting vulnerabilities, etc. However, it is challenging to infer function signatures from the bytecode due to a lack of type information. Existing work solving this problem depended heavily on limited databases or hard-coded heuristic patterns. However, these approaches are hard to be adapted to semantic differences in distinct languages and various compiler versions when developing smart contracts. In this paper, we propose a novel framework DeepInfer that first leverages deep learning techniques to automatically infer function signatures and returns. The novelties of DeepInfer are: 1) DeepInfer lifts the bytecode into the Intermediate Representation (IR) to preserve code semantics; 2) DeepInfer extracts the type-related knowledge (e.g., critical data flows, constant values, and control flow graphs) from the IR to recover function signatures and returns. We conduct experiments on Solidity and Vyper smart contracts and the results show that DeepInfer performs faster and more accurate than existing tools, while being immune to changes in different languages and various compiler versions.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {745–757},
numpages = {13},
keywords = {Deep Learning, Smart Contract, Type Inference},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3759425.3763397,
author = {Chen, Xiang and Zhou, Anshunkang and Ye, Chengfeng and Zhang, Charles},
title = {ClearAgent: Agentic Binary Analysis for Effective Vulnerability Detection},
year = {2025},
isbn = {9798400721489},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3759425.3763397},
doi = {10.1145/3759425.3763397},
abstract = {Statically detecting vulnerabilities at the binary level is crucial for the security of Commercial-Off-The-Shelf (COTS) software when source code is not available. However, traditional methods suffer from the inherent limitations of binary translation and static analysis, which hinder their scalability for complex real-world binaries. Recent efforts that leverage Large Language Models (LLMs) for vulnerability detection are still limited by possible hallucination, inaccurate code property retrieval, and insufficient guidance.    In this paper, we propose a new agentic binary analysis framework ClearAgent, which features a novel binary interface that provides both LLM-friendly and analyzer-friendly tools to facilitate effective understanding of binary code semantics with rich context. ClearAgent works by automatically interacting with the interface and iteratively exploring for buggy binary code. For candidate bug reports, ClearAgent further tries to verify the existence of the vulnerability by constructing concrete inputs that can trigger the buggy locations.},
booktitle = {Proceedings of the 1st ACM SIGPLAN International Workshop on Language Models and Programming Languages},
pages = {130–137},
numpages = {8},
keywords = {Agent, Binary Analysis, Vulnerability Detection},
location = {Singapore, Singapore},
series = {LMPL '25}
}

@inproceedings{10.1145/3713081.3731728,
author = {Zhou, Li and Dacier, Marc and Konstantinou, Charalambos},
title = {ReGraph: A Tool for Binary Similarity Identification},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731728},
doi = {10.1145/3713081.3731728},
abstract = {Binary Code Similarity Detection (BCSD) is not only essential for security tasks such as vulnerability identification but also for code copying detection, yet it remains challenging due to binary stripping and diverse compilation environments. Existing methods tend to adopt increasingly complex neural networks for better accuracy performance. The computation time increases with the complexity. Even with powerful GPUs, the treatment of large-scale software becomes time-consuming. To address these issues, we present a framework called ReGraph to efficiently compare binary code functions across architectures and optimization levels. Our evaluation with public datasets highlights that ReGraph exhibits a significant speed advantage, performing 700 times faster than Natural Language Processing (NLP)-based methods while maintaining comparable accuracy results with respect to the state-of-the-art models.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {6–10},
numpages = {5},
keywords = {binary code similarity detection, code property graph, graph neural network, code lifting, binary code re-optimization},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@article{10.1145/3729330,
author = {Li, Yixuan and Magalh\~{a}es, Jos\'{e} Wesley de Souza and Brauckmann, Alexander and O'Boyle, Michael F. P. and Polgreen, Elizabeth},
title = {Guided Tensor Lifting},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {PLDI},
url = {https://doi.org/10.1145/3729330},
doi = {10.1145/3729330},
abstract = {Domain-specific languages (DSLs) for machine learning are revolutionizing the speed and efficiency of machine learning workloads as they enable users easy access to high-performance compiler optimizations and accelerators. However, to take advantage of these capabilities, a user must first translate their legacy code from the language it is currently written in, into the new DSL. The process of automatically lifting code into these DSLs has been identified by several recent works, which propose program synthesis as a solution. However, synthesis is expensive and struggles to scale without carefully designed and hard-wired heuristics. In this paper, we present an approach for lifting that combines an enumerative synthesis approach with a Large Language Model used to automatically learn the domain-specific heuristics for program lifting, in the form of a probabilistic grammar. Our approach outperforms the state-of-the-art tools in this area, despite only using learned heuristics.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {227},
numpages = {23},
keywords = {Code Generation, Code Optimization, Large Language Model, Lifting, Program Synthesis, Tensor Algebra}
}

@inproceedings{10.1145/3766882.3767171,
author = {Lamprou, Evangelos and Kalhauge, Christian Gram and Rinard, Martin C. and Vasilakis, Nikos},
title = {Guarding LLM-aided Software Transformation Tasks via Component Exoskeletons},
year = {2025},
isbn = {9798400722059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3766882.3767171},
doi = {10.1145/3766882.3767171},
abstract = {Large language models (LLMs) are achieving state-of-the-art results across a wide variety of software transformation tasks---including translating across languages and lifting opaque software components to high-level languages. Unfortunately, their results are often subtly incorrect, insecure, or underperformant---affecting the widespread deployment of these LLM-driven techniques in settings that go beyond the narrow scope of academic papers. This paper posits that such widespread deployment crucially depends on developing appropriate model guardrails for safeguarding the results of the transformation process. Such guardrails can be supported by component exoskeletons, tunable partial specifications extracted mostly automatically from the original, pre-transformed component. Exoskeletons serve as component projections that supplement, and often go through, the entire transformation process, confirming that the new, transformed component meets the original specifications. They show promise on several real-world scenarios and unearth exciting research directions.},
booktitle = {Proceedings of the 4th Workshop on Practical Adoption Challenges of ML for Systems},
pages = {13–18},
numpages = {6},
keywords = {component exoskeletons, large language models, software transformation},
location = {Seoul, Republic of Korea},
series = {PACMI '25}
}

@inproceedings{10.1145/3474369.3486865,
author = {Deshpande, Chinmay and Gens, David and Franz, Michael},
title = {StackBERT: Machine Learning Assisted Static Stack Frame Size Recovery on Stripped and Optimized Binaries},
year = {2021},
isbn = {9781450386579},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474369.3486865},
doi = {10.1145/3474369.3486865},
abstract = {The call stack represents one of the core abstractions that compiler-generated programs leverage to organize binary execution at runtime. For many use cases reasoning about stack accesses of binary functions is crucial: security-sensitive applications may require patching even after deployment, and binary instrumentation, rewriting, and lifting all necessitate detailed knowledge about the function frame layout of the affected program. As no comprehensive solution to the stack symbolization problem exists to date, existing approaches have to resort to workarounds like emulated stack environments, resulting in increased runtime overheads.In this paper we present StackBERT, a framework to statically reason about and reliably recover stack frame information of binary functions in stripped and highly optimized programs. The core idea behind our approach is to formulate binary analysis as a self-supervised learning problem by automatically generating ground truth data from a large corpus of open-source programs. We train a state-of-the-art Transformer model with self-attention and finetune for stack frame size prediction. We show that our finetuned model yields highly accurate estimates of a binary function's stack size from its function body alone across different instruction-set architectures, compiler toolchains, and optimization levels. We successfully verify the static estimates against runtime data through dynamic executions of standard benchmarks and additional studies, demonstrating that StackBERT's predictions generalize to 93.44% of stripped and highly optimized test binaries not seen during training. We envision these results to be useful for improving binary rewriting and lifting approaches in the future.},
booktitle = {Proceedings of the 14th ACM Workshop on Artificial Intelligence and Security},
pages = {85–95},
numpages = {11},
keywords = {binary lifting, machine learning, recompilation, stack symbolization},
location = {Virtual Event, Republic of Korea},
series = {AISec '21}
}

@inproceedings{10.1145/3394885.3431600,
author = {Zeng, Wei and Davoodi, Azadeh and Topaloglu, Rasit Onur},
title = {ObfusX: Routing Obfuscation with Explanatory Analysis of a Machine Learning Attack},
year = {2021},
isbn = {9781450379991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394885.3431600},
doi = {10.1145/3394885.3431600},
abstract = {This is the first work that incorporates recent advancements in "explainability" of machine learning (ML) to build a routing obfuscator called ObfusX. We adopt a recent metric---the SHAP value---which explains to what extent each layout feature can reveal each unknown connection for a recent ML-based split manufacturing attack model. The unique benefits of SHAP-based analysis include the ability to identify the best candidates for obfuscation, together with the dominant layout features which make them vulnerable. As a result, ObfusX can achieve better hit rate (97% lower) while perturbing significantly fewer nets when obfuscating using a via perturbation scheme, compared to prior work. When imposing the same wirelength limit using a wire lifting scheme, ObfusX performs significantly better in performance metrics (e.g., 2.4 times more reduction on average in percentage of netlist recovery).},
booktitle = {Proceedings of the 26th Asia and South Pacific Design Automation Conference},
pages = {548–554},
numpages = {7},
keywords = {explainable artificial intelligence, machine learning, routing obfuscation, split manufacturing},
location = {Tokyo, Japan},
series = {ASPDAC '21}
}

@inproceedings{10.1145/3736425.3772109,
author = {Shoji, Yutaka and Arisaka, Sohei and Ono, Eikichi and Mihara, Kuniaki},
title = {Poster Abstract: Data Assimilation for HVAC Simulations in Koopman-Invariant Subspace using Kalman Filter},
year = {2025},
isbn = {9798400719455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736425.3772109},
doi = {10.1145/3736425.3772109},
abstract = {Real-time state estimation in nonlinear HVAC dynamics requires computationally expensive nonlinear filtering methods. We present a data assimilation framework enabling standard linear Kalman filtering for nonlinear systems through Koopman operator theory. We transform nonlinear CFD simulations into linear dynamics using extended dynamic mode decomposition with neural network lifting functions. Our experiments demonstrate successful reconstruction of temperature and velocity fields from only 18 temperature sensors, achieving temperature RMSE of 0.16 °C and velocity RMSEs of 0.035 m/s and 0.031 m/s for u- and v-components respectively, notably inferring unobserved velocity fields solely from temperature measurements.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {306–307},
numpages = {2},
location = {Colorado School of Mines, Golden, CO, USA},
series = {BuildSys '25}
}

@inproceedings{10.1145/3512353.3512370,
author = {Malhotra, Ruchika and Deswal, Dhananjay and Chaudhry, Jai},
title = {Decoding the Brain Waves using EEG signals for classifying Body Gestures by applying suitable ML &amp; DL Techniques},
year = {2022},
isbn = {9781450395571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512353.3512370},
doi = {10.1145/3512353.3512370},
abstract = {This work aims to use EEG brain signals captured from the scalp of subjects at 500 Hz for classification of grasping tasks which is useful for BCI (Brain-Computer Interface) and comparative analysis of appropriate Machine Learning and Deep Learning Algorithms for the same. The dataset consists of 32 features and 6 output classes. Multinomial Logistic Regression, LSTM, CNN, RNN and ANN Algorithms were used for this purpose.},
booktitle = {Proceedings of the 2022 4th Asia Pacific Information Technology Conference},
pages = {116–122},
numpages = {7},
keywords = {ANN, CNN, Comparative Analysis, EEG, LR, LSTM, RNN},
location = {Virtual Event, Thailand},
series = {APIT '22}
}

@inproceedings{10.1145/3604237.3626914,
author = {Buet-Golfouse, Francois and Martin, Nicholas WD},
title = {Lifting Volterra Diffusions via Kernel Decomposition},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626914},
doi = {10.1145/3604237.3626914},
abstract = {Rough volatility models have garnered considerable attention among practitioners due to their remarkable empirical fit. However, their non-Markovian nature arises from the presence of a kernel (leading to so-called Voltera diffusions), which complicates pricing and calibration tasks. In this paper, we present our novel contribution of employing machine learning techniques to either approximate or learn the kernel function in a manner that renders it Markovian, effectively “lifting” the non-Markovian Volterra diffusion. Through empirical investigations encompassing a diverse set of kernels, we demonstrate the efficacy of our approach, opening new avenues for improved modelling and analysis in rough volatility models.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {481–489},
numpages = {9},
keywords = {Fractional Kernel, Kernel Decomposition, Random Fourier Features, Rough Heston Model, Volterra Diffusion},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1145/3637843.3637853,
author = {Devarakonda, Sachidananda Bharadwaj and Sharma, Soumyajit Sen and Rudra Pal, Abhishek},
title = {Design and development of medical cobot to assist surgeon},
year = {2024},
isbn = {9798400708282},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637843.3637853},
doi = {10.1145/3637843.3637853},
abstract = {This paper presents an automated collaborative robot that works with a surgeon during a surgical operation incorporated with Machine learning algorithms and Deep learning algorithms to assist the surgeon by performing auxiliary actions. Our main objective is to create a framework for a collaborative nurse robot that upon voice instruction, will recognize and classify the surgical instruments present in the surgical tray and execute manual tasks such as picking up and delivering that instrument to its operator. There have been discussions on the types of co-bots and the types that can embrace the prescribed idea. After visualizing a co-bot model, designing it in CAD software is a crucial initiation to judge the practicality of the robot. The robot was designed to test its navigation before prototyping it. The main objectives to accomplish the working of an assistant medical co-bot is discussed. For object detection Aruco marker that uses Convolution Neural Network is implicated, for voice detection Google's speech recognition system having Deep neural network algorithm is embraced and for training the Co-bot using Arduino libraries is being discussed. Python has been used as a programming language and pyserial to communicate with Arduino from other two systems i.e., voice recognition system and object detection system. This medical Co-bot reflects our effort to lessen stress on surgeon and human error during operation.},
booktitle = {Proceedings of the 2023 9th International Conference on Robotics and Artificial Intelligence},
pages = {38–44},
numpages = {7},
keywords = {Component, assistant nurse, automation, collaborative robots, deep learning, image classification, machine learning, modeling, python, surgical instruments, voice recognition},
location = {Singapore, Singapore},
series = {ICRAI '23}
}

@inproceedings{10.1145/3519939.3523702,
author = {Verbeek, Freek and Bockenek, Joshua and Fu, Zhoulai and Ravindran, Binoy},
title = {Formally verified lifting of C-compiled x86-64 binaries},
year = {2022},
isbn = {9781450392655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3519939.3523702},
doi = {10.1145/3519939.3523702},
abstract = {Lifting binaries to a higher-level representation is an essential step for decompilation, binary verification, patching and security analysis. In this paper, we present the first approach to provably overapproximative x86-64 binary lifting. A stripped binary is verified for certain sanity properties such as return address integrity and calling convention adherence. Establishing these properties allows the binary to be lifted to a representation that contains an overapproximation of all possible execution paths of the binary. The lifted representation contains disassembled instructions, reconstructed control flow, invariants and proof obligations that are sufficient to prove the sanity properties as well as correctness of the lifted representation. We apply this approach to Linux Foundation and Intel’s Xen Hypervisor covering about 400K instructions. This demonstrates our approach is the first approach to provably overapproximative binary lifting scalable to commercial off-the-shelf systems. The lifted representation is exportable to the Isabelle/HOL theorem prover, allowing formal verification of its correctness. If our technique succeeds and the proofs obligations are proven true, then – under the generated assumptions – the lifted representation is correct.},
booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {934–949},
numpages = {16},
keywords = {Binary Analysis, Disassembly, Formal Verification},
location = {San Diego, CA, USA},
series = {PLDI 2022}
}

@article{10.1145/3486860,
author = {Alrabaee, Saed and Debbabi, Mourad and Wang, Lingyu},
title = {A Survey of Binary Code Fingerprinting Approaches: Taxonomy, Methodologies, and Features},
year = {2022},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3486860},
doi = {10.1145/3486860},
abstract = {Binary code fingerprinting is crucial in many security applications. Examples include malware detection, software infringement, vulnerability analysis, and digital forensics. It is also useful for security researchers and reverse engineers since it enables high fidelity reasoning about the binary code such as revealing the functionality, authorship, libraries used, and vulnerabilities. Numerous studies have investigated binary code with the goal of extracting fingerprints that can illuminate the semantics of a target application. However, extracting fingerprints is a challenging task since a substantial amount of significant information will be lost during compilation, notably, variable and function naming, the original data and control flow structures, comments, semantic information, and the code layout. This article provides the first systematic review of existing binary code fingerprinting approaches and the contexts in which they are used. In addition, it discusses the applications that rely on binary code fingerprints, the information that can be captured during the fingerprinting process, and the approaches used and their implementations. It also addresses limitations and open questions related to the fingerprinting process and proposes future directions.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {19},
numpages = {41},
keywords = {Binary code analysis, reverse engineering, software security}
}

@inproceedings{10.1145/3721238.3730597,
author = {Chang, Yue and Liu, Mengfei and Wang, Zhecheng and Chen, Peter Yichen and Grinspun, Eitan},
title = {Lifting the Winding Number: Precise Discontinuities in Neural Fields for Physics Simulation},
year = {2025},
isbn = {9798400715402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721238.3730597},
doi = {10.1145/3721238.3730597},
abstract = {Cutting thin-walled deformable structures is common in daily life, but poses significant challenges for simulation due to the introduced spatial discontinuities. Traditional methods rely on mesh-based domain representations, which require frequent remeshing and refinement to accurately capture evolving discontinuities. These challenges are further compounded in reduced-space simulations, where the basis functions are inherently geometry- and mesh-dependent, making it difficult or even impossible for the basis to represent the diverse family of discontinuities introduced by cuts.Recent advances in representing basis functions with neural fields offer a promising alternative, leveraging their discretization-agnostic nature to represent deformations across varying geometries. However, the inherent continuity of neural fields is an obstruction to generalization, particularly if discontinuities are encoded in neural network weights.We present Wind Lifter, a novel neural representation designed to accurately model complex cuts in thin-walled deformable structures. Our approach constructs neural fields that reproduce discontinuities precisely at specified locations, without “baking in” the position of the cut line. To achieve this, we augment the input coordinates of the neural field with the generalized winding number of any given cut line, effectively lifting the input from two to three dimensions. Lifting allows the network to focus on the easier problem of learning a 3D everywhere-continuous volumetric field, while a corresponding restriction operator enables the final output field to precisely resolve strict discontinuities. Crucially, our approach does not embed the discontinuity in the neural network’s weights, opening avenues to generalization of cut placement.Our method achieves real-time simulation speeds and supports dynamic updates to cut line geometry during the simulation. Moreover, the explicit representation of discontinuities makes our neural field intuitive to control and edit, offering a significant advantage over traditional neural fields, where discontinuities are embedded within the network’s weights, and enabling new applications that rely on general cut placement.},
booktitle = {Proceedings of the Special Interest Group on Computer Graphics and Interactive Techniques Conference Conference Papers},
articleno = {25},
numpages = {11},
keywords = {Cutting, Discontinuity, Reduced-order modeling, Implicit neural representation, Computational design},
location = {
},
series = {SIGGRAPH Conference Papers '25}
}

@inproceedings{10.1145/3701551.3707419,
author = {Zebaze, Janice Anta and Jiomekong, Azanzi and Souopgui, Innocent and Djuidje Kenmoe, Germaine},
title = {Bearing Power Loss Predictions in Wind Turbine Gearbox: An Approach Based on LLMs},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3707419},
doi = {10.1145/3701551.3707419},
abstract = {A constant and consistent supply in electrical energy in a location is a reflection of a good economy. Developing countries nevertheless don't have access to this quality of energy, which slows down their economy and consequently development. Wind is a clean, sustainable and renewable resource which can be used to meet the energy needs in such countries. However, the intermittent nature of wind yields fluctuations on the amount of energy produced by a wind turbine. Coupled with frictional power losses in the wind turbine gearbox bearings, one can't be sure on the exact amount of energy that will be produced. This leads to the distribution and management issues. To tackle this issue, we propose here the use of Large Language models. These are tools which have been proving their potential in various domains till date and whose potential are still to be seen in the field to our knowledge. Taking advantage of their flexibility and adaptability to any model and dataset, we intend to explore its abilities in the fields of wind energy and tribology. Making use of available data, predictions on the wind energy potential and power losses will be carried out using Large Language models such as BERT. The results of this work intends to promote the use of wind energy by lifting barriers in thee management and knowledge of the resource.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {1080–1083},
numpages = {4},
keywords = {artificial intelligence, data, large language models, physical sciences and engineering, rolling element bearings, tribology},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3688868.3689199,
author = {Bagga, Ereena and Yang, Ang},
title = {Real-Time Posture Monitoring and Risk Assessment for Manual Lifting Tasks Using MediaPipe and LSTM},
year = {2024},
isbn = {9798400711954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688868.3689199},
doi = {10.1145/3688868.3689199},
abstract = {This research focuses on developing a real-time posture monitoring and risk assessment system for manual lifting tasks using advanced AI and computer vision technologies. Musculoskeletal disorders (MSDs) are a significant concern for workers involved in manual lifting, and traditional methods for posture correction are often inadequate due to delayed feedback and lack of personalized assessment. Our proposed solution integrates AI-driven posture detection, detailed keypoint analysis, risk level determination, and real-time feedback delivered through a user-friendly web interface. The system aims to improve posture, reduce the risk of MSDs, and enhance user engagement. The research involves comprehensive data collection, model training, and iterative development to ensure high accuracy and user satisfaction. The solution's effectiveness is evaluated against existing methodologies, demonstrating significant improvements in real-time feedback and risk assessment. This study contributes to the field by offering a novel approach to posture correction that addresses existing gaps and provides practical, immediate benefits to users.},
booktitle = {Proceedings of the 1st International Workshop on Multimedia Computing for Health and Medicine},
pages = {79–85},
numpages = {7},
keywords = {artificial intelligence, computer vision, machine learning., musculoskeletal disorders (msds), real-time posture monitoring},
location = {Melbourne VIC, Australia},
series = {MCHM'24}
}

@inproceedings{10.1145/3760658.3760666,
author = {Zhang, Fan and Zhang, Lixia and Li, Xiang and Li, Mingjia and Ren, Yuxi},
title = {Prediction of Air Marshals' Physical Performance Based on Least Squares Support Vector Machine and Prediction Error Correction},
year = {2025},
isbn = {9798400718526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3760658.3760666},
doi = {10.1145/3760658.3760666},
abstract = {In order to obtain better prediction results of air marshals' physical performance, the air marshals' physical performance prediction model with least squares support vector machine and prediction error correction is proposed. Firstly, the physical performance of air marshals is modeled and predicted by lifting wavelets and least squares support vector machine, then the prediction results of physical performance of air marshals are corrected by prediction error correction, and finally, tested through a case study on air marshals' physical performance prediction, and comparison experiments are carried out with other prediction models of the physical performance of air marshals to validate its superiority. The results show that the model proposed in this paper reduces the prediction error of air marshals' physical performance, and improves the stability of the prediction results of air marshals' physical performance through prediction error correction, and the prediction accuracy is better than other air marshals' physical performance prediction models.},
booktitle = {Proceedings of the 2025 9th International Conference on Deep Learning Technologies},
pages = {52–56},
numpages = {5},
keywords = {air marshals' physical performance, least squares support vector machine, prediction accuracy, prediction error correction, prediction model},
location = {
},
series = {ICDLT '25}
}

@inproceedings{10.1145/3773365.3773502,
author = {Xiao, Qunan and Wang, Hao and Liu, Zhixi and Zhang, Xiao and Ma, Bo and Lin, Chen and Liu, Chang and Nie, Jieliang and Li, Xiqin and Huang, Yue},
title = {Intelligent Control and Monitoring of AI-Driven Landing Double Rocker Arm Holding Systems in Mountainous Power Grid Construction},
year = {2025},
isbn = {9798400718748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3773365.3773502},
doi = {10.1145/3773365.3773502},
abstract = {Artificial Intelligence (AI) has emerged as a transformative force in power grid construction, offering novel solutions to challenges such as labor shortages, safety risks, and inefficiencies—particularly in complex terrains like mountainous regions. This paper presents both a comprehensive review of AI-driven technologies in tower assembly and a detailed account of an innovative engineering solution: the development of an intelligent, lightweight, self-erecting landing double rocker arm holding system. The proposed system integrates advanced structural design principles with AI-based real-time monitoring and control, enabling rapid deployment and enhanced safety in narrow and high-altitude tower windows. Finite element simulations and field applications on 110 kV and 220 kV projects demonstrate significant reductions in labor demands, material usage, and setup time. The results highlight the synergy of intelligent equipment and AI in achieving safe, efficient, and scalable tower assembly, setting a replicable benchmark for smart construction practices in the power grid sector.},
booktitle = {Proceedings of the 2025 8th International Conference on Computer Information Science and Artificial Intelligence},
pages = {875–881},
numpages = {7},
keywords = {Artificial Intelligence, Automated Control, Computer Vision, Intelligent control, Lightweight design, Machine Learning, Mast system, Power Grid Construction, Safety Monitoring, Tower Assembly},
location = {
},
series = {CISAI '25}
}

@inproceedings{10.1145/3611643.3613079,
author = {Toledo, Felipe and Shriver, David and Elbaum, Sebastian and Dwyer, Matthew B.},
title = {Deeper Notions of Correctness in Image-Based DNNs: Lifting Properties from Pixel to Entities},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613079},
doi = {10.1145/3611643.3613079},
abstract = {Deep Neural Networks (DNNs) that process images are being widely used for many safety-critical tasks, from autonomous vehicles to medical diagnosis. Currently, DNN correctness properties are defined at the pixel level over the entire input. Such properties are useful to expose system failures related to sensor noise or adversarial attacks, but they cannot capture features that are relevant to domain-specific entities and reflect richer types of behaviors. To overcome this limitation, we envision the specification of properties based on the entities that may be present in image input, capturing their semantics and how they change. Creating such properties today is difficult as it requires determining where the entities appear in images, defining how each entity can change, and writing a specification that is compatible with each particular V&amp;V client. We introduce an initial framework structured around those challenges to assist in the generation of Domain-specific Entity-based properties automatically by leveraging object detection models to identify entities in images and creating properties based on entity features. Our feasibility study provides initial evidence that the new properties can uncover interesting system failures, such as changes in skin color can modify the output of a gender classification network. We conclude by analyzing the framework potential to implement the vision and by outlining directions for future work.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2122–2126},
numpages = {5},
keywords = {Neural networks, fairness, properties, validation, verification},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3689236.3696046,
author = {Gao, Ruimei and Zhang, Lina},
title = {Research on the Optimization Algorithm to Avoid Malicious Code Attacks},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689236.3696046},
doi = {10.1145/3689236.3696046},
abstract = {In order to solve the accuracy, time consuming and anti-detection ability of traditional LAN malicious attack code classification method, this paper proposes a LAN malicious code classification method based on improved optimization algorithm. This method adopts 3 D coordinate technology to expand the spatial location of malicious code to a wider range, so as to improve the characteristics of malicious code, so as to effectively prevent malicious attacks. To solve the time-consuming problem, a new transfer learning technology is adopted to improve the anti-confounding ability. In addition, in order to solve the problem of large network computing volume and slow code recovery speed, the MobileNetV3 convolutional neural network model is adopted, combined with the Ranger optimization algorithm technology, to speed up the time-consuming network convergence process. Both the CIFAR-10 and VisualQA datasets achieved 93.5% and 91.2%, with a 2.3% improvement in accuracy and a 25% improvement in detection efficiency compared to Sentiment140. The improved algorithm has significantly improved the accuracy in the classification than the traditional method, reaching the level of 1.05%. These improved algorithms not only improve the accuracy of the model, but also enhance the resistance to confounding, and improve the efficiency of classification detection.},
booktitle = {Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
pages = {242–251},
numpages = {10},
location = {
},
series = {ICCSIE '24}
}

@article{10.1145/3729255,
author = {Li, Jiaying and Hao, Chunxue},
title = {Support Triangle Machine},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {PLDI},
url = {https://doi.org/10.1145/3729255},
doi = {10.1145/3729255},
abstract = {Approximations play a pivotal role in verifying deep neural networks (DNNs). Existing approaches typically rely on either single-neuron approximations (simpler to design but less precise) or multi-neuron approximations (higher precision but significantly more complex to construct). Between them, a notable gap exists.    This work bridges the gap. The idea is to lift single-neuron approximations into multi-neuron approximations with precision gain. To this end, we formulate the approximation transition as a novel problem, named Convex Approximation Lifting (CAL), and propose a constructive approach, Support Triangle Machine (STM), to solving it. STM is grounded in two core insights: (i) there exists a simple geometric structure, called the support triangle, along with an efficient triangle lifting technique that connects single-neuron approximations and multi-neuron approximations; and (ii) typical single-neuron approximations can be easily decomposed into multiple atomically liftable components. Specifically, given a CAL instance, STM constructs a multi-neuron approximation by iteratively processing each output coordinate. For each coordinate, it decomposes the single-neuron approximation into several linear parts, lifts each of them using the triangle lifting technique, and then synthesize an intermediate approximation, which later servers as input for the next iteration.    We theoretically prove the correctness of STM and empirically evaluate its performance on a variety of CAL problems and DNN verification tasks. Experimental results demonstrate STM's broad applicability, improved precision, and sustained efficiency. Beyond DNN verification, STM has the potential to facilitate approximation construction process in more general tasks, and we expect it to catalyze further research in related fields.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {156},
numpages = {24},
keywords = {Approximation Lifting, Convex Approximation, Support Triangle Machine}
}

@inproceedings{10.1109/PACT52795.2021.00012,
author = {Collie, Bruce and O'Boyle, Michael F.P.},
title = {Program Lifting using Gray-Box Behavior},
year = {2024},
isbn = {9781665442787},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/PACT52795.2021.00012},
doi = {10.1109/PACT52795.2021.00012},
abstract = {Porting specialized application components to new platforms is difficult. This is particularly true if the components depend on proprietary libraries, or specific hardware. To tackle this, existing work has sought to recover high-level descriptions of application components to ease their retargeting. However, existing schemes are either too limited, targeting just one application domain, or too weak, making them ill-suited to recovering real-world programs. Additionally, many rely on help in the form of problem-specific user annotations or complex specifications.This paper develops a new approach using gray-box program synthesis, which recovers code by automatically constructing a program to match the behavior of an unknown component. However, unlike other synthesis approaches, it exploits the dynamic or gray-box behavior of a component to guide recovery. For example, the execution time, memory access patterns or observed instruction traces can all be used to direct synthesis.We evaluate our technique (Haze) extensively against existing program synthesizers and a domain-specific lifter. Our scheme is able to generalize effectively across domains, synthesizing and lifting more programs than prior techniques, without any external assistance. We validate our methodology using bounded model checking, demonstrating that our synthesized programs are correct. Finally, we apply our approach to machine learning workloads, obtaining significant speedups automatically.},
booktitle = {Proceedings of the 30th International Conference on Parallel Architectures and Compilation Techniques},
pages = {60–74},
numpages = {15},
keywords = {compilers, lifting, program synthesis},
location = {Atlanta, GA, USA},
series = {PACT '21}
}

@inproceedings{10.1145/3765416.3765434,
author = {Huang, Shipei and Liang, Jian and Zhang, Yang and Yao, Wanyin and Liang, Yaoxin},
title = {Functional analysis of patient-assisted transfer equipment based on the Analytic Hierarchy Process combined with Artificial In-telligence},
year = {2025},
isbn = {9798400719547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3765416.3765434},
doi = {10.1145/3765416.3765434},
abstract = {With the worsening of population ageing and the continuous increase in the number of chronic disease patients, traditional patient transportation methods are not only inefficient, but also difficult to fully guarantee the comfort and safety of patients. Therefore, improving patient handling efficiency and reducing the labour intensity of nursing staff have become important directions for optimising current medical services. The article elaborates on the complementary roles of the Analytic Hierarchy Process and Artificial Intelligence in decision-making. Subsequently, based on the Analytic Hierarchy Process, the functionality of patient-assisted transfer equipment was analysed, and a hierarchical structure model was constructed based on survey data to determine the priority of core functions and provide key guidance for device development.},
booktitle = {Proceedings of the 2025 International Conference on Artificial Intelligence and Product Design},
pages = {104–108},
numpages = {5},
keywords = {aging, artificial intelligence, assistive equipment, behavior},
location = {
},
series = {AIPD '25}
}

@inproceedings{10.1145/3611643.3616289,
author = {Jain, Kush and Alon, Uri and Groce, Alex and Le Goues, Claire},
title = {Contextual Predictive Mutation Testing},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616289},
doi = {10.1145/3611643.3616289},
abstract = {Mutation testing is a powerful technique for assessing and improving test suite quality that artificially introduces bugs and checks whether the test suites catch them. However, it is also computationally expensive and thus does not scale to large systems and projects. One promising recent approach to tackling this scalability problem uses machine learning to predict whether the tests will detect the synthetic bugs, without actually running those tests. However, existing predictive mutation testing approaches still misclassify 33% of detection outcomes on a randomly sampled set of mutant-test suite pairs. We introduce MutationBERT, an approach for predictive mutation testing that simultaneously encodes the source method mutation and test method, capturing key context in the input representation. Thanks to its higher precision, MutationBERT saves 33% of the time spent by a prior approach on checking/verifying live mutants. MutationBERT, also outperforms the state-of-the-art in both same project and cross project settings, with meaningful improvements in precision, recall, and F1 score. We validate our input representation, and aggregation approaches for lifting predictions from the test matrix level to the test suite level, finding similar improvements in performance. MutationBERT not only enhances the state-of-the-art in predictive mutation testing, but also presents practical benefits for real-world applications, both in saving developer time and finding hard to detect mutants that prior approaches do not.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {250–261},
numpages = {12},
keywords = {code coverage, mutation analysis, test oracles},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3732775.3733574,
author = {Ibrahim, Abdul Qadir and G\"{o}tschel, Sebastian and Ruprecht, Daniel},
title = {Space-Time Parallel Scaling of Parareal with a Physics-Informed Fourier Neural Operator Coarse Propagator Applied to the Black-Scholes Equation},
year = {2025},
isbn = {9798400718861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3732775.3733574},
doi = {10.1145/3732775.3733574},
abstract = {Iterative parallel-in-time algorithms like Parareal can extend scaling beyond the saturation of purely spatial parallelization when solving initial value problems. However, they require the user to build coarse models to handle the unavoidable serial transport of information in time. This is a time-consuming and difficult process since there is still limited theoretical insight into what constitutes a good and efficient coarse model. Novel approaches from machine learning to solve differential equations could provide a more generic way to find coarse-level models for multi-level parallel-in-time algorithms. This paper demonstrates that a physics-informed Fourier Neural Operator (PINO) is an effective coarse model for the parallelization in time of the two-asset Black-Scholes equation using Parareal. We demonstrate that PINO-Parareal converges as fast as a bespoke numerical coarse model and that, in combination with spatial parallelization by domain decomposition, it provides better overall speedup than both purely spatial parallelization and space-time parallelization with a numerical coarse propagator.},
booktitle = {Proceedings of the Platform for Advanced Scientific Computing Conference},
pages = {1–11},
numpages = {11},
keywords = {parareal, parallel-in-time integration, physics-informed neural operator, machine learning, space-time parallelization, black-scholes equation},
location = {FHNW University of Applied Sciences and Arts Northwestern Switzerland, Brugg-Windisch, Switzerland},
series = {PASC '25}
}

@inproceedings{10.1145/3675094.3678999,
author = {Lyu, Tian and Yu, Yiang and Narayan, Ashwin and Yu, Haoyong},
title = {A Non-collocated Wearable Framework for Back Support Exoskeleton Payload Estimation},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678999},
doi = {10.1145/3675094.3678999},
abstract = {Back-support exoskeletons(BSEs) show promise in preventing occupational low back pain (OLBP). To address a counter-intuitive interpretation of users' demand with the conventional BSEs, which are controlled based on the lifting speed, and offer users to interpret and anticipate the system's output performance. This paper develops a non-collocated, easy-to-equip wearable system enhancing BSEs' capability to perceive operational loads. We designed a Convolution-inspired Trunk Event Recognition (CTER) algorithm for trunk lifting and bending motion detection. Moreover, conceptualizing human motion signals as audio sequences, the study proposed two deep learning classification models leveraging speech processing techniques. This system is capable of detecting body trunk lifting and bending motions, and features onboard estimation of payload categorized into 0, 5, 10, and 15 kg groups.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {877–880},
numpages = {4},
keywords = {back support exoskeleton, occupational low back pain, payload estimation, trunk motion detection},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3746059.3747678,
author = {Takahira, Kentaro and Yu, Yue and Fujiwara, Takanori and Suzuki, Ryo and Qu, Huamin},
title = {InSituTale: Enhancing Augmented Data Storytelling with Physical Objects},
year = {2025},
isbn = {9798400720376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746059.3747678},
doi = {10.1145/3746059.3747678},
abstract = {Augmented data storytelling enhances narrative delivery by integrating visualizations with physical environments and presenter actions. Existing systems predominantly rely on body gestures or speech to control visualizations, leaving interactions with physical objects largely underexplored. We introduce augmented physical data storytelling, an approach enabling presenters to manipulate visualizations through physical object interactions. To inform this approach, we first conducted a survey of data-driven presentations to identify common visualization commands. We then conducted workshops with nine HCI/VIS researchers to collect mappings between physical manipulations and these commands. Guided by these insights, we developed InSituTale, a prototype that combines object tracking via a depth camera with Vision-LLM for detecting real-world events. Through physical manipulations, presenters can dynamically execute various visualization commands, delivering cohesive data storytelling experiences that blend physical and digital elements. A user study with 12 participants demonstrated that InSituTale enables intuitive interactions, offers high utility, and facilitates an engaging presentation experience.},
booktitle = {Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
articleno = {51},
numpages = {15},
keywords = {Visualization; Data-Driven Storytelling; Tangible Interaction; Augmented Reality; Augmented Presentation; Video},
location = {
},
series = {UIST '25}
}

@inproceedings{10.1145/3372047.3372056,
author = {Yongfeng, Cheng and Sheng, Li and Zhicheng, Lu and Cheng, Wang and Xiaoning, Wang and Shujun, Zhang},
title = {Method and Experiment Research for Moving of Main UHV Substations Equipment in Full Assembly State},
year = {2020},
isbn = {9781450376228},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372047.3372056},
doi = {10.1145/3372047.3372056},
abstract = {In UHV substation, moving main transformer and HV shunt reactor in full assembly can reduce the interruption duration in equipment replacement, which is important for the operation of the grid. The UHV transformer and HV shunt reactor are large in volume and heavy in weight. The moving of them in full assembly is a sophisticated process, considering the vibration in the moving will have negative effect on the stable operation of the equipment. This paper carried out method and experimental research on the moving of transformer and HV shunt reactor in full assembly. The research results indicated that the 1,000kV transformer can be moved in full assembly with specially designed track system and vehicle. The maximum acceleration in the moving test was 0.4g and the maximum pull force was 76.7 kN. Traction machinery with output force larger than 200kN is recommended for practice. The 1,000kV HV shunt reactor could be moved in full assembly by tractor vehicle, and the maximum acceleration in test was 0.32g. The results showed that the system designed in this paper is effective in vibration control of the moving process. To further control the vibration amplitude, it is recommended to improve the jacking process, such as applying elastic cushion in the contacting surface of jack or lifting the equipment synchronously.},
booktitle = {Proceedings of the 2019 The 2nd International Conference on Robotics, Control and Automation Engineering},
pages = {243–249},
numpages = {7},
keywords = {HV shunt reactor, Movement, Transformer, Ultra-high voltage, Vibration},
location = {Lanzhou, China},
series = {RCAE 2019}
}

@inproceedings{10.1145/3627673.3679813,
author = {H\r{u}la, Jan and Moj\'{\i}ek, David and Janota, Mikol\'{a}},
title = {Understanding GNNs for Boolean Satisfiability through Approximation Algorithms},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679813},
doi = {10.1145/3627673.3679813},
abstract = {This paper delves into the interpretability of Graph Neural Networks in the context of Boolean Satisfiability. The goal is to demystify the internal workings of these models and provide insightful perspectives into their decision-making processes. This is done by uncovering connections to two approximation algorithms studied in the domain of Boolean Satisfiability: Belief Propagation and Semidefinite Programming Relaxations. Revealing these connections has empowered us to introduce a suite of impactful enhancements. The first significant enhancement is a curriculum training procedure, which incrementally increases the problem complexity in the training set, together with increasing the number of message passing iterations of the Graph Neural Network. We show that the curriculum, together with several other optimizations, reduces the training time by more than an order of magnitude compared to the baseline without the curriculum. Furthermore, we apply decimation and sampling of initial embeddings, which significantly increase the percentage of solved problems.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {953–961},
numpages = {9},
keywords = {approximation algorithms, belief propagation, boolean satisfiability, graph neural networks, neuro-symbolic AI, semidefinite programming},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3677388.3696339,
author = {Egan, Donal and Jovane, Alberto and Szkaradek, Jan and Fletcher, George and Cosker, Darren and McDonnell, Rachel},
title = {Dog Code: Human to Quadruped Embodiment using Shared Codebooks},
year = {2024},
isbn = {9798400710902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677388.3696339},
doi = {10.1145/3677388.3696339},
abstract = {Many VR animal embodiment sytsems suffer from poor animation fidelity, typically animating the animal avatars using inverse kinematics. We address this issue, presenting a novel deep-learning method, centred around a shared codebook, for mapping human motion to quadruped motion. Rather than trying to directly bridge the gap from human motion to quadruped motion, a task which has proven difficult, we first use a rule-based retargeter, relying on inverse and forward kinematics, to retarget human motions to an intermediate motion domain in which the motions share the same skeleton as the quadruped. We then use finite scalar quantization to construct a shared latent space, or codebook, between this intermediate domain and the quadruped motion domain. We do this by first pre-defining a finite number of discrete latent codes and then teaching these codes, using unsupervised deep-learning, to represent semantically similar motions in the two domains. We incorporate our real-time human-to-quadruped motion mapping into a VR quadruped embodiment system. The output quadruped animations are natural and realistic, while also preserving the semantics of users’ actions. Moreover, there is a strong synchrony between the input human motions and retargeted quadruped motions, an important factor for inducing a strong sense of VR embodiment.},
booktitle = {Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games},
articleno = {10},
numpages = {11},
keywords = {Deep-learning, Motion retargeting, Quadruped embodiment, VR embodiment},
location = {Arlington, VA, USA},
series = {MIG '24}
}

@inproceedings{10.1145/3762329.3762341,
author = {Yang, Xiao and Li, Chuanchang and Zhang, Weiwei},
title = {DGPL: A Cross-View Semantic Segmentation Perception Model in Bird's-Eye View},
year = {2025},
isbn = {9798400718625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3762329.3762341},
doi = {10.1145/3762329.3762341},
abstract = {To address the challenges of low feature fusion efficiency, weak long-range object recognition, and high computational overhead in cross-view transformation for autonomous driving perception, we propose DGPL—an end-to-end Bird's Eye View (BEV) semantic segmentation perception model. The model simultaneously extracts multi-camera image semantic features and pixel-level depth information through a shared convolutional neural network. Innovatively, it incorporates a non-uniform learnable depth estimation module to achieve high-precision depth prediction for near-field targets while ensuring efficiency for far-field targets. A reverse grid pooling optimization module is designed to significantly accelerate the projection of 3D features into BEV space. Concurrently, a distance-aware loss function is optimized to enhance recognition capability for distant small objects. Experiments on the nuScenes dataset demonstrate that DGPL achieves state-of-the-art performance in 3D object detection with 42.5 mAP and 45.8 NDS, while outperforming mainstream methods in BEV semantic segmentation tasks. Moreover, the model requires only 9.8 million parameters and achieves an inference speed of 38.5 fps, substantially enhancing feasibility for engineering deployment.},
booktitle = {Proceedings of the 2nd International Conference on Artificial Intelligence of Things and Computing},
pages = {59–64},
numpages = {6},
keywords = {Bird's eye view, Cross-view perception, Semantic segmentation},
location = {
},
series = {AITC '25}
}

@inproceedings{10.1145/3746027.3758177,
author = {Li, Xun and Santa Cruz, Rodrigo and Xi, Mingze and Zhang, Hu and Perera, Madhawa and Wang, Ziwei and Ravendran, Ahalya and Matthews, Brandon J. and Xu, Feng and Adcock, Matt and Wang, Dadong and Liu, Jiajun},
title = {Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic Reasoning and Robotic Task Planning},
year = {2025},
isbn = {9798400720352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746027.3758177},
doi = {10.1145/3746027.3758177},
abstract = {To enable robots to comprehend high-level human instructions and perform complex tasks, a key challenge lies in achieving comprehensive scene understanding: interpreting and interacting with the 3D environment in a meaningful way. This requires a smart map that fuses accurate geometric structure with rich, human-understandable semantics. To address this, we introduce the 3D Queryable Scene Representation (3D QSR), a novel framework built on multimedia data that unifies three complementary 3D representations: (1) 3D-consistent novel view rendering and segmentation from panoptic reconstruction, (2) precise geometry from 3D point clouds, and (3) structured, scalable organization via 3D scene graphs. Built on an object-centric design, the framework integrates with large vision-language models to enable semantic queryability by linking multimodal object embeddings, and supporting object-level retrieval of geometric, visual, and semantic information. The retrieved data are then loaded into a robotic task planner for downstream execution.We evaluate our approach through simulated robotic task planning scenarios in Unity, guided by abstract language instructions and using the indoor public dataset Replica. Furthermore, we apply it in a digital duplicate of a real wet lab environment to test QSR-supported robotic task planning for emergency response. The results demonstrate the framework's ability to facilitate scene understanding and integrate spatial and semantic reasoning, effectively translating high-level human instructions into precise robotic task planning in complex 3D environments.},
booktitle = {Proceedings of the 33rd ACM International Conference on Multimedia},
pages = {12492–12500},
numpages = {9},
keywords = {3d scene representation, 3d scene understanding, multi-modal, multi-view captioning, robotic perception, robotic task planning, unity, vision-language models, visual language grounding},
location = {Dublin, Ireland},
series = {MM '25}
}

@inproceedings{10.1145/3689945.3694807,
author = {Zhang, Yancheng and Chen, Xun and Lou, Qian},
title = {HEBridge: Connecting Arithmetic and Logic Operations in FV-style HE Schemes},
year = {2024},
isbn = {9798400712418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689945.3694807},
doi = {10.1145/3689945.3694807},
abstract = {Fully homomorphic encryption (FHE) allows computation over encrypted data without decryption and is considered one of the most essential primitives for privacy-preserving applications. However, there are still no universal FHE schemes that can support efficient and precise evaluation of both arithmetic and logic operations. Many endeavors have been made to enhance the capability of FHE for general computation, such as scheme switching and polynomial approximation. However, the overhead of scheme switching remains prohibitive for real applications with large bit-width inputs. On the other hand, the approximation methods have large errors around the pivotal point, limiting their application in precision-sensitive tasks. Recent studies show that FV-style HE schemes can support efficient and precise logic operations via polynomial interpolation. However, these methods cannot be seamlessly incorporated with arithmetic operations. In this work, we introduce HEBridge to connect the arithmetic and logic operations in the FV-style HE schemes. We first demonstrate that the arithmetic and logic operations operate over different underlying plaintext spaces. To enable continuous arithmetic and logic operations, we propose a reduction function and a lifting function to switch between these plaintext spaces. With HEBridge, we can exploit fast arithmetic and precise logic operations simultaneously in FV-style HE schemes. Experimental results show that the proposed HEBridge is 32.9\texttimes{} faster than direct interpolation methods and 1 to 3 orders of magnitude more efficient than scheme switching on large bit-width inputs.},
booktitle = {Proceedings of the 12th Workshop on Encrypted Computing &amp; Applied Homomorphic Cryptography},
pages = {23–35},
numpages = {13},
keywords = {digit decomposition, polynomial interpolation, universal fully homomorphic encryption},
location = {Salt Lake City, UT, USA},
series = {WAHC '24}
}

@article{10.1145/3567730,
author = {Fan, Neil Xu and Xiao, Robert},
title = {Reducing the Latency of Touch Tracking on Ad-hoc Surfaces},
year = {2022},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {ISS},
url = {https://doi.org/10.1145/3567730},
doi = {10.1145/3567730},
abstract = {Touch sensing on ad-hoc surfaces has the potential to transform everyday surfaces in the environment - desks, tables and walls - into tactile, touch-interactive surfaces, creating large, comfortable interactive spaces without the cost of large touch sensors. Depth sensors are a promising way to provide touch sensing on arbitrary surfaces, but past systems have suffered from high latency and poor touch detection accuracy. We apply a novel state machine-based approach to analyzing touch events, combined with a machine-learning approach to predictively classify touch events from depth data with lower latency and higher touch accuracy than previous approaches. Our system can reduce end-to-end touch latency to under 70ms, comparable to conventional capacitive touchscreens. Additionally, we open-source our dataset of over 30,000 touch events recorded in depth, infrared and RGB for the benefit of future researchers.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {577},
numpages = {11},
keywords = {ad-hoc surfaces, latency reduction, touch detection}
}

@article{10.1145/3522739,
author = {Dai, Yuanchao and Wu, Jing and Fan, Yuanzhao and Wang, Jin and Niu, Jianwei and Gu, Fei and Shen, Shigen},
title = {MSEva: A Musculoskeletal Rehabilitation Evaluation System Based on EMG Signals},
year = {2022},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1550-4859},
url = {https://doi.org/10.1145/3522739},
doi = {10.1145/3522739},
abstract = {In order to better assist the rehabilitation treatment of patients with musculoskeletal injury, standard rehabilitation actions are needed to guide the musculoskeletal rehabilitation process. With more and more urgent demands, the musculoskeletal rehabilitation evaluation systems have attracted a high degree of attention. Experts have proposed a series of systems based on laser, ultrasound, and image, which can give reasonable recognition and judgment. However, these systems either require specialized and expensive equipment or can be affected by ionizing radiation. How to construct a musculoskeletal rehabilitation evaluation system with low cost, good effect, and little injury is still a great challenge. In this article, we propose MSEva, a musculoskeletal rehabilitation evaluation system based on EMG signals. Specifically, the system uses EMG sensors to collect a large amount of data for five rehabilitation actions. Secondly, MSEva uses Wavelet Transform (WT) to extract the signal features and then puts the processed data into the Long Short-Term Memory (LSTM) network for model training. Finally, the system uses the LSTM model to evaluate the normality of the EMG response of rehabilitation actions. The results show that the average accuracy of MSEva reaches 94.37%, which has important evaluation value in guiding the rehabilitation of musculoskeletal patients.},
journal = {ACM Trans. Sen. Netw.},
month = dec,
articleno = {6},
numpages = {23},
keywords = {EMG signals, rehabilitation evaluation, LSTM network}
}

@inproceedings{10.1145/3459104.3459142,
author = {Amirtha Varshini, A.S. and Bhavani, Guguloth and Vithya and Thilagavathy, R.},
title = {Real-time Hand Gesture Recognition for Robotic Arm and Home Automation},
year = {2021},
isbn = {9781450389839},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459104.3459142},
doi = {10.1145/3459104.3459142},
abstract = {Hand gestures are a symbolic and non-vocal language and are used by an individual to communicate. With computer vision, hand gestures can be detected and be used to talk with a capable computer, leading to the field of Human-Computer interconnection. The field of computer vision has been achieving cutting edge results with the advent of deep learning models. The work implements the Inception v3 architecture [1], which is a convolutional neural network. The model is retrained on our data set using Transfer learning, with which we reduce the requirements on computational resources, data and time. In this project, a hand gesture is performed in front of a web camera of a system. The gestures are predicted as one among six gestures with a corresponding probability. This project deals with the applications of the detected hand gestures in home automation and control of a robotic arm. Hand gestures are simple to perform, and it makes managing home effortless compared to manually intervening and providing instructions to a machine. In the home automation model, the gesture classification results from the system are transmitted to the microcontroller which switches on or off a home device. The robotic arm is a mechanical system which is used in manipulating the movement of lifting, moving, and placing the workpiece to lighten the work of man. It is equipped with servo motors and is controlled by our hand gestures to perform lifting and dropping of objects and rotation of the robotic arm.},
booktitle = {2021 International Symposium on Electrical, Electronics and Information Engineering},
pages = {218–223},
numpages = {6},
location = {Seoul, Republic of Korea},
series = {ISEEIE 2021}
}

@inproceedings{10.1145/3652988.3673934,
author = {Guichoux, T\'{e}o and Soulier, Laure and Obin, Nicolas and Pelachaud, Catherine},
title = {2D or not 2D: How Does the Dimensionality of Gesture Representation Affect 3D Co-Speech Gesture Generation?},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673934},
doi = {10.1145/3652988.3673934},
abstract = {Co-speech gestures are fundamental for communication. The advent of recent deep learning techniques has facilitated the creation of lifelike, synchronous co-speech gestures for Embodied Conversational Agents. "In-the-wild" datasets, aggregating video content from platforms like YouTube via human pose detection technologies, provide a feasible solution by offering 2D skeletal sequences aligned with speech. Concurrent developments in lifting models enable the conversion of these 2D sequences into 3D gesture databases. However, it is important to note that the 3D poses estimated from the 2D extracted poses are, in essence, approximations of the ground-truth, which remains in the 2D domain. This distinction raises questions about the impact of gesture representation dimensionality on the quality of generated motions. Our study examines the effect of using either 2D or 3D joint coordinates as training data on the performance of speech-to-gesture deep generative models.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {22},
numpages = {4},
keywords = {Co-speech gesture generation, Diffusion Models, Pose Representation, Sequence modeling},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@inproceedings{10.1145/3512527.3531408,
author = {Amara, Kenza and Douze, Matthijs and Sablayrolles, Alexandre and J\'{e}gou, Herv\'{e}},
title = {Nearest Neighbor Search with Compact Codes: A Decoder Perspective},
year = {2022},
isbn = {9781450392389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512527.3531408},
doi = {10.1145/3512527.3531408},
abstract = {Modern approaches for fast retrieval of similar vectors on billion-scaled datasets rely on compressed-domain approaches such as binary sketches or product quantization. These methods minimize a certain loss, typically the Mean Squared Error or other objective functions tailored to the retrieval problem. In this paper, we re-interpret popular methods such as binary hashing or product quantizers as auto-encoders, and point out that they implicitly make suboptimal assumptions on the form of the decoder. We design backward-compatible decoders that improve the reconstruction of the vectors from the same codes, which translates to a better performance in nearest neighbor search. Our method significantly improves over binary hashing methods and product quantization on popular benchmarks.},
booktitle = {Proceedings of the 2022 International Conference on Multimedia Retrieval},
pages = {167–175},
numpages = {9},
keywords = {indexing, nearest-neighbors, quantization},
location = {Newark, NJ, USA},
series = {ICMR '22}
}

@inproceedings{10.1145/3581783.3611843,
author = {Ying, Qichao and Liu, Jiaxin and Li, Sheng and Xu, Haisheng and Qian, Zhenxing and Zhang, Xinpeng},
title = {RetouchingFFHQ: A Large-scale Dataset for Fine-grained Face Retouching Detection},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3611843},
doi = {10.1145/3581783.3611843},
abstract = {The widespread use of face retouching filters on short-video platforms has raised concerns about the authenticity of digital appearances and the impact of deceptive advertising. To address these issues, there is a pressing need to develop advanced face retouching techniques. However, the lack of large-scale and fine-grained face retouching datasets has been a major obstacle to progress in this field. In this paper, we introduce RetouchingFFHQ, a large-scale and fine-grained face retouching dataset that contains over half a million conditionally-retouched images. RetouchingFFHQ stands out from previous datasets due to its large scale, high quality, fine-grainedness, and customization. By including four typical types of face retouching operations and different retouching levels, we extend the binary face retouching detection into a fine-grained, multi-retouching type, and multi-retouching level estimation problem. Additionally, we propose a Multi-granularity Attention Module (MAM) as a plugin for CNN backbones for enhanced cross-scale representation learning. Extensive experiments using different baselines as well as our proposed method on RetouchingFFHQ show decent performance on face retouching detection.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {737–746},
numpages = {10},
keywords = {datasets, deep learning, face retouching detection, forensics},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inbook{10.1145/3756423.3756545,
author = {Zhao, Zhiyao and Fu, Tingyu and Yan, Yifei and Han, Bingchen and Xiong, Yueling and Wu, Peng},
title = {The Design of Small-Scale Intelligent Hovercraft},
year = {2025},
isbn = {9798400714351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756423.3756545},
abstract = {To overcome the limitations of traditional hovercraft in complex sea conditions and multifunctional collaborative applications, our team has designed a small intelligent unmanned hovercraft featuring an efficient cushion-lifting system. Based on the core principles of the air-spring model and simulation studies of cushion flow characteristics, we utilized Abaqus software to deeply explore the hovercraft's water-entry dynamics and attitude variations under varying pressures, achieving precise capture of airbag centroid velocity and displacement. A physical model was constructed for CFD simulations, laying a solid foundation for aerodynamic design optimization. The hovercraft integrates multiple sensors, including LIDAR and sonar, to form a comprehensive environmental perception matrix for real-time of obstacle, current and terrain. Driven by data, the intelligent control system incorporates machine learning and expert systems for smart decision-making, enabling precise control of parameters such as speed and steering to achieve adaptive navigation in complex waters or terrains. This innovation opens up new avenues for multi-domain applications and leads the trend in hovercraft technology transformation.},
booktitle = {Proceedings of the 2025 International Conference on Artificial Intelligence and Smart Manufacturing},
pages = {742–745},
numpages = {4}
}

@inproceedings{10.1145/3658617.3697565,
author = {Liu, Fangxin and Wang, Zongwu and Xu, Peng and Huang, Shiyuan and Jiang, Li},
title = {Exploiting Differential-Based Data Encoding for Enhanced Query Efficiency},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697565},
doi = {10.1145/3658617.3697565},
abstract = {Storing large-scale high-dimensional data, which is rapidly generated by both industry and academia, poses substantial challenges, primarily in terms of storage and maintenance costs. While data compression techniques offer a potential solution to these challenges, they must overcome two critical hurdles: 1) preserving data integrity within lossless bounds and 2) maintaining query performance on compressed data.To address the above challenges, we propose a novel approach based on differential techniques that combine high-dimensional data compression with an efficient query engine. Specifically, Our methodology begins by employing vector quantization to transform high-dimensional vectors into compact integer sequences, known as quantization codes---a classical and versatile compression method. Subsequently, we introduce DCQ, which builds upon the differential concept to perform lossless compression on quantization codes. DCQ organizes quantization codes into a tree structure and constructs a hierarchy of trees by analyzing the dissimilarity between two quantization codes. To minimize the impact on query performance, we have developed an adaptive reconstruction algorithm that partitions and reconstructs the original tree structure. This algorithm effectively balances the workload for searching each sub-tree, optimizing the compression-performance trade-off. Finally, we adopt a storage format based on multiple subtrees for rapid searching, thereby enabling differential storage to facilitate efficient queries. Extensive experiments on various large-scale real-world datasets show that DCQ achieves a compression ratio of up to 2.5 on the quantization codes and achieves &gt; 50\texttimes{} performance improvement compared to the state-of-the-art general-purpose lossless compression techniques.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {594–600},
numpages = {7},
location = {Tokyo, Japan},
series = {ASPDAC '25}
}

@inproceedings{10.1145/3579990.3580008,
author = {Thangamani, Arun and Jost, Tiago Trevisan and Loechner, Vincent and Genaud, St\'{e}phane and Bramas, B\'{e}renger},
title = {Lifting Code Generation of Cardiac Physiology Simulation to Novel Compiler Technology},
year = {2023},
isbn = {9798400701016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579990.3580008},
doi = {10.1145/3579990.3580008},
abstract = {The study of numerical models for the human body has become a major focus of the research community in biology and medicine.   For instance, numerical ionic models of a complex organ, such as the heart, must be able to represent individual cells and their interconnections through ionic channels, forming a system with billions of cells, and requiring efficient code to handle such a large system.   The modeling of the electrical system of the heart combines a compute-intensive kernel that calculates the intensity of current flowing through cell membranes, and feeds a linear solver for computing the electrical potential of each cell.    Considering this context, we propose limpetMLIR, a code generator and compiler transformer to accelerate the kernel phase of ionic models and bridge the gap between compiler technology and electrophysiology simulation.   LimpetMLIR makes use of the MLIR infrastructure, its dialects, and transformations to drive forward the study of ionic models, and accelerate the execution of multi-cell systems.   Experiments conducted in 43 ionic models show that our limpetMLIR based code generation greatly outperforms current state-of-the-art simulation systems by an average of   2.9x, reaching peak speedups of more than 15x in some cases.   To our knowledge, this is the first work that deeply connects an optimizing compiler infrastructure to electrophysiology models of the human body, showing the potential benefits of using compiler technology in the simulation of human cell interactions.},
booktitle = {Proceedings of the 21st ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {68–80},
numpages = {13},
keywords = {Code generation and optimization, code transformation, domain-specific languages, vectorization},
location = {Montr\'{e}al, QC, Canada},
series = {CGO '23}
}

@inproceedings{10.1145/3457335.3461712,
author = {Mehmood, Usama and Bak, Stanley and Smolka, Scott A. and Stoller, Scott D.},
title = {Safe CPS from unsafe controllers},
year = {2021},
isbn = {9781450383998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3457335.3461712},
doi = {10.1145/3457335.3461712},
abstract = {Modern cyber-physical systems (CPS) interact with the physical world, hence their correctness is important. In this work, we build upon the Simplex Architecture, where control authority may switch from an unverified and potentially unsafe advanced controller to a verified-safe baseline controller in order to maintain system safety. We take the approach further by lifting the requirement that the baseline controller must be verified or even correct, instead also treating it as a black-box component. This change is important; there are many types of powerful control techniques---model predictive control and neural network controllers---that often work well in practice, but are unlikely to be formally proven correct due to complexity. We prove such an architecture maintains safety, and present case studies where model-predictive control provides safety for multi-robot coordination, and unverified neural networks provably prevent collisions for groups of F-16 aircraft.},
booktitle = {Proceedings of the Workshop on Computation-Aware Algorithmic Design for Cyber-Physical Systems},
pages = {26–28},
numpages = {3},
keywords = {cyber-physical systems, formal verification, simplex architecture},
location = {Nashville, Tennessee},
series = {CAADCPS '21}
}

@article{10.1145/3687463,
author = {Mack, Joshua and Krishnakumar, Anish and Ogras, Umit and Akoglu, Ali},
title = {Tutorial: A Novel Runtime Environment for Accelerator-Rich Heterogeneous Architectures},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
issn = {1539-9087},
url = {https://doi.org/10.1145/3687463},
doi = {10.1145/3687463},
abstract = {As the landscape of computing advances, system designers are increasingly exploring methodologies that leverage higher levels of heterogeneity to enhance performance within constrained size, weight, power, and cost parameters. CEDR (Compiler-integrated Extensible DSSoC Runtime) stands as an ecosystem facilitating productive and efficient application development and deployment across heterogeneous computing systems. It fosters the co-design of applications, scheduling heuristics, and accelerators within a unified framework. Our goal is to present CEDR as a promising environment for lifting the barriers to research on heterogeneous systems and addressing the broader challenges within domain-specific architectures. We introduce CEDR and discuss the evolutionary design decisions underlying its programming model. Subsequently, we explore its utility for a broad range of users through design sweeps on off-the-shelf heterogeneous platforms across scheduling heuristics, hardware compositions, and workload scenarios.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = dec,
articleno = {20},
numpages = {24},
keywords = {Domain-specific SoCs, heterogeneous application runtimes}
}

@inproceedings{10.1145/3494110.3528244,
author = {Shafiei, Ali and Rimmer, Vera and Tsingenopoulos, Ilias and Desmet, Lieven and Joosen, Wouter},
title = {Position Paper: On Advancing Adversarial Malware Generation Using Dynamic Features},
year = {2022},
isbn = {9781450391795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494110.3528244},
doi = {10.1145/3494110.3528244},
abstract = {Along the evolution of malware detection systems, adversaries develop sophisticated evasion techniques that render malicious samples undetectable. Especially for ML-based detection systems, an effective approach is to craft adversarial malware to evade detection. In this position paper, we conduct a critical review of existing adversarial attacks against malware detection, and conclude that current research focuses mainly on evasion techniques against static analysis; generating adversarial Windows samples to evade dynamic analysis remains largely unexplored. In the context of black-box attack scenarios, we investigate an adversary's potential to carry out practical transformations in order to influence behavioral features observed by ML systems and security products. Moreover, we investigate the range of dynamic behavior transformations and identify critical properties and associated challenges that relate to feasibility, automation, technical costs and detection risks. Through this discussion, we propose solutions to important challenges and present promising paths for future research on evasive malware under dynamic analysis.},
booktitle = {Proceedings of the 1st Workshop on Robust Malware Analysis},
pages = {15–20},
numpages = {6},
keywords = {adversarial attack, dynamic analysis, evasion, malware detection},
location = {Nagasaki, Japan},
series = {WoRMA '22}
}

@inproceedings{10.1145/3708359.3712122,
author = {Srinivasan, Arjun and Setlur, Vidya and Satyanarayan, Arvind},
title = {Pluto: Authoring Semantically Aligned Text and Charts for Data-Driven Communication},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712122},
doi = {10.1145/3708359.3712122},
abstract = {Textual content (including titles, annotations, and captions) plays a central role in helping readers understand a visualization by emphasizing, contextualizing, or summarizing the depicted data. Yet, existing visualization tools provide limited support for jointly authoring the two modalities of text and visuals such that both convey semantically-rich information and are cohesively integrated. In response, we introduce Pluto, a mixed-initiative authoring system that uses features of a chart’s construction (e.g., visual encodings) as well as any textual descriptions a user may have drafted to make suggestions about the content and presentation of the two modalities. For instance, a user can begin to type out a description and interactively brush a region of interest in the chart, and Pluto&nbsp;will generate a relevant auto-completion of the sentence. Similarly, based on a written description, Pluto&nbsp;may suggest lifting a sentence out as an annotation or the visualization’s title, or may suggest applying a data transformation (e.g., sort) to better align the two modalities. A preliminary user study revealed that Pluto’s recommendations were particularly useful for bootstrapping the authoring process and helped identify different strategies participants adopt when jointly authoring text and charts. Based on study feedback, we discuss design implications for integrating interactive verification features between charts and text, offering control over text verbosity and tone, and enhancing the bidirectional flow in unified text and chart authoring tools.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1123–1140},
numpages = {18},
keywords = {Visualization, description, caption, mixed-initiative, recommendation.},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3649476.3660380,
author = {Saber Latibari, Banafsheh and Salehi, Soheil and Homayoun, Houman and Sasan, Avesta},
title = {IRET: Incremental Resolution Enhancing Transformer},
year = {2024},
isbn = {9798400706059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649476.3660380},
doi = {10.1145/3649476.3660380},
abstract = {In our research paper, we introduce a revolutionary approach to designing energy-aware dynamically prunable Vision Transformers for use in edge applications. Our solution denoted as Incremental Resolution Enhancing Transformer (IRET), works by the sequential sampling of the input image. However, in our case, the embedding size of input tokens is considerably smaller than prior-art solutions. This embedding is used in the first few layers of the IRET vision transformer until a reliable attention matrix is formed. Then the attention matrix is used to sample additional information using a learnable 2D lifting scheme only for important tokens and IRET drops the tokens receiving low attention scores. Hence, as the model pays more attention to a subset of tokens for its task, its focus and resolution also increase. This incremental attention-guided sampling of input and dropping of unattended tokens allow IRET to significantly prune its computation tree on demand. By controlling the threshold for dropping unattended tokens and increasing the focus of attended ones, we can train a model that dynamically trades off complexity for accuracy. This is especially useful for edge devices, where accuracy and complexity could be dynamically traded based on factors such as battery life, reliability, etc.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2024},
pages = {620–625},
numpages = {6},
keywords = {Attention, Focus, Token Dropping, Vision Transformer},
location = {Clearwater, FL, USA},
series = {GLSVLSI '24}
}

@inbook{10.1145/3743093.3771064,
author = {Wicaksono, Nugroho and Muflikhah, Lailil and Yudistira, Novanto},
title = {IDiffPose: Equilibrium Substitution for Lightweight Diffusion-Graph-Based Pose Estimation},
year = {2025},
isbn = {9798400720055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3743093.3771064},
abstract = {Recent diffusion–graph frameworks such as DiffPose have advanced monocular 2D-to-3D pose lifting by coupling graph convolutional networks (GCNs) with denoising diffusion models. However, their depth is still bounded by the number of explicit attention–GCN blocks, limiting the receptive field under a fixed parameter budget. We propose IDiffPose, short for Implicit Diffusion Pose, an equilibrium substitution that replaces a selected deep block with a weight-tied operator whose representation is computed via a small number of unrolled fixed-point iterations. The training objective remains standard DDPM-style denoising, inference uses a deterministic DDIM sampler, and the forward process injects heteroscedastic Gaussian noise scaled by 2D heat-map uncertainty. Because the same weights are re-used across iterations, the model attains large effective depth with a compact parameter footprint; when non-equilibrium blocks are frozen, the number of trainable parameters drops substantially. On Human3.6M, substituting only the middle block improves MPJPE from 31.55 to 31.10&nbsp;mm and P-MPJPE from 24.72 to 24.47&nbsp;mm with 167,521 trainable parameters (vs. 1,025,674 explicit), while making all blocks implicit reaches 30.90/24.51&nbsp;mm. These results show equilibrium substitution is a practical drop-in upgrade for diffusion-based pose lifting, yielding consistent accuracy with favorable efficiency controls.},
booktitle = {Proceedings of the 7th ACM International Conference on Multimedia in Asia},
articleno = {118},
numpages = {5}
}

@article{10.1145/3631412,
author = {Wang, Yang and Hong, Feng and Jiang, Yufei and Bao, Chenyu and Liu, Chao and Guo, Zhongwen},
title = {ToothFairy: Real-time Tooth-by-tooth Brushing Monitor Using Earphone Reversed Signals},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3631412},
doi = {10.1145/3631412},
abstract = {Tooth brushing monitors have the potential to enhance oral hygiene and encourage the development of healthy brushing habits. However, previous studies fall short of recognizing each tooth due to limitations in external sensors and variations among users. To address these challenges, we present ToothFairy, a real-time tooth-by-tooth brushing monitor that uses earphone reverse signals captured within the oral cavity to identify each tooth during brushing. The key component of ToothFairy is a novel bone-conducted acoustic attenuation model, which quantifies sound propagation within the oral cavity. This model eliminates the need for machine learning and can be calibrated with just one second of brushing data for each tooth by a new user. ToothFairy also addresses practical issues such as brushing detection and tooth region determination. Results from extensive experiments, involving 10 volunteers and 25 combinations of five commercial off-the-shelf toothbrush and earphone models each, show that ToothFairy achieves tooth recognition with an average accuracy of 90.5%.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {185},
numpages = {19},
keywords = {Acoustic Attenuation, Earphone Reversed Signals, Toothbrushing}
}

@inproceedings{10.1145/3663529.3663865,
author = {Dinella, Elizabeth and Lahiri, Shuvendu K. and Naik, Mayur},
title = {Inferring Natural Preconditions via Program Transformation},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663865},
doi = {10.1145/3663529.3663865},
abstract = {We introduce an approach for inferring natural preconditions from code. Prior works generate preconditions from scratch through combinations of boolean predicates, but fall short in readability and ease of comprehension. In contrast, our technique leverages the structure of the target method as a seed to infer a precondition through program transformations. Our technique is a multi-phase approach involving iterative test generation and program transformation. Our evaluation shows that humans can more easily reason over preconditions inferred using our approach. Consumers of our preconditions completed reasoning tasks more accurately (92.86%) with an average total duration of 109 seconds. In contrast, consumers of the preconditions inferred by prior work took twice as long (217 seconds) to finish the study and answered with lower accuracy (85.61%).},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {657–658},
numpages = {2},
keywords = {Automated Testing, Natural Language Processing, Preconditions},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@article{10.1145/3547643,
author = {Vasilenko, Elizaveta and Vazou, Niki and Barthe, Gilles},
title = {Safe couplings: coupled refinement types},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {ICFP},
url = {https://doi.org/10.1145/3547643},
doi = {10.1145/3547643},
abstract = {We enhance refinement types with mechanisms to reason about relational properties of probabilistic computations. Our mechanisms, which are inspired from probabilistic couplings, are applicable to a rich set of probabilistic properties, including expected sensitivity, which ensures that the distance between outputs of two probabilistic computations can be controlled from the distance between their inputs. We implement our mechanisms in the type system of Liquid Haskell and we use them to formally verify Haskell implementations of two classic machine learning algorithms: Temporal Difference (TD) reinforcement learning and stochastic gradient descent (SGD). We formalize a fragment of our system for discrete distributions and we prove soundness with respect to a set-theoretical semantics.},
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {112},
numpages = {29},
keywords = {Haskell, program verification, refinement types, relational types}
}

@inproceedings{10.1145/3383455.3422520,
author = {Watson, William and Liu, Bo},
title = {Financial table extraction in image documents},
year = {2021},
isbn = {9781450375849},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383455.3422520},
doi = {10.1145/3383455.3422520},
abstract = {Table extraction has long been a pervasive problem in financial services. This is more challenging in the image domain, where content is locked behind cumbersome pixel format. Luckily, advances in deep learning for image segmentation, OCR, and sequence modeling provides the necessary heavy lifting to achieve impressive results. This paper presents an end-to-end pipeline for identifying, extracting and transcribing tabular content in image documents, while retaining the original spatial relations with high fidelity.},
booktitle = {Proceedings of the First ACM International Conference on AI in Finance},
articleno = {51},
numpages = {8},
keywords = {financial tables, image segmentation, optical character recognition, sequence modeling, table extraction},
location = {New York, New York},
series = {ICAIF '20}
}

@inproceedings{10.1145/3759355.3759627,
author = {F\'{o}thi, \'{A}ron and Fazekas, Bence and Gy\"{o}ngy\"{o}ssy, Natabara M\'{a}t\'{e} and Fenech, Kristian},
title = {Skel3D: Skeleton Guided Novel View Synthesis},
year = {2025},
isbn = {9798400715891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3759355.3759627},
doi = {10.1145/3759355.3759627},
abstract = {In this paper, we present an approach for monocular open-set novel view synthesis (NVS) that leverages object skeletons to guide the underlying diffusion model. Building upon a baseline that utilizes a pre-trained 2D image generator, our method takes advantage of the Objaverse dataset, which includes animated objects with bone structures. By introducing a skeleton guide layer following the existing ray conditioning normalization (RCN) layer, our approach enhances pose accuracy and multiview consistency. The skeleton guide layer provides detailed structural information for the generative model, improving the quality of the synthesized views. Experimental results demonstrate that our skeleton-guided method significantly enhances consistency and accuracy across diverse object categories within the Objaverse dataset. Our method outperforms existing state-of-the-art NVS techniques both quantitatively and qualitatively, without relying on explicit 3D representations. The code is available at https://github.com/skel3d/skel3d},
booktitle = {Proceedings of the Intelligent Robotics FAIR 2025},
pages = {92–99},
numpages = {8},
location = {
},
series = {IntRob '25}
}

@article{10.1145/3763358,
author = {Wei, Kaixuan and Romero, Hector and Amata, Hadi and Sun, Jipeng and Fu, Qiang and Heide, Felix and Heidrich, Wolfgang},
title = {Large-Area Fabrication-aware Computational Diffractive Optics},
year = {2025},
issue_date = {December 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3763358},
doi = {10.1145/3763358},
abstract = {Differentiable optics, as an emerging paradigm that jointly optimizes optics and (optional) image processing algorithms, has made many innovative optical designs possible across a broad range of imaging and display applications. Many of these systems utilize diffractive optical components for holography, PSF engineering, or wavefront shaping. Existing approaches have, however, mostly remained limited to laboratory prototypes, owing to a large quality gap between simulation and manufactured devices.We aim at lifting the fundamental technical barriers to the practical use of learned diffractive optical systems. To this end, we propose a fabrication-aware design pipeline for diffractive optics fabricated by direct-write grayscale lithography followed by replication with nano-imprinting, which is directly suited for inexpensive mass-production of large area designs. We propose a super-resolved neural lithography model that can accurately predict the 3D geometry generated by the fabrication process. This model can be seamlessly integrated into existing differentiable optics frameworks, enabling fabrication-aware, end-to-end optimization of computational optical systems. To tackle the computational challenges, we also devise tensor-parallel compute framework centered on distributing large-scale FFT computation across many GPUs.As such, we demonstrate large scale diffractive optics designs up to 32.16 mm \texttimes{} 21.44 mm, simulated on grids of up to 128,640 by 85,760 feature points. We find adequate agreement between simulation and fabricated prototypes for applications such as holography and PSF engineering. We also achieve high image quality from an imaging system comprised only of a single diffractive optical element, with images processed only by a one-step inverse filter utilizing the simulation PSF. We believe our findings lift the fabrication limitations for real-world applications of diffractive optics and differentiable optical design.},
journal = {ACM Trans. Graph.},
month = dec,
articleno = {243},
numpages = {17},
keywords = {computational optics, computational imaging, computational fabrication}
}

@inproceedings{10.1145/3503222.3507714,
author = {Ahmad, Maaz Bin Safeer and Root, Alexander J. and Adams, Andrew and Kamil, Shoaib and Cheung, Alvin},
title = {Vector instruction selection for digital signal processors using program synthesis},
year = {2022},
isbn = {9781450392051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503222.3507714},
doi = {10.1145/3503222.3507714},
abstract = {Instruction selection, whereby input code represented in an intermediate representation is translated into executable instructions from the target platform, is often the most target-dependent component in optimizing compilers. Current approaches include pattern matching, which is brittle and tedious to design, or search-based methods, which are limited by scalability of the search algorithm. In this paper, we propose a new algorithm that first abstracts the target platform instructions into high-level uber-instructions, with each uber-instruction unifying multiple concrete instructions from the target platform. Program synthesis is used to lift input code sequences into semantically equivalent sequences of uber-instructions and then to lower from uber-instructions to machine code. Using 21 real-world benchmarks, we show that our synthesis-based instruction selection algorithm can generate instruction sequences for a hardware target, with the synthesized code performing up to 2.1x faster as compared to code generated by a professionally-developed optimizing compiler for the same platform.},
booktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {1004–1016},
numpages = {13},
keywords = {Instruction selection, compiler optimizations, program synthesis},
location = {Lausanne, Switzerland},
series = {ASPLOS '22}
}

@article{10.1145/3434333,
author = {Aguirre, Alejandro and Barthe, Gilles and Hsu, Justin and Kaminski, Benjamin Lucien and Katoen, Joost-Pieter and Matheja, Christoph},
title = {A pre-expectation calculus for probabilistic sensitivity},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {POPL},
url = {https://doi.org/10.1145/3434333},
doi = {10.1145/3434333},
abstract = {Sensitivity properties describe how changes to the input of a program affect the output, typically by upper bounding the distance between the outputs of two runs by a monotone function of the distance between the corresponding inputs. When programs are probabilistic, the distance between outputs is a distance between distributions. The Kantorovich lifting provides a general way of defining a distance between distributions by lifting the distance of the underlying sample space; by choosing an appropriate distance on the base space, one can recover other usual probabilistic distances, such as the Total Variation distance. We develop a relational pre-expectation calculus to upper bound the Kantorovich distance between two executions of a probabilistic program. We illustrate our methods by proving algorithmic stability of a machine learning algorithm, convergence of a reinforcement learning algorithm, and fast mixing for card shuffling algorithms. We also consider some extensions: using our calculus to show convergence of Markov chains to the uniform distribution over states and an asynchronous extension to reason about pairs of program executions with different control flow.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {52},
numpages = {28},
keywords = {probabilistic programming, verification}
}

@inproceedings{10.1145/3583780.3615100,
author = {Liu, Runshi and Hou, Zhipeng},
title = {UniTE: A Unified Treatment Effect Estimation Method for One-sided and Two-sided Marketing},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615100},
doi = {10.1145/3583780.3615100},
abstract = {Many internet platforms are two-sided markets that involve two types of participants. Examples include e-commerce platforms like Taobao (retailers and consumers) and ride-hailing platforms like Uber (drivers and passengers). Participants of different types in the two-sided market have relationships (i.e., supply and demand) that provide externalities and network benefits. On two-sided platforms, marketing campaigns are designed by subsidizing supply or demand. Uplift models built in this scenario usually consider the treatment assignment for only one of the two sides. However, ignoring the interaction of treatments between two sides or treating them as noises may result in incomplete models and inaccurate predictions. As far as we know, there is not much work related to modeling the combinational treatment effects in the two-sided market. In this paper, we first introduce the two-sided treatment effects estimation problem and then propose a Unified Treatment effect Estimation (UniTE) method for one-sided and two-sided marketing. We extend the Robinson Decomposition to two-sided, in which the relationship of the three involved tasks, namely the outcome, the propensity, and the treatment effect, is theoretically derived. Based on the decomposition result, a multi-task-based neural network model is proposed to integrate the three tasks and learn the inter-task-related common information, which prompts the model to estimate the treatment effects better. We also propose a unified synthetic data generation method that adapts to one/two-sided situations to verify the treatment effects estimation performance. Extensive and comprehensive experimental results show that our method outperforms the other methods.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {1472–1481},
numpages = {10},
keywords = {multi-task learning, neural networks, optimization, treatment effects, two-sided market, uplift},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@article{10.1109/TASLP.2023.3294692,
author = {Lemercier, Jean-Marie and Richter, Julius and Welker, Simon and Gerkmann, Timo},
title = {StoRM: A Diffusion-Based Stochastic Regeneration Model for Speech Enhancement and Dereverberation},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3294692},
doi = {10.1109/TASLP.2023.3294692},
abstract = {Diffusion models have shown a great ability at bridging the performance gap between predictive and generative approaches for speech enhancement. We have shown that they may even outperform their predictive counterparts for non-additive corruption types or when they are evaluated on mismatched conditions. However, diffusion models suffer from a high computational burden, mainly as they require to run a neural network for each reverse diffusion step, whereas predictive approaches only require one pass. As diffusion models are generative approaches they may also produce vocalizing and breathing artifacts in adverse conditions. In comparison, in such difficult scenarios, predictive models typically do not produce such artifacts but tend to distort the target speech instead, thereby degrading the speech quality. In this work, we present a stochastic regeneration approach where an estimate given by a predictive model is provided as a guide for further diffusion. We show that the proposed approach uses the predictive model to remove the vocalizing and breathing artifacts while producing very high quality samples thanks to the diffusion model, even in adverse conditions. We further show that this approach enables to use lighter sampling schemes with fewer diffusion steps without sacrificing quality, thus lifting the computational burden by an order of magnitude. Source code and audio examples are available online.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jul,
pages = {2724–2737},
numpages = {14}
}

@inproceedings{10.1145/3474963.3474993,
author = {Guo, Wanda and Wang, Xin and Jiao, Bo},
title = {Real-time Obstacles Avoidance for Crawler Crane based on DQN},
year = {2021},
isbn = {9781450389792},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474963.3474993},
doi = {10.1145/3474963.3474993},
abstract = {Safety always is a crucial consideration for crawler cranes running with dozens of tons of load in its work site. However, around its work site, besides static obstacles, there are many dynamic obstacles, such as workers and engineering vehicles. These obstacles are potential risk for crane in congested work site. Therefore, risk probability and loss can be reduced in project of lifting engineering by dynamic lift-path planning system. However, presently, most proposed methods pay attention to search path in totally known environment. In this paper, we present a dynamic obstacles avoidance planner for crawler cranes in no-walk scenarios in partially known environment. This planner considers the lifted module as a 3DOF convex robot with discrete rotational and translational motions. First, we improved the structure of neural network of Deep Q-network by applying Resnet block for achieving real-time path planning for crawler crane. Thereafter, we also improved Artificial Potential Field Method (APFM) and apply it to search path for lifted module. And for shortening training time, we also apply the data generated by APFM to pre-train our neural network. Finally, we verified and compared the performance of APFM and DQN by simulation. The result of simulation can demonstrate the effectiveness of the presented planner.},
booktitle = {Proceedings of the 13th International Conference on Computer Modeling and Simulation},
pages = {210–217},
numpages = {8},
keywords = {APFM, Crane, DQN, Path planning},
location = {Melbourne, VIC, Australia},
series = {ICCMS '21}
}

@inproceedings{10.1145/3503161.3547871,
author = {Qiu, Zhongwei and Yang, Qiansheng and Wang, Jian and Fu, Dongmei},
title = {IVT: An End-to-End Instance-guided Video Transformer for 3D Pose Estimation},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3547871},
doi = {10.1145/3503161.3547871},
abstract = {Video 3D human pose estimation aims to localize the 3D coordinates of human joints from videos. Recent transformer-based approaches focus on capturing the spatiotemporal information from sequential 2D poses, which cannot model the contextual depth feature effectively since the visual depth features are lost in the step of 2D pose estimation. In this paper, we simplify the paradigm into an end-to-end framework, Instance-guided Video Transformer (IVT), which enables learning spatiotemporal contextual depth information from visual features effectively and predicts 3D poses directly from video frames. In particular, we firstly formulate video frames as a series of instance-guided tokens and each token is in charge of predicting the 3D pose of a human instance. These tokens contain body structure information since they are extracted by the guidance of joint offsets from the human center to the corresponding body joints. Then, these tokens are sent into IVT for learning spatiotemporal contextual depth. In addition, we propose a cross-scale instance-guided attention mechanism to handle the variational scales among multiple persons. Finally, the 3D poses of each person are decoded from instance-guided tokens by coordinate regression. Experiments on three widely-used 3D pose estimation benchmarks show that the proposed IVT achieves state-of-the-art performances.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {6174–6182},
numpages = {9},
keywords = {human pose estimation, video transformer},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inbook{10.1145/3727648.3727699,
author = {Xu, Wei and Wang, Jirong},
title = {Mechanical structure design of lower limb rehabilitation training robot},
year = {2025},
isbn = {9798400712647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727648.3727699},
abstract = {In this paper, a rehabilitation training robot with passive and active rehabilitation training modes is designed for patients who are unable to stand and walk, such as those paralysed by traumatic brain injury or stroke, and the selection and design of the robot's mechanical structure and control system are completed according to the design parameters and requirements. The three-dimensional virtual prototype of the lower limb rehabilitation training robot is established by Solidworks and simplified into a two-dimensional planar model for easy analysis to derive the dynamics model of the system in the joint space, which is capable of describing the mechanical characteristics and dynamic behaviour of the robot in the process of movement, and it has an important practical application value for the in-depth study of lower limb rehabilitation robots.},
booktitle = {Proceedings of the 4th International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {303–309},
numpages = {7}
}

@inproceedings{10.1145/3641519.3657480,
author = {Jang, Wonjong and Jung, Yucheol and Kim, Hyomin and Ju, Gwangjin and Son, Chaewon and Son, Jooeun and Lee, Seungyong},
title = {Toonify3D: StyleGAN-based 3D Stylized Face Generator},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657480},
doi = {10.1145/3641519.3657480},
abstract = {Recent advances in generative models enable high-quality facial image stylization. Toonify is a popular StyleGAN-based framework that has been widely used for facial image stylization. Our goal is to create expressive 3D faces by turning Toonify into a 3D stylized face generator. Toonify is fine-tuned with a few gradient descent steps from StyleGAN trained for standard faces, and its features would carry semantic and visual information aligned with the features of the original StyleGAN model. Based on this observation, we design a versatile 3D-lifting method for StyleGAN, StyleNormal, that regresses a surface normal map of a StyleGAN-generated face using StyleGAN features. Due to the feature alignment between Toonify and StyleGAN, although StyleNormal is trained for regular faces, it can be applied for various stylized faces without additional fine-tuning. To learn local geometry of faces under various illuminations, we introduce a novel regularization term, the normal consistency loss, based on lighting manipulation in the GAN latent space. Finally, we present Toonify3D, a fully automated framework based on StyleNormal, that can generate full-head 3D stylized avatars and support GAN-based 3D facial expression editing.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {17},
numpages = {11},
keywords = {3D face stylization, StyleGAN, Toonify},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3757377.3763810,
author = {Liu, Mengfei and Chang, Yue and Wang, Zhecheng and Chen, Peter Yichen and Grinspun, Eitan},
title = {Precise Gradient Discontinuities in Neural Fields for Subspace Physics},
year = {2025},
isbn = {9798400721373},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757377.3763810},
doi = {10.1145/3757377.3763810},
abstract = {Discontinuities in spatial derivatives appear in a wide range of physical systems, from creased thin sheets to materials with sharp stiffness transitions. Accurately modeling these features is essential for simulation but remains challenging for traditional mesh-based methods, which require discontinuity-aligned remeshing—entangling geometry with simulation and hindering generalization across shape families. Neural fields offer an appealing alternative by encoding basis functions as smooth, continuous functions over space, enabling simulation across varying shapes. However, their smoothness makes them poorly suited for representing gradient discontinuities. Prior work addresses discontinuities in function values, but capturing sharp changes in spatial derivatives while maintaining function continuity has received little attention. We introduce a neural field construction that captures gradient discontinuities without baking their location into the network weights. By augmenting input coordinates with a smoothly clamped distance function in a lifting framework, we enable encoding of gradient jumps at evolving interfaces. This design supports discretization-agnostic simulation of parametrized shape families with heterogeneous materials and evolving creases, enabling new reduced-order capabilities such as shape morphing, interactive crease editing, and simulation of soft-rigid hybrid structures. We further demonstrate that our method can be combined with previous lifting techniques to jointly capture both gradient and value discontinuities, supporting simultaneous cuts and creases within a unified model.},
booktitle = {Proceedings of the SIGGRAPH Asia 2025 Conference Papers},
articleno = {26},
numpages = {11},
keywords = {Heterogeneous Elastodynamics, Discontinuity, Crease, Reduced-order modeling, Implicit neural representation},
location = {
},
series = {SA Conference Papers '25}
}

@inproceedings{10.1145/3447993.3482861,
author = {Wang, Ruxin and Huang, Long and Wang, Chen},
title = {Distracted driving detection by sensing the hand gripping of the phone},
year = {2021},
isbn = {9781450383424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447993.3482861},
doi = {10.1145/3447993.3482861},
abstract = {Phone usage while driving is unanimously considered a really dangerous habit due to a strong correlation with road accidents. This paper proposes a phone-use monitoring system that detects the driver's handheld phone use and eliminates the distraction at once. Specifically, the proposed system emits periodic ultrasonic pulses to sense if the phone is being held in hand or placed on support surfaces (e.g., seat and cup holder) by capturing the unique signal interference resulted from the contact object's damping, reflection and refraction. We derive the short-time Fourier transform from the microphone data to describe such impacts and develop a CNN-based binary classifier to discriminate the phone use between the handheld and the handsfree status. Additionally, we design a classification error correction filter to correct the classification errors during the monitoring. The experiments with six people, one phone and one car model show that our system achieves 99% accuracy in recognizing handheld phone-use activities.},
booktitle = {Proceedings of the 27th Annual International Conference on Mobile Computing and Networking},
pages = {828–830},
numpages = {3},
keywords = {acoustic sensing, driver safety, phone-use monitoring},
location = {New Orleans, Louisiana},
series = {MobiCom '21}
}

@inproceedings{10.1145/3705391.3705419,
author = {Wang, Wenbo and Lai, Wugang and Lin, Fanqiang and Zhao, Hongshun},
title = {Design of Micro Digital Power Analysis and Detection Device},
year = {2025},
isbn = {9798400709630},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3705391.3705419},
doi = {10.1145/3705391.3705419},
abstract = {A power analyzer is an instrument used to test the performance of electrical appliances and troubleshoot electrical faults. At present, the power analyzer on the market generally has the disadvantages of difficult to use, high energy consumption, expensive and so on. Therefore, a micro digital power analysis and detection device is proposed in this paper, which can solve the above problems well. This device uses STM32F407 as the core processor, combined with the OPA227,TLC2254A and other precision operational amplifiers to form the core part of the device. The transformer circuit in the device can collect the power signal of the electrical equipment, and convert the power signal into a low-level signal that can be collected by ADC through the conversion circuit and digital phase discriminator, and then transmit it to the MCU for FFT calculation and filtering processing. Finally, the parameters such as active power and total harmonic distortion (THD) are displayed on the screen, so as to analyze the performance and state of the electrical equipment. The experimental results show that the device has the advantages of low power consumption, less cost and simple use when the measurement parameters are accurate.},
booktitle = {Proceedings of the 2024 6th International Conference on Telecommunications and Communication Engineering},
pages = {175–179},
numpages = {5},
keywords = {Fourier Transform Algorithm, Operational Amplifier, Power Analyzer, STM32},
location = {
},
series = {ICTCE '24}
}

@inproceedings{10.1145/3743049.3743062,
author = {Hartfill, Judith and Arz, Michael and Steinicke, Frank},
title = {EMG-based Confirmation of Gaze Selection in Extended Reality},
year = {2025},
isbn = {9798400715822},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3743049.3743062},
doi = {10.1145/3743049.3743062},
abstract = {Gaze input is an emerging technology for head-mounted displays (HMDs). While selecting a target object with gaze can be quick, confirming this selection solely through gaze is difficult. Thus, alternative approaches (like vision-based pinching) are needed, but may not be accessible (e.g., because of missing limbs), feasible (e.g., in low light), or acceptable (e.g., in public spaces). This paper explores electrode placement for electromyography (EMG) on legs, arms, and face and compares four methods for confirming gaze selection: (A) Palm lifting, (B) Finger tapping, (C) Biting, and (D) Foot tapping. In a preliminary study, we evaluated these techniques based on task completion time and user preference and compared them to a camera-based hand gesture selection method (pinching) as a baseline. Users performed specific gestures recognized via electrodes. Results indicated similar task completion times across all placements, with Foot tapping and Finger tapping preferred by users. We then conducted a user study assessing EMG-based confirmations with Foot tapping and Finger tapping versus a hand gesture method (pinching), using built-in hand tracking. Results showed that while most participants preferred pinching, EMG-based gestures performed comparably and demonstrated potential as an alternative to camera-based confirmation techniques.},
booktitle = {Proceedings of the Mensch Und Computer 2025},
pages = {375–384},
numpages = {10},
keywords = {Eye gaze, confirmation, EMG, gesture, VR, XR},
location = {
},
series = {MuC '25}
}

@inproceedings{10.1145/3526113.3545683,
author = {Xu, Zheer and Meng, Yankang and Bi, Xiaojun and Yang, Xing-Dong},
title = {Phrase-Gesture Typing on Smartphones},
year = {2022},
isbn = {9781450393201},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526113.3545683},
doi = {10.1145/3526113.3545683},
abstract = {We study phrase-gesture typing, a gesture typing method that allows users to type short phrases by swiping through all the letters of the words in a phrase using a single, continuous gesture. Unlike word-gesture typing, where text needs to be entered word by word, phrase-gesture typing enters text phrase by phrase. To demonstrate the usability of phrase-gesture typing, we implemented a prototype called PhraseSwipe. Our system is composed of a frontend interface designed specifically for typing through phrases and a backend phrase-level gesture decoder developed based on a transformer-based neural language model. Our decoder was trained using five million phrases of varying lengths of up to five words, chosen randomly from the Yelp Review Dataset. Through a user study with 12 participants, we demonstrate that participants could type using PhraseSwipe at an average speed of 34.5 WPM with a Word Error Rate of 1.1%.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
articleno = {55},
numpages = {11},
keywords = {gesture input, language model, machine learning, text entry},
location = {Bend, OR, USA},
series = {UIST '22}
}

@inproceedings{10.1145/3776865.3776893,
author = {Mao, Xinyan and Zeng, Qingjie and Chen, Enbo and Li, Lin and Yu, Baoyi and Wen, Yan},
title = {Research on the Integration of Automated Loading System and High-bay Warehouse Sorting System},
year = {2025},
isbn = {9798400721144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3776865.3776893},
doi = {10.1145/3776865.3776893},
abstract = {This paper explores the deep integration design and application effects of a newly added automated loading system with the existing high-bay warehouse sorting system. Addressing issues such as efficiency bottlenecks, information silos, and high labor costs in industry logistics operations, the study proposes an intelligent solution based on an industrial internet architecture. By introducing core modules such as an intelligent loading platform, full-process automation from warehousing management and sorting operations to loading and shipping has been achieved. Application results show that after system integration, loading efficiency has been significantly improved, while manual intervention and logistics operation costs have been effectively reduced.},
booktitle = {Proceedings of the 2025 3rd International Conference on Internet of Things and Cloud Computing Technology},
pages = {164–169},
numpages = {6},
keywords = {Automated loading system, High-bay warehouse sorting system, Intelligent logistics, System integration},
location = {
},
series = {IoTCCT '25}
}

@inproceedings{10.1145/3719027.3765208,
author = {B\"{a}umer, Fabian and Maehren, Marcel and Brinkmann, Marcus and Schwenk, J\"{o}rg},
title = {Finding SSH Strict Key Exchange Violations by State Learning},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3765208},
doi = {10.1145/3719027.3765208},
abstract = {SSH is an important protocol for secure remote shell access to servers on the Internet. At USENIX 2024, B\"{a}umer et al. presented the Terrapin attack on SSH, which relies on the attacker injecting optional messages during the key exchange. To mitigate this attack, SSH vendors adopted an extension developed by OpenSSH called strict key exchange (''strict KEX''). With strict KEX, optional messages are forbidden during the handshake, preventing the attack. In practice, this should simplify the state machine of an SSH handshake to a linear message flow similar to that of TLS. In this work, we analyze the design, implementation, and security of strict KEX in popular SSH servers, using black-box state learning, which can uncover the hidden state machine of an implementation. In practice, it is limited by the number of learned messages and the complexity of the state machine. Thus, learning the complete state machine of SSH is infeasible. Previous research on SSH, therefore, excluded optional messages, learning only a partial state machine. However, these messages are a critical part of the Terrapin attack. We propose to instead learn the complete state machine of the handshake phase of an SSH server, but with strict KEX enabled. We investigate the security of ten SSH implementations supporting strict KEX for up to five key exchange algorithms. In total, we learn 33 state machines, revealing significant differences in the implementations. We show that seven implementations violate the strict KEX specification and find two critical security vulnerabilities. One results in a rogue session attack in the proprietary Tectia SSH implementation. Another affects the official SSH implementation of the Erlang Open Telecom Platform, and enables unauthenticated remote code execution in the security context of the SSH server.},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {246–260},
numpages = {15},
keywords = {man-in-the-middle, message injection, protocol violations, ssh, state learning, strict key exchange},
location = {Taipei, Taiwan},
series = {CCS '25}
}

@inproceedings{10.1145/3702468.3702472,
author = {Chu, Ruilin and Yu, Miao and Tan, Yingzi},
title = {Research on Biped Robot Motion Control and Gait Based on CPG},
year = {2024},
isbn = {9798400717031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702468.3702472},
doi = {10.1145/3702468.3702472},
abstract = {To address the limitations and instability against disturbances of the walking gait of existing bipedal robots based on the inverted pendulum model, this paper proposes a new control method based on the Central Pattern Generator (CPG) model. By incorporating Hopf oscillators and Kuramoto terms into the original inverted pendulum model, and by adjusting parameters, this method enables the controller to produce stable and gait-periodic oscillations that match the robot's stride, thereby making the robot's center of gravity more stable and enhancing its disturbance resistance during walking. This study also connects the improved controller with the robot's joint motors and adjusts the robot's leg-lifting height and foot trajectory using Bezier curve interpolation, based on the Zero Moment Point (ZMP) gait generation method, to plan a complete robot gait. Finally, through simulations and experiments of the bipedal humanoid robot walking continuously and under sinusoidal disturbances, it was found that the new model can maintain a smaller fluctuation range of the center of gravity during walking, stabilize more quickly against external disturbances, and produce less noise when disturbed. This verifies the feasibility and effectiveness of the proposed control strategy.},
booktitle = {Proceedings of the 2024 7th International Conference on Robot Systems and Applications},
pages = {21–27},
numpages = {7},
keywords = {Central Pattern Generator, Gait Generation, Humanoid Robot, Inverted Pendulum},
location = {
},
series = {ICRSA '24}
}

@inproceedings{10.1145/3757940.3757945,
author = {Zhang, Shenghan and Meng, Fanzhao and Zhang, Rongji and Zhang, Yanshuo and Wang, Zhen and Wang, Guoqing},
title = {Design of Greenhouse Tomato Picking Robot Based on intelligent control},
year = {2025},
isbn = {9798400714948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757940.3757945},
doi = {10.1145/3757940.3757945},
abstract = {At present, China's Tomato Picking methods mainly rely on labor, which has problems such as high labor intensity, high labor cost and high fruit damage rate. This paper designs a small greenhouse tomato picking machine, including visual recognition system, lifting system, picking system, storage system, automatic driving system, power supply system, control system and other parts. It is convenient for operation, use and maintenance, in order to realize the mechanization and automation of tomato picking process, reduce the picking cost and improve the work efficiency. In the greenhouse dynamic environment, the control variable method is used to control the light environment variables. A total of 8 rounds of tests were conducted, and each round of tests lasted for 5 minutes. Each round of test was conducted in the ridge section with different tomato distribution density to evaluate the universality of the system. The test scenarios include branch and leaf occlusion and artificial simulation of dynamic obstacles. The final result is taken as the average value of 8 rounds of test results. The core positioning scheme uses LIDAR and binocular vision. Through multi-level data fusion and dynamic interference suppression technology, the scheme improves the positioning accuracy of the system in the signal interference environment, and improves the perception ability in complex environment. Combined with the visual assisted LIDAR positioning scheme, the picking efficiency is improved by 15%. The false cutting rate is stable at 6.5%, and the developed picking prototype has reached an average picking rate of 28.4 pieces/minute, which basically meets the needs of automatic tomato picking. It has the advantages of low cost, integration of harvesting and collection, adaptability to different ridges, continuous operation throughout the day and so on. It can effectively assist fruit farmers, reduce labor burden and cost, and has a good application prospect.},
booktitle = {Proceedings of the 2025 5th International Conference on Control and Intelligent Robotics},
pages = {32–37},
numpages = {6},
keywords = {Automated picking, Dynamic obstacle avoidance, Picking robot, SLAM algorithm},
location = {
},
series = {ICCIR '25}
}

@article{10.1145/3664828,
author = {Little, Max A and He, Xi and Kayas, Ugur},
title = {Polymorphic dynamic programming by algebraic shortcut fusion},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {36},
number = {2},
issn = {0934-5043},
url = {https://doi.org/10.1145/3664828},
doi = {10.1145/3664828},
abstract = {Dynamic programming (DP) is a broadly applicable algorithmic design paradigm for the efficient, exact solution of otherwise intractable, combinatorial problems. However, the design of such algorithms is often presented informally in an ad-hoc manner. It is sometimes difficult to justify the correctness of these DP algorithms. To address this issue, this article presents a rigorous algebraic formalism for systematically deriving DP algorithms, based on semiring polymorphism. We start with a specification, construct a (brute-force) algorithm to compute the required solution which is self-evidently correct because it exhaustively generates and evaluates all possible solutions meeting the specification. We then derive, primarily through the use of shortcut fusion, an implementation of this algorithm which is both efficient and correct. We also demonstrate how, with the use of semiring lifting, the specification can be augmented with combinatorial constraints and through semiring lifting, show how these constraints can also be fused with the derived algorithm. This article furthermore demonstrates how existing DP algorithms for a given combinatorial problem can be abstracted from their original context and re-purposed to solve other combinatorial problems.This approach can be applied to the full scope of combinatorial problems expressible in terms of semirings. This includes, for example: optimisation, optimal probability and Viterbi decoding, probabilistic marginalization, logical inference, fuzzy sets, differentiable softmax, and relational and provenance queries. The approach, building on many ideas from the existing literature on constructive algorithmics, exploits generic properties of (semiring) polymorphic functions, tupling and formal sums (lifting), and algebraic simplifications arising from constraint algebras. We demonstrate the effectiveness of this formalism for some example applications arising in signal processing, bioinformatics and reliability engineering. Python software implementing these algorithms can be downloaded from: .},
journal = {Form. Asp. Comput.},
month = jun,
articleno = {11},
numpages = {32},
keywords = {Dynamic programming, combinatorial optimisation, shortcut fusion, semiring}
}

@inproceedings{10.1145/3489517.3530435,
author = {Jiang, Lei and Lou, Qian and Joshi, Nrushad},
title = {MATCHA: a fast and energy-efficient accelerator for fully homomorphic encryption over the torus},
year = {2022},
isbn = {9781450391429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489517.3530435},
doi = {10.1145/3489517.3530435},
abstract = {Fully Homomorphic Encryption over the Torus (TFHE) allows arbitrary computations to happen directly on ciphertexts using homomorphic logic gates. However, each TFHE gate on state-of-the-art hardware platforms such as GPUs and FPGAs is extremely slow (&gt; 0.2ms). Moreover, even the latest FPGA-based TFHE accelerator cannot achieve high energy efficiency, since it frequently invokes expensive double-precision floating point FFT and IFFT kernels. In this paper, we propose a fast and energy-efficient accelerator, MATCHA, to process TFHE gates. MATCHA supports aggressive bootstrapping key unrolling to accelerate TFHE gates without decryption errors by approximate multiplication-less integer FFTs and IFFTs, and a pipelined datapath. Compared to prior accelerators, MATCHA improves the TFHE gate processing throughput by 2.3x, and the throughput per Watt by 6.3x.},
booktitle = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
pages = {235–240},
numpages = {6},
keywords = {TFHE, accelerator, bootstrapping, fully homomorphic encryption},
location = {San Francisco, California},
series = {DAC '22}
}

@article{10.1145/3450626.3459775,
author = {Bangaru, Sai Praveen and Michel, Jesse and Mu, Kevin and Bernstein, Gilbert and Li, Tzu-Mao and Ragan-Kelley, Jonathan},
title = {Systematically differentiating parametric discontinuities},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3450626.3459775},
doi = {10.1145/3450626.3459775},
abstract = {Emerging research in computer graphics, inverse problems, and machine learning requires us to differentiate and optimize parametric discontinuities. These discontinuities appear in object boundaries, occlusion, contact, and sudden change over time. In many domains, such as rendering and physics simulation, we differentiate the parameters of models that are expressed as integrals over discontinuous functions. Ignoring the discontinuities during differentiation often has a significant impact on the optimization process. Previous approaches either apply specialized hand-derived solutions, smooth out the discontinuities, or rely on incorrect automatic differentiation.We propose a systematic approach to differentiating integrals with discontinuous integrands, by developing a new differentiable programming language. We introduce integration as a language primitive and account for the Dirac delta contribution from differentiating parametric discontinuities in the integrand. We formally define the language semantics and prove the correctness and closure under the differentiation, allowing the generation of gradients and higher-order derivatives. We also build a system, Teg, implementing these semantics. Our approach is widely applicable to a variety of tasks, including image stylization, fitting shader parameters, trajectory optimization, and optimizing physical designs.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {107},
numpages = {18},
keywords = {automatic differentiation, differentiable graphics, differentiable physics, differentiable programming, differentiable rendering, domain-specific language}
}

@article{10.1145/3290351,
author = {Sato, Tetsuya and Aguirre, Alejandro and Barthe, Gilles and Gaboardi, Marco and Garg, Deepak and Hsu, Justin},
title = {Formal verification of higher-order probabilistic programs: reasoning about approximation, convergence, Bayesian inference, and optimization},
year = {2019},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {POPL},
url = {https://doi.org/10.1145/3290351},
doi = {10.1145/3290351},
abstract = {Probabilistic programming provides a convenient lingua franca for writing succinct and rigorous descriptions of probabilistic models and inference tasks. Several probabilistic programming languages, including Anglican, Church or Hakaru, derive their expressiveness from a powerful combination of continuous distributions, conditioning, and higher-order functions. Although very important for practical applications, these features raise fundamental challenges for program semantics and verification. Several recent works offer promising answers to these challenges, but their primary focus is on foundational semantics issues. In this paper, we take a step further by developing a suite of logics, collectively named PPV for proving properties of programs written in an expressive probabilistic higher-order language with continuous sampling operations and primitives for conditioning distributions. Our logics mimic the comfortable reasoning style of informal proofs using carefully selected axiomatizations of key results from probability theory. The versatility of our logics is illustrated through the formal verification of several intricate examples from statistics, probabilistic inference, and machine learning. We further show expressiveness by giving sound embeddings of existing logics. In particular, we do this in a parametric way by showing how the semantics idea of (unary and relational) ⊤⊤-lifting can be internalized in our logics. The soundness of PPV follows by interpreting programs and assertions in quasi-Borel spaces (QBS), a recently proposed variant of Borel spaces with a good structure for interpreting higher order probabilistic programs.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {38},
numpages = {30},
keywords = {formal reasoning, probabilistic programming, relational type systems}
}

@inproceedings{10.1145/3531130.3533366,
author = {Mio, Matteo and Sarkis, Ralph and Vignudelli, Valeria},
title = {Beyond Nonexpansive Operations in Quantitative Algebraic Reasoning},
year = {2022},
isbn = {9781450393515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531130.3533366},
doi = {10.1145/3531130.3533366},
abstract = {The framework of quantitative equational logic has been successfully applied to reason about algebras whose carriers are metric spaces and operations are nonexpansive. We extend this framework in two orthogonal directions: algebras endowed with generalised metric space structures, and operations being nonexpansive up to a lifting. We apply our results to the algebraic axiomatisation of the \L{}ukaszyk–Karmowski distance on probability distributions, which has recently found application in the field of representation learning on Markov processes.},
booktitle = {Proceedings of the 37th Annual ACM/IEEE Symposium on Logic in Computer Science},
articleno = {52},
numpages = {13},
keywords = {equational logic, free algebras, metrics, monads, probability distributions, quantitative reasoning},
location = {Haifa, Israel},
series = {LICS '22}
}

@article{10.1145/3450626.3459848,
author = {Granskog, Jonathan and Schnabel, Till N. and Rousselle, Fabrice and Nov\'{a}k, Jan},
title = {Neural scene graph rendering},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3450626.3459848},
doi = {10.1145/3450626.3459848},
abstract = {We present a neural scene graph---a modular and controllable representation of scenes with elements that are learned from data. We focus on the forward rendering problem, where the scene graph is provided by the user and references learned elements. The elements correspond to geometry and material definitions of scene objects and constitute the leaves of the graph; we store them as high-dimensional vectors. The position and appearance of scene objects can be adjusted in an artist-friendly manner via familiar transformations, e.g. translation, bending, or color hue shift, which are stored in the inner nodes of the graph. In order to apply a (non-linear) transformation to a learned vector, we adopt the concept of linearizing a problem by lifting it into higher dimensions: we first encode the transformation into a high-dimensional matrix and then apply it by standard matrix-vector multiplication. The transformations are encoded using neural networks. We render the scene graph using a streaming neural renderer, which can handle graphs with a varying number of objects, and thereby facilitates scalability. Our results demonstrate a precise control over the learned object representations in a number of animated 2D and 3D scenes. Despite the limited visual complexity, our work presents a step towards marrying traditional editing mechanisms with learned representations, and towards high-quality, controllable neural rendering.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {164},
numpages = {11},
keywords = {generalization, modularity, neural networks, neural scene representations, rendering}
}

@inproceedings{10.1145/3643834.3661551,
author = {Sharma, Adwait and Ivanov, Alexander and Lai, Frances and Grossman, Tovi and Santosa, Stephanie},
title = {GraspUI: Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661551},
doi = {10.1145/3643834.3661551},
abstract = {Objects are indispensable tools in our daily lives. Recent research has demonstrated their potential to act as conduits for digital interactions with microgestures, however, the primary focus was on situations where the hand firmly grasps an object. We introduce GraspUI, an exploratory design space of object-centric gestures within the seven distinct phases of the grasping process, spanning pre-, during, and post-grasp movements. We conducted ideation sessions with mixed-reality designers from industry and academia to explore gesture integration throughout the entire grasping process. The outcome was 38 storyboards envisioning practical applications. To evaluate the design space’s utility, we performed a video-based assessment with end-users. We then implemented an interactive prototype and quantified the overhead cost of performing proposed gestures through a secondary study. Participants reacted positively to gestures and could integrate them into existing usage of objects. To conclude, we highlight technical and usability guidelines for implementing and extending GraspUI systems.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {1275–1289},
numpages = {15},
keywords = {design space, everyday objects, grasp, grasping process, hand-object manipulation, input},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3448016.3457287,
author = {G\'{e}vay, G\'{a}bor E. and Quian\'{e}-Ruiz, Jorge-Arnulfo and Markl, Volker},
title = {The Power of Nested Parallelism in Big Data Processing  Hitting Three Flies with One Slap },
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3457287},
doi = {10.1145/3448016.3457287},
abstract = {Many common data analysis tasks, such as performing hyperparameter optimization, processing a partitioned graph, and treating a matrix as a vector of vectors, offer natural opportunities for nested-parallel operations, i.e., launching parallel operations from inside other parallel operations. However, state-of-the-art dataflow engines, such as Spark and Flink, do not support nested parallelism. Users must implement workarounds, causing orders of magnitude slowdowns for their tasks, let alone the implementation effort.We present Matryoshka, a system that enables dataflow engines to support nested parallelism, even in the presence of control flow statements at inner nesting levels. Matryoshka achieves this via a novel two-phase flattening process, which translates nested-parallel programs to flat-parallel programs that can efficiently run on existing dataflow engines. The first phase introduces novel nesting primitives into the code, which allows for dynamic optimizations based on intermediate data characteristics in the second phase at runtime. We validate our system using several common data analysis tasks, such as PageRank and K-means.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {605–618},
numpages = {14},
keywords = {nested data, nested parallel collections, nested parallel operations},
location = {Virtual Event, China},
series = {SIGMOD '21}
}

@inproceedings{10.1145/3613904.3642936,
author = {Chen, Xinyu and Li, Yuqi and Chen, Jintao and Li, Jiabao and Wang, Chong and Tang, Pinyan},
title = {Enhancing Home Exercise Experiences with Video Motion-Tracking for Automatic Display Height Adjustment},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642936},
doi = {10.1145/3613904.3642936},
abstract = {The increasing demand for home fitness solutions underscores the need for interactive displays that enhance user experiences. This study introduces a technology that autonomously adjusts display height using the skeletal information of demonstrators from videos, catering to home fitness needs. A user study involving thirty participants compared fixed height, manual adjustment, and automatic adjustment conditions. Head flexion angles and NASA-TLX survey responses were used for evaluation. Results showed a significant reduction in head flexion angles with automatic adjustment, promoting proper spinal alignment. NASA-TLX responses indicated lower mental, effort, and frustration ratings, along with improved performance and perceived support in the automatic adjustment condition compared to other conditions. These findings confirm that motion-based height adjustment improves posture and enhances the overall interactive experience. This research demonstrates the feasibility of integrating responsive ergonomics into interactive displays and suggests the importance of further personalization, conducting diverse user studies, and refining algorithms to fully leverage the potential of this technology.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {310},
numpages = {13},
keywords = {Automatic Height Adjustment, Head Flexion Angle, Interactive Exercise Displays, NASA-TLX survey, User Experience Design},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3581783.3613771,
author = {Jiang, Jiawei and Feng, Yuchao and Chen, Jiacheng and Guo, Dongyan and Zheng, Jianwei},
title = {Latent-space Unfolding for MRI Reconstruction},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3613771},
doi = {10.1145/3581783.3613771},
abstract = {To circumvent the problems caused by prolonged acquisition periods, compressed sensing MRI enjoys a high usage profile to accelerate the recovery of high-quality images from under-sampled k-space data. Most current solutions dedicate to solving this issue with the pursuit of certain prior properties, yet the treatments are all enforced in the original space, resulting in limited feature information. To achieve a performance promotion yet with the guarantee of running efficiency, in this work, we propose a latent-space unfolding network (LsUNet). Specifically, by an elaborately designed reversible network, the inputs are first mapped to a channel-lifted latent space, which taps the potential of capturing spatial-invariant features sufficiently. Within the latent space, we then unfold an accelerated optimization algorithm to iterate an efficient and feasible solution, in which a parallelly dual-domain update is equipped for better feature fusion. Finally, an inverse embedding transformation of the recovered high-dimensional representation is applied to achieve the expected estimation. LsUNet enjoys high interpretability due to the physically induced modules, which not only facilitates an intuitive understanding of the internal operating mechanism but also endows it with high generalization ability. Comprehensive experiments on different datasets and various sampling rates/patterns demonstrate the advantages of our proposal over the latest methods both visually and numerically.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {1294–1302},
numpages = {9},
keywords = {fast mri, latet-space unfolding, local and global features, parallelly dual-domain update},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3563703.3596659,
author = {Sun, Ruojia and Wallop, Althea Vail and Leslie, Grace and Do, Ellen Yi-Luen},
title = {SoniSpace: Expressive Movement Interaction to Encourage Taking Up Space with the Body},
year = {2023},
isbn = {9781450398985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563703.3596659},
doi = {10.1145/3563703.3596659},
abstract = {Movement forms the basis of our thoughts, emotions, and ways of being in the world. Informed by somaesthetics, we design for “taking up space” (e.g. encouraging expansive body movements), which may in turn alter our emotional experience. We demonstrate SoniSpace, an expressive movement interaction experience that uses movement sonification and visualization to encourage users to take up space with their body. We apply a first-person design approach to embed qualities of awareness, exploration, and comfort into the sound and visual design to promote authentic and enjoyable movement expression regardless of prior movement experience. Preliminary results from 20 user experiences with the system show that users felt more comfortable with taking up space and with movement in general following the interaction. We discuss our findings about designing for somatically-focused movement interactions and directions for future work.},
booktitle = {Companion Publication of the 2023 ACM Designing Interactive Systems Conference},
pages = {279–283},
numpages = {5},
keywords = {interactive visuals, movement-based interaction, sensory feedback, soma design, sonification},
location = {Pittsburgh, PA, USA},
series = {DIS '23 Companion}
}

@inproceedings{10.1145/3584376.3584422,
author = {Ning, Yingsong and Chen, Yifei and Xu, Zixuan and Ma, Wangran and Wang, Shoujin and Zhao, Shiyu},
title = {The Control of intelligent building robot patrol technology based on Raspberry Pi},
year = {2023},
isbn = {9781450398343},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584376.3584422},
doi = {10.1145/3584376.3584422},
abstract = {With the rapid development of intelligent buildings, the intelligent research of mobile robots has set off an upsurge. In this paper, the research is carried out on building intelligent security robots, the wheeled robot platform is built, and an autonomous inspection system is designed. Through communication, electronics, Internet, Internet of Things, satellite remote sensing, laser ranging, radar ranging, satellite positioning and inertial navigation combination, computer, machinery manufacturing, and other technologies, the robot construction and equipment, hardware and circuit integration, embedded software development, etc. are designed and manufactured to realize intelligent work. Robot participation in inspection makes up for the empty period of manual inspection, avoids the risks and disadvantages of manual inspection, improves production efficiency, reduces the burden of operations and maintenance personnel, and saves costs.},
booktitle = {Proceedings of the 2022 4th International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {250–254},
numpages = {5},
keywords = {Path planning, Radar scanning, Target identification, Target tracking},
location = {Dongguan, China},
series = {RICAI '22}
}

@inproceedings{10.1145/3460421.3480423,
author = {Baronetto, Annalisa and Uhlenberg, Lena and Wassermann, Dominik and Amft, Oliver},
title = {Simulation of Garment-Embedded Contact Sensor Performance under Motion Dynamics},
year = {2021},
isbn = {9781450384629},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460421.3480423},
doi = {10.1145/3460421.3480423},
abstract = {We propose a simulation method to evaluate the performance of garment-embedded contact sensors while performing common Activities of Daily Living (ADL). Our method comprises four steps: dynamic 3D human body model generation, automated smart garment design, ADL simulation, dynamic sensor fitting and sensor displacement evaluation. We generated 100 3D human body models with varying body shapes and virtually dressed them with three differently fitted smart T-Shirts. We then analysed the sensor-body distance and sensor displacement while performing common ADLs. An Electrocardiogram (ECG) smart shirt was considered as an example application. Results show a decrease in sensor distance while BMI increases for both sexes. Compared to females, males show higher sensor displacement and displacement variance, whereas women show higher distance variance compared to men for all ADLs, especially in the region below the breast. Our method can be used to evaluate contact sensor performance for different body shapes, ADLs, and garment designs.},
booktitle = {Proceedings of the 2021 ACM International Symposium on Wearable Computers},
pages = {73–77},
numpages = {5},
keywords = {contact sensors, garment fitting, smart garment design},
location = {Virtual, USA},
series = {ISWC '21}
}

@inproceedings{10.1145/3503161.3547850,
author = {BAI, Yeqi and Ma, Tao and Wang, Lipo and Zhang, Zhenjie},
title = {Speech Fusion to Face: Bridging the Gap Between Human's Vocal Characteristics and Facial Imaging},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3547850},
doi = {10.1145/3503161.3547850},
abstract = {While deep learning technologies are now capable of generating realistic images confusing humans, the research efforts are turning to the synthesis of images for more concrete and application-specific purposes. Facial image generation based on vocal characteristics from speech is one of such important yet challenging tasks. It is the key enabler to influential use cases of image generation, especially for business in public security and entertainment. Existing solutions to the problem of speech2face renders limited image quality and fails to preserve facial similarity due to the lack of quality dataset for training and appropriate integration of vocal features. In this paper, we investigate these key technical challenges and propose Speech Fusion to Face, or SF2F in short, attempting to address the issue of facial image quality and the poor connection between vocal feature domain and modern image generation models. By adopting new strategies on data model and training, we demonstrate dramatic performance boost over state-of-the-art solution, by doubling the recall of individual identity, and lifting the quality score from 15 to 19 based on the mutual information score with VGGFace classifier.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {2042–2050},
numpages = {9},
keywords = {multi-modal, video learning},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3508352.3549390,
author = {Bustany, Ismail and Kahng, Andrew B. and Koutis, Ioannis and Pramanik, Bodhisatta and Wang, Zhiang},
title = {SpecPart: A Supervised Spectral Framework for Hypergraph Partitioning Solution Improvement},
year = {2022},
isbn = {9781450392174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3508352.3549390},
doi = {10.1145/3508352.3549390},
abstract = {State-of-the-art hypergraph partitioners follow the multilevel paradigm that constructs multiple levels of progressively coarser hypergraphs that are used to drive cut refinements on each level of the hierarchy. Multilevel partitioners are subject to two limitations: (i) Hypergraph coarsening processes rely on local neighborhood structure without fully considering the global structure of the hypergraph. (ii) Refinement heuristics can stagnate on local minima. In this paper, we describe SpecPart, the first supervised spectral framework that directly tackles these two limitations. SpecPart solves a generalized eigenvalue problem that captures the balanced partitioning objective and global hypergraph structure in a low-dimensional vertex embedding while leveraging initial high-quality solutions from multilevel partitioners as hints. SpecPart further constructs a family of trees from the vertex embedding and partitions them with a tree-sweeping algorithm. Then, a novel overlay of multiple tree-based partitioning solutions, followed by lifting to a coarsened hypergraph, where an ILP partitioning instance is solved to alleviate local stagnation. We have validated SpecPart on multiple sets of benchmarks. Experimental results show that for some benchmarks, our SpecPart can substantially improve the cutsize by more than 50% with respect to the best published solutions obtained with leading partitioners hMETIS and KaHyPar.},
booktitle = {Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design},
articleno = {13},
numpages = {9},
keywords = {hypergraph partitioning, supervised spectral partitioning},
location = {San Diego, California},
series = {ICCAD '22}
}

@inproceedings{10.1145/3458709.3458986,
author = {Aso, Kohei and Hwang, Dong-Hyun and Koike, Hideki},
title = {Portable 3D Human Pose Estimation for Human-Human Interaction using a Chest-Mounted Fisheye Camera},
year = {2021},
isbn = {9781450384285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3458709.3458986},
doi = {10.1145/3458709.3458986},
abstract = {We propose a system that estimates the 3D body pose of other parties using a single RGB chest-mounted ultra-wide fisheye camera. Although the fisheye camera can capture a wide field of view, it is difficult to apply image processing for perspective images because of its strong distortion. In our method, the input fisheye image is converted to an equirectangular image to detect another person and their 2D keypoints, and then convert them to a 3D pose. In order to adapt to the distortion of equirectangular images, we generate a synthetic dataset and fine-tune the model. We also estimate the location of the other person so that we can reconstruct the absolute camera-centered global pose. We evaluate the accuracy on real-world data and show that the fine-tuned model performs best.},
booktitle = {Proceedings of the Augmented Humans International Conference 2021},
pages = {116–120},
numpages = {5},
keywords = {Computer vision, Egocentric video, Fisheye camera, Human pose estimation, Human-human interaction, Mobile motion capture},
location = {Rovaniemi, Finland},
series = {AHs '21}
}

@article{10.1145/3591270,
author = {Chen, Yu-Fang and Chung, Kai-Min and Leng\'{a}l, Ond\v{r}ej and Lin, Jyun-Ao and Tsai, Wei-Lun and Yen, Di-De},
title = {An Automata-Based Framework for Verification and Bug Hunting in Quantum Circuits},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591270},
doi = {10.1145/3591270},
abstract = {We introduce a new paradigm for analysing and finding bugs in quantum circuits. In our approach, the problem is given by a ‍triple {P} C {Q} and the question is whether, given a set P of quantum states on the input of a circuit C, the set of quantum states on the output is equal to (or included in) a set Q. While this is not suitable to specify, e.g., functional correctness of a quantum circuit, it is sufficient to detect many bugs in quantum circuits. We propose a technique based on tree automata to compactly represent sets of quantum states and develop transformers to implement the semantics of quantum gates over this representation. Our technique computes with an algebraic representation of quantum states, avoiding the inaccuracy of working with floating-point numbers. We implemented the proposed approach in a prototype tool and evaluated its performance against various benchmarks from the literature. The evaluation shows that our approach is quite scalable, e.g., we managed to verify a large circuit with 40 qubits and 141,527 gates, or catch bugs injected into a circuit with 320 qubits and 1,758 gates, where all tools we compared with failed. In addition, our work establishes a connection between quantum program verification and automata, opening new possibilities to exploit the richness of automata theory and automata-based verification in the world of quantum computing.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {156},
numpages = {26},
keywords = {quantum circuits, tree automata, verification}
}

@article{10.1145/3609131,
author = {Cola\c{c}o, Jean-Louis and Mendler, Michael and Pauget, Baptiste and Pouzet, Marc},
title = {A Constructive State-based Semantics and Interpreter for a Synchronous Data-flow Language with State Machines},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3609131},
doi = {10.1145/3609131},
abstract = {Scade is a domain-specific synchronous functional language used to implement safety-critical real-time software for more than twenty years. Two main approaches have been considered for its semantics: (i) an indirect collapsing semantics based on a source-to-source translation of high-level constructs into a data-flow core language whose semantics is precisely specified and is the entry for code generation; a relational synchronous semantics, akin to Esterel, that applies directly to the source. It defines what is a valid synchronous reaction but hides, on purpose, if a semantics exists, is unique and can be computed; hence, it is not executable.This paper presents, for the first time, an executable, state-based semantics for a language that has the key constructs of Scade all together, in particular the arbitrary combination of data-flow equations and hierarchical state machines. It can apply directly to the source language before static checks and compilation steps. It is constructive in the sense that the language in which the semantics is defined is a statically typed functional language with call-by-value and strong normalization, e.g., it is expressible in a proof-assistant where all functions terminate. It leads to a reference, purely functional, interpreter. This semantics is modular and can account for possible errors, allowing to establish what property is ensured by each static verification performed by the compiler. It also clarifies how causality is treated in Scade compared with Esterel.This semantics can serve as an oracle for compiler testing and validation; to prototype novel language constructs before they are implemented, to execute possibly unfinished models or that are correct but rejected by the compiler; to prove the correctness of compilation steps.The semantics given in the paper is implemented as an interpreter in a purely functional style, in OCaml.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = sep,
articleno = {152},
numpages = {26},
keywords = {Programming language, dynamic semantics, synchronous programming, embedded software}
}

@inproceedings{10.1145/3703595.3705873,
author = {Alexandru, Cass and Choudhury, Vikraman and Rot, Jurriaan and van der Weide, Niels},
title = {Intrinsically Correct Sorting in Cubical Agda},
year = {2025},
isbn = {9798400713477},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703595.3705873},
doi = {10.1145/3703595.3705873},
abstract = {The paper "Sorting with Bialgebras and Distributive Laws" by Hinze et al. uses the framework of bialgebraic semantics to define sorting algorithms.        From distributive laws between functors they construct pairs of sorting algorithms using both folds and unfolds.        Pairs of sorting algorithms arising this way include insertion/selection sort and quick/tree sort.                We extend this work to define intrinsically correct variants in cubical Agda.        Our key idea is to index our data types by multisets, which concisely captures that a sorting algorithm terminates with an ordered permutation of its input list.        By lifting bialgebraic semantics to the indexed setting, we obtain the correctness of sorting algorithms purely from the distributive law.},
booktitle = {Proceedings of the 14th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {34–49},
numpages = {16},
keywords = {bialgebras, cubical Agda, distributive laws, intrinsic correctness, sorting},
location = {Denver, CO, USA},
series = {CPP '25}
}

@inproceedings{10.1145/3498891.3501259,
author = {Aranovich, Ra\'{u}l and Wu, Muting and Yu, Dian and Katsy, Katya and Ahmadnia, Benyamin and Bishop, Matthew and Filkov, Vladimir and Sagae, Kenji},
title = {Beyond NVD: Cybersecurity meets the Semantic Web.},
year = {2022},
isbn = {9781450385732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3498891.3501259},
doi = {10.1145/3498891.3501259},
abstract = {Cybersecurity experts rely on the knowledge stored in databases like the NVD to do their work, but these are not the only sources of information about threats and vulnerabilities. Much of that information flows through social media channels. In this paper we argue that security experts and general users alike can benefit from the technologies of the Semantic Web, merging heterogeneous sources of knowledge in an ontological representation. We present a system that has an ontology of vulnerabilities at its core, but that is enhanced with NLP tools to identify cybersecurity-related information in social media and to launch queries over heterogeneous data sources. The transformative power of Semantic Web technologies for cybersecurity, which has been proven in the biomedical field, is evaluated and discussed.},
booktitle = {Proceedings of the 2021 New Security Paradigms Workshop},
pages = {59–69},
numpages = {11},
keywords = {cybersecurity, neural networks, nlp, ontology, social media},
location = {Virtual Event, USA},
series = {NSPW '21}
}

@inproceedings{10.1145/3487664.3487761,
author = {Futami, Kyosuke and Oyama, Kohei and Murao, Kazuya},
title = {A Method to Recognize Facial Gesture using Infrared Distance Sensor Array on Ear Accessories},
year = {2022},
isbn = {9781450395564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3487664.3487761},
doi = {10.1145/3487664.3487761},
abstract = {Many hands-free input methods using ear accessories have been proposed. Although most of previous studies use canal type earphones, we focus on the following two points. 1) A method for using the hands-free input function with ear accessories that are not canal type. 2) A method for using the same hands-free input function across multiple ear accessories. Then, using an infrared distance sensor attached to the ear accessory, we propose a method for recognizing the gesture of the user’s facial expression. Based on the change in distance between the infrared distance sensor attached to the ear accessory and the skin, the proposed method detects skin movement around the ear, which differs for each facial expression gesture. We created a prototype system for the root of the ear, earlobe, and tragus ear accessories. The evaluation result for nine gestures and five subjects showed that F-value was 0.94 or more for one device alone, and the F-value was 0.97 or more for the pattern combining multiple devices.},
booktitle = {The 23rd International Conference on Information Integration and Web Intelligence},
pages = {650–654},
numpages = {5},
keywords = {Ear accessories, Earphone, Facial gesture recognition, Hands-free input interface, Infrared distance sensor},
location = {Linz, Austria},
series = {iiWAS2021}
}

@inproceedings{10.1145/3442188.3445867,
author = {Heidari, Hoda and Kleinberg, Jon},
title = {Allocating Opportunities in a Dynamic Model of Intergenerational Mobility},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445867},
doi = {10.1145/3442188.3445867},
abstract = {Opportunities such as higher education can promote intergenerational mobility, leading individuals to achieve levels of socioeconomic status above that of their parents. We develop a dynamic model for allocating such opportunities in a society that exhibits bottlenecks in mobility; the problem of optimal allocation reflects a trade-off between the benefits conferred by the opportunities in the current generation and the potential to elevate the socioeconomic status of recipients, shaping the composition of future generations in ways that can benefit further from the opportunities. We show how optimal allocations in our model arise as solutions to continuous optimization problems over multiple generations, and we find in general that these optimal solutions can favor recipients of low socioeconomic status over slightly higher-performing individuals of high socioeconomic status --- a form of socioeconomic affirmative action that the society in our model discovers in the pursuit of purely payoff-maximizing goals. We characterize how the structure of the model can lead to either temporary or persistent affirmative action, and we consider extensions of the model with more complex processes modulating the movement between different levels of socioeconomic status.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {15–25},
numpages = {11},
keywords = {Intergenerational mobility, continuous Markov Decision Processes (MDP), optimal allocation policy, socioeconomic affirmative action},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@article{10.1145/3547630,
author = {Yoon, Irene and Zakowski, Yannick and Zdancewic, Steve},
title = {Formal reasoning about layered monadic interpreters},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {ICFP},
url = {https://doi.org/10.1145/3547630},
doi = {10.1145/3547630},
abstract = {Monadic computations built by interpreting, or handling, operations of a   free monad are a compelling formalism for modeling language semantics and   defining the behaviors of effectful systems.   The resulting layered semantics offer the promise of modular reasoning principles  based on the equational theory of the underlying monads.   However, there are a number of obstacles to using such layered   interpreters in practice. With more layers comes more boilerplate and glue   code needed to define the monads and interpreters involved. That overhead is   compounded by the need to define and justify the relational reasoning   principles that characterize the equivalences at each layer.    This paper addresses these problems by significantly extending the   capabilities of the Coq interaction trees (ITrees) library, which   supports layered monadic interpreters. We characterize a rich class of   interpretable monads---obtained by applying monad transformers to   ITrees---and show how to generically lift interpreters through them. We   also introduce a corresponding framework for relational reasoning about   "equivalence of monads up to a relation R". This collection of   typeclasses, instances, new reasoning principles, and tactics greatly   generalizes the existing theory of the ITree library, eliminating large   amounts of unwieldy boilerplate code and dramatically simplifying proofs.},
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {99},
numpages = {29},
keywords = {Coq, coinduction, compiler correctness, monads}
}

@article{10.1145/3473598,
author = {Aguirre, Alejandro and Barthe, Gilles and Gaboardi, Marco and Garg, Deepak and Katsumata, Shin-ya and Sato, Tetsuya},
title = {Higher-order probabilistic adversarial computations: categorical semantics and program logics},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {ICFP},
url = {https://doi.org/10.1145/3473598},
doi = {10.1145/3473598},
abstract = {Adversarial computations are a widely studied class of computations where resource-bounded probabilistic adversaries have access to oracles, i.e., probabilistic procedures with private state. These computations arise routinely in several domains, including security, privacy and machine learning. In this paper, we develop program logics for reasoning about adversarial computations in a higher-order setting. Our logics are built on top of a simply typed λ-calculus extended with a graded monad for probabilities and state. The grading is used to model and restrict the memory footprint and the cost (in terms of oracle calls) of computations. Under this view, an adversary is a higher-order expression that expects as arguments the code of its oracles. We develop unary program logics for reasoning about error probabilities and expected values, and a relational logic for reasoning about coupling-based properties. All logics feature rules for adversarial computations, and yield guarantees that are valid for all adversaries that satisfy a fixed resource policy. We prove the soundness of the logics in the category of quasi-Borel spaces, using a general notion of graded predicate liftings, and we use logical relations over graded predicate liftings to establish the soundness of proof rules for adversaries. We illustrate the working of our logics with simple but illustrative examples.},
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {93},
numpages = {30},
keywords = {Probabilistic programming, program logics, semantic models}
}

@article{10.1145/3704880,
author = {Arranz Olmos, Santiago and Barthe, Gilles and Blatter, Lionel and Gr\'{e}goire, Benjamin and Laporte, Vincent},
title = {Preservation of Speculative Constant-Time by Compilation},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {POPL},
url = {https://doi.org/10.1145/3704880},
doi = {10.1145/3704880},
abstract = {Compilers often weaken or even discard software-based countermeasures commonly used to protect programs against side-channel attacks; worse, they may also introduce vulnerabilities that attackers can exploit. The solution to this problem is to develop compilers that preserve such countermeasures. Prior work establishes that (a mildly modified version of) the CompCert and Jasmin formally verified compilers preserve constant-time, an information flow policy that ensures that programs are protected against timing side-channel attacks. However, nothing is known about preservation of speculative constant-time, a strengthening of the constant-time policy that ensures that programs are protected against Spectre-v1 attacks. We first show that preservation of speculative constant-time fails in practice by providing examples of secure programs whose compilation is not speculative constant-time using GCC (GCC -O0 and GCC -O1) and Jasmin. Then, we define a proof-of-concept compiler that distills some of the critical passes of the Jasmin compiler and use the Coq proof assistant to prove that it preserves speculative constant-time. Finally, we patch the Jasmin speculative constant-time type checker and demonstrate that all cryptographic implementations written in Jasmin can be fixed with minimal impact.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {44},
numpages = {33},
keywords = {Compilers, Formal security models, Formal software verification}
}

@inproceedings{10.1145/3618305.3623589,
author = {Carvalho, Lu\'{\i}s},
title = {Semantic Versioning for Python Programs},
year = {2023},
isbn = {9798400703843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3618305.3623589},
doi = {10.1145/3618305.3623589},
abstract = {We propose a language-based approach to software   versioning. Unlike the traditional approach of mainstream version control systems,  where each evolution step is represented by a textual diff, we treat   versions as programming elements. Each evolution step, merge operation,   and version relationship, is represented explicitly in the program.   This provides compile time guarantees for safety code reuse from previous versions, as   well as forward and backwards compatibility between versions, allowing clients to use newly introduced code without needing to refactor their program.   By lifting the versioning to the language level, we pave the way for tools that interact with   software repositories to have more insight regarding the evolution of the software semantics.},
booktitle = {Companion Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
pages = {13–15},
numpages = {3},
keywords = {Software evolution, type theory},
location = {Cascais, Portugal},
series = {SPLASH 2023}
}

@article{10.1145/3571209,
author = {Lu, Sirui and Bod\'{\i}k, Rastislav},
title = {Grisette: Symbolic Compilation as a Functional Programming Library},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {POPL},
url = {https://doi.org/10.1145/3571209},
doi = {10.1145/3571209},
abstract = {The development of constraint solvers simplified automated reasoning about programs and shifted the engineering burden to implementing symbolic compilation tools that translate programs into efficiently solvable constraints. We describe Grisette, a reusable symbolic evaluation framework for implementing domain-specific symbolic compilers. Grisette evaluates all execution paths and merges their states into a normal form that avoids making guards mutually exclusive. This ordered-guards representation reduces the constraint size 5-fold and the solving time more than 2-fold. Grisette is designed entirely as a library, which sidesteps the complications of lifting the host language into the symbolic domain. Grisette is purely functional, enabling memoization of symbolic compilation as well as monadic integration with host libraries. Grisette is statically typed, which allows catching programming errors at compile time rather than delaying their detection to the constraint solver. We implemented Grisette in Haskell and evaluated it on benchmarks that stress both the symbolic evaluation and constraint solving.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {16},
numpages = {33},
keywords = {State Merging, Symbolic Compilation}
}

@article{10.1145/3498716,
author = {Jeffrey, Alan and Riely, James and Batty, Mark and Cooksey, Simon and Kaysin, Ilya and Podkopaev, Anton},
title = {The leaky semicolon: compositional semantic dependencies for relaxed-memory concurrency},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {POPL},
url = {https://doi.org/10.1145/3498716},
doi = {10.1145/3498716},
abstract = {Program logics and semantics tell a pleasant story about sequential composition: when executing (S1;S2), we first execute S1 then S2. To improve performance, however, processors execute instructions out of order, and compilers reorder programs even more dramatically. By design, single-threaded systems cannot observe these reorderings; however, multiple-threaded systems can, making the story considerably less pleasant. A formal attempt to understand the resulting mess is known as a “relaxed memory model.” Prior models either fail to address sequential composition directly, or overly restrict processors and compilers, or permit nonsense thin-air behaviors which are unobservable in practice.  To support sequential composition while targeting modern hardware, we enrich the standard event-based approach with preconditions and families of predicate transformers. When calculating the meaning of (S1; S2), the predicate transformer applied to the precondition of an event e from S2 is chosen based on the set of events in S1 upon which e depends. We apply this approach to two existing memory models.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {54},
numpages = {30},
keywords = {Arm8, C11, Compiler Optimizations, Concurrency, Multi-Copy Atomicity, Pomsets, Preconditions, Predicate Transformers, Relaxed Memory Models, Thin-Air Reads}
}

@article{10.1145/3547640,
author = {Ullrich, Sebastian and de Moura, Leonardo},
title = {‘do’ unchained: embracing local imperativity in a purely functional language (functional pearl)},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {ICFP},
url = {https://doi.org/10.1145/3547640},
doi = {10.1145/3547640},
abstract = {Purely functional programming languages pride themselves with reifying effects that are implicit in imperative languages into reusable and composable abstractions such as monads. This reification allows for more exact control over effects as well as the introduction of new or derived effects. However, despite libraries of more and more powerful abstractions over effectful operations being developed, syntactically the common 'do' notation still lags behind equivalent imperative code it is supposed to mimic regarding verbosity and code duplication. In this paper, we explore extending 'do' notation with other imperative language features that can be added to simplify monadic code: local mutation, early return, and iteration. We present formal translation rules that compile these features back down to purely functional code, show that the generated code can still be reasoned over using an implementation of the translation in the Lean 4 theorem prover, and formally prove the correctness of the translation rules relative to a simple static and dynamic semantics in Lean.},
journal = {Proc. ACM Program. Lang.},
month = aug,
articleno = {109},
numpages = {28},
keywords = {Lean, functional programming, interactive theorem proving}
}

@inproceedings{10.1145/3664647.3680990,
author = {Gu, Renshu and Zhu, Jiajun and Si, Yixuan and Gao, Fei and Xu, Jiamin and Xu, Gang},
title = {3D Human Pose Estimation from Multiple Dynamic Views via Single-view Pretraining with Procrustes Alignment},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680990},
doi = {10.1145/3664647.3680990},
abstract = {3D Human pose estimation from multiple cameras with unknown calibration has received less attention than it should. The few existing data-driven solutions do not fully exploit 3D training data that are available on the market, and typically train from scratch for every novel multi-view scene, which impedes both accuracy and efficiency. We show how to exploit 3D training data to the fullest and associate multiple dynamic views efficiently to achieve high precision on novel scenes using a simple yet effective framework, dubbed Multiple Dynamic View Pose estimation (MDVPose). MDVPose utilizes novel scenarios data to finetune a single-view pretrained motion encoder in multi-view setting, aligns arbitrary number of views in a unified coordinate via Procruste alignment, and imposes multi-view consistency. The proposed method achieves 22.1 mm P-MPJPE or 34.2 mm MPJPE on the challenging in-the-wild Ski-Pose PTZ dataset, which outperforms the state-of-the-art method by 24.8% P-MPJPE (-7.3 mm) and 19.0% MPJPE (-8.0 mm). It also outperforms the state-of-the-art methods by a large margin (-18.2mm P-MPJPE and -28.3mm MPJPE) on the EgoBody dataset. In addition, MDVPose achieves robust performance on the Human3.6M datasets featuring multiple static cameras. Code is available at https://github.com/iGame-Lab/MDVPose.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10363–10372},
numpages = {10},
keywords = {3d human pose estimation, dynamic viewpoint, multi-view},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3656413,
author = {Spies, Simon and G\"{a}her, Lennard and Sammler, Michael and Dreyer, Derek},
title = {Quiver: Guided Abductive Inference of Separation Logic Specifications in Coq},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {PLDI},
url = {https://doi.org/10.1145/3656413},
doi = {10.1145/3656413},
abstract = {Over the past two decades, there has been a great deal of progress on verification of full functional correctness of programs using separation logic, sometimes even producing “foundational” proofs in proof assistants like Coq. Unfortunately, even though existing approaches to this problem provide significant support for automated verification, they still incur a significant specification overhead: the user must supply the specification against which the program is verified, and the specification may be long, complex, or tedious to formulate.In this paper, we introduce Quiver, the first technique for inferring functional correctness specifications in separation logic while simultaneously verifying foundationally that they are correct. To guide Quiver towards the final specification, we take hints from the user in the form of a specification sketch, and then complete the sketch using inference. To do so, Quiver introduces a new abductive deductive verification technique, which integrates ideas from abductive inference (for specification inference) together with deductive separation logic automation (for foundational verification). The result is that users have to provide some guidance, but significantly less than with traditional deductive verification techniques based on separation logic. We have evaluated Quiver on a range of case studies, including code from popular open-source libraries.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {183},
numpages = {25},
keywords = {specification inference, abduction, functional correctness, Iris, Coq}
}

@article{10.1145/3592460,
author = {Trevithick, Alex and Chan, Matthew and Stengel, Michael and Chan, Eric and Liu, Chao and Yu, Zhiding and Khamis, Sameh and Chandraker, Manmohan and Ramamoorthi, Ravi and Nagano, Koki},
title = {Real-Time Radiance Fields for Single-Image Portrait View Synthesis},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592460},
doi = {10.1145/3592460},
abstract = {We present a one-shot method to infer and render a photorealistic 3D representation from a single unposed image (e.g., face portrait) in real-time. Given a single RGB input, our image encoder directly predicts a canonical triplane representation of a neural radiance field for 3D-aware novel view synthesis via volume rendering. Our method is fast (24 fps) on consumer hardware, and produces higher quality results than strong GAN-inversion baselines that require test-time optimization. To train our triplane encoder pipeline, we use only synthetic data, showing how to distill the knowledge from a pretrained 3D GAN into a feedforward encoder. Technical contributions include a Vision Transformer-based triplane encoder, a camera data augmentation strategy, and a well-designed loss function for synthetic data training. We benchmark against the state-of-the-art methods, demonstrating significant improvements in robustness and image quality in challenging real-world settings. We showcase our results on portraits of faces (FFHQ) and cats (AFHQ), but our algorithm can also be applied in the future to other categories with a 3D-aware image generator.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {135},
numpages = {15},
keywords = {view synthesis, inverse rendering, neural radiance field}
}

