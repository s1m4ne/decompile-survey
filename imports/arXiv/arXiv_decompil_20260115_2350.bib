@article{arXiv:2204.08393,
  title = {Proton Stability: From the Standard Model to Beyond Grand Unification},
  author = {Juven Wang and Zheyan Wan and Yi-Zhuang You},
  abstract = {A proton is known for its longevity, but what is its lifetime? While many Grand Unified Theories predict the proton decay with a finite lifetime, we show that the Standard Model (SM) and some versions of Ultra Unification (which replace sterile neutrinos with new exotic gapped/gapless sectors, e.g., topological or conformal field theory under global anomaly cancellation constraints) with a discrete baryon plus lepton symmetry permit a stable proton. For the 4d SM with \$N\_f\$ families of 15 or 16 Weyl fermions, in addition to the continuous baryon minus lepton U(1)\$\_\{\\bf B - L\}\$ symmetry, there is also a compatible discrete baryon plus lepton \$\\mathbb\{Z\}\_\{2N\_f, \\bf B + L\}\$ symmetry. The \$\\mathbb\{Z\}\_\{2N\_f, \\bf B + L\}\$ is discrete due to the ABJ anomaly under the BPST SU(2) instanton. Although both U(1)\$\_\{\\bf B - L\}\$ and \$\\mathbb\{Z\}\_\{2N\_f, \\bf B + L\}\$ symmetries are anomaly-free under the dynamical SM gauge field, it is important to check whether they have mixed anomalies with the gravitational background field and higher symmetries (whose charged objects are Wilson electric or 't Hooft magnetic line operators) of SM. We can also replace the U(1)\$\_\{\\bf B - L\}\$ with a discrete variant \$\\mathbb\{Z\}\_\{4,X\}\$ for \$X \\equiv 5(\{\\bf B - L\})-\\frac\{2\}\{3\} \{\\tilde Y\}\$ of electroweak hypercharge \$\{\\tilde Y\}\$. We explore a systematic classification of candidate perturbative local and nonperturbative global anomalies of the 4d SM, including all these gauge and gravitational backgrounds, via a cobordism theory, which controls the SM's deformation class. We discuss the proton stability of the SM and Ultra Unification in the presence of discrete \$\{\\bf B + L\}\$ symmetry protection, in particular (U(1)\$\_\{\\bf B - L\} \\times \\mathbb\{Z\}\_\{2N\_f,\\bf B + L\})/\{\\mathbb\{Z\}\_2\textasciicircum{}\{\\rm F\}\}\$ or \$(\\mathbb\{Z\}\_\{4,X\} \\times \\mathbb\{Z\}\_\{2N\_f, \\bf B + L\})/\{\\mathbb\{Z\}\_2\textasciicircum{}\{\\rm F\}\}\$ symmetry with the fermion parity \$\\mathbb\{Z\}\_2\textasciicircum{}\{\\rm F\}\$.},
  journal = {arXiv preprint arXiv:2204.08393},
  year = {2022},
  month = {04},
  eprint = {2204.08393},
  archivePrefix = {arXiv},
  primaryClass = {hep-ph},
  categories = {hep-ph cond-mat.str-el hep-lat hep-th},
  comment = {6 pages. Sequel to arXiv:2112.14765. v2: refinement. Related talks: https://www.youtube.com/results?search\_query=cobordism+deformation+standard+model+crticiality. The original title "Proton Stability: From the Standard Model to Ultra Unification" is adjusted in PRD},
  updated = {2022-08-18T16:16:16Z},
  published = {2022-04-18T16:45:01Z},
  url = {https://arxiv.org/abs/2204.08393v2},
  pdf = {https://arxiv.org/pdf/2204.08393v2},
  doi = {10.1103/PhysRevD.106.025016},
  note = {Journal reference: Phys. Rev. D 106, 025016 (2022)},
}

@article{arXiv:2112.14765,
  title = {Cobordism and Deformation Class of the Standard Model},
  author = {Juven Wang and Zheyan Wan and Yi-Zhuang You},
  abstract = {'t Hooft anomalies of quantum field theories (QFTs) with an invertible global symmetry G (including spacetime and internal symmetries) in a \$d\$d spacetime are known to be classified by a \$d+1\$d cobordism group TP\$\_\{d+1\}\$(G), whose group generator is a \$d+1\$d cobordism invariant written as an invertible topological field theory (iTFT) Z\$\_\{d+1\}\$. The deformation class of QFT is recently proposed to be specified by its symmetry G and an iTFT Z\$\_\{d+1\}\$. Seemingly different QFTs of the same deformation class can be deformed to each other via quantum phase transitions. In this work, we ask which deformation class controls the 4d ungauged or gauged (SU(3)\$\\times\$SU(2)\$\\times\$U(1))/\$\\mathbb\{Z\}\_q\$ Standard Model (SM) for \$q=1,2,3,6\$ with a continuous or discrete \$(\\bf\{B\}-\\bf\{L\})\$ symmetry. We show that the answer contains some combination of 5d iTFTs: two \$\\mathbb\{Z\}\$ classes associated with \$(\\bf\{B\}-\\bf\{L\})\textasciicircum{}3\$ and \$(\\bf\{B\}-\\bf\{L\})\$-(gravity)\$\textasciicircum{}2\$ 4d perturbative local anomalies, a mod 16 class Atiyah-Patodi-Singer \$η\$ invariant and a mod 2 class Stiefel-Whitney \$w\_2w\_3\$ invariant associated with 4d nonperturbative global anomalies, and additional \$\\mathbb\{Z\}\_3\\times\\mathbb\{Z\}\_2\$ classes involving higher symmetries whose charged objects are Wilson electric or 't Hooft magnetic line operators. Out of \$\\mathbb\{Z\}\$ classes of local anomalies and 24576 classes of global anomalies, we pin down a deformation class of SM labeled by \$(N\_f,n\_\{ν\_\{R\}\},\$ p\$',q)\$, the family and "right-handed sterile" neutrino numbers, magnetic monopole datum, and mod \$q\$ relation. Grand Unifications and Ultra Unification that replaces sterile neutrinos with new exotic gapped/gapless sectors (e.g., topological or conformal field theory) or gravitational sectors with topological or cobordism constraints, all reside in an SM deformation class. Neighbor phases/transitions/critical regions near SM exhibit beyond SM phenomena.},
  journal = {arXiv preprint arXiv:2112.14765},
  year = {2021},
  month = {12},
  eprint = {2112.14765},
  archivePrefix = {arXiv},
  primaryClass = {hep-th},
  categories = {hep-th cond-mat.str-el hep-lat hep-ph math-ph},
  comment = {6 pages. Sequel to arXiv:1910.14668, arXiv:2006.16996, arXiv:2008.06499, arXiv:2012.15860, arXiv:2106.16248, arXiv:2111.10369, arXiv:2202.13498, arXiv:2204.08393. Related prior talks: https://www.youtube.com/results?search\_query=cobordism+deformation+standard+model+ultra+unification+crticiality. v4: Phys. Rev. D (Letter)},
  updated = {2022-08-18T15:15:15Z},
  published = {2021-12-29T18:59:51Z},
  url = {https://arxiv.org/abs/2112.14765v4},
  pdf = {https://arxiv.org/pdf/2112.14765v4},
  doi = {10.1103/PhysRevD.106.L041701},
  note = {Journal reference: Phys. Rev. D 106, L041701 (2022)},
}

@article{arXiv:2012.15860,
  title = {Ultra Unification},
  author = {Juven Wang},
  abstract = {Strong, electromagnetic, and weak forces were unified in the Standard Model (SM) with spontaneous gauge symmetry breaking. These forces were further conjectured to be unified in a simple Lie group gauge interaction in the Grand Unification (GUT). In this work, we propose a theory beyond the SM and GUT by adding new gapped Topological Phase Sectors consistent with the nonperturbative global anomaly cancellation and cobordism constraints (especially from the baryon minus lepton number \$\{\\bf B\}-\{\\bf L\}\$, the electroweak hypercharge \$Y\$, and the mixed gauge-gravitational anomaly). Gapped Topological Phase Sectors are constructed via symmetry extension, whose low energy contains unitary Lorentz invariant topological quantum field theories (TQFTs): either 3+1d non-invertible TQFT, or 4+1d invertible or non-invertible TQFT (short-range or long-range entangled gapped phase). Alternatively, there could also be right-handed "sterile" neutrinos, gapless unparticle physics, more general interacting conformal field theories, or gravity with topological cobordism constraints, or their combinations to altogether cancel the mixed gauge-gravitational anomaly. We propose that a new high-energy physics frontier beyond the conventional 0d particle physics relies on the new Topological Force and Topological Matter including gapped extended objects (gapped 1d line and 2d surface operators or defects, etc., whose open ends carry deconfined fractionalized particle or anyonic string excitations) or gapless conformal matter. Physical characterizations of these gapped extended objects require the mathematical theories of cohomology, cobordism, or category. Although weaker than the weak force, Topological Force is infinite-range or long-range which does not decay in the distance, and mediates between the linked worldvolume trajectories via fractional or categorical statistical interactions.},
  journal = {arXiv preprint arXiv:2012.15860},
  year = {2020},
  month = {12},
  eprint = {2012.15860},
  archivePrefix = {arXiv},
  primaryClass = {hep-th},
  categories = {hep-th cond-mat.str-el hep-ph},
  comment = {38 pages. Sequel to: arXiv:1910.14668, arXiv:2006.16996, arXiv:2008.06499. Supplementary: arXiv:1809.11171, arXiv:1705.06728. Physical Review journal version accepted subtitle: Unified model beyond grand unification. v3: refinement, and more clarifications on math/physics and neutrino masses. Related talks: https://www.youtube.com/results?search\_query=Ultra+Unification+Quantum+Criticality+Wang},
  updated = {2022-02-01T15:00:00Z},
  published = {2020-12-31T18:59:50Z},
  url = {https://arxiv.org/abs/2012.15860v3},
  pdf = {https://arxiv.org/pdf/2012.15860v3},
  doi = {10.1103/PhysRevD.103.105024},
  note = {Journal reference: Phys. Rev. D 103, 105024 (2021)},
}

@article{arXiv:2106.16248,
  title = {Gauge Enhanced Quantum Criticality Beyond the Standard Model},
  author = {Juven Wang and Yi-Zhuang You},
  abstract = {Standard lore views our 4d quantum vacuum governed by one of the candidate Standard Models (SMs), while lifting towards some Grand Unification-like structure (GUT) at higher energy scales. In contrast, in our work, we introduce an alternative view that the SM arises from various neighbor vacua competition in a quantum phase diagram. In general, we regard the SM arising near the gapless quantum criticality (either critical points or critical regions) between the competing neighbor vacua. In particular, we demonstrate how the \$su(3)\\times su(2)\\times u(1)\$ SM with 16n Weyl fermions arises near the quantum criticality between the GUT competition of Georgi-Glashow (GG) \$su(5)\$ and Pati-Salam (PS) \$su(4)\\times su(2)\\times su(2)\$. We propose two enveloping toy models. Model I is a conventional \$so(10)\$ GUT with a Spin(10) gauge group plus GUT-Higgs potential inducing various Higgs transitions. Model II modifies Model I plus a 4d discrete torsion Wess-Zumino-Witten-like term built from GUT-Higgs field (that matches a nonperturbative global mixed gauge-gravity anomaly captured by a 5d invertible topological field theory \$w\_2w\_3\$), which manifests a Beyond-Landau-Ginzburg criticality between GG and PS models, with extra Beyond-the-Standard-Model (BSM) excitations emerging near a quantum critical region. If the internal symmetries were treated as global symmetries, we show a gapless 4d deconfined quantum criticality with new BSM fractionalized fragmentary excitations of Color-Flavor separation, and gauge enhancement including a Dark Gauge force sector, altogether requiring a double fermionic Spin structure named DSpin. If the internal symmetries are dynamically gauged, we show a 4d boundary criticality such that only appropriately gauge enhanced dynamical GUT gauge fields propagate into an extra-dimensional 5d bulk. The phenomena may be regarded as SM deformation or morphogenesis.},
  journal = {arXiv preprint arXiv:2106.16248},
  year = {2021},
  month = {06},
  eprint = {2106.16248},
  archivePrefix = {arXiv},
  primaryClass = {hep-th},
  categories = {hep-th cond-mat.str-el hep-lat hep-ph},
  comment = {65 pages. Primers: https://www.youtube.com/results?search\_query=ultra+unification+quantum+crticiality+deformation+standard+model. Dedicate to Subir Sachdev (60), Xiao-Gang Wen (60), Edward Witten (70), Shing-Tung Yau (72). v3: Add more figures, motivations, comments on proton decay, non-perturbative effects on perturbatively irrelevant deformations. Sequel: arXiv:2111.10369, arXiv:2112.14765},
  updated = {2022-02-22T22:22:22Z},
  published = {2021-06-30T17:59:55Z},
  url = {https://arxiv.org/abs/2106.16248v3},
  pdf = {https://arxiv.org/pdf/2106.16248v3},
  doi = {10.1103/PhysRevD.106.025013},
  note = {Journal reference: Phys. Rev. D 106, 025013 (2022)},
}

@article{arXiv:2512.24296,
  title = {Quantum Thermodynamics and Quantum Perspectives},
  author = {Camille L Latune},
  abstract = {After a brief historical perspective, we introduce the key notions of work and heat for quantum systems, to then apply them to quantum engines operating on quantum Otto and Carnot cycles. The irreversible and dissipative character of the quantum Otto cycle is briefly analyzed, contrasting with the energetic optimality of the quantum Carnot cycle. The central question of quantum effects is also addressed and illustrated with several examples. Finally, the last part strives to explain the role that quantum thermodynamics plays for quantum applications and quantum technologies, particularly in relation to energy optimization and the trade-off between performances and energy costs.},
  journal = {arXiv preprint arXiv:2512.24296},
  year = {2025},
  month = {12},
  eprint = {2512.24296},
  archivePrefix = {arXiv},
  primaryClass = {quant-ph},
  categories = {quant-ph},
  comment = {in French language, Contribution to the celebration of the 200 years of Sadi Carnot's book "Reflections on the Motive Power of Fire", in French and part of the book "Chaleur, énergie, thermodynamique: le message de Carnot aujourd'hui... 200 ans après", direction G. Bertrand, Ed. Univ. de Dijon (2025). https://eud.ube.fr/sciences/891-chaleur-energie-thermodynamique-9782364415829.html?search\_query=carnot\&results=3},
  updated = {2025-12-30T15:36:24Z},
  published = {2025-12-30T15:36:24Z},
  url = {https://arxiv.org/abs/2512.24296v1},
  pdf = {https://arxiv.org/pdf/2512.24296v1},
  note = {Journal reference: "Chaleur, Energie, Thermodynamique: le message de Carnot aujourd'hui... 200 ans apres", sous la direction de Gilles Bertrand - Editions universitaires de Dijon (2025)},
}

@article{arXiv:2507.04931,
  title = {LIFT: Automating Symbolic Execution Optimization with Large Language Models for AI Networks},
  author = {Ruoxi Wang and Kun Li and Minghui Xu and Yue Zhang and Kaidi Xu and Chunchi Liu and Yinhao Xiao and Xiuzhen Cheng},
  abstract = {Dynamic Symbolic Execution (DSE) is a key technique in program analysis, widely used in software testing, vulnerability discovery, and formal verification. In distributed AI systems, DSE plays a crucial role in identifying hard-to-detect bugs, especially those arising from complex network communication patterns. However, traditional approaches to symbolic execution are often hindered by scalability issues and inefficiencies, particularly in large-scale systems. This paper introduces LIFT (Large-language-model Integrated Functional-equivalent-IR Transformation), a novel framework that leverages Large Language Models (LLMs) to automate the optimization of Intermediate Representations (IRs) in symbolic execution. LIFT addresses the challenges of symbolic execution by providing a scalable, context-sensitive solution for IR transformation. The framework consists of two phases: IR Analysis and Optimization, where LLMs optimize time-intensive IR blocks, and Symbolic Execution and Validation, which includes benchmarking and semantic verification to ensure correctness and generalizability. Experiments on real-world binaries demonstrated significant performance improvements, including a 53.5\\\% reduction in execution time for bigtest and a 10.24\\\% reduction for random, along with reductions in IR statements, PUT instructions, and temporary variables. These results demonstrate that LLMs simplify IRs while maintaining functional correctness, enhancing symbolic execution in distributed AI systems.},
  journal = {arXiv preprint arXiv:2507.04931},
  year = {2025},
  month = {07},
  eprint = {2507.04931},
  archivePrefix = {arXiv},
  primaryClass = {cs.CR},
  categories = {cs.CR},
  comment = {Accepted by ACM SIGCOMM 2025 - 2nd Workshop on Networks for AI Computing (NAIC). 7 pages, 2 figures, 2 tables},
  updated = {2025-07-07T12:26:56Z},
  published = {2025-07-07T12:26:56Z},
  url = {https://arxiv.org/abs/2507.04931v1},
  pdf = {https://arxiv.org/pdf/2507.04931v1},
}

@article{arXiv:2304.04658,
  title = {GraphBinMatch: Graph-based Similarity Learning for Cross-Language Binary and Source Code Matching},
  author = {Ali TehraniJamsaz and Hanze Chen and Ali Jannesari},
  abstract = {Matching binary to source code and vice versa has various applications in different fields, such as computer security, software engineering, and reverse engineering. Even though there exist methods that try to match source code with binary code to accelerate the reverse engineering process, most of them are designed to focus on one programming language. However, in real life, programs are developed using different programming languages depending on their requirements. Thus, cross-language binary-to-source code matching has recently gained more attention. Nonetheless, the existing approaches still struggle to have precise predictions due to the inherent difficulties when the problem of matching binary code and source code needs to be addressed across programming languages. In this paper, we address the problem of cross-language binary source code matching. We propose GraphBinMatch, an approach based on a graph neural network that learns the similarity between binary and source codes. We evaluate GraphBinMatch on several tasks, such as cross-language binary-to-source code matching and cross-language source-to-source matching. We also evaluate our approach performance on single-language binary-to-source code matching. Experimental results show that GraphBinMatch outperforms state-of-the-art significantly, with improvements as high as 15\% over the F1 score.},
  journal = {arXiv preprint arXiv:2304.04658},
  year = {2023},
  month = {04},
  eprint = {2304.04658},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE},
  updated = {2023-04-10T15:36:31Z},
  published = {2023-04-10T15:36:31Z},
  url = {https://arxiv.org/abs/2304.04658v1},
  pdf = {https://arxiv.org/pdf/2304.04658v1},
}

@article{arXiv:1809.04193,
  title = {Faster Variational Execution with Transparent Bytecode Transformation},
  author = {Chu-Pan Wong and Jens Meinicke and Lukas Lazarek and Christian Kästner},
  abstract = {Variational execution is a novel dynamic analysis technique for exploring highly configurable systems and accurately tracking information flow. It is able to efficiently analyze many configurations by aggressively sharing redundancies of program executions. The idea of variational execution has been demonstrated to be effective in exploring variations in the program, especially when the configuration space grows out of control. Existing implementations of variational execution often require heavy lifting of the runtime interpreter, which is painstaking and error-prone. Furthermore, the performance of this approach is suboptimal. For example, the state-of-the-art variational execution interpreter for Java, VarexJ, slows down executions by 100 to 800 times over a single execution for small to medium size Java programs. Instead of modifying existing JVMs, we propose to transform existing bytecode to make it variational, so it can be executed on an unmodified commodity JVM. Our evaluation shows a dramatic improvement on performance over the state-of-the-art, with a speedup of 2 to 46 times, and high efficiency in sharing computations.},
  journal = {arXiv preprint arXiv:1809.04193},
  year = {2018},
  month = {09},
  eprint = {1809.04193},
  archivePrefix = {arXiv},
  primaryClass = {cs.PL},
  categories = {cs.PL cs.SE},
  updated = {2018-09-11T22:54:37Z},
  published = {2018-09-11T22:54:37Z},
  url = {https://arxiv.org/abs/1809.04193v1},
  pdf = {https://arxiv.org/pdf/1809.04193v1},
}

@article{arXiv:2505.07360,
  title = {BinMetric: A Comprehensive Binary Analysis Benchmark for Large Language Models},
  author = {Xiuwei Shang and Guoqiang Chen and Shaoyin Cheng and Benlong Wu and Li Hu and Gangyang Li and Weiming Zhang and Nenghai Yu},
  abstract = {Binary analysis remains pivotal in software security, offering insights into compiled programs without source code access. As large language models (LLMs) continue to excel in diverse language understanding and generation tasks, their potential in decoding complex binary data structures becomes evident. However, the lack of standardized benchmarks in this domain limits the assessment and comparison of LLM's capabilities in binary analysis and hinders the progress of research and practical applications. To bridge this gap, we introduce BinMetric, a comprehensive benchmark designed specifically to evaluate the performance of large language models on binary analysis tasks. BinMetric comprises 1,000 questions derived from 20 real-world open-source projects across 6 practical binary analysis tasks, including decompilation, code summarization, assembly instruction generation, etc., which reflect actual reverse engineering scenarios. Our empirical study on this benchmark investigates the binary analysis capabilities of various state-of-the-art LLMs, revealing their strengths and limitations in this field. The findings indicate that while LLMs show strong potential, challenges still exist, particularly in the areas of precise binary lifting and assembly synthesis. In summary, BinMetric makes a significant step forward in measuring the binary analysis capabilities of LLMs, establishing a new benchmark leaderboard, and our study provides valuable insights for the future development of these LLMs in software security.},
  journal = {arXiv preprint arXiv:2505.07360},
  year = {2025},
  month = {05},
  eprint = {2505.07360},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE},
  comment = {23 pages, 5 figures, to be published in IJCAI 2025},
  updated = {2025-05-12T08:54:07Z},
  published = {2025-05-12T08:54:07Z},
  url = {https://arxiv.org/abs/2505.07360v1},
  pdf = {https://arxiv.org/pdf/2505.07360v1},
}

@article{arXiv:2304.09842,
  title = {Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models},
  author = {Pan Lu and Baolin Peng and Hao Cheng and Michel Galley and Kai-Wei Chang and Ying Nian Wu and Song-Chun Zhu and Jianfeng Gao},
  abstract = {Large language models (LLMs) have achieved remarkable progress in solving various natural language processing tasks due to emergent reasoning abilities. However, LLMs have inherent limitations as they are incapable of accessing up-to-date information (stored on the Web or in task-specific knowledge bases), using external tools, and performing precise mathematical and logical reasoning. In this paper, we present Chameleon, an AI system that mitigates these limitations by augmenting LLMs with plug-and-play modules for compositional reasoning. Chameleon synthesizes programs by composing various tools (e.g., LLMs, off-the-shelf vision models, web search engines, Python functions, and heuristic-based modules) for accomplishing complex reasoning tasks. At the heart of Chameleon is an LLM-based planner that assembles a sequence of tools to execute to generate the final response. We showcase the effectiveness of Chameleon on two multi-modal knowledge-intensive reasoning tasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54\% overall accuracy on ScienceQA, improving the best published few-shot result by 11.37\%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0\%, lifting the state of the art to 98.78\%. Our analysis also shows that the GPT-4-powered planner exhibits more consistent and rational tool selection via inferring potential constraints from instructions, compared to a ChatGPT-powered planner. The project is available at https://chameleon-llm.github.io.},
  journal = {arXiv preprint arXiv:2304.09842},
  year = {2023},
  month = {04},
  eprint = {2304.09842},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  categories = {cs.CL cs.AI cs.CV cs.LG},
  comment = {32 pages, 10 figures, 24 tables. Accepted to NeurIPS 2023},
  updated = {2023-10-31T17:43:39Z},
  published = {2023-04-19T17:47:47Z},
  url = {https://arxiv.org/abs/2304.09842v3},
  pdf = {https://arxiv.org/pdf/2304.09842v3},
}

@article{arXiv:2501.09201,
  title = {Towards Semantics Lifting for Scientific Computing: A Case Study on FFT},
  author = {Naifeng Zhang and Sanil Rao and Mike Franusich and Franz Franchetti},
  abstract = {The rise of automated code generation tools, such as large language models (LLMs), has introduced new challenges in ensuring the correctness and efficiency of scientific software, particularly in complex kernels, where numerical stability, domain-specific optimizations, and precise floating-point arithmetic are critical. We propose a stepwise semantics lifting approach using an extended SPIRAL framework with symbolic execution and theorem proving to statically derive high-level code semantics from LLM-generated kernels. This method establishes a structured path for verifying the source code's correctness via a step-by-step lifting procedure to high-level specification. We conducted preliminary tests on the feasibility of this approach by successfully lifting GPT-generated fast Fourier transform code to high-level specifications.},
  journal = {arXiv preprint arXiv:2501.09201},
  year = {2025},
  month = {01},
  eprint = {2501.09201},
  archivePrefix = {arXiv},
  primaryClass = {cs.PL},
  categories = {cs.PL cs.SC},
  comment = {Accepted at the Theory and Practice of Static Analysis Workshop (TPSA), in conjunction with the ACM SIGPLAN Symposium on Principles of Programming Languages (POPL), 2025},
  updated = {2025-01-15T23:24:32Z},
  published = {2025-01-15T23:24:32Z},
  url = {https://arxiv.org/abs/2501.09201v1},
  pdf = {https://arxiv.org/pdf/2501.09201v1},
}

@article{arXiv:2405.20611,
  title = {Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in Lifted Compiled Code},
  author = {Gary A. McCully and John D. Hastings and Shengjie Xu and Adam Fortier},
  abstract = {Detecting vulnerabilities within compiled binaries is challenging due to lost high-level code structures and other factors such as architectural dependencies, compilers, and optimization options. To address these obstacles, this research explores vulnerability detection using natural language processing (NLP) embedding techniques with word2vec, BERT, and RoBERTa to learn semantics from intermediate representation (LLVM IR) code. Long short-term memory (LSTM) neural networks were trained on embeddings from encoders created using approximately 48k LLVM functions from the Juliet dataset. This study is pioneering in its comparison of word2vec models with multiple bidirectional transformers (BERT, RoBERTa) embeddings built using LLVM code to train neural networks to detect vulnerabilities in compiled binaries. Word2vec Skip-Gram models achieved 92\% validation accuracy in detecting vulnerabilities, outperforming word2vec Continuous Bag of Words (CBOW), BERT, and RoBERTa. This suggests that complex contextual embeddings may not provide advantages over simpler word2vec models for this task when a limited number (e.g. 48K) of data samples are used to train the bidirectional transformer-based models. The comparative results provide novel insights into selecting optimal embeddings for learning compiler-independent semantic code representations to advance machine learning detection of vulnerabilities in compiled binaries.},
  journal = {arXiv preprint arXiv:2405.20611},
  year = {2024},
  month = {05},
  eprint = {2405.20611},
  archivePrefix = {arXiv},
  primaryClass = {cs.CR},
  categories = {cs.CR cs.CL cs.LG cs.SE},
  comment = {Updated with improvements},
  updated = {2024-09-27T13:29:00Z},
  published = {2024-05-31T03:57:19Z},
  url = {https://arxiv.org/abs/2405.20611v3},
  pdf = {https://arxiv.org/pdf/2405.20611v3},
  doi = {10.1109/CARS61786.2024.10778724},
  note = {Journal reference: 2024 IEEE Cyber Awareness and Research Symposium (CARS), Grand Forks, ND, USA, 2024, pp. 1-8},
}

@article{arXiv:2509.14646,
  title = {SALT4Decompile: Inferring Source-level Abstract Logic Tree for LLM-Based Binary Decompilation},
  author = {Yongpan Wang and Xin Xu and Xiaojie Zhu and Xiaodong Gu and Beijun Shen},
  abstract = {Decompilation is widely used in reverse engineering to recover high-level language code from binary executables. While recent approaches leveraging Large Language Models (LLMs) have shown promising progress, they typically treat assembly code as a linear sequence of instructions, overlooking arbitrary jump patterns and isolated data segments inherent to binary files. This limitation significantly hinders their ability to correctly infer source code semantics from assembly code. To address this limitation, we propose \\saltm, a novel binary decompilation method that abstracts stable logical features shared between binary and source code. The core idea of \\saltm is to abstract selected binary-level operations, such as specific jumps, into a high-level logic framework that better guides LLMs in semantic recovery. Given a binary function, \\saltm constructs a Source-level Abstract Logic Tree (\\salt) from assembly code to approximate the logic structure of high-level language. It then fine-tunes an LLM using the reconstructed \\salt to generate decompiled code. Finally, the output is refined through error correction and symbol recovery to improve readability and correctness. We compare \\saltm to three categories of baselines (general-purpose LLMs, commercial decompilers, and decompilation methods) using three well-known datasets (Decompile-Eval, MBPP, Exebench). Our experimental results demonstrate that \\saltm is highly effective in recovering the logic of the source code, significantly outperforming state-of-the-art methods (e.g., 70.4\\\% TCP rate on Decompile-Eval with a 10.6\\\% improvement). The results further validate its robustness against four commonly used obfuscation techniques. Additionally, analyses of real-world software and a user study confirm that our decompiled output offers superior assistance to human analysts in comprehending binary functions.},
  journal = {arXiv preprint arXiv:2509.14646},
  year = {2025},
  month = {09},
  eprint = {2509.14646},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE cs.PL},
  comment = {13 pages, 7 figures},
  updated = {2025-09-18T05:57:15Z},
  published = {2025-09-18T05:57:15Z},
  url = {https://arxiv.org/abs/2509.14646v1},
  pdf = {https://arxiv.org/pdf/2509.14646v1},
}

@article{arXiv:2501.19259,
  title = {Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone FlighT at the Edge},
  author = {Amogh Joshi and Sourav Sanyal and Kaushik Roy},
  abstract = {The integration of human-intuitive interactions into autonomous systems has been limited. Traditional Natural Language Processing (NLP) systems struggle with context and intent understanding, severely restricting human-robot interaction. Recent advancements in Large Language Models (LLMs) have transformed this dynamic, allowing for intuitive and high-level communication through speech and text, and bridging the gap between human commands and robotic actions. Additionally, autonomous navigation has emerged as a central focus in robotics research, with artificial intelligence (AI) increasingly being leveraged to enhance these systems. However, existing AI-based navigation algorithms face significant challenges in latency-critical tasks where rapid decision-making is critical. Traditional frame-based vision systems, while effective for high-level decision-making, suffer from high energy consumption and latency, limiting their applicability in real-time scenarios. Neuromorphic vision systems, combining event-based cameras and spiking neural networks (SNNs), offer a promising alternative by enabling energy-efficient, low-latency navigation. Despite their potential, real-world implementations of these systems, particularly on physical platforms such as drones, remain scarce. In this work, we present Neuro-LIFT, a real-time neuromorphic navigation framework implemented on a Parrot Bebop2 quadrotor. Leveraging an LLM for natural language processing, Neuro-LIFT translates human speech into high-level planning commands which are then autonomously executed using event-based neuromorphic vision and physics-driven planning. Our framework demonstrates its capabilities in navigating in a dynamic environment, avoiding obstacles, and adapting to human instructions in real-time.},
  journal = {arXiv preprint arXiv:2501.19259},
  year = {2025},
  month = {01},
  eprint = {2501.19259},
  archivePrefix = {arXiv},
  primaryClass = {cs.RO},
  categories = {cs.RO cs.CV cs.LG cs.NE eess.SY},
  comment = {Accepted for publication at the International Joint Conference on Neural Networks (IJCNN) 2025},
  updated = {2025-04-26T18:37:29Z},
  published = {2025-01-31T16:17:03Z},
  url = {https://arxiv.org/abs/2501.19259v2},
  pdf = {https://arxiv.org/pdf/2501.19259v2},
}

@article{arXiv:2506.18240,
  title = {Quantum-Classical Hybrid Quantized Neural Network},
  author = {Wenxin Li and Chuan Wang and Hongdong Zhu and Qi Gao and Yin Ma and Hai Wei and Kai Wen},
  abstract = {In this work, we introduce a novel Quadratic Binary Optimization (QBO) framework for training a quantized neural network. The framework enables the use of arbitrary activation and loss functions through spline interpolation, while Forward Interval Propagation addresses the nonlinearities and the multi-layered, composite structure of neural networks via discretizing activation functions into linear subintervals. This preserves the universal approximation properties of neural networks while allowing complex nonlinear functions accessible to quantum solvers, broadening their applicability in artificial intelligence. Theoretically, we derive an upper bound on the approximation error and the number of Ising spins required by deriving the sample complexity of the empirical risk minimization problem from an optimization perspective. A key challenge in solving the associated large-scale Quadratic Constrained Binary Optimization (QCBO) model is the presence of numerous constraints. To overcome this, we adopt the Quantum Conditional Gradient Descent (QCGD) algorithm, which solves QCBO directly on quantum hardware. We establish the convergence of QCGD under a quantum oracle subject to randomness, bounded variance, and limited coefficient precision, and further provide an upper bound on the Time-To-Solution. To enhance scalability, we further incorporate a decomposed copositive optimization scheme that replaces the monolithic lifted model with sample-wise subproblems. This decomposition substantially reduces the quantum resource requirements and enables efficient low-bit neural network training. We further propose the usage of QCGD and Quantum Progressive Hedging (QPH) algorithm to efficiently solve the decomposed problem.},
  journal = {arXiv preprint arXiv:2506.18240},
  year = {2025},
  month = {06},
  eprint = {2506.18240},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  categories = {cs.LG cs.AI physics.optics},
  updated = {2025-12-08T06:41:28Z},
  published = {2025-06-23T02:12:36Z},
  url = {https://arxiv.org/abs/2506.18240v4},
  pdf = {https://arxiv.org/pdf/2506.18240v4},
}

@article{arXiv:2304.12866,
  title = {Binary stochasticity enabled highly efficient neuromorphic deep learning achieves better-than-software accuracy},
  author = {Yang Li and Wei Wang and Ming Wang and Chunmeng Dou and Zhengyu Ma and Huihui Zhou and Peng Zhang and Nicola Lepri and Xumeng Zhang and Qing Luo and Xiaoxin Xu and Guanhua Yang and Feng Zhang and Ling Li and Daniele Ielmini and Ming Liu},
  abstract = {Deep learning needs high-precision handling of forwarding signals, backpropagating errors, and updating weights. This is inherently required by the learning algorithm since the gradient descent learning rule relies on the chain product of partial derivatives. However, it is challenging to implement deep learning in hardware systems that use noisy analog memristors as artificial synapses, as well as not being biologically plausible. Memristor-based implementations generally result in an excessive cost of neuronal circuits and stringent demands for idealized synaptic devices. Here, we demonstrate that the requirement for high precision is not necessary and that more efficient deep learning can be achieved when this requirement is lifted. We propose a binary stochastic learning algorithm that modifies all elementary neural network operations, by introducing (i) stochastic binarization of both the forwarding signals and the activation function derivatives, (ii) signed binarization of the backpropagating errors, and (iii) step-wised weight updates. Through an extensive hybrid approach of software simulation and hardware experiments, we find that binary stochastic deep learning systems can provide better performance than the software-based benchmarks using the high-precision learning algorithm. Also, the binary stochastic algorithm strongly simplifies the neural network operations in hardware, resulting in an improvement of the energy efficiency for the multiply-and-accumulate operations by more than three orders of magnitudes.},
  journal = {arXiv preprint arXiv:2304.12866},
  year = {2023},
  month = {04},
  eprint = {2304.12866},
  archivePrefix = {arXiv},
  primaryClass = {cs.NE},
  categories = {cs.NE cs.LG eess.SP physics.data-an},
  updated = {2023-04-25T14:38:36Z},
  published = {2023-04-25T14:38:36Z},
  url = {https://arxiv.org/abs/2304.12866v1},
  pdf = {https://arxiv.org/pdf/2304.12866v1},
  doi = {10.1002/aisy.202300399},
  note = {Journal reference: Adv. Intel. Sys., 6(1), 2300399, 2024},
}

@article{arXiv:2201.07420,
  title = {Cross-Language Binary-Source Code Matching with Intermediate Representations},
  author = {Yi Gui and Yao Wan and Hongyu Zhang and Huifang Huang and Yulei Sui and Guandong Xu and Zhiyuan Shao and Hai Jin},
  abstract = {Binary-source code matching plays an important role in many security and software engineering related tasks such as malware detection, reverse engineering and vulnerability assessment. Currently, several approaches have been proposed for binary-source code matching by jointly learning the embeddings of binary code and source code in a common vector space. Despite much effort, existing approaches target on matching the binary code and source code written in a single programming language. However, in practice, software applications are often written in different programming languages to cater for different requirements and computing platforms. Matching binary and source code across programming languages introduces additional challenges when maintaining multi-language and multi-platform applications. To this end, this paper formulates the problem of cross-language binary-source code matching, and develops a new dataset for this new problem. We present a novel approach XLIR, which is a Transformer-based neural network by learning the intermediate representations for both binary and source code. To validate the effectiveness of XLIR, comprehensive experiments are conducted on two tasks of cross-language binary-source code matching, and cross-language source-source code matching, on top of our curated dataset. Experimental results and analysis show that our proposed XLIR with intermediate representations significantly outperforms other state-of-the-art models in both of the two tasks.},
  journal = {arXiv preprint arXiv:2201.07420},
  year = {2022},
  month = {01},
  eprint = {2201.07420},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE cs.AI},
  comment = {SANER2022},
  updated = {2022-01-19T05:17:02Z},
  published = {2022-01-19T05:17:02Z},
  url = {https://arxiv.org/abs/2201.07420v1},
  pdf = {https://arxiv.org/pdf/2201.07420v1},
}

@article{arXiv:2401.11161,
  title = {BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching},
  author = {Ling Jiang and Junwen An and Huihui Huang and Qiyi Tang and Sen Nie and Shi Wu and Yuqun Zhang},
  abstract = {While third-party libraries are extensively reused to enhance productivity during software development, they can also introduce potential security risks such as vulnerability propagation. Software composition analysis, proposed to identify reused TPLs for reducing such risks, has become an essential procedure within modern DevSecOps. As one of the mainstream SCA techniques, binary-to-source SCA identifies the third-party source projects contained in binary files via binary source code matching, which is a major challenge in reverse engineering since binary and source code exhibit substantial disparities after compilation. The existing binary-to-source SCA techniques leverage basic syntactic features that suffer from redundancy and lack robustness in the large-scale TPL dataset, leading to inevitable false positives and compromised recall. To mitigate these limitations, we introduce BinaryAI, a novel binary-to-source SCA technique with two-phase binary source code matching to capture both syntactic and semantic code features. First, BinaryAI trains a transformer-based model to produce function-level embeddings and obtain similar source functions for each binary function accordingly. Then by applying the link-time locality to facilitate function matching, BinaryAI detects the reused TPLs based on the ratio of matched source functions. Our experimental results demonstrate the superior performance of BinaryAI in terms of binary source code matching and the downstream SCA task. Specifically, our embedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving 22.54\% recall@1 and 0.34 MRR compared with 10.75\% and 0.17 respectively. Additionally, BinaryAI outperforms all existing binary-to-source SCA tools in TPL detection, increasing the precision from 73.36\% to 85.84\% and recall from 59.81\% to 64.98\% compared with the well-recognized commercial SCA product.},
  journal = {arXiv preprint arXiv:2401.11161},
  year = {2024},
  month = {01},
  eprint = {2401.11161},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE},
  comment = {In Proceedings of the 46th International Conference on Software Engineering (ICSE'24)},
  updated = {2024-08-26T03:11:04Z},
  published = {2024-01-20T07:57:57Z},
  url = {https://arxiv.org/abs/2401.11161v3},
  pdf = {https://arxiv.org/pdf/2401.11161v3},
}

@article{arXiv:2412.20992,
  title = {Verified Lifting of Deep learning Operators},
  author = {Qi Zhan and Xing Hu and Xin Xia and Shanping Li},
  abstract = {Deep learning operators are fundamental components of modern deep learning frameworks. With the growing demand for customized operators, it has become increasingly common for developers to create their own. However, designing and implementing operators is complex and error-prone, due to hardware-specific optimizations and the need for numerical stability. There is a pressing need for tools that can summarize the functionality of both existing and user-defined operators. To address this gap, this work introduces a novel framework for the verified lifting of deep learning operators, which synthesizes high-level mathematical formulas from low-level implementations. Our approach combines symbolic execution, syntax-guided synthesis, and SMT-based verification to produce readable and formally verified mathematical formulas. In synthesis, we employ a combination of top-down and bottom-up strategies to explore the vast search space efficiently; In verification, we design invariant synthesis patterns and leverage SMT solvers to validate the correctness of the derived summaries; In simplification, we use egraph-based techniques with custom rules to restore complex formulas to their natural, intuitive forms. Evaluated on a dataset of deep learning operators implemented in Triton from the real world, our method demonstrates the effectiveness of synthesis and verification compared to existing techniques. This framework bridges the gap between low-level implementations and high-level abstractions, improving understanding and reliability in deep learning operator development.},
  journal = {arXiv preprint arXiv:2412.20992},
  year = {2024},
  month = {12},
  eprint = {2412.20992},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  categories = {cs.LG cs.PL stat.ML},
  updated = {2024-12-30T14:57:32Z},
  published = {2024-12-30T14:57:32Z},
  url = {https://arxiv.org/abs/2412.20992v1},
  pdf = {https://arxiv.org/pdf/2412.20992v1},
}

@article{arXiv:1910.11717,
  title = {Selective Lambda Lifting},
  author = {Sebastian Graf and Simon Peyton Jones},
  abstract = {Lambda lifting is a well-known transformation, traditionally employed for compiling functional programs to supercombinators. However, more recent abstract machines for functional languages like OCaml and Haskell tend to do closure conversion instead for direct access to the environment, so lambda lifting is no longer necessary to generate machine code. We propose to revisit selective lambda lifting in this context as an optimising code generation strategy and conceive heuristics to identify beneficial lifting opportunities. We give a static analysis for estimating impact on heap allocations of a lifting decision. Performance measurements of our implementation within the Glasgow Haskell Compiler on a large corpus of Haskell benchmarks suggest modest speedups.},
  journal = {arXiv preprint arXiv:1910.11717},
  year = {2019},
  month = {10},
  eprint = {1910.11717},
  archivePrefix = {arXiv},
  primaryClass = {cs.PL},
  categories = {cs.PL},
  comment = {Rejected from ICFP 2019},
  updated = {2019-10-28T14:53:56Z},
  published = {2019-10-25T13:31:21Z},
  url = {https://arxiv.org/abs/1910.11717v2},
  pdf = {https://arxiv.org/pdf/1910.11717v2},
}

@article{arXiv:2304.01102,
  title = {RunBugRun -- An Executable Dataset for Automated Program Repair},
  author = {Julian Aron Prenner and Romain Robbes},
  abstract = {Recently, we can notice a transition to data-driven techniques in Automated Program Repair (APR), in particular towards deep neural networks. This entails training on hundreds of thousands or even millions of non-executable code fragments. We would like to bring more attention to an aspect of code often neglected in Neural Program Repair (NPR), namely its execution. Code execution has several significant advantages. It allows for test-based evaluation of candidate fixes and can provide valuable information to aid repair. In this work we present a fully executable dataset of 450,000 small buggy/fixed program pairs originally submitted to programming competition websites written in eight different programming languages. Along with the dataset we provide infrastructure to compile, safely execute and test programs as well as fine-grained bug-type labels. To give a point of reference, we provide basic evaluation results for two baselines, one based on a generate-and-validate approach and one on deep learning. With this dataset we follow several goals: we want to lift Neural Program Repair beyond fully static code representations, foster the use of execution-based features and, by including several different languages, counterbalance the predominance of Java in the current landscape of APR datasets and benchmarks.},
  journal = {arXiv preprint arXiv:2304.01102},
  year = {2023},
  month = {04},
  eprint = {2304.01102},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE cs.LG},
  updated = {2023-04-03T16:02:00Z},
  published = {2023-04-03T16:02:00Z},
  url = {https://arxiv.org/abs/2304.01102v1},
  pdf = {https://arxiv.org/pdf/2304.01102v1},
}

@article{arXiv:2506.10125,
  title = {D-LiFT: Improving LLM-based Decompiler Backend via Code Quality-driven Fine-tuning},
  author = {Muqi Zou and Hongyu Cai and Hongwei Wu and Zion Leonahenahe Basque and Arslan Khan and Berkay Celik and Dave and Tian and Antonio Bianchi and Ruoyu and Wang and Dongyan Xu},
  abstract = {As one of the key tools in many security tasks, decompilers reconstruct human-readable source code from binaries. Yet, despite recent advances, their outputs often suffer from syntactic and semantic errors and remain difficult to read. Recently, with the advent of large language models (LLMs), researchers began to explore the potential of LLMs to refine decompiler output. Nevertheless, our study of these approaches reveals their problems, such as introducing new errors and relying on unreliable accuracy validation. In this paper, we present D-LIFT, an enhanced decompiler-LLM pipeline with a fine-tuned LLM using code quality-aware reinforcement learning. Unlike prior work that overlooks preserving accuracy, D-LIFT adheres to a key principle for enhancing the quality of decompiled code: preserving accuracy while improving readability. Central to D-LIFT, we propose D-Score, an integrated code quality assessment system to score the decompiled source code from multiple aspects, and use it to guide reinforcement learning fine-tuning and to select the best output during inference. In line with our principle, D-Score assigns low scores to any inaccurate output and only awards higher scores for readability to code that passes the accuracy check. Our implementation, based on Ghidra and a range of LLMs, demonstrates significant improvements for the accurate decompiled code from the coreutils and util-linux projects. Compared to baseline LLMs without D-Score-driven fine-tuning, our trained LLMs produce 55.3\% more improved decompiled functions, as measured by D-Score. Overall, D-LIFT improves the quality of 68.2\% of all the functions produced by the native decompiler.},
  journal = {arXiv preprint arXiv:2506.10125},
  year = {2025},
  month = {06},
  eprint = {2506.10125},
  archivePrefix = {arXiv},
  primaryClass = {cs.CR},
  categories = {cs.CR cs.SE},
  updated = {2025-08-15T18:26:50Z},
  published = {2025-06-11T19:09:08Z},
  url = {https://arxiv.org/abs/2506.10125v2},
  pdf = {https://arxiv.org/pdf/2506.10125v2},
  author_affiliations = {Muqi Zou: Jing; Hongyu Cai: Jing; Hongwei Wu: Jing; Zion Leonahenahe Basque: Jing; Arslan Khan: Jing; Berkay Celik: Jing; Dave: Jing; Tian: Fish; Antonio Bianchi: Fish; Ruoyu: Fish},
}

@article{arXiv:2511.05791,
  title = {VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models},
  author = {Manav Kulshrestha and S. Talha Bukhari and Damon Conover and Aniket Bera},
  abstract = {Robotic grasping is a fundamental capability for autonomous manipulation; however, most existing methods rely on large-scale expert annotations and necessitate retraining to handle new objects. We present VLAD-Grasp, a Vision-Language model Assisted zero-shot approach for Detecting grasps. From a single RGB-D image, our method (1) prompts a large vision-language model to generate a goal image where a straight rod "impales" the object, representing an antipodal grasp, (2) predicts depth and segmentation to lift this generated image into 3D, and (3) aligns generated and observed object point clouds via principal component analysis and correspondence-free optimization to recover an executable grasp pose. Unlike prior work, our approach is training-free and does not rely on curated grasp datasets. Despite this, VLAD-Grasp achieves performance that is competitive with or superior to that of state-of-the-art supervised models on the Cornell and Jacquard datasets. We further demonstrate zero-shot generalization to novel real-world objects on a Franka Research 3 robot, highlighting vision-language foundation models as powerful priors for robotic manipulation.},
  journal = {arXiv preprint arXiv:2511.05791},
  year = {2025},
  month = {11},
  eprint = {2511.05791},
  archivePrefix = {arXiv},
  primaryClass = {cs.RO},
  categories = {cs.RO cs.AI cs.LG},
  comment = {8 pages, 4 figures, under review},
  updated = {2025-11-08T01:47:40Z},
  published = {2025-11-08T01:47:40Z},
  url = {https://arxiv.org/abs/2511.05791v1},
  pdf = {https://arxiv.org/pdf/2511.05791v1},
}

@article{arXiv:2507.14570,
  title = {LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges},
  author = {Xu Cheng and Liang Yao and Feng He and Yukuo Cen and Yufei He and Chenhui Zhang and Wenzheng Feng and Hongyun Cai and Jie Tang},
  abstract = {Graph Neural Networks (GNNs) have emerged as powerful tools for various graph mining tasks, yet existing scalable solutions often struggle to balance execution efficiency with prediction accuracy. These difficulties stem from iterative message-passing techniques, which place significant computational demands and require extensive GPU memory, particularly when dealing with the neighbor explosion issue inherent in large-scale graphs. This paper introduces a scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN, which can perform representation learning on 100 billion graphs with a single GPU in 10 hours and shows a 13.8\% improvement in User Acquisition scenarios. We examine existing graph partitioning methods and design a superior graph partition algorithm named LPMetis. In particular, LPMetis outperforms current state-of-the-art (SOTA) approaches on various evaluation metrics. In addition, our paper proposes a subgraph augmentation strategy to enhance the model's predictive performance. It exhibits excellent compatibility, allowing the entire framework to accommodate various GNN algorithms. Successfully deployed on the Tencent platform, LPS-GNN has been tested on public and real-world datasets, achieving performance lifts of 8. 24\% to 13. 89\% over SOTA models in online applications.},
  journal = {arXiv preprint arXiv:2507.14570},
  year = {2025},
  month = {07},
  eprint = {2507.14570},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  categories = {cs.LG cs.AI},
  updated = {2025-07-19T10:44:26Z},
  published = {2025-07-19T10:44:26Z},
  url = {https://arxiv.org/abs/2507.14570v1},
  pdf = {https://arxiv.org/pdf/2507.14570v1},
}

@article{arXiv:2601.05772,
  title = {StriderSPD: Structure-Guided Joint Representation Learning for Binary Security Patch Detection},
  author = {Qingyuan Li and Chenchen Yu and Chuanyi Li and Xin-Cheng Wen and Cheryl Lee and Cuiyun Gao and Bin Luo},
  abstract = {Vulnerabilities severely threaten software systems, making the timely application of security patches crucial for mitigating attacks. However, software vendors often silently patch vulnerabilities with limited disclosure, where Security Patch Detection (SPD) comes to protect software assets. Recently, most SPD studies have targeted Open-Source Software (OSS), yet a large portion of real-world software is closed-source, where patches are distributed as binaries without accessible source code. The limited binary SPD approaches often lift binaries to abstraction levels, i.e., assembly code or pseudo-code. However, assembly code is register-based instructions conveying limited semantics, while pseudo-code lacks parser-compatible grammar to extract structure, both hindering accurate vulnerability-fix representation learning. In addition, previous studies often obtain training and testing data from the same project for evaluation, which fails to reflect closed-source conditions. To alleviate the above challenges, we propose \\textbf\{\\textit\{StriderSPD\}\}, a \\underline\{Str\}ucture-gu\\underline\{ide\}d joint \\underline\{r\}epresentation \\underline\{SPD\} framework of binary code that integrates a graph branch into a large language model (LLM), leveraging structural information to guide the LLM in identifying security patches. Our novel design of the adapters in the graph branch effectively aligns the representations between assembly code and pseudo-code at the LLM's token level. We further present a two-stage training strategy to address the optimization imbalance caused by the large parameter disparity between StriderSPD's two branches, which enables proper branch fitting. To enable more realistic evaluation, we construct a binary SPD benchmark that is disjoint from prior datasets in both projects and domains and extensively evaluate StriderSPD on this benchmark.},
  journal = {arXiv preprint arXiv:2601.05772},
  year = {2026},
  month = {01},
  eprint = {2601.05772},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE cs.CR},
  updated = {2026-01-09T12:55:29Z},
  published = {2026-01-09T12:55:29Z},
  url = {https://arxiv.org/abs/2601.05772v1},
  pdf = {https://arxiv.org/pdf/2601.05772v1},
}

@article{arXiv:2101.08116,
  title = {Improving type information inferred by decompilers with supervised machine learning},
  author = {Javier Escalada and Ted Scully and Francisco Ortin},
  abstract = {In software reverse engineering, decompilation is the process of recovering source code from binary files. Decompilers are used when it is necessary to understand or analyze software for which the source code is not available. Although existing decompilers commonly obtain source code with the same behavior as the binaries, that source code is usually hard to interpret and certainly differs from the original code written by the programmer. Massive codebases could be used to build supervised machine learning models aimed at improving existing decompilers. In this article, we build different classification models capable of inferring the high-level type returned by functions, with significantly higher accuracy than existing decompilers. We automatically instrument C source code to allow the association of binary patterns with their corresponding high-level constructs. A dataset is created with a collection of real open-source applications plus a huge number of synthetic programs. Our system is able to predict function return types with a 79.1\% F1-measure, whereas the best decompiler obtains a 30\% F1-measure. Moreover, we document the binary patterns used by our classifier to allow their addition in the implementation of existing decompilers.},
  journal = {arXiv preprint arXiv:2101.08116},
  year = {2021},
  month = {01},
  eprint = {2101.08116},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE cs.LG cs.PL},
  updated = {2021-02-24T11:01:27Z},
  published = {2021-01-19T11:45:46Z},
  url = {https://arxiv.org/abs/2101.08116v2},
  pdf = {https://arxiv.org/pdf/2101.08116v2},
  author_affiliations = {Javier Escalada: University of Oviedo; Ted Scully: Cork Institute of Technology; Francisco Ortin: University of Oviedo},
}

@article{arXiv:2507.10624,
  title = {Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning},
  author = {Zheng Zhang},
  abstract = {Large Language Models (LLMs) display striking surface fluency yet systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy, and logical consistency. This paper offers a structural diagnosis of such failures, revealing a persistent gap between \\textit\{comprehension\} and \\textit\{competence\}. Through controlled experiments and architectural analysis, we demonstrate that LLMs often articulate correct principles without reliably applying them--a failure rooted not in knowledge access, but in computational execution. We term this phenomenon the computational \\textit\{split-brain syndrome\}, where instruction and action pathways are geometrically and functionally dissociated. This core limitation recurs across domains, from mathematical operations to relational inferences, and explains why model behavior remains brittle even under idealized prompting. We argue that LLMs function as powerful pattern completion engines, but lack the architectural scaffolding for principled, compositional reasoning. Our findings delineate the boundary of current LLM capabilities and motivate future models with metacognitive control, principle lifting, and structurally grounded execution. This diagnosis also clarifies why mechanistic interpretability findings may reflect training-specific pattern coordination rather than universal computational principles, and why the geometric separation between instruction and execution pathways suggests limitations in neural introspection and mechanistic analysis.},
  journal = {arXiv preprint arXiv:2507.10624},
  year = {2025},
  month = {07},
  eprint = {2507.10624},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  categories = {cs.AI cs.LG},
  comment = {v2: Two TMLR revision rounds addressing reviewer feedback. Added real-world validation (3.4), interpretability analysis (7), computational hallucination framework, strengthened theory. v3: Sec 3.2 - added transformer architecture diagram, clarified UAT capacity vs computational limits, improved role specialization theorem presentation},
  updated = {2025-11-14T15:49:48Z},
  published = {2025-07-14T04:01:45Z},
  url = {https://arxiv.org/abs/2507.10624v3},
  pdf = {https://arxiv.org/pdf/2507.10624v3},
}

@article{arXiv:2405.19581,
  title = {Source Code Foundation Models are Transferable Binary Analysis Knowledge Bases},
  author = {Zian Su and Xiangzhe Xu and Ziyang Huang and Kaiyuan Zhang and Xiangyu Zhang},
  abstract = {Human-Oriented Binary Reverse Engineering (HOBRE) lies at the intersection of binary and source code, aiming to lift binary code to human-readable content relevant to source code, thereby bridging the binary-source semantic gap. Recent advancements in uni-modal code model pre-training, particularly in generative Source Code Foundation Models (SCFMs) and binary understanding models, have laid the groundwork for transfer learning applicable to HOBRE. However, existing approaches for HOBRE rely heavily on uni-modal models like SCFMs for supervised fine-tuning or general LLMs for prompting, resulting in sub-optimal performance. Inspired by recent progress in large multi-modal models, we propose that it is possible to harness the strengths of uni-modal code models from both sides to bridge the semantic gap effectively. In this paper, we introduce a novel probe-and-recover framework that incorporates a binary-source encoder-decoder model and black-box LLMs for binary analysis. Our approach leverages the pre-trained knowledge within SCFMs to synthesize relevant, symbol-rich code fragments as context. This additional context enables black-box LLMs to enhance recovery accuracy. We demonstrate significant improvements in zero-shot binary summarization and binary function name recovery, with a 10.3\% relative gain in CHRF and a 16.7\% relative gain in a GPT4-based metric for summarization, as well as a 6.7\% and 7.4\% absolute increase in token-level precision and recall for name recovery, respectively. These results highlight the effectiveness of our approach in automating and improving binary code analysis.},
  journal = {arXiv preprint arXiv:2405.19581},
  year = {2024},
  month = {05},
  eprint = {2405.19581},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE cs.AI cs.CL},
  updated = {2024-10-30T16:12:36Z},
  published = {2024-05-30T00:17:44Z},
  url = {https://arxiv.org/abs/2405.19581v2},
  pdf = {https://arxiv.org/pdf/2405.19581v2},
}

@article{arXiv:2108.07639,
  title = {Learning C to x86 Translation: An Experiment in Neural Compilation},
  author = {Jordi Armengol-Estapé and Michael F. P. O'Boyle},
  abstract = {Deep learning has had a significant impact on many fields. Recently, code-to-code neural models have been used in code translation, code refinement and decompilation. However, the question of whether these models can automate compilation has yet to be investigated. In this work, we explore neural compilation, building and evaluating Transformer models that learn how to produce x86 assembler from C code. Although preliminary results are relatively weak, we make our data, models and code publicly available to encourage further research in this area.},
  journal = {arXiv preprint arXiv:2108.07639},
  year = {2021},
  month = {08},
  eprint = {2108.07639},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  categories = {cs.AI cs.PL},
  comment = {Published in AIPLANS 2021},
  updated = {2022-12-16T11:21:46Z},
  published = {2021-08-17T14:11:15Z},
  url = {https://arxiv.org/abs/2108.07639v2},
  pdf = {https://arxiv.org/pdf/2108.07639v2},
  note = {Journal reference: Armengol-Estapé, J. and O'Boyle, M. Learning C to x86 translation: An experiment in neural compilation. In Advances in Programming Languages and Neurosymbolic Systems Workshop, 2021. URL \\url\{https://openreview.net/forum?id=444ug\_EYXet\}},
}

@article{arXiv:2404.18249,
  title = {Tenspiler: A Verified Lifting-Based Compiler for Tensor Operations (Extended Version)},
  author = {Jie Qiu and Colin Cai and Sahil Bhatia and Niranjan Hasabnis and Sanjit A. Seshia and Alvin Cheung},
  abstract = {Tensor processing infrastructures such as deep learning frameworks and specialized hardware accelerators have revolutionized how computationally intensive code from domains such as deep learning and image processing is executed and optimized. These infrastructures provide powerful and expressive abstractions while ensuring high performance. However, to utilize them, code must be written specifically using the APIs / ISAs of such software frameworks or hardware accelerators. Importantly, given the fast pace of innovation in these domains, code written today quickly becomes legacy as new frameworks and accelerators are developed, and migrating such legacy code manually is a considerable effort. To enable developers in leveraging such DSLs while preserving their current programming paradigm, we introduce Tenspiler, a verified lifting-based compiler that uses program synthesis to translate sequential programs written in general-purpose programming languages (e.g., C++ or Python code) into tensor operations. Central to Tenspiler is our carefully crafted yet simple intermediate language, named TensIR, that expresses tensor operations. TensIR enables efficient lifting, verification, and code generation. Currently, Tenspiler already supports \$\\textbf\{six\}\$ DSLs, spanning a broad spectrum of software and hardware environments. Furthermore, we show that new backends can be easily supported by Tenspiler by adding simple pattern-matching rules for TensIR. Using 10 real-world code benchmark suites, our experimental evaluation shows that by translating code to be executed on \$\\textbf\{6\}\$ different software frameworks and hardware devices, Tenspiler offers on average 105\$\\times\$ kernel and 9.65\$\\times\$ end-to-end execution time improvement over the fully-optimized sequential implementation of the same benchmarks.},
  journal = {arXiv preprint arXiv:2404.18249},
  year = {2024},
  month = {04},
  eprint = {2404.18249},
  archivePrefix = {arXiv},
  primaryClass = {cs.PL},
  categories = {cs.PL},
  updated = {2024-12-14T08:29:46Z},
  published = {2024-04-28T17:10:17Z},
  url = {https://arxiv.org/abs/2404.18249v3},
  pdf = {https://arxiv.org/pdf/2404.18249v3},
}

@article{arXiv:2105.05159,
  title = {Proving LTL Properties of Bitvector Programs and Decompiled Binaries (Extended)},
  author = {Yuandong Cyrus Liu and Chengbin Pang and Daniel Dietsch and Eric Koskinen and Ton-Chanh Le and Georgios Portokalidis and Jun Xu},
  abstract = {There is increasing interest in applying verification tools to programs that have bitvector operations (eg., binaries). SMT solvers, which serve as a foundation for these tools, have thus increased support for bitvector reasoning through bit-blasting and linear arithmetic approximations. In this paper we show that similar linear arithmetic approximation of bitvector operations can be done at the source level through transformations. Specifically, we introduce new paths that over-approximate bitvector operations with linear conditions/constraints, increasing branching but allowing us to better exploit the well-developed integer reasoning and interpolation of verification tools. We show that, for reachability of bitvector programs, increased branching incurs negligible overhead yet, when combined with integer interpolation optimizations, enables more programs to be verified. We further show this exploitation of integer interpolation in the common case also enables competitive termination verification of bitvector programs and leads to the first effective technique for LTL verification of bitvector programs. Finally, we provide an in-depth case study of decompiled ("lifted") binary programs, which emulate X86 execution through frequent use of bitvector operations. We present a new tool DarkSea, the first tool capable of verifying reachability, termination, and LTL of lifted binaries.},
  journal = {arXiv preprint arXiv:2105.05159},
  year = {2021},
  month = {05},
  eprint = {2105.05159},
  archivePrefix = {arXiv},
  primaryClass = {cs.PL},
  categories = {cs.PL cs.FL cs.SE eess.SY},
  comment = {39 pages(including Appendix), 10 tables, 4 Postscript figures, accepted to APLAS 2021},
  updated = {2021-08-28T05:44:26Z},
  published = {2021-05-11T16:12:02Z},
  url = {https://arxiv.org/abs/2105.05159v2},
  pdf = {https://arxiv.org/pdf/2105.05159v2},
  author_affiliations = {Yuandong Cyrus Liu: Stevens Institute of Technology; Chengbin Pang: Stevens Institute of Technology; Daniel Dietsch: University of Freiburg; Eric Koskinen: Stevens Institute of Technology; Ton-Chanh Le: Stevens Institute of Technology; Georgios Portokalidis: Stevens Institute of Technology; Jun Xu: Stevens Institute of Technology},
}

@article{arXiv:2302.08760,
  title = {3D Human Pose Lifting with Grid Convolution},
  author = {Yangyuxuan Kang and Yuyang Liu and Anbang Yao and Shandong Wang and Enhua Wu},
  abstract = {Existing lifting networks for regressing 3D human poses from 2D single-view poses are typically constructed with linear layers based on graph-structured representation learning. In sharp contrast to them, this paper presents Grid Convolution (GridConv), mimicking the wisdom of regular convolution operations in image space. GridConv is based on a novel Semantic Grid Transformation (SGT) which leverages a binary assignment matrix to map the irregular graph-structured human pose onto a regular weave-like grid pose representation joint by joint, enabling layer-wise feature learning with GridConv operations. We provide two ways to implement SGT, including handcrafted and learnable designs. Surprisingly, both designs turn out to achieve promising results and the learnable one is better, demonstrating the great potential of this new lifting representation learning formulation. To improve the ability of GridConv to encode contextual cues, we introduce an attention module over the convolutional kernel, making grid convolution operations input-dependent, spatial-aware and grid-specific. We show that our fully convolutional grid lifting network outperforms state-of-the-art methods with noticeable margins under (1) conventional evaluation on Human3.6M and (2) cross-evaluation on MPI-INF-3DHP. Code is available at https://github.com/OSVAI/GridConv},
  journal = {arXiv preprint arXiv:2302.08760},
  year = {2023},
  month = {02},
  eprint = {2302.08760},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  categories = {cs.CV cs.AI cs.LG},
  comment = {Oral paper at AAAI 2023. Project website: https://github.com/OSVAI/GridConv},
  updated = {2023-02-17T08:52:16Z},
  published = {2023-02-17T08:52:16Z},
  url = {https://arxiv.org/abs/2302.08760v1},
  pdf = {https://arxiv.org/pdf/2302.08760v1},
}

@article{arXiv:1910.10398,
  title = {Random 2.5D U-net for Fully 3D Segmentation},
  author = {Christoph Angermann and Markus Haltmeier},
  abstract = {Convolutional neural networks are state-of-the-art for various segmentation tasks. While for 2D images these networks are also computationally efficient, 3D convolutions have huge storage requirements and therefore, end-to-end training is limited by GPU memory and data size. To overcome this issue, we introduce a network structure for volumetric data without 3D convolution layers. The main idea is to include projections from different directions to transform the volumetric data to a sequence of images, where each image contains information of the full data. We then apply 2D convolutions to these projection images and lift them again to volumetric data using a trainable reconstruction algorithm. The proposed architecture can be applied end-to-end to very large data volumes without cropping or sliding-window techniques. For a tested sparse binary segmentation task, it outperforms already known standard approaches and is more resistant to generation of artefacts.},
  journal = {arXiv preprint arXiv:1910.10398},
  year = {2019},
  month = {10},
  eprint = {1910.10398},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  categories = {cs.CV cs.LG eess.IV stat.ML},
  comment = {Submission for joint MICCAI-Workshops on Computing and Visualization for Intravascular Imaging and Computer Assisted Stenting (CVII-STENT) 2019},
  updated = {2019-10-23T08:02:09Z},
  published = {2019-10-23T08:02:09Z},
  url = {https://arxiv.org/abs/1910.10398v1},
  pdf = {https://arxiv.org/pdf/1910.10398v1},
  doi = {10.1007/978-3-030-33327-0\_19},
}

@article{arXiv:2505.04852,
  title = {PR2: Peephole Raw Pointer Rewriting with LLMs for Translating C to Safer Rust},
  author = {Yifei Gao and Chengpeng Wang and Pengxiang Huang and Xuwei Liu and Mingwei Zheng and Xiangyu Zhang},
  abstract = {There has been a growing interest in translating C code to Rust due to Rust's robust memory and thread safety guarantees. Tools such as C2RUST enable syntax-guided transpilation from C to semantically equivalent Rust code. However, the resulting Rust programs often rely heavily on unsafe constructs--particularly raw pointers--which undermines Rust's safety guarantees. This paper aims to improve the memory safety of Rust programs generated by C2RUST by eliminating raw pointers. Specifically, we propose a peephole raw pointer rewriting technique that lifts raw pointers in individual functions to appropriate Rust data structures. Technically, PR2 employs decision-tree-based prompting to guide the pointer lifting process. Additionally, it leverages code change analysis to guide the repair of errors introduced during rewriting, effectively addressing errors encountered during compilation and test case execution. We implement PR2 as a prototype and evaluate it using gpt-4o-mini on 28 real-world C projects. The results show that PR2 successfully eliminates 13.22\% of local raw pointers across these projects, significantly enhancing the safety of the translated Rust code. On average, PR2 completes the transformation of a project in 5.44 hours, at an average cost of \$1.46.},
  journal = {arXiv preprint arXiv:2505.04852},
  year = {2025},
  month = {05},
  eprint = {2505.04852},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE cs.AI cs.PL},
  updated = {2025-05-09T06:32:08Z},
  published = {2025-05-07T23:30:27Z},
  url = {https://arxiv.org/abs/2505.04852v2},
  pdf = {https://arxiv.org/pdf/2505.04852v2},
}

@article{arXiv:2509.24507,
  title = {SemGuard: Real-Time Semantic Evaluator for Correcting LLM-Generated Code},
  author = {Qinglin Wang and Zhihong Sun and Ruyun Wang and Tao Huang and Zhi Jin and Ge Li and Chen Lyu},
  abstract = {Large Language Models (LLMs) can translate natural language requirements into code, yet empirical analyses of representative models reveal that semantic errors-programs that compile but behave incorrectly-constitute the majority of observed faults (e.g., >60\% on DeepSeek-Coder-6.7B and QwenCoder-7B). Post-hoc repair pipelines detect such faults only after execution, incurring latency, relying on incomplete test suites, and often mis-localizing the defect. Since semantic drift originates in the autoregressive decoding process, intervening while the code is being generated is a direct way to stop error propagation. Constrained-decoding approaches such as ROCODE attempt this, but still wait until the entire program runs to obtain feedback and use entropy heuristics that do not truly capture semantics. A more effective solution must inject semantic signals-early and precisely-into the decoding process.We present SemGuard, a semantic-evaluator-driven framework that performs real-time, line-level semantic supervision. To train the evaluator, we build SemDiff, the first dataset with fine-grained annotations that mark the exact line where a correct and an incorrect implementation diverge. The evaluator, once embedded in the LLM's decoder, flags deviations on partial code, rolls back to the faulty line, and guides regeneration-without executing the program or requiring test cases. Across four benchmarks, SemGuard consistently outperforms state-of-the-art baselines. It lowers the semantic error rate by 19.86\% on SemDiff relative to ROCODE, and lifts Pass@1 by 48.92\% on the real-world LiveCodeBench with CodeLlama-7B. Similar gains hold for StarCoder2-7B on MBPP and for DeepSeekCoder-6.7B on the Java benchmark SemDiff-Java, demonstrating model- and language-agnostic effectiveness.},
  journal = {arXiv preprint arXiv:2509.24507},
  year = {2025},
  month = {09},
  eprint = {2509.24507},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE},
  comment = {Accepted by the 40th IEEE/ACM Automated Software Engineering Conference (ASE 2025)},
  updated = {2025-09-29T09:21:32Z},
  published = {2025-09-29T09:21:32Z},
  url = {https://arxiv.org/abs/2509.24507v1},
  pdf = {https://arxiv.org/pdf/2509.24507v1},
}

@article{arXiv:2103.05221,
  title = {Learning to Find Usages of Library Functions in Optimized Binaries},
  author = {Toufique Ahmed and Premkumar Devanbu and Anand Ashok Sawant},
  abstract = {Much software, whether beneficent or malevolent, is distributed only as binaries, sans source code. Absent source code, understanding binaries' behavior can be quite challenging, especially when compiled under higher levels of compiler optimization. These optimizations can transform comprehensible, "natural" source constructions into something entirely unrecognizable. Reverse engineering binaries, especially those suspected of being malevolent or guilty of intellectual property theft, are important and time-consuming tasks. There is a great deal of interest in tools to "decompile" binaries back into more natural source code to aid reverse engineering. Decompilation involves several desirable steps, including recreating source-language constructions, variable names, and perhaps even comments. One central step in creating binaries is optimizing function calls, using steps such as inlining. Recovering these (possibly inlined) function calls from optimized binaries is an essential task that most state-of-the-art decompiler tools try to do but do not perform very well. In this paper, we evaluate a supervised learning approach to the problem of recovering optimized function calls. We leverage open-source software and develop an automated labeling scheme to generate a reasonably large dataset of binaries labeled with actual function usages. We augment this large but limited labeled dataset with a pre-training step, which learns the decompiled code statistics from a much larger unlabeled dataset. Thus augmented, our learned labeling model can be combined with an existing decompilation tool, Ghidra, to achieve substantially improved performance in function call recovery, especially at higher levels of optimization.},
  journal = {arXiv preprint arXiv:2103.05221},
  year = {2021},
  month = {03},
  eprint = {2103.05221},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE},
  updated = {2021-09-17T01:34:54Z},
  published = {2021-03-09T04:48:03Z},
  url = {https://arxiv.org/abs/2103.05221v2},
  pdf = {https://arxiv.org/pdf/2103.05221v2},
  doi = {10.1109/TSE.2021.3106572},
  note = {Journal reference: Transactions on Software Engineering (2021)},
}

@article{arXiv:1802.07119,
  title = {TRLF: An Effective Semi-fragile Watermarking Method for Tamper Detection and Recovery based on LWT and FNN},
  author = {Behrouz Bolourian Haghighi and Amir Hossein Taherinia and Reza Monsefi},
  abstract = {This paper proposes a novel method for tamper detection and recovery using semi-fragile data hiding, based on Lifting Wavelet Transform (LWT) and Feed-Forward Neural Network (FNN). In TRLF, first, the host image is decomposed up to one level using LWT, and the Discrete Cosine Transform (DCT) is applied to each 2*2 blocks of diagonal details. Next, a random binary sequence is embedded in each block as the watermark by correlating \$DC\$ coefficients. In authentication stage, first, the watermarked image geometry is reconstructed by using Speeded Up Robust Features (SURF) algorithm and extract watermark bits by using FNN. Afterward, logical exclusive-or operation between original and extracted watermark is applied to detect tampered region. Eventually, in the recovery stage, tampered regions are recovered by image digest which is generated by inverse halftoning technique. The performance and efficiency of TRLF and its robustness against various geometric, non-geometric and hybrid attacks are reported. From the experimental results, it can be seen that TRLF is superior in terms of robustness and quality of the digest and watermarked image respectively, compared to the-state-of-the-art fragile and semi-fragile watermarking methods. In addition, imperceptibility has been improved by using different correlation steps as the gain factor for flat (smooth) and texture (rough) blocks.},
  journal = {arXiv preprint arXiv:1802.07119},
  year = {2018},
  month = {02},
  eprint = {1802.07119},
  archivePrefix = {arXiv},
  primaryClass = {cs.CR},
  categories = {cs.CR cs.MM},
  updated = {2018-02-18T18:36:35Z},
  published = {2018-02-18T18:36:35Z},
  url = {https://arxiv.org/abs/1802.07119v1},
  pdf = {https://arxiv.org/pdf/1802.07119v1},
}

@article{arXiv:2212.09239,
  title = {On Non-Interactive Source Simulation via Fourier Transform},
  author = {Farhad Shirani and Mohsen Heidari},
  abstract = {The non-interactive source simulation (NISS) scenario is considered. In this scenario, a pair of distributed agents, Alice and Bob, observe a distributed binary memoryless source \$(X\textasciicircum{}d,Y\textasciicircum{}d)\$ generated based on joint distribution \$P\_\{X,Y\}\$. The agents wish to produce a pair of discrete random variables \$(U\_d,V\_d)\$ with joint distribution \$P\_\{U\_d,V\_d\}\$, such that \$P\_\{U\_d,V\_d\}\$ converges in total variation distance to a target distribution \$Q\_\{U,V\}\$ as the input blocklength \$d\$ is taken to be asymptotically large. Inner and outer bounds are obtained on the set of distributions \$Q\_\{U,V\}\$ which can be produced given an input distribution \$P\_\{X,Y\}\$. To this end, a bijective mapping from the set of distributions \$Q\_\{U,V\}\$ to a union of star-convex sets is provided. By leveraging proof techniques from discrete Fourier analysis along with a novel randomized rounding technique, inner and outer bounds are derived for each of these star-convex sets, and by inverting the aforementioned bijective mapping, necessary and sufficient conditions on \$Q\_\{U,V\}\$ and \$P\_\{X,Y\}\$ are provided under which \$Q\_\{U,V\}\$ can be produced from \$P\_\{X,Y\}\$. The bounds are applicable in NISS scenarios where the output alphabets \$\\mathcal\{U\}\$ and \$\\mathcal\{V\}\$ have arbitrary finite size. In case of binary output alphabets, the outer-bound recovers the previously best-known outer-bound.},
  journal = {arXiv preprint arXiv:2212.09239},
  year = {2022},
  month = {12},
  eprint = {2212.09239},
  archivePrefix = {arXiv},
  primaryClass = {cs.IT},
  categories = {cs.IT cs.CR eess.SY math.PR},
  updated = {2022-12-19T04:25:49Z},
  published = {2022-12-19T04:25:49Z},
  url = {https://arxiv.org/abs/2212.09239v1},
  pdf = {https://arxiv.org/pdf/2212.09239v1},
}

@article{arXiv:2308.04838,
  title = {No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT},
  author = {Zhijie Liu and Yutian Tang and Xiapu Luo and Yuming Zhou and Liang Feng Zhang},
  abstract = {Large language models (LLMs) have demonstrated impressive capabilities across various NLP tasks. Additionally, LLMs are also highly valuable in supporting software engineering tasks, particularly in the field of code generation. Automatic code generation is a process of automatically generating source code or executable code based on given specifications or requirements, improving developer productivity. In this study, we perform a systematic empirical assessment to the quality of code generation using ChatGPT. We leverage 728 algorithm problems in five languages (i.e., C, C++, Java, Python, and JavaScript) and 18 CWEs with 54 code scenarios for the code generation task. Our evaluation encompasses a comprehensive analysis of code snippets generated by ChatGPT, focusing on three critical aspects: correctness, complexity, and security. We also specifically investigate ChatGPT's ability to engage in multi-round fixing process (i.e., ChatGPT's dialog ability) of facilitating code generation. By delving into the generated code and examining the experimental results, this work provides valuable insights into the performance of ChatGPT in tackling code generation tasks over the three critical aspects. Overall, our findings uncover potential issues and limitations that arise in the ChatGPT-based code generation and lay the groundwork for improving AI and LLM-based code generation techniques.},
  journal = {arXiv preprint arXiv:2308.04838},
  year = {2023},
  month = {08},
  eprint = {2308.04838},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE},
  updated = {2024-04-13T04:58:47Z},
  published = {2023-08-09T10:01:09Z},
  url = {https://arxiv.org/abs/2308.04838v2},
  pdf = {https://arxiv.org/pdf/2308.04838v2},
}

@article{arXiv:2503.23748,
  title = {THEMIS: Towards Practical Intellectual Property Protection for Post-Deployment On-Device Deep Learning Models},
  author = {Yujin Huang and Zhi Zhang and Qingchuan Zhao and Xingliang Yuan and Chunyang Chen},
  abstract = {On-device deep learning (DL) has rapidly gained adoption in mobile apps, offering the benefits of offline model inference and user privacy preservation over cloud-based approaches. However, it inevitably stores models on user devices, introducing new vulnerabilities, particularly model-stealing attacks and intellectual property infringement. While system-level protections like Trusted Execution Environments (TEEs) provide a robust solution, practical challenges remain in achieving scalable on-device DL model protection, including complexities in supporting third-party models and limited adoption in current mobile solutions. Advancements in TEE-enabled hardware, such as NVIDIA's GPU-based TEEs, may address these obstacles in the future. Currently, watermarking serves as a common defense against model theft but also faces challenges here as many mobile app developers lack corresponding machine learning expertise and the inherent read-only and inference-only nature of on-device DL models prevents third parties like app stores from implementing existing watermarking techniques in post-deployment models. To protect the intellectual property of on-device DL models, in this paper, we propose THEMIS, an automatic tool that lifts the read-only restriction of on-device DL models by reconstructing their writable counterparts and leverages the untrainable nature of on-device DL models to solve watermark parameters and protect the model owner's intellectual property. Extensive experimental results across various datasets and model structures show the superiority of THEMIS in terms of different metrics. Further, an empirical investigation of 403 real-world DL mobile apps from Google Play is performed with a success rate of 81.14\%, showing the practicality of THEMIS.},
  journal = {arXiv preprint arXiv:2503.23748},
  year = {2025},
  month = {03},
  eprint = {2503.23748},
  archivePrefix = {arXiv},
  primaryClass = {cs.CR},
  categories = {cs.CR cs.LG cs.SE},
  comment = {To Appear in the 34th USENIX Security Symposium, August 13-15, 2025},
  updated = {2025-03-31T05:58:57Z},
  published = {2025-03-31T05:58:57Z},
  url = {https://arxiv.org/abs/2503.23748v1},
  pdf = {https://arxiv.org/pdf/2503.23748v1},
}

@article{arXiv:2404.16041,
  title = {Forklift: An Extensible Neural Lifter},
  author = {Jordi Armengol-Estapé and Rodrigo C. O. Rocha and Jackson Woodruff and Pasquale Minervini and Michael F. P. O'Boyle},
  abstract = {The escalating demand to migrate legacy software across different Instruction Set Architectures (ISAs) has driven the development of assembly-to-assembly translators to map between their respective assembly languages. However, the development of these tools requires substantial engineering effort. State-of-the-art approaches use lifting, a technique where source assembly code is translated to an architecture-independent intermediate representation (IR) (for example, the LLVM IR) and use a pre-existing compiler to recompile the IR to the target ISA. However, the hand-written rules these lifters employ are sensitive to the particular compiler and optimization level used to generate the code and require significant engineering effort to support each new ISA. We propose Forklift, the first neural lifter that learns how to translate assembly to LLVM IR using a token-level encoder-decoder Transformer. We show how to incrementally add support to new ISAs by fine tuning the assembly encoder and freezing the IR decoder, improving the overall accuracy and efficiency. We collect millions of parallel LLVM IR, x86, ARM, and RISC-V programs across compilers and optimization levels to train Forklift and set up an input/output-based accuracy harness. We evaluate Forklift on two challenging benchmark suites and translate 2.5x more x86 programs than a state-of-the-art hand-written lifter and 4.4x more x86 programs than GPT-4 as well as enabling translation from new ISAs.},
  journal = {arXiv preprint arXiv:2404.16041},
  year = {2024},
  month = {04},
  eprint = {2404.16041},
  archivePrefix = {arXiv},
  primaryClass = {cs.PL},
  categories = {cs.PL cs.AI cs.LG},
  updated = {2024-04-01T17:27:58Z},
  published = {2024-04-01T17:27:58Z},
  url = {https://arxiv.org/abs/2404.16041v1},
  pdf = {https://arxiv.org/pdf/2404.16041v1},
}

@article{arXiv:2409.17115,
  title = {Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale},
  author = {Fan Zhou and Zengzhi Wang and Qian Liu and Junlong Li and Pengfei Liu},
  abstract = {Large language model pre-training has traditionally relied on human experts to craft heuristics for improving the corpora quality, resulting in numerous rules developed to date. However, these rules lack the flexibility to address the unique characteristics of individual example effectively. Meanwhile, applying tailored rules to every example is impractical for human experts. In this paper, we demonstrate that even small language models, with as few as 0.3B parameters, can exhibit substantial data refining capabilities comparable to those of human experts. We introduce Programming Every Example (ProX), a novel framework that treats data refinement as a programming task, enabling models to refine corpora by generating and executing fine-grained operations, such as string normalization, for each individual example at scale. Experimental results show that models pre-trained on ProX-curated data outperform either original data or data filtered by other selection methods by more than 2\% across various downstream benchmarks. Its effectiveness spans various model sizes and pre-training corpora, including C4, RedPajama-V2, FineWeb, FineWeb-Edu, and DCLM. Furthermore, ProX exhibits significant potential in domain-specific continual pre-training: without domain specific design, models trained on OpenWebMath refined by ProX outperform human-crafted rule-based methods, improving average accuracy by 7.6\% over Mistral-7B, with 14.6\% for Llama-2-7B and 20.3\% for CodeLlama-7B, all within 10B tokens to be comparable to models like Llemma-7B trained on 200B tokens. Further analysis highlights that ProX significantly saves training FLOPs, offering a promising path for efficient LLM pre-training. We are open-sourcing ProX with >500B corpus, models, and sharing all training and implementation details for reproducible research and future innovation. Code: https://github.com/GAIR-NLP/ProX},
  journal = {arXiv preprint arXiv:2409.17115},
  year = {2024},
  month = {09},
  eprint = {2409.17115},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  categories = {cs.CL cs.AI cs.LG},
  comment = {47 pages, 13 figures, 34 tables},
  updated = {2025-02-14T16:44:08Z},
  published = {2024-09-25T17:28:13Z},
  url = {https://arxiv.org/abs/2409.17115v2},
  pdf = {https://arxiv.org/pdf/2409.17115v2},
}

@article{arXiv:2406.10529,
  title = {A Theory of Interpretable Approximations},
  author = {Marco Bressan and Nicolò Cesa-Bianchi and Emmanuel Esposito and Yishay Mansour and Shay Moran and Maximilian Thiessen},
  abstract = {Can a deep neural network be approximated by a small decision tree based on simple features? This question and its variants are behind the growing demand for machine learning models that are *interpretable* by humans. In this work we study such questions by introducing *interpretable approximations*, a notion that captures the idea of approximating a target concept \$c\$ by a small aggregation of concepts from some base class \$\\mathcal\{H\}\$. In particular, we consider the approximation of a binary concept \$c\$ by decision trees based on a simple class \$\\mathcal\{H\}\$ (e.g., of bounded VC dimension), and use the tree depth as a measure of complexity. Our primary contribution is the following remarkable trichotomy. For any given pair of \$\\mathcal\{H\}\$ and \$c\$, exactly one of these cases holds: (i) \$c\$ cannot be approximated by \$\\mathcal\{H\}\$ with arbitrary accuracy; (ii) \$c\$ can be approximated by \$\\mathcal\{H\}\$ with arbitrary accuracy, but there exists no universal rate that bounds the complexity of the approximations as a function of the accuracy; or (iii) there exists a constant \$κ\$ that depends only on \$\\mathcal\{H\}\$ and \$c\$ such that, for *any* data distribution and *any* desired accuracy level, \$c\$ can be approximated by \$\\mathcal\{H\}\$ with a complexity not exceeding \$κ\$. This taxonomy stands in stark contrast to the landscape of supervised classification, which offers a complex array of distribution-free and universally learnable scenarios. We show that, in the case of interpretable approximations, even a slightly nontrivial a-priori guarantee on the complexity of approximations implies approximations with constant (distribution-free and accuracy-free) complexity. We extend our trichotomy to classes \$\\mathcal\{H\}\$ of unbounded VC dimension and give characterizations of interpretability based on the algebra generated by \$\\mathcal\{H\}\$.},
  journal = {arXiv preprint arXiv:2406.10529},
  year = {2024},
  month = {06},
  eprint = {2406.10529},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  categories = {cs.LG cs.AI stat.ML},
  comment = {To appear at COLT 2024},
  updated = {2024-06-15T06:43:45Z},
  published = {2024-06-15T06:43:45Z},
  url = {https://arxiv.org/abs/2406.10529v1},
  pdf = {https://arxiv.org/pdf/2406.10529v1},
}

@article{arXiv:2505.21577,
  title = {RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving},
  author = {Huacan Wang and Ziyi Ni and Shuo Zhang and Shuo Lu and Sen Hu and Ziyang He and Chen Hu and Jiaye Lin and Yifu Guo and Ronghao Chen and Xin Li and Daxin Jiang and Yuntao Du and Pin Lyu},
  abstract = {The ultimate goal of code agents is to solve complex tasks autonomously. Although large language models (LLMs) have made substantial progress in code generation, real-world tasks typically demand full-fledged code repositories rather than simple scripts. Building such repositories from scratch remains a major challenge. Fortunately, GitHub hosts a vast, evolving collection of open-source repositories, which developers frequently reuse as modular components for complex tasks. Yet, existing frameworks like OpenHands and SWE-Agent still struggle to effectively leverage these valuable resources. Relying solely on README files provides insufficient guidance, and deeper exploration reveals two core obstacles: overwhelming information and tangled dependencies of repositories, both constrained by the limited context windows of current LLMs. To tackle these issues, we propose RepoMaster, an autonomous agent framework designed to explore and reuse GitHub repositories for solving complex tasks. For efficient understanding, RepoMaster constructs function-call graphs, module-dependency graphs, and hierarchical code trees to identify essential components, providing only identified core elements to the LLMs rather than the entire repository. During autonomous execution, it progressively explores related components using our exploration tools and prunes information to optimize context usage. Evaluated on the adjusted MLE-bench, RepoMaster achieves a 110\% relative boost in valid submissions over the strongest baseline OpenHands. On our newly released GitTaskBench, RepoMaster lifts the task-pass rate from 40.7\% to 62.9\% while reducing token usage by 95\%. Our code and demonstration materials are publicly available at https://github.com/QuantaAlpha/RepoMaster.},
  journal = {arXiv preprint arXiv:2505.21577},
  year = {2025},
  month = {05},
  eprint = {2505.21577},
  archivePrefix = {arXiv},
  primaryClass = {cs.SE},
  categories = {cs.SE cs.AI},
  comment = {A novel approach; Very practical},
  updated = {2025-08-25T13:40:36Z},
  published = {2025-05-27T08:35:05Z},
  url = {https://arxiv.org/abs/2505.21577v3},
  pdf = {https://arxiv.org/pdf/2505.21577v3},
}

@article{arXiv:1901.06540,
  title = {A Pre-Expectation Calculus for Probabilistic Sensitivity},
  author = {Alejandro Aguirre and Gilles Barthe and Justin Hsu and Benjamin Lucien Kaminski and Joost-Pieter Katoen and Christoph Matheja},
  abstract = {Sensitivity properties describe how changes to the input of a program affect the output, typically by upper bounding the distance between the outputs of two runs by a monotone function of the distance between the corresponding inputs. When programs are probabilistic, the distance between outputs is a distance between distributions. The Kantorovich lifting provides a general way of defining a distance between distributions by lifting the distance of the underlying sample space; by choosing an appropriate distance on the base space, one can recover other usual probabilistic distances, such as the Total Variation distance. We develop a relational pre-expectation calculus to upper bound the Kantorovich distance between two executions of a probabilistic program. We illustrate our methods by proving algorithmic stability of a machine learning algorithm, convergence of a reinforcement learning algorithm, and fast mixing for card shuffling algorithms. We also consider some extensions: proving lower bounds on the Total Variation distance and convergence to the uniform distribution. Finally, we describe an asynchronous extension of our calculus to reason about pairs of program executions with different control flow.},
  journal = {arXiv preprint arXiv:1901.06540},
  year = {2019},
  month = {01},
  eprint = {1901.06540},
  archivePrefix = {arXiv},
  primaryClass = {cs.LO},
  categories = {cs.LO cs.PL},
  comment = {Major revision},
  updated = {2020-08-10T07:57:37Z},
  published = {2019-01-19T15:23:19Z},
  url = {https://arxiv.org/abs/1901.06540v2},
  pdf = {https://arxiv.org/pdf/1901.06540v2},
}

@article{arXiv:1907.12475,
  title = {Energy-Efficient Processing and Robust Wireless Cooperative Transmission for Edge Inference},
  author = {Kai Yang and Yuanming Shi and Wei Yu and Zhi Ding},
  abstract = {Edge machine learning can deliver low-latency and private artificial intelligent (AI) services for mobile devices by leveraging computation and storage resources at the network edge. This paper presents an energy-efficient edge processing framework to execute deep learning inference tasks at the edge computing nodes whose wireless connections to mobile devices are prone to channel uncertainties. Aimed at minimizing the sum of computation and transmission power consumption with probabilistic quality-of-service (QoS) constraints, we formulate a joint inference tasking and downlink beamforming problem that is characterized by a group sparse objective function. We provide a statistical learning based robust optimization approach to approximate the highly intractable probabilistic-QoS constraints by nonconvex quadratic constraints, which are further reformulated as matrix inequalities with a rank-one constraint via matrix lifting. We design a reweighted power minimization approach by iteratively reweighted \$\\ell\_1\$ minimization with difference-of-convex-functions (DC) regularization and updating weights, where the reweighted approach is adopted for enhancing group sparsity whereas the DC regularization is designed for inducing rank-one solutions. Numerical results demonstrate that the proposed approach outperforms other state-of-the-art approaches.},
  journal = {arXiv preprint arXiv:1907.12475},
  year = {2019},
  month = {07},
  eprint = {1907.12475},
  archivePrefix = {arXiv},
  primaryClass = {cs.IT},
  categories = {cs.IT cs.LG eess.SP},
  comment = {This paper has been accepted by IEEE Internet of Things Journal},
  updated = {2020-03-02T09:19:35Z},
  published = {2019-07-29T15:24:58Z},
  url = {https://arxiv.org/abs/1907.12475v2},
  pdf = {https://arxiv.org/pdf/1907.12475v2},
}

@article{arXiv:2203.11386,
  title = {Optimizing Binary Decision Diagrams with MaxSAT for classification},
  author = {Hao Hu and Marie-José Huguet and Mohamed Siala},
  abstract = {The growing interest in explainable artificial intelligence (XAI) for critical decision making motivates the need for interpretable machine learning (ML) models. In fact, due to their structure (especially with small sizes), these models are inherently understandable by humans. Recently, several exact methods for computing such models are proposed to overcome weaknesses of traditional heuristic methods by providing more compact models or better prediction quality. Despite their compressed representation of Boolean functions, Binary decision diagrams (BDDs) did not gain enough interest as other interpretable ML models. In this paper, we first propose SAT-based models for learning optimal BDDs (in terms of the number of features) that classify all input examples. Then, we lift the encoding to a MaxSAT model to learn optimal BDDs in limited depths, that maximize the number of examples correctly classified. Finally, we tackle the fragmentation problem by introducing a method to merge compatible subtrees for the BDDs found via the MaxSAT model. Our empirical study shows clear benefits of the proposed approach in terms of prediction quality and intrepretability (i.e., lighter size) compared to the state-of-the-art approaches.},
  journal = {arXiv preprint arXiv:2203.11386},
  year = {2022},
  month = {03},
  eprint = {2203.11386},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  categories = {cs.AI cs.LG},
  comment = {This is the preprint version of the paper accepted in AAAI'22},
  updated = {2022-03-21T23:17:37Z},
  published = {2022-03-21T23:17:37Z},
  url = {https://arxiv.org/abs/2203.11386v1},
  pdf = {https://arxiv.org/pdf/2203.11386v1},
}

@article{arXiv:2403.01907,
  title = {Capacity of the Hebbian-Hopfield network associative memory},
  author = {Mihailo Stojnic},
  abstract = {In \\cite\{Hop82\}, Hopfield introduced a \\emph\{Hebbian\} learning rule based neural network model and suggested how it can efficiently operate as an associative memory. Studying random binary patterns, he also uncovered that, if a small fraction of errors is tolerated in the stored patterns retrieval, the capacity of the network (maximal number of memorized patterns, \$m\$) scales linearly with each pattern's size, \$n\$. Moreover, he famously predicted \$α\_c=\\lim\_\{n\\rightarrow\\infty\}\\frac\{m\}\{n\}\\approx 0.14\$. We study this very same scenario with two famous pattern's basins of attraction: \\textbf\{\\emph\{(i)\}\} The AGS one from \\cite\{AmiGutSom85\}; and \\textbf\{\\emph\{(ii)\}\} The NLT one from \\cite\{Newman88,Louk94,Louk94a,Louk97,Tal98\}. Relying on the \\emph\{fully lifted random duality theory\} (fl RDT) from \\cite\{Stojnicflrdt23\}, we obtain the following explicit capacity characterizations on the first level of lifting: \\begin\{equation\} α\_c\textasciicircum{}\{(AGS,1)\} = \\left ( \\max\_\{δ\\in \\left ( 0,\\frac\{1\}\{2\}\\right ) \}\\frac\{1-2δ\}\{\\sqrt\{2\} \\mbox\{erfinv\} \\left ( 1-2δ\\right )\} - \\frac\{2\}\{\\sqrt\{2π\}\} e\textasciicircum{}\{-\\left ( \\mbox\{erfinv\}\\left ( 1-2δ\\right )\\right )\textasciicircum{}2\}\\right )\textasciicircum{}2 \\approx \\mathbf\{0.137906\} \\end\{equation\} \\begin\{equation\} α\_c\textasciicircum{}\{(NLT,1)\} = \\frac\{\\mbox\{erf\}(x)\textasciicircum{}2\}\{2x\textasciicircum{}2\}-1+\\mbox\{erf\}(x)\textasciicircum{}2 \\approx \\mathbf\{0.129490\}, \\quad 1-\\mbox\{erf\}(x)\textasciicircum{}2- \\frac\{2\\mbox\{erf\}(x)e\textasciicircum{}\{-x\textasciicircum{}2\}\}\{\\sqrtπx\}+\\frac\{2e\textasciicircum{}\{-2x\textasciicircum{}2\}\}π=0. \\end\{equation\} A substantial numerical work gives on the second level of lifting \$α\_c\textasciicircum{}\{(AGS,2)\} \\approx \\mathbf\{0.138186\}\$ and \$α\_c\textasciicircum{}\{(NLT,2)\} \\approx \\mathbf\{0.12979\}\$, effectively uncovering a remarkably fast lifting convergence. Moreover, the obtained AGS characterizations exactly match the replica symmetry based ones of \\cite\{AmiGutSom85\} and the corresponding symmetry breaking ones of \\cite\{SteKuh94\}.},
  journal = {arXiv preprint arXiv:2403.01907},
  year = {2024},
  month = {03},
  eprint = {2403.01907},
  archivePrefix = {arXiv},
  primaryClass = {stat.ML},
  categories = {stat.ML cond-mat.dis-nn cs.IT cs.LG math.PR},
  updated = {2024-03-04T10:10:23Z},
  published = {2024-03-04T10:10:23Z},
  url = {https://arxiv.org/abs/2403.01907v1},
  pdf = {https://arxiv.org/pdf/2403.01907v1},
}

@article{arXiv:2006.04847,
  title = {Procrustean Orthogonal Sparse Hashing},
  author = {Mariano Tepper and Dipanjan Sengupta and Ted Willke},
  abstract = {Hashing is one of the most popular methods for similarity search because of its speed and efficiency. Dense binary hashing is prevalent in the literature. Recently, insect olfaction was shown to be structurally and functionally analogous to sparse hashing [6]. Here, we prove that this biological mechanism is the solution to a well-posed optimization problem. Furthermore, we show that orthogonality increases the accuracy of sparse hashing. Next, we present a novel method, Procrustean Orthogonal Sparse Hashing (POSH), that unifies these findings, learning an orthogonal transform from training data compatible with the sparse hashing mechanism. We provide theoretical evidence of the shortcomings of Optimal Sparse Lifting (OSL) [22] and BioHash [30], two related olfaction-inspired methods, and propose two new methods, Binary OSL and SphericalHash, to address these deficiencies. We compare POSH, Binary OSL, and SphericalHash to several state-of-the-art hashing methods and provide empirical results for the superiority of the proposed methods across a wide range of standard benchmarks and parameter settings.},
  journal = {arXiv preprint arXiv:2006.04847},
  year = {2020},
  month = {06},
  eprint = {2006.04847},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  categories = {cs.LG stat.ML},
  updated = {2020-06-08T18:09:33Z},
  published = {2020-06-08T18:09:33Z},
  url = {https://arxiv.org/abs/2006.04847v1},
  pdf = {https://arxiv.org/pdf/2006.04847v1},
}

@article{arXiv:2404.18098,
  title = {Parameterized Dynamic Logic -- Towards A Cyclic Logical Framework for General Program Specification and Verification},
  author = {Yuanrui Zhang},
  abstract = {We present a theory of parameterized dynamic logic, namely DLp, for specifying and reasoning about a rich set of program models based on their transitional behaviours. Different from most dynamic logics that deal with regular expressions or a particular type of formalisms, DLp introduces a type of labels called "program configurations" as explicit program status for symbolic executions, allowing programs and formulas to be of arbitrary forms according to interested domains. This characteristic empowers dynamic logical formulas with a direct support of symbolic-execution-based reasoning, while still maintaining reasoning based on syntactic structures in traditional dynamic logics through a rule-lifting process. We propose a proof system and build a cyclic preproof structure special for DLp, which guarantees the soundness of infinite proof trees induced by symbolically executing programs with explicit/implicit loop structures. The soundness of DLp is formally analyzed and proved. DLp provides a flexible verification framework based on the theories of dynamic logics. It helps reduce the burden of developing different dynamic-logic theories for different programs, and save the additional transformations in the derivations of non-compositional programs. We give some examples of instantiations of DLp in particular domains, showing the potential and advantages of using DLp in practical usage.},
  journal = {arXiv preprint arXiv:2404.18098},
  year = {2024},
  month = {04},
  eprint = {2404.18098},
  archivePrefix = {arXiv},
  primaryClass = {cs.LO},
  categories = {cs.LO cs.SE},
  comment = {Major revisions from last comments: 1. fix the whole proof system of DLp and its related proofs; 2. add additional two examples for illustrations of lifting processes and an implication of a more complex configuration; 3. further revise the introduction part to adapt these changes; 4. add a formal definition of while programs in the logic},
  updated = {2025-01-29T18:43:16Z},
  published = {2024-04-28T07:08:44Z},
  url = {https://arxiv.org/abs/2404.18098v4},
  pdf = {https://arxiv.org/pdf/2404.18098v4},
}

@article{arXiv:2310.02295,
  title = {Unsupervised Complex Semi-Binary Matrix Factorization for Activation Sequence Recovery of Quasi-Stationary Sources},
  author = {Romain Delabeye and Martin Ghienne and Olivia Penas and Jean-Luc Dion},
  abstract = {Advocating for a sustainable, resilient and human-centric industry, the three pillars of Industry 5.0 call for an increased understanding of industrial processes and manufacturing systems, as well as their energy sustainability. One of the most fundamental elements of comprehension is knowing when the systems are operated, as this is key to locating energy intensive subsystems and operations. Such knowledge is often lacking in practice. Activation statuses can be recovered from sensor data though. Some non-intrusive sensors (accelerometers, current sensors, etc.) acquire mixed signals containing information about multiple actuators at once. Despite their low cost as regards the fleet of systems they monitor, additional signal processing is required to extract the individual activation sequences. To that end, sparse regression techniques can extract leading dynamics in sequential data. Notorious dictionary learning algorithms have proven effective in this regard. This paper considers different industrial settings in which the identification of binary subsystem activation sequences is sought. In this context, it is assumed that each sensor measures an extensive physical property, source signals are periodic, quasi-stationary and independent, albeit these signals may be correlated and their noise distribution is arbitrary. Existing methods either restrict these assumptions, e.g., by imposing orthogonality or noise characteristics, or lift them using additional assumptions, typically using nonlinear transforms.},
  journal = {arXiv preprint arXiv:2310.02295},
  year = {2023},
  month = {10},
  eprint = {2310.02295},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  categories = {cs.LG eess.SP},
  updated = {2023-10-03T09:29:16Z},
  published = {2023-10-03T09:29:16Z},
  url = {https://arxiv.org/abs/2310.02295v1},
  pdf = {https://arxiv.org/pdf/2310.02295v1},
  author_affiliations = {Romain Delabeye: QUARTZ, ISAE-Supméca; Martin Ghienne: QUARTZ, ISAE-Supméca; Olivia Penas: QUARTZ, ISAE-Supméca; Jean-Luc Dion: QUARTZ, ISAE-Supméca},
}

@article{arXiv:2507.11676,
  title = {Quantum Circuits Are Just a Phase},
  author = {Chris Heunen and Louis Lemonnier and Christopher McNally and Alex Rice},
  abstract = {Quantum programs today are written at a low level of abstraction - quantum circuits akin to assembly languages - and the unitary parts of even advanced quantum programming languages essentially function as circuit description languages. This state of affairs impedes scalability, clarity, and support for higher-level reasoning. More abstract and expressive quantum programming constructs are needed. To this end, we introduce a simple syntax for generating unitaries from "just a phase"; we combine a (global) phase operation that captures phase shifts with a quantum analogue of the "if let" construct that captures subspace selection via pattern matching. This minimal language lifts the focus from gates to eigendecomposition, conjugation, and controlled unitaries; common building blocks in quantum algorithm design. We demonstrate several aspects of the expressive power of our language in several ways. Firstly, we establish that our representation is universal by deriving a universal quantum gate set. Secondly, we show that important quantum algorithms can be expressed naturally and concisely, including Grover's search algorithm, Hamiltonian simulation, Quantum Fourier Transform, Quantum Signal Processing, and the Quantum Eigenvalue Transformation. Furthermore, we give clean denotational semantics grounded in categorical quantum mechanics. Finally, we implement a prototype compiler that efficiently translates terms of our language to quantum circuits, and prove that it is sound with respect to these semantics. Collectively, these contributions show that this construct offers a principled and practical step toward more abstract and structured quantum programming.},
  journal = {arXiv preprint arXiv:2507.11676},
  year = {2025},
  month = {07},
  eprint = {2507.11676},
  archivePrefix = {arXiv},
  primaryClass = {cs.PL},
  categories = {cs.PL cs.LO quant-ph},
  comment = {42 pages, 5 figures},
  updated = {2025-12-01T16:26:39Z},
  published = {2025-07-15T19:31:53Z},
  url = {https://arxiv.org/abs/2507.11676v2},
  pdf = {https://arxiv.org/pdf/2507.11676v2},
  doi = {10.1145/3776731},
}

@article{arXiv:2601.05887,
  title = {Cybersecurity AI: A Game-Theoretic AI for Guiding Attack and Defense},
  author = {Víctor Mayoral-Vilches and María Sanz-Gómez and Francesco Balassone and Stefan Rass and Lidia Salas-Espejo and Benjamin Jablonski and Luis Javier Navarrete-Lozano and Maite del Mundo de Torres and Cristóbal R. J. Veas Chavez},
  abstract = {AI-driven penetration testing now executes thousands of actions per hour but still lacks the strategic intuition humans apply in competitive security. To build cybersecurity superintelligence --Cybersecurity AI exceeding best human capability-such strategic intuition must be embedded into agentic reasoning processes. We present Generative Cut-the-Rope (G-CTR), a game-theoretic guidance layer that extracts attack graphs from agent's context, computes Nash equilibria with effort-aware scoring, and feeds a concise digest back into the LLM loop \\emph\{guiding\} the agent's actions. Across five real-world exercises, G-CTR matches 70--90\% of expert graph structure while running 60--245x faster and over 140x cheaper than manual analysis. In a 44-run cyber-range, adding the digest lifts success from 20.0\% to 42.9\%, cuts cost-per-success by 2.7x, and reduces behavioral variance by 5.2x. In Attack-and-Defense exercises, a shared digest produces the Purple agent, winning roughly 2:1 over the LLM-only baseline and 3.7:1 over independently guided teams. This closed-loop guidance is what produces the breakthrough: it reduces ambiguity, collapses the LLM's search space, suppresses hallucinations, and keeps the model anchored to the most relevant parts of the problem, yielding large gains in success rate, consistency, and reliability.},
  journal = {arXiv preprint arXiv:2601.05887},
  year = {2026},
  month = {01},
  eprint = {2601.05887},
  archivePrefix = {arXiv},
  primaryClass = {cs.CR},
  categories = {cs.CR},
  updated = {2026-01-09T16:06:10Z},
  published = {2026-01-09T16:06:10Z},
  url = {https://arxiv.org/abs/2601.05887v1},
  pdf = {https://arxiv.org/pdf/2601.05887v1},
}

@article{arXiv:2512.06155,
  title = {Sift or Get Off the PoC: Applying Information Retrieval to Vulnerability Research with SiftRank},
  author = {Caleb Gross},
  abstract = {Security research is fundamentally a problem of resource constraint and consequent prioritization. There is simply too much attack surface and too little time and energy to spend analyzing it all. The most effective security researchers are often those who are most skilled at intuitively deciding which part of an expansive attack surface to investigate. We demonstrate that this problem of selecting the most promising option from among many possibilities can be reframed as an information retrieval problem, and solved using document ranking techniques with LLMs performing the heavy lifting as general-purpose rankers. We present SiftRank, a ranking algorithm achieving O(n) complexity through three key mechanisms: listwise ranking using an LLM to order documents in small batches of approximately 10 items at a time; inflection-based convergence detection that adaptively terminates ranking when score distributions have stabilized; and iterative refinement that progressively focuses ranking effort on the most relevant documents. Unlike existing reranking approaches that require a separate first-stage retrieval step to narrow datasets to approximately 100 candidates, SiftRank operates directly on thousands of items, with each document evaluated across multiple randomized batches to mitigate inconsistent judgments by an LLM. We demonstrate practical effectiveness on N-day vulnerability analysis, successfully identifying a vulnerability-fixing function among 2,197 changed functions in a stripped binary firmware patch within 99 seconds at an inference cost of \$0.82. Our approach enables scalable security prioritization for problems that are generally constrained by manual analysis, requiring only standard LLM API access without specialized infrastructure, embedding, or domain-specific fine-tuning. An open-source implementation of SiftRank may be found at https://github.com/noperator/siftrank.},
  journal = {arXiv preprint arXiv:2512.06155},
  year = {2025},
  month = {12},
  eprint = {2512.06155},
  archivePrefix = {arXiv},
  primaryClass = {cs.CR},
  categories = {cs.CR cs.IR},
  updated = {2025-12-05T21:09:32Z},
  published = {2025-12-05T21:09:32Z},
  url = {https://arxiv.org/abs/2512.06155v1},
  pdf = {https://arxiv.org/pdf/2512.06155v1},
}

@article{arXiv:2306.03542,
  title = {Masked Autoencoders are Efficient Continual Federated Learners},
  author = {Subarnaduti Paul and Lars-Joel Frey and Roshni Kamath and Kristian Kersting and Martin Mundt},
  abstract = {Machine learning is typically framed from a perspective of i.i.d., and more importantly, isolated data. In parts, federated learning lifts this assumption, as it sets out to solve the real-world challenge of collaboratively learning a shared model from data distributed across clients. However, motivated primarily by privacy and computational constraints, the fact that data may change, distributions drift, or even tasks advance individually on clients, is seldom taken into account. The field of continual learning addresses this separate challenge and first steps have recently been taken to leverage synergies in distributed supervised settings, in which several clients learn to solve changing classification tasks over time without forgetting previously seen ones. Motivated by these prior works, we posit that such federated continual learning should be grounded in unsupervised learning of representations that are shared across clients; in the loose spirit of how humans can indirectly leverage others' experience without exposure to a specific task. For this purpose, we demonstrate that masked autoencoders for distribution estimation are particularly amenable to this setup. Specifically, their masking strategy can be seamlessly integrated with task attention mechanisms to enable selective knowledge transfer between clients. We empirically corroborate the latter statement through several continual federated scenarios on both image and binary datasets.},
  journal = {arXiv preprint arXiv:2306.03542},
  year = {2023},
  month = {06},
  eprint = {2306.03542},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  categories = {cs.LG},
  updated = {2024-07-18T13:22:21Z},
  published = {2023-06-06T09:38:57Z},
  url = {https://arxiv.org/abs/2306.03542v2},
  pdf = {https://arxiv.org/pdf/2306.03542v2},
}

